unique_id	context	label	input_context	citance
CCT1	This article presents a regressive-iterative approach for reconstructing historical landscapes using a geographical information system (GIS). In historical research, regressive methods moving step-by-step back in time from a better known later situation were already applied by #CITATION_TAG (1883) or by Bloch (1931) for the reconstruction of medieval agrarian landscapes in France and have been used since then within historical research (e.g. Forschungsinitiative Umweltgeschichte 1999). The method presented here takes a similar approach. In this study, we integrated three types of evidence: (1) numerous historical sources, both textual and cartographic, (2) analysis of fluvial processes that were typical for the Austrian Danube before regulation, and (3) assessment of river engineering measures of the past with regard to their effectiveness and their impact on river behaviour. This approach constitutes a temporally regressive method (in the sense of Marc Bloch), but comprises iterative work steps to refine the results for more recent time situations.	5	This article presents a regressive-iterative approach for reconstructing historical landscapes using a geographical information system (GIS). In historical research, regressive methods moving step-by-step back in time from a better known later situation were already applied by #CITATION_TAG (1883) or by Bloch (1931) for the reconstruction of medieval agrarian landscapes in France and have been used since then within historical research (e.g. Forschungsinitiative Umweltgeschichte 1999). The method presented here takes a similar approach. In this study, we integrated three types of evidence: (1) numerous historical sources, both textual and cartographic, (2) analysis of fluvial processes that were typical for the Austrian Danube before regulation, and (3) assessment of river engineering measures of the past with regard to their effectiveness and their impact on river behaviour. This approach constitutes a temporally regressive method (in the sense of Marc Bloch), but comprises iterative work steps to refine the results for more recent time situations.	n
CCT2	"The increased threat posed by the Ottoman army and the second siege of Vienna in 1683 gave rise to numerous maps and views that illustrate acts of war. Most of them focus only on the historical city centre or show the riverscape in a generalised manner. The riverine structures were mostly copied from older drawings, which can be identified as sources. Hence, little information about the past configuration of the riverscape can be extracted from the great number of 17th/18th century maps and illustrations. The most important exception is a map designed by Colonel Giuseppe Baron Priami in 1663 for the improvement of Vienna""s fortifications. It can be considered as the first map of the Viennese riverscape, which is depicted in a geographically largely correct manner (Mohilla and Michlmayr 1996;Opll 2004). 9 Even more interesting are several river regulation plans that were drawn after the siege from 1686 onwards, in particular the famous work of the Italian cartographer Leander Anguissola from 1688 and a newly found map by Hoffmann von Anckherskron et al. dating from 1700. Compared to older plans and maps, both maps show large areas of the Viennese riverscape in a regular map projection. Problems remain: In Anguissola""s map, the differentiation between planned and existing hydraulic structures is not always clear and the map was modified at a later date to adapt it to the changed conditions of the riverscape. For example, a new cut-off channel at the Donaukanal excavated in 1700-1703 and bridges built in 1704 were later added, so it could serve as the basis for proposed hydraulic constructions in 1712 (#CITATION_TAG 1977). 11 The map from Hoffmann von Anckherskron et al. (1700) can be considered as the oldest Viennese river engineering map with a high degree of position accuracy and an outstanding level of detail. It was produced as a planning basis for the construction of a new course for the upper Donaukanal and so far it has never been described in the historical literature. It even shows minor relicts of past hydraulic structures below the low water level and several transects through the river arms. The map provides a sound reference for the localisation of hydraulic structures built in the late 17th century of which-until now-we only partly knew about from written sources."	0	"9 Even more interesting are several river regulation plans that were drawn after the siege from 1686 onwards, in particular the famous work of the Italian cartographer Leander Anguissola from 1688 and a newly found map by Hoffmann von Anckherskron et al. dating from 1700. Compared to older plans and maps, both maps show large areas of the Viennese riverscape in a regular map projection. Problems remain: In Anguissola""s map, the differentiation between planned and existing hydraulic structures is not always clear and the map was modified at a later date to adapt it to the changed conditions of the riverscape. For example, a new cut-off channel at the Donaukanal excavated in 1700-1703 and bridges built in 1704 were later added, so it could serve as the basis for proposed hydraulic constructions in 1712 (#CITATION_TAG 1977). 11 The map from Hoffmann von Anckherskron et al. (1700) can be considered as the oldest Viennese river engineering map with a high degree of position accuracy and an outstanding level of detail. It was produced as a planning basis for the construction of a new course for the upper Donaukanal and so far it has never been described in the historical literature. It even shows minor relicts of past hydraulic structures below the low water level and several transects through the river arms."	l
CCT3	"The increased threat posed by the Ottoman army and the second siege of Vienna in 1683 gave rise to numerous maps and views that illustrate acts of war. Most of them focus only on the historical city centre or show the riverscape in a generalised manner. The riverine structures were mostly copied from older drawings, which can be identified as sources. Hence, little information about the past configuration of the riverscape can be extracted from the great number of 17th/18th century maps and illustrations. The most important exception is a map designed by Colonel Giuseppe Baron Priami in 1663 for the improvement of Vienna""s fortifications. It can be considered as the first map of the Viennese riverscape, which is depicted in a geographically largely correct manner (Mohilla and Michlmayr 1996;#CITATION_TAG 2004). 9 Even more interesting are several river regulation plans that were drawn after the siege from 1686 onwards, in particular the famous work of the Italian cartographer Leander Anguissola from 1688 and a newly found map by Hoffmann von Anckherskron et al. dating from 1700. Compared to older plans and maps, both maps show large areas of the Viennese riverscape in a regular map projection. Problems remain: In Anguissola""s map, the differentiation between planned and existing hydraulic structures is not always clear and the map was modified at a later date to adapt it to the changed conditions of the riverscape. For example, a new cut-off channel at the Donaukanal excavated in 1700-1703 and bridges built in 1704 were later added, so it could serve as the basis for proposed hydraulic constructions in 1712 (Slezak 1977). 11 The map from Hoffmann von Anckherskron et al. (1700) can be considered as the oldest Viennese river engineering map with a high degree of position accuracy and an outstanding level of detail. It was produced as a planning basis for the construction of a new course for the upper Donaukanal and so far it has never been described in the historical literature. It even shows minor relicts of past hydraulic structures below the low water level and several transects through the river arms. The map provides a sound reference for the localisation of hydraulic structures built in the late 17th century of which-until now-we only partly knew about from written sources."	4	"The riverine structures were mostly copied from older drawings, which can be identified as sources. Hence, little information about the past configuration of the riverscape can be extracted from the great number of 17th/18th century maps and illustrations. The most important exception is a map designed by Colonel Giuseppe Baron Priami in 1663 for the improvement of Vienna""s fortifications. It can be considered as the first map of the Viennese riverscape, which is depicted in a geographically largely correct manner (Mohilla and Michlmayr 1996;#CITATION_TAG 2004). 9 Even more interesting are several river regulation plans that were drawn after the siege from 1686 onwards, in particular the famous work of the Italian cartographer Leander Anguissola from 1688 and a newly found map by Hoffmann von Anckherskron et al. dating from 1700. Compared to older plans and maps, both maps show large areas of the Viennese riverscape in a regular map projection. Problems remain: In Anguissola""s map, the differentiation between planned and existing hydraulic structures is not always clear and the map was modified at a later date to adapt it to the changed conditions of the riverscape."	n
CCT4	"The most important source is provided by Schmeltzl (1548), who documented the length of each bridge by counting the steps needed for crossing the bridge and the numbers of bridge pillars in 1547. He additionally noted the approximate distance between the outer and the inner main bridges. Bonifatius Wolmuet produced a map of the city of Vienna in the same year, for which he measured the length of the inner bridge (Schlagbr√ºcke). 22 alculating Schmeltzl""s mean step length based on Wolmuet""s bridge length allows the lengths of the main bridges in 1547 to be calculated (for more details on the history of the Viennese bridges see Sonnlechner et al. 2013, in this issue). Since bridge length refers to bankfull width of a channel, which in Vienna coincides approximately with the 1-year flood, it provides a good measure for the discharge capacity of river channels. According to the """"hydraulic geometry"""" approach introduced by #CITATION_TAG and Maddock (1953), channel forms respond to changes in the flow regime. Bridge lengths beyond the range of widths typical for the Austrian Danube point either to inaccuracies in the cartographic sources or to amplified morphological turnover due to short-term channel shiftings (as happened in Vienna around 1565)."	0	"Bonifatius Wolmuet produced a map of the city of Vienna in the same year, for which he measured the length of the inner bridge (Schlagbr√ºcke). 22 alculating Schmeltzl""s mean step length based on Wolmuet""s bridge length allows the lengths of the main bridges in 1547 to be calculated (for more details on the history of the Viennese bridges see Sonnlechner et al. 2013, in this issue). Since bridge length refers to bankfull width of a channel, which in Vienna coincides approximately with the 1-year flood, it provides a good measure for the discharge capacity of river channels. According to the """"hydraulic geometry"""" approach introduced by #CITATION_TAG and Maddock (1953), channel forms respond to changes in the flow regime. Bridge lengths beyond the range of widths typical for the Austrian Danube point either to inaccuracies in the cartographic sources or to amplified morphological turnover due to short-term channel shiftings (as happened in Vienna around 1565)."	d
CCT5	"The aim to """"reconstruct"""" the historical development of a river landscape true-to-life is a priori doomed to fail. The preserved information is too fragmentary; the available sources are too different in type and content. Some sources are more resistant to the reconstruction of past riverscapes than others. Historical sources (maps, plans, documents, etc.) were not created for use in a GIS, they were produced for particular reasons and thus always reflect how the riverscape was perceived. They reflect the interests and motives of their producers and recipients and are therefore only fragments of a historical state. The methodological quest is to determine which fragments can be useful for the reconstruction. The challenge is greater in a landscape that has undergone incessant change, as was the case with the historical Danube near Vienna. It has to be borne in mind that all historical relicts from the Danube""s history are sources for the changing perception of that river. Historians ask for the motivation and interests that were important in the making, using and keeping of their sources (#CITATION_TAG 1993). Approaching a source from an environmental history viewpoint means interpreting it both as an expression of changing biophysical relations to the environment and of changing cultural attitudes, ideas and ideals about nature. Interpreting it requires integrative methods including source critique. An interdisciplinary team""s different perspectives are helpful in this endeavour. So our project team included historians from the Centre for Environmental History Vienna (Alpen-Adria University Klagenfurt) and the Municipal and Provincial Archives of Vienna, and fluvial morphologists from the University of Natural Resources and Life Sciences Vienna (BOKU)."	0	"The methodological quest is to determine which fragments can be useful for the reconstruction. The challenge is greater in a landscape that has undergone incessant change, as was the case with the historical Danube near Vienna. It has to be borne in mind that all historical relicts from the Danube""s history are sources for the changing perception of that river. Historians ask for the motivation and interests that were important in the making, using and keeping of their sources (#CITATION_TAG 1993). Approaching a source from an environmental history viewpoint means interpreting it both as an expression of changing biophysical relations to the environment and of changing cultural attitudes, ideas and ideals about nature. Interpreting it requires integrative methods including source critique. An interdisciplinary team""s different perspectives are helpful in this endeavour."	n
CCT6	This article presents a regressive-iterative approach for reconstructing historical landscapes using a geographical information system (GIS). In historical research, regressive methods moving step-by-step back in time from a better known later situation were already applied by Seebohm (1883) or by #CITATION_TAG (1931) for the reconstruction of medieval agrarian landscapes in France and have been used since then within historical research (e.g. Forschungsinitiative Umweltgeschichte 1999). The method presented here takes a similar approach. In this study, we integrated three types of evidence: (1) numerous historical sources, both textual and cartographic, (2) analysis of fluvial processes that were typical for the Austrian Danube before regulation, and (3) assessment of river engineering measures of the past with regard to their effectiveness and their impact on river behaviour. This approach constitutes a temporally regressive method (in the sense of Marc Bloch), but comprises iterative work steps to refine the results for more recent time situations.	5	This article presents a regressive-iterative approach for reconstructing historical landscapes using a geographical information system (GIS). In historical research, regressive methods moving step-by-step back in time from a better known later situation were already applied by Seebohm (1883) or by #CITATION_TAG (1931) for the reconstruction of medieval agrarian landscapes in France and have been used since then within historical research (e.g. Forschungsinitiative Umweltgeschichte 1999). The method presented here takes a similar approach. In this study, we integrated three types of evidence: (1) numerous historical sources, both textual and cartographic, (2) analysis of fluvial processes that were typical for the Austrian Danube before regulation, and (3) assessment of river engineering measures of the past with regard to their effectiveness and their impact on river behaviour. This approach constitutes a temporally regressive method (in the sense of Marc Bloch), but comprises iterative work steps to refine the results for more recent time situations.	n
CCT7	Reconstructing riverscapes over decades or even centuries better approximates the former situations than the reconstruction of a single point in time. In recent years, GISbased studies of historical fluvial morphology were conducted over the long term to reveal the causes of past channel changes and floodplain degradation (Gurnell et al. 1994(Gurnell et al. , 2005Marston et al. 1995;Kiss et al. 2008). Some historical studies specifically focus on the spatial distribution of riverine habitats and the land cover of riverscapes. In Europe, such investigations were conducted on several French rivers (e.g. Girel et al. 1997;Kondolf et al. 2007), the current Slovak Danube (Pis√∫t 2002), the lower Rhine (Schoor et al. 1999;Wolfert 2001), the Dyje River, Czech Republic (Skokanova 2008) and on several English rivers (Lewin 2010). Outside Europe, comparable studies exist for e.g. the upper Mississippi (de Jager et al. 2011) and the Sacramento River, California (Greco et al. 2007). In ecology and environmental history alike, GIS techniques have often been deployed to reconstruct past land cover and land use changes based on historical maps such as cadastral maps. These include, amongst others, the Baltimore-Chesapeake region (#CITATION_TAG et al. 1997), the American Great Plains (Cunfer 2008), the Rocky Mountains (Aspinall 2004), Southern Germany (Bender et al. 2005;Schuppert and Dix 2009), the Tisza River in Hungary (Heged√ºs and Duray 2009) and several Austrian villages and rivers (Forschungsinitiative Umweltgeschichte 1999;Haidvogl 2008). Knowles (2002) has already demonstrated the potential of GIS techniques for historical research.	0	In Europe, such investigations were conducted on several French rivers (e.g. Girel et al. 1997;Kondolf et al. 2007), the current Slovak Danube (Pis√∫t 2002), the lower Rhine (Schoor et al. 1999;Wolfert 2001), the Dyje River, Czech Republic (Skokanova 2008) and on several English rivers (Lewin 2010). Outside Europe, comparable studies exist for e.g. the upper Mississippi (de Jager et al. 2011) and the Sacramento River, California (Greco et al. 2007). In ecology and environmental history alike, GIS techniques have often been deployed to reconstruct past land cover and land use changes based on historical maps such as cadastral maps. These include, amongst others, the Baltimore-Chesapeake region (#CITATION_TAG et al. 1997), the American Great Plains (Cunfer 2008), the Rocky Mountains (Aspinall 2004), Southern Germany (Bender et al. 2005;Schuppert and Dix 2009), the Tisza River in Hungary (Heged√ºs and Duray 2009) and several Austrian villages and rivers (Forschungsinitiative Umweltgeschichte 1999;Haidvogl 2008). Knowles (2002) has already demonstrated the potential of GIS techniques for historical research.	i
CCT8	Reconstructing riverscapes over decades or even centuries better approximates the former situations than the reconstruction of a single point in time. In recent years, GISbased studies of historical fluvial morphology were conducted over the long term to reveal the causes of past channel changes and floodplain degradation (Gurnell et al. 1994(Gurnell et al. , 2005Marston et al. 1995;Kiss et al. 2008). Some historical studies specifically focus on the spatial distribution of riverine habitats and the land cover of riverscapes. In Europe, such investigations were conducted on several French rivers (e.g. Girel et al. 1997;Kondolf et al. 2007), the current Slovak Danube (Pis√∫t 2002), the lower Rhine (Schoor et al. 1999;Wolfert 2001), the Dyje River, Czech Republic (Skokanova 2008) and on several English rivers (Lewin 2010). Outside Europe, comparable studies exist for e.g. the upper Mississippi (de Jager et al. 2011) and the Sacramento River, California (Greco et al. 2007). In ecology and environmental history alike, GIS techniques have often been deployed to reconstruct past land cover and land use changes based on historical maps such as cadastral maps. These include, amongst others, the Baltimore-Chesapeake region (Foresman et al. 1997), the American Great Plains (Cunfer 2008), the Rocky Mountains (Aspinall 2004), Southern Germany (Bender et al. 2005;Schuppert and Dix 2009), the Tisza River in Hungary (Heged√ºs and Duray 2009) and several Austrian villages and rivers (Forschungsinitiative #CITATION_TAG 1999;Haidvogl 2008). Knowles (2002) has already demonstrated the potential of GIS techniques for historical research.	0	In Europe, such investigations were conducted on several French rivers (e.g. Girel et al. 1997;Kondolf et al. 2007), the current Slovak Danube (Pis√∫t 2002), the lower Rhine (Schoor et al. 1999;Wolfert 2001), the Dyje River, Czech Republic (Skokanova 2008) and on several English rivers (Lewin 2010). Outside Europe, comparable studies exist for e.g. the upper Mississippi (de Jager et al. 2011) and the Sacramento River, California (Greco et al. 2007). In ecology and environmental history alike, GIS techniques have often been deployed to reconstruct past land cover and land use changes based on historical maps such as cadastral maps. These include, amongst others, the Baltimore-Chesapeake region (Foresman et al. 1997), the American Great Plains (Cunfer 2008), the Rocky Mountains (Aspinall 2004), Southern Germany (Bender et al. 2005;Schuppert and Dix 2009), the Tisza River in Hungary (Heged√ºs and Duray 2009) and several Austrian villages and rivers (Forschungsinitiative #CITATION_TAG 1999;Haidvogl 2008). Knowles (2002) has already demonstrated the potential of GIS techniques for historical research.	i
CCT9	Reconstructing riverscapes over decades or even centuries better approximates the former situations than the reconstruction of a single point in time. In recent years, GISbased studies of historical fluvial morphology were conducted over the long term to reveal the causes of past channel changes and floodplain degradation (#CITATION_TAG et al. 1994(Gurnell et al. , 2005Marston et al. 1995;Kiss et al. 2008). Some historical studies specifically focus on the spatial distribution of riverine habitats and the land cover of riverscapes. In Europe, such investigations were conducted on several French rivers (e.g. Girel et al. 1997;Kondolf et al. 2007), the current Slovak Danube (Pis√∫t 2002), the lower Rhine (Schoor et al. 1999;Wolfert 2001), the Dyje River, Czech Republic (Skokanova 2008) and on several English rivers (Lewin 2010). Outside Europe, comparable studies exist for e.g. the upper Mississippi (de Jager et al. 2011) and the Sacramento River, California (Greco et al. 2007). In ecology and environmental history alike, GIS techniques have often been deployed to reconstruct past land cover and land use changes based on historical maps such as cadastral maps. These include, amongst others, the Baltimore-Chesapeake region (Foresman et al. 1997), the American Great Plains (Cunfer 2008), the Rocky Mountains (Aspinall 2004), Southern Germany (Bender et al. 2005;Schuppert and Dix 2009), the Tisza River in Hungary (Heged√ºs and Duray 2009) and several Austrian villages and rivers (Forschungsinitiative Umweltgeschichte 1999;Haidvogl 2008). Knowles (2002) has already demonstrated the potential of GIS techniques for historical research.	0	Reconstructing riverscapes over decades or even centuries better approximates the former situations than the reconstruction of a single point in time. In recent years, GISbased studies of historical fluvial morphology were conducted over the long term to reveal the causes of past channel changes and floodplain degradation (#CITATION_TAG et al. 1994(Gurnell et al. , 2005Marston et al. 1995;Kiss et al. 2008). Some historical studies specifically focus on the spatial distribution of riverine habitats and the land cover of riverscapes. In Europe, such investigations were conducted on several French rivers (e.g. Girel et al. 1997;Kondolf et al. 2007), the current Slovak Danube (Pis√∫t 2002), the lower Rhine (Schoor et al. 1999;Wolfert 2001), the Dyje River, Czech Republic (Skokanova 2008) and on several English rivers (Lewin 2010). Outside Europe, comparable studies exist for e.g. the upper Mississippi (de Jager et al. 2011) and the Sacramento River, California (Greco et al. 2007).	n
CCT10	"In the first half of the 18th century, the number of topographical sources substantially increased, and from the late 18th century a great variety of different types are available. At that time, topographical views and maps produced for commercial purposes gained 8 Except for Slezak (1980), who came to the same conclusion. considerable public attention. Several of these maps were created on the basis of the wellknown city map from Leander Anguissola and Johann Jacob Marinoni in 1704 and published under the title """"Accuratissima Viennae Austriae Ichnographica Delineatio"""" (""""Most accurate plan of Vienna in Austria"""") in 1706. 12 True to its title, the plan shows the city with its fortifications and with the growing suburbs, which at that time had already spread into the riverine landscape-namely the Leopoldstadt on the large island confined by the Danube and the Donaukanal (here called the Neuer Canal; #CITATION_TAG et al. 2013, in this issue). In this plan the Danube itself is at least as important as the urban settlement. The main contemporary intention of the plan was to show the newly strengthened fortifications of the Habsburg residence. An additional second ring of fortification walls and ramparts (called the Linienwall) had been built in 1704 to better protect the residence. This plan makes clear that the Danube was an essential part of the city""s fortification system. To the northeast, the Danube was Vienna""s fortification. In the floodplain, only parts of the Leopoldstadt and the head of the only bridge crossing the main arm of the Danube were fortified with man-made structures. In later editions of the map up to c. 1785, only the settlement areas within the town were updated; the riverscape was depicted as unchanged, a pretence that the riverscape had been stable over decades. However, the comparison with the famous """"Jagdatlas Kaiser Karls VI. (""""Atlas of imperial hunting grounds"""") produced by J. J. Marinoni between 1726 and 1729 reveals that the riverscape had experienced substantial alterations since 1704. 13 This map series is the first geometrically coherent cartographic source that also covers areas remote from the historical city centre (Marinoni 1751). 14 n the 18th century, the growth of the city also gave rise to new regulation projects. Thus hundreds of hydraulic construction plans were generated, but many show constructions never implemented. Numerous of these plans were compiled by the hydraulic engineer Johann Sigismund Hubert, who constructed the first larger flood protection scheme for Vienna. Since most plans only refer to minor regulation works, many of them have never been described in the literature. In this case, only the comparative analysis of the numerous plans with written sources can help clarify which works were actually realised."	2	"At that time, topographical views and maps produced for commercial purposes gained 8 Except for Slezak (1980), who came to the same conclusion. considerable public attention. Several of these maps were created on the basis of the wellknown city map from Leander Anguissola and Johann Jacob Marinoni in 1704 and published under the title """"Accuratissima Viennae Austriae Ichnographica Delineatio"""" (""""Most accurate plan of Vienna in Austria"""") in 1706. 12 True to its title, the plan shows the city with its fortifications and with the growing suburbs, which at that time had already spread into the riverine landscape-namely the Leopoldstadt on the large island confined by the Danube and the Donaukanal (here called the Neuer Canal; #CITATION_TAG et al. 2013, in this issue). In this plan the Danube itself is at least as important as the urban settlement. The main contemporary intention of the plan was to show the newly strengthened fortifications of the Habsburg residence. An additional second ring of fortification walls and ramparts (called the Linienwall) had been built in 1704 to better protect the residence."	r
CCT11	"Taken together, the various historical sources document a major rearrangement of the Danube channel network. In order to conclude whether identified fluvial dynamics reflect the river""s typical behaviour rather than an exceptional hydromorphological state, climatic changes and related flood regimes also have to be considered (Howard 1996;McCarney-Castle et al. 2011;Macklin et al. 2012). For example, increasing runoff generally leads to channel straightening and profile widening. Together with augmented sediment loads, it additionally fosters the transformation from meandering to braiding (Nanson and Knighton 1996;Marti and Bezzola 2004). The major channel shifts at the Viennese Danube therefore have to be interpreted against the background of the Grindelwald Fluctuation, the first extreme phase of the Little Ice Age from the 1560s to the 1620s (Pfister 1980(Pfister , 2007#CITATION_TAG 1999;Hohensinner et al. 2013, in this issue). Accordingly, the period from the mid to late 16th century must be considered as the key phase to understand the evolution of the riverscape, the intentions of discussed/implemented regulation measures and, consequently, the interpretation of historical sources in the following centuries."	4	"In order to conclude whether identified fluvial dynamics reflect the river""s typical behaviour rather than an exceptional hydromorphological state, climatic changes and related flood regimes also have to be considered (Howard 1996;McCarney-Castle et al. 2011;Macklin et al. 2012). For example, increasing runoff generally leads to channel straightening and profile widening. Together with augmented sediment loads, it additionally fosters the transformation from meandering to braiding (Nanson and Knighton 1996;Marti and Bezzola 2004). The major channel shifts at the Viennese Danube therefore have to be interpreted against the background of the Grindelwald Fluctuation, the first extreme phase of the Little Ice Age from the 1560s to the 1620s (Pfister 1980(Pfister , 2007#CITATION_TAG 1999;Hohensinner et al. 2013, in this issue). Accordingly, the period from the mid to late 16th century must be considered as the key phase to understand the evolution of the riverscape, the intentions of discussed/implemented regulation measures and, consequently, the interpretation of historical sources in the following centuries."	m
CCT12	It provides an inestimably valuable source for the identification and localisation of river arms that existed decades or even centuries earlier. Based on this survey, we generated a digital terrain model in that served as a main basis for the reconstruction works in the current study (#CITATION_TAG 2007;. From the period when the comprehensive regulation programme was finally accomplished (1870-1875), a multitude of historical data is available, from very detailed technical plans and reports to illustrative maps for the interested public, which are less useful for reconstruction.	2	It provides an inestimably valuable source for the identification and localisation of river arms that existed decades or even centuries earlier. Based on this survey, we generated a digital terrain model in that served as a main basis for the reconstruction works in the current study (#CITATION_TAG 2007;. From the period when the comprehensive regulation programme was finally accomplished (1870-1875), a multitude of historical data is available, from very detailed technical plans and reports to illustrative maps for the interested public, which are less useful for reconstruction.	a
CCT13	Due to the different forms of channel adjustments and floodplain inundation-active overflow, backwater flooding, or seepage inundation-such floodplains featured a great variety of depositional processes. Lateral point-bar accretion, overbank vertical-deposition, braid-channel accretion in wider profiles and abandoned channel accretion were most typical. The different processes are associated with specific sediment fractions. Annual erosion rates ranged from 1.6 % of the floodplain terrain in the Lobau directly downstream from Vienna to 2.5 % in the more dynamic Danube sections such as the Machland, 160 km upstream from Vienna (#CITATION_TAG and Jungwirth 2009). Within a few decades, large shares of the floodplain terrain were renewed. Accordingly, high shares of morphologically young terrain were typical.	2	Due to the different forms of channel adjustments and floodplain inundation-active overflow, backwater flooding, or seepage inundation-such floodplains featured a great variety of depositional processes. Lateral point-bar accretion, overbank vertical-deposition, braid-channel accretion in wider profiles and abandoned channel accretion were most typical. The different processes are associated with specific sediment fractions. Annual erosion rates ranged from 1.6 % of the floodplain terrain in the Lobau directly downstream from Vienna to 2.5 % in the more dynamic Danube sections such as the Machland, 160 km upstream from Vienna (#CITATION_TAG and Jungwirth 2009). Within a few decades, large shares of the floodplain terrain were renewed. Accordingly, high shares of morphologically young terrain were typical.	u
CCT14	The requirement for testing intrarater and inter-rater reliability was planned to include a sample size of at least 40 persons. 24 The TP counts were distributed as discrete numerical variables and were normally distributed. For the quantification of intrarater and inter-rater reproducibility of TP examination, two types of analysis were applied: the intraclass correlation coefficient (ICC) and the Bland-Altman method for assessing agreement. 25 26 CC provides information on the ability to differentiate between the variation between subjects and measurement variation. The ICC was defined as the ratio of variance among patients (subject variability) over the total variance (subject variability, observer variability and measurement variability). ICC ranges between 0 (no reliability) and 1 ( perfect reliability), and values of ICCs are excellent when >0.75 and poor when <0.40. Results between these ranges represent moderate-to-good reliability. 27 According to another reference, ICC >0.7 is considered good. 25 he Bland-Altman method provides insight into the distribution of differences in relation to mean values. #CITATION_TAG greement was quantified by calculating the mean difference between two sets of observations and the SD for this difference. The closer the mean difference was to 0 and the smaller the SD of this difference, the better was the agreement. The differences were depicted in relation to the mean values. The 95% limits of agreement were defined as the mean difference between the raters ¬±1.96 √ó SD of the difference . Furthermore, agreement within ¬±1 TPs and ¬±3 TPs was calculated.	5	Results between these ranges represent moderate-to-good reliability. 27 According to another reference, ICC >0.7 is considered good. 25 he Bland-Altman method provides insight into the distribution of differences in relation to mean values. #CITATION_TAG greement was quantified by calculating the mean difference between two sets of observations and the SD for this difference. The closer the mean difference was to 0 and the smaller the SD of this difference, the better was the agreement. The differences were depicted in relation to the mean values. The 95% limits of agreement were defined as the mean difference between the raters ¬±1.96 √ó SD of the difference . Furthermore, agreement within ¬±1 TPs and ¬±3 TPs was calculated.	_
CCT15	The present study showed that digital TP examination resulted in total TP counts with acceptable-to-excellent reliability when calibration of the thumbs with a dolorimeter was performed before the testing. This indicated that the measurement error, which was less than 2 TPs, was considerably smaller than the variation between individuals. The lesser experienced Rater B did not perform as well as the more experienced Rater A, and this was especially evident on comparison of the lower limits of the CIs. However, the reliability of Rater B was acceptable, but more training and regular use would probably improve the results. Training has been shown to reduce the variability in applying a kg digital force. 29 greement is independent of the variation between subjects. We consider an agreement of more than 70% as good, and it was found for ¬±3 TPs in both men and women, indicating that digital TP examination in daily practice may be used, keeping in mind the uncertainty of ¬±3 TPs. This part of the result was especially important, since we found that TP counts were higher in women than in men, in line with other studies. In the general population, TP counts of more than 10 and 6 have been identified in 10-20% of women and men, respectively. 6 7 Thus, a TP count of 9 may be normal in women, but high in men. The median TP count of 8 was elevated as compared with the median TP count in the general population, which is between 3 and 6 TPs. 6 Previously, it has been shown that TP counts were elevated in regional pain conditions as compared with pain-free controls, but lower than in fibromyalgia. #CITATION_TAG owever, SDD ranged from 4 to 6, indicating less precision of TP examination than reliability. Thus, according to the present study, TP examination may result in TP counts that may differentiate between high, intermediate or low levels, but not between different levels in the low or high range. Moreover, TP examination-as used in the present study-would not be sufficiently precise to differentiate between patients with higher or lower TP counts than 10/11 TPs such as are used in the diagnosis of fibromyalgia.	1	6 7 Thus, a TP count of 9 may be normal in women, but high in men. The median TP count of 8 was elevated as compared with the median TP count in the general population, which is between 3 and 6 TPs. 6 Previously, it has been shown that TP counts were elevated in regional pain conditions as compared with pain-free controls, but lower than in fibromyalgia. #CITATION_TAG owever, SDD ranged from 4 to 6, indicating less precision of TP examination than reliability. Thus, according to the present study, TP examination may result in TP counts that may differentiate between high, intermediate or low levels, but not between different levels in the low or high range. Moreover, TP examination-as used in the present study-would not be sufficiently precise to differentiate between patients with higher or lower TP counts than 10/11 TPs such as are used in the diagnosis of fibromyalgia.	G
CCT16	"First, ants could use a comparison strategy, in which ants that have visited both nests would compare their qualities and recruit nestmates only to the better one [20]. Second, ants visiting just one nest could determine how long they hesitate before recruiting nestmates (recruitment latency) based on the nest quality [20]. A combination of these two mechanisms has been used as the basis of several decision models [18,[21][22][23][24]. Although lone T. rugatulus ant workers are capable of comparing the attributes of nest-sites which are very close together [25], the evidence for individual ants making direct comparisons between nests during colony emigration is weak #CITATION_TAG, and furthermore, ant colonies are able to choose a distant good nest over a nearby poor nest, when recruitment latency differences would be expected to be cancelled out by travel time (Fig. 1a) [26,27]. The third possible mechanism of choice is a sequential search strategy, based on a very simple rule of thumb, a ""threshold rule by which an ant assesses a nest against her own fixed quality threshold, and either accepts the nest and begins recruitment, or rejects it and continues searching [26]. Qualitydependent recruitment latency has been demonstrated empirically only when colonies were presented with a single new nest and were not required to make a choice [20,22,24,28]. Robinson et al. [26] hypothesized that these apparent recruitment latency effects could emerge as a by-product of a threshold rule, because ants that find a low-quality nest will tend to reject it and continue searching, whereas ants that find a high quality nest will tend to accept it and begin recruitment. In addition, Robinson et al. [26] hypothesized that the apparent comparison phenomenon in which ants that have visited equidistant poor and good nests usually recruit only to the good nest (Fig. 1b; [20]) can be explained more parsimoniously with a threshold rule in which the poor nest is rejected and forgotten, then the good nest is discovered and accepted, rather than requiring individual ants to perform the more cognitively complex task of remembering and comparing the qualities of different nests. We aim to test the hypothesis that this simple parsimonious mechanism (the threshold rule) is sufficient to reproduce observed empirical patterns of collective decision-making."	4	"First, ants could use a comparison strategy, in which ants that have visited both nests would compare their qualities and recruit nestmates only to the better one [20]. Second, ants visiting just one nest could determine how long they hesitate before recruiting nestmates (recruitment latency) based on the nest quality [20]. A combination of these two mechanisms has been used as the basis of several decision models [18,[21][22][23][24]. Although lone T. rugatulus ant workers are capable of comparing the attributes of nest-sites which are very close together [25], the evidence for individual ants making direct comparisons between nests during colony emigration is weak #CITATION_TAG, and furthermore, ant colonies are able to choose a distant good nest over a nearby poor nest, when recruitment latency differences would be expected to be cancelled out by travel time (Fig. 1a) [26,27]. The third possible mechanism of choice is a sequential search strategy, based on a very simple rule of thumb, a ""threshold rule by which an ant assesses a nest against her own fixed quality threshold, and either accepts the nest and begins recruitment, or rejects it and continues searching [26]. Qualitydependent recruitment latency has been demonstrated empirically only when colonies were presented with a single new nest and were not required to make a choice [20,22,24,28]. Robinson et al. [26] hypothesized that these apparent recruitment latency effects could emerge as a by-product of a threshold rule, because ants that find a low-quality nest will tend to reject it and continue searching, whereas ants that find a high quality nest will tend to accept it and begin recruitment."	h
CCT17	"First, ants could use a comparison strategy, in which ants that have visited both nests would compare their qualities and recruit nestmates only to the better one #CITATION_TAG. Second, ants visiting just one nest could determine how long they hesitate before recruiting nestmates (recruitment latency) based on the nest quality [20]. A combination of these two mechanisms has been used as the basis of several decision models [18,[21][22][23][24]. Although lone T. rugatulus ant workers are capable of comparing the attributes of nest-sites which are very close together [25], the evidence for individual ants making direct comparisons between nests during colony emigration is weak [26], and furthermore, ant colonies are able to choose a distant good nest over a nearby poor nest, when recruitment latency differences would be expected to be cancelled out by travel time (Fig. 1a) [26,27]. The third possible mechanism of choice is a sequential search strategy, based on a very simple rule of thumb, a ""threshold rule by which an ant assesses a nest against her own fixed quality threshold, and either accepts the nest and begins recruitment, or rejects it and continues searching [26]. Qualitydependent recruitment latency has been demonstrated empirically only when colonies were presented with a single new nest and were not required to make a choice [20,22,24,28]. Robinson et al. [26] hypothesized that these apparent recruitment latency effects could emerge as a by-product of a threshold rule, because ants that find a low-quality nest will tend to reject it and continue searching, whereas ants that find a high quality nest will tend to accept it and begin recruitment. In addition, Robinson et al. [26] hypothesized that the apparent comparison phenomenon in which ants that have visited equidistant poor and good nests usually recruit only to the good nest (Fig. 1b; [20]) can be explained more parsimoniously with a threshold rule in which the poor nest is rejected and forgotten, then the good nest is discovered and accepted, rather than requiring individual ants to perform the more cognitively complex task of remembering and comparing the qualities of different nests. We aim to test the hypothesis that this simple parsimonious mechanism (the threshold rule) is sufficient to reproduce observed empirical patterns of collective decision-making."	0	First, ants could use a comparison strategy, in which ants that have visited both nests would compare their qualities and recruit nestmates only to the better one #CITATION_TAG. Second, ants visiting just one nest could determine how long they hesitate before recruiting nestmates (recruitment latency) based on the nest quality [20]. A combination of these two mechanisms has been used as the basis of several decision models [18,[21][22][23][24]. Although lone T. rugatulus ant workers are capable of comparing the attributes of nest-sites which are very close together [25], the evidence for individual ants making direct comparisons between nests during colony emigration is weak [26], and furthermore, ant colonies are able to choose a distant good nest over a nearby poor nest, when recruitment latency differences would be expected to be cancelled out by travel time (Fig. 1a) [26,27].	F
CCT18	"First, ants could use a comparison strategy, in which ants that have visited both nests would compare their qualities and recruit nestmates only to the better one [20]. Second, ants visiting just one nest could determine how long they hesitate before recruiting nestmates (recruitment latency) based on the nest quality [20]. A combination of these two mechanisms has been used as the basis of several decision models [18,[21][22][23][24]. Although lone T. rugatulus ant workers are capable of comparing the attributes of nest-sites which are very close together #CITATION_TAG, the evidence for individual ants making direct comparisons between nests during colony emigration is weak [26], and furthermore, ant colonies are able to choose a distant good nest over a nearby poor nest, when recruitment latency differences would be expected to be cancelled out by travel time (Fig. 1a) [26,27]. The third possible mechanism of choice is a sequential search strategy, based on a very simple rule of thumb, a ""threshold rule by which an ant assesses a nest against her own fixed quality threshold, and either accepts the nest and begins recruitment, or rejects it and continues searching [26]. Qualitydependent recruitment latency has been demonstrated empirically only when colonies were presented with a single new nest and were not required to make a choice [20,22,24,28]. Robinson et al. [26] hypothesized that these apparent recruitment latency effects could emerge as a by-product of a threshold rule, because ants that find a low-quality nest will tend to reject it and continue searching, whereas ants that find a high quality nest will tend to accept it and begin recruitment. In addition, Robinson et al. [26] hypothesized that the apparent comparison phenomenon in which ants that have visited equidistant poor and good nests usually recruit only to the good nest (Fig. 1b; [20]) can be explained more parsimoniously with a threshold rule in which the poor nest is rejected and forgotten, then the good nest is discovered and accepted, rather than requiring individual ants to perform the more cognitively complex task of remembering and comparing the qualities of different nests. We aim to test the hypothesis that this simple parsimonious mechanism (the threshold rule) is sufficient to reproduce observed empirical patterns of collective decision-making."	0	"First, ants could use a comparison strategy, in which ants that have visited both nests would compare their qualities and recruit nestmates only to the better one [20]. Second, ants visiting just one nest could determine how long they hesitate before recruiting nestmates (recruitment latency) based on the nest quality [20]. A combination of these two mechanisms has been used as the basis of several decision models [18,[21][22][23][24]. Although lone T. rugatulus ant workers are capable of comparing the attributes of nest-sites which are very close together #CITATION_TAG, the evidence for individual ants making direct comparisons between nests during colony emigration is weak [26], and furthermore, ant colonies are able to choose a distant good nest over a nearby poor nest, when recruitment latency differences would be expected to be cancelled out by travel time (Fig. 1a) [26,27]. The third possible mechanism of choice is a sequential search strategy, based on a very simple rule of thumb, a ""threshold rule by which an ant assesses a nest against her own fixed quality threshold, and either accepts the nest and begins recruitment, or rejects it and continues searching [26]. Qualitydependent recruitment latency has been demonstrated empirically only when colonies were presented with a single new nest and were not required to make a choice [20,22,24,28]. Robinson et al. [26] hypothesized that these apparent recruitment latency effects could emerge as a by-product of a threshold rule, because ants that find a low-quality nest will tend to reject it and continue searching, whereas ants that find a high quality nest will tend to accept it and begin recruitment."	h
CCT19	"First, ants could use a comparison strategy, in which ants that have visited both nests would compare their qualities and recruit nestmates only to the better one [20]. Second, ants visiting just one nest could determine how long they hesitate before recruiting nestmates (recruitment latency) based on the nest quality [20]. A combination of these two mechanisms has been used as the basis of several decision models [18,[21][22][23]#CITATION_TAG. Although lone T. rugatulus ant workers are capable of comparing the attributes of nest-sites which are very close together [25], the evidence for individual ants making direct comparisons between nests during colony emigration is weak [26], and furthermore, ant colonies are able to choose a distant good nest over a nearby poor nest, when recruitment latency differences would be expected to be cancelled out by travel time (Fig. 1a) [26,27]. The third possible mechanism of choice is a sequential search strategy, based on a very simple rule of thumb, a ""threshold rule by which an ant assesses a nest against her own fixed quality threshold, and either accepts the nest and begins recruitment, or rejects it and continues searching [26]. Qualitydependent recruitment latency has been demonstrated empirically only when colonies were presented with a single new nest and were not required to make a choice [20,22,24,28]. Robinson et al. [26] hypothesized that these apparent recruitment latency effects could emerge as a by-product of a threshold rule, because ants that find a low-quality nest will tend to reject it and continue searching, whereas ants that find a high quality nest will tend to accept it and begin recruitment. In addition, Robinson et al. [26] hypothesized that the apparent comparison phenomenon in which ants that have visited equidistant poor and good nests usually recruit only to the good nest (Fig. 1b; [20]) can be explained more parsimoniously with a threshold rule in which the poor nest is rejected and forgotten, then the good nest is discovered and accepted, rather than requiring individual ants to perform the more cognitively complex task of remembering and comparing the qualities of different nests. We aim to test the hypothesis that this simple parsimonious mechanism (the threshold rule) is sufficient to reproduce observed empirical patterns of collective decision-making."	5	"First, ants could use a comparison strategy, in which ants that have visited both nests would compare their qualities and recruit nestmates only to the better one [20]. Second, ants visiting just one nest could determine how long they hesitate before recruiting nestmates (recruitment latency) based on the nest quality [20]. A combination of these two mechanisms has been used as the basis of several decision models [18,[21][22][23]#CITATION_TAG. Although lone T. rugatulus ant workers are capable of comparing the attributes of nest-sites which are very close together [25], the evidence for individual ants making direct comparisons between nests during colony emigration is weak [26], and furthermore, ant colonies are able to choose a distant good nest over a nearby poor nest, when recruitment latency differences would be expected to be cancelled out by travel time (Fig. 1a) [26,27]. The third possible mechanism of choice is a sequential search strategy, based on a very simple rule of thumb, a ""threshold rule by which an ant assesses a nest against her own fixed quality threshold, and either accepts the nest and begins recruitment, or rejects it and continues searching [26]. Qualitydependent recruitment latency has been demonstrated empirically only when colonies were presented with a single new nest and were not required to make a choice [20,22,24,28]."	c
CCT20	Social animals make collective decisions between available options, particularly about where the group spends its time. When making a shared collective decision, a group faces the challenges of integrating information from multiple individuals and managing the different decision-preferences of group members [11]. Such decisions are influenced by individual information, conflicts of interest and time-constraints [12,13]. To understand how a collective decision is reached, the rules followed by contributing members of the group must be identified [14]. Emigrating social insects are a good model system for the study of collective decisionmaking, because all members share the aim of coming to a consensus about a new, good nest site as soon as possible, but the information about available site quality is distributed very unevenly within the colony [15,#CITATION_TAG]. To investigate the mechanism of decision making, we used models of, and experiments on, emigrating cavity-nesting rock ants, Temnothorax albipennis.	2	When making a shared collective decision, a group faces the challenges of integrating information from multiple individuals and managing the different decision-preferences of group members [11]. Such decisions are influenced by individual information, conflicts of interest and time-constraints [12,13]. To understand how a collective decision is reached, the rules followed by contributing members of the group must be identified [14]. Emigrating social insects are a good model system for the study of collective decisionmaking, because all members share the aim of coming to a consensus about a new, good nest site as soon as possible, but the information about available site quality is distributed very unevenly within the colony [15,#CITATION_TAG]. To investigate the mechanism of decision making, we used models of, and experiments on, emigrating cavity-nesting rock ants, Temnothorax albipennis.	r
CCT21	"Animals need to make choices between multiple available options at many stages in their life histories, such as during mate selection, foraging, or when deciding where to shelter or to build a nest. The fitness benefits of choosing the best option mean that decision-making strategies will be subject to natural selection. Multiple comparison or ""best of n"" strategies perform most accurately, and are likely to be optimal when searching and sampling costs are low, e.g. on a lek [1,2] and when long-term fitness implications of the decision are high, e.g. in home range selection [3]. In other situations, e.g. during foraging, there can be substantial time costs to making accurate decisions [4,5], and these costs can be so great as to make quicker less accurate decisions more efficient [6]. Animals may be best served by using a simpler ""rule of thumb which reduces sampling time, but still ensures the option they choose is good enough. One simple but effective strategy is sequential search in which the animal keeps searching until it finds an option that exceeds a threshold of acceptability [2,#CITATION_TAG]. This kind of fixedthreshold strategy is used in foraging [8], mate choice [9] and refuge selection [10]. An intermediate strategy is to allow thresholds to be influenced by experience of previous options; in effect this would cause a ""sequential comparison""."	0	"Multiple comparison or ""best of n"" strategies perform most accurately, and are likely to be optimal when searching and sampling costs are low, e.g. on a lek [1,2] and when long-term fitness implications of the decision are high, e.g. in home range selection [3]. In other situations, e.g. during foraging, there can be substantial time costs to making accurate decisions [4,5], and these costs can be so great as to make quicker less accurate decisions more efficient [6]. Animals may be best served by using a simpler ""rule of thumb which reduces sampling time, but still ensures the option they choose is good enough. One simple but effective strategy is sequential search in which the animal keeps searching until it finds an option that exceeds a threshold of acceptability [2,#CITATION_TAG]. This kind of fixedthreshold strategy is used in foraging [8], mate choice [9] and refuge selection [10]. An intermediate strategy is to allow thresholds to be influenced by experience of previous options; in effect this would cause a ""sequential comparison""."	i
CCT22	"A colony emigration by rock ants begins with scouts searching for and assessing new sites. Successful scouts recruit nest-mates using tandem running, in which an informed ant leads another to the new site [17]. When the number of ants at a site reaches a ""quorum threshold the ants switch to rapid transport behaviour to carry the brood, queen and remaining nest-mates to the new nest #CITATION_TAG. Ant colonies discriminate between nest sites on the basis of a range of attributes including cavity dimensions, light level and entrance width [16,19]. Three possible mechanisms by which the colony collectively chooses the better of two nests have been proposed: i) comparison ii) recruitment latency iii) threshold rule."	0	"A colony emigration by rock ants begins with scouts searching for and assessing new sites. Successful scouts recruit nest-mates using tandem running, in which an informed ant leads another to the new site [17]. When the number of ants at a site reaches a ""quorum threshold the ants switch to rapid transport behaviour to carry the brood, queen and remaining nest-mates to the new nest #CITATION_TAG. Ant colonies discriminate between nest sites on the basis of a range of attributes including cavity dimensions, light level and entrance width [16,19]. Three possible mechanisms by which the colony collectively chooses the better of two nests have been proposed: i) comparison ii) recruitment latency iii) threshold rule."	e
CCT23	The second previously-proposed mechanism, quality dependent recruitment latencies, is an attractive idea -it does not rely on comparisons, and self-organised decisions can emerge because ants finding a poor nest delay before recruiting, effectively giving others that have found a good nest a head-start in the recruitment process. The initial advantage is amplified by recruitment, and this can be shown to be sufficient to account for collective choice [24]. In both the threshold rule and the recruitment latency hypothesis, a scout makes a probabilistic, quality-dependent decision about whether to recruit each time she visits a nest. The difference between these mechanisms come from the assumptions made about what the scout does after leaving the nest, and how this results in a colony decision-mechanism. In our threshold rule, the ant either commits or continues searching. In the recruitment latency hypothesis, ants which do not immediately start recruiting may subsequently recruit, with a quality-dependent latency. In the original formulation of this idea [20] it is mentioned that ants might discover other nests during this latent period, but it is not suggested that the latency is actually a result of the search for other nests. Searching for alternatives has a more prominent role in later versions of the recruitment latency model [24] making it more similar to our threshold model, however, the idea of simple quality-dependent recruitment latencies functioning as a choice mechanism still appears often in discussions of collective decisionmaking [11,38,39]. There are two empirical problems with such a mechanism. Firstly, colonies are able to choose a good nest, even when it is so much further away than a poor nest that travel time should cancel out differences in recruitment latency [27]. Secondly, all empirical evidence for quality-dependent recruitment latencies comes from studies offering a colony just one new nest [20,22,24,28]. When recruitment latencies are measured in multiple nest experiments, no quality-dependent recruitment latencies differences are observed [this study and 26]. We used modelling to investigate these empirical results. Our simulation and analytical results reproduce quality-dependent recruitment latency in a single-nest experiment, but show that the presence of an extra nest disrupts the quality-dependence of the latency to commitment and recruitment (Figs. 5-6). When a single poor nest is offered, acceptance times in the model will be geometrically distributed, with few ants accepting the site early due to rare assessment errors or low individual-thresholds, and the remainder continuing to re-assess the same site until they eventually decide it is good enough. When a second higher quality site is introduced, the same small proportion of ants will accept the poor site early due to low-threshold or assessment error, but the remainder will now tend to discover the alternative, superior site, and recruit to this quickly on average because of its increased quality. The same pattern would be observed for a threshold-rule with direct comparison (see Text S1), and also for a quality-dependent recruitment latency-rule, if it is assumed that ants search for alternatives during the latency period and have a high probability of finding other sites [20]. However, these alternative models are less parsimonious, requiring ants to remember the qualities and/or locations of visited sites and evaluate this in making subsequent comparisons or use the information to decide when and where to start recruiting. These results also clearly demonstrate that a phenomenon observed when only one option is available, cannot be assumed to function in the same way when choosing between multiple options (see also [7]). Another well-studied example of collective decision-making is nest-site choice by swarming honeybees (Apis mellifera). Like ant colonies, bee swarms are able to choose between different nest sites, and individual bees do not need to have visited multiple sites for the swarm to be able to choose between them [40]. However, the way the scouts act on this information differs between the two groups. The ants seem to use a binary decision process to either accept that nest or continue searching. Ants accepting a nest recruit others, causing a positive feedback process, but ant scouts do not modulate their recruitment according to nest quality, e.g. by recruiting at a faster rate or for longer to a higher quality nest [20,26]. In contrast, bees use a graded process, whereby scouts initially discovering a new nest-site almost always recruit [41], but the duration and rate of the recruiting waggle-dances are dependent on nest quality #CITATION_TAG. This means that more recruits are brought to better nest-sites, leading to a positive feedback process usually resulting in a unanimous choice of the better site [42]. One possible reason for this difference in strategy could be differences in nest availability: if suitable honeybee nest sites are relatively rare, then it might be better for scouts to avoid ever rejecting a potential nest outright.	1	However, the way the scouts act on this information differs between the two groups. The ants seem to use a binary decision process to either accept that nest or continue searching. Ants accepting a nest recruit others, causing a positive feedback process, but ant scouts do not modulate their recruitment according to nest quality, e.g. by recruiting at a faster rate or for longer to a higher quality nest [20,26]. In contrast, bees use a graded process, whereby scouts initially discovering a new nest-site almost always recruit [41], but the duration and rate of the recruiting waggle-dances are dependent on nest quality #CITATION_TAG. This means that more recruits are brought to better nest-sites, leading to a positive feedback process usually resulting in a unanimous choice of the better site [42]. One possible reason for this difference in strategy could be differences in nest availability: if suitable honeybee nest sites are relatively rare, then it might be better for scouts to avoid ever rejecting a potential nest outright.	r
CCT24	"Animals need to make choices between multiple available options at many stages in their life histories, such as during mate selection, foraging, or when deciding where to shelter or to build a nest. The fitness benefits of choosing the best option mean that decision-making strategies will be subject to natural selection. Multiple comparison or ""best of n"" strategies perform most accurately, and are likely to be optimal when searching and sampling costs are low, e.g. on a lek [1,2] and when long-term fitness implications of the decision are high, e.g. in home range selection [3]. In other situations, e.g. during foraging, there can be substantial time costs to making accurate decisions [4,5], and these costs can be so great as to make quicker less accurate decisions more efficient [6]. Animals may be best served by using a simpler ""rule of thumb which reduces sampling time, but still ensures the option they choose is good enough. One simple but effective strategy is sequential search in which the animal keeps searching until it finds an option that exceeds a threshold of acceptability [2,7]. This kind of fixedthreshold strategy is used in foraging #CITATION_TAG, mate choice [9] and refuge selection [10]. An intermediate strategy is to allow thresholds to be influenced by experience of previous options; in effect this would cause a ""sequential comparison""."	0	"In other situations, e.g. during foraging, there can be substantial time costs to making accurate decisions [4,5], and these costs can be so great as to make quicker less accurate decisions more efficient [6]. Animals may be best served by using a simpler ""rule of thumb which reduces sampling time, but still ensures the option they choose is good enough. One simple but effective strategy is sequential search in which the animal keeps searching until it finds an option that exceeds a threshold of acceptability [2,7]. This kind of fixedthreshold strategy is used in foraging #CITATION_TAG, mate choice [9] and refuge selection [10]. An intermediate strategy is to allow thresholds to be influenced by experience of previous options; in effect this would cause a ""sequential comparison""."	i
CCT25	"Direct comparison of alternatives is seen in a range of animals and contexts, including foraging in scrub jays and humans [8,52], mate choice in bower-birds and dance-flies [53,#CITATION_TAG] and shell assessment by hermit crabs [55]. A best-of-n comparison strategy would maximise decision accuracy [2], so why do neither individual bees nor ants appear to use this strategy when foraging or choosing a new home? One possibility is that multiple comparisons are too cognitively complex for ant and bee brains. However, small insects including bees are competent at related cognitive processes, including contextual learning, discrimination between stimuli and associative recall [56]. Male dance-flies compare the size of potential mates before choosing [54], and there is evidence to suggest that honeybee workers are capable of comparative evaluation of flowers [57] and that lone T. rugatulus ant workers are capable of comparing the attributes of nest-sites which are very close together [25]. There may, therefore, be reasons other than cognitive constraints for why relying on individual best-of-n comparisons to inform collective choices does not appear to have evolved as a decision mechanism in bees or ants. One possible reason is that during their evolutionary history the ants have typically been faced with decisions about whether to accept a single option at a time, rather than simultaneously having information about multiple options, and this has shaped the evolution of their decision process [7]. Another possible reason is the potential speed advantage of avoiding a sampling period. Sampling periods can be costly [2,7] and pose the mathematically complex problem of deciding how long to sample for before starting the decision process [58]. Avoiding best-of-n comparisons allows a potentially vulnerable colony to select the first nest encountered, if it is good enough. Perhaps even more important is distributing the decision-making process, relying less on information-processing by a single individual; rather allowing the decision to emerge from a collective process to which even partly-informed individuals can contribute. In this colony-level cognition, the relevant information about the environment is represented within the individuals in a colony, their actions and interactions. At the collective level this generates new information: which nest the colony should choose [59]. In both bees and ants, the information held by individuals is integrated into a colony choice by means of a quorum threshold, which triggers rapid implementation of the decision [18,60]. Although the colony will usually choose the site which reaches quorum first, this does not mean that the colony as a whole must ""satisfice accepting the first nest surpassing some minimum standard. Using quality-dependent initiation (in Temnothorax ants) or modulation (in honeybees) of the recruitment process leading to the attainment of a quorum, the colony in effect carries out a concurrent but indirect collective comparison process, which may implement optimal decision-making through the actions of partly-informed individuals [61]. This ensures that the nest to reach a quorum first is also likely to be the best option, even when there is an array of possible alternatives [16,42]. Thus without the individuals using a ""best-of-n"" comparison strategy, the colony is able to solve a ""best-of-n"" challenge [16,62]."	1	Direct comparison of alternatives is seen in a range of animals and contexts, including foraging in scrub jays and humans [8,52], mate choice in bower-birds and dance-flies [53,#CITATION_TAG] and shell assessment by hermit crabs [55]. A best-of-n comparison strategy would maximise decision accuracy [2], so why do neither individual bees nor ants appear to use this strategy when foraging or choosing a new home? One possibility is that multiple comparisons are too cognitively complex for ant and bee brains. However, small insects including bees are competent at related cognitive processes, including contextual learning, discrimination between stimuli and associative recall [56].	D
CCT26	"First, ants could use a comparison strategy, in which ants that have visited both nests would compare their qualities and recruit nestmates only to the better one [20]. Second, ants visiting just one nest could determine how long they hesitate before recruiting nestmates (recruitment latency) based on the nest quality [20]. A combination of these two mechanisms has been used as the basis of several decision models [18,[21][22][23][24]. Although lone T. rugatulus ant workers are capable of comparing the attributes of nest-sites which are very close together [25], the evidence for individual ants making direct comparisons between nests during colony emigration is weak [26], and furthermore, ant colonies are able to choose a distant good nest over a nearby poor nest, when recruitment latency differences would be expected to be cancelled out by travel time (Fig. 1a) [26,27]. The third possible mechanism of choice is a sequential search strategy, based on a very simple rule of thumb, a ""threshold rule by which an ant assesses a nest against her own fixed quality threshold, and either accepts the nest and begins recruitment, or rejects it and continues searching [26]. Qualitydependent recruitment latency has been demonstrated empirically only when colonies were presented with a single new nest and were not required to make a choice [20,22,24,#CITATION_TAG]. Robinson et al. [26] hypothesized that these apparent recruitment latency effects could emerge as a by-product of a threshold rule, because ants that find a low-quality nest will tend to reject it and continue searching, whereas ants that find a high quality nest will tend to accept it and begin recruitment. In addition, Robinson et al. [26] hypothesized that the apparent comparison phenomenon in which ants that have visited equidistant poor and good nests usually recruit only to the good nest (Fig. 1b; [20]) can be explained more parsimoniously with a threshold rule in which the poor nest is rejected and forgotten, then the good nest is discovered and accepted, rather than requiring individual ants to perform the more cognitively complex task of remembering and comparing the qualities of different nests. We aim to test the hypothesis that this simple parsimonious mechanism (the threshold rule) is sufficient to reproduce observed empirical patterns of collective decision-making."	0	"A combination of these two mechanisms has been used as the basis of several decision models [18,[21][22][23][24]. Although lone T. rugatulus ant workers are capable of comparing the attributes of nest-sites which are very close together [25], the evidence for individual ants making direct comparisons between nests during colony emigration is weak [26], and furthermore, ant colonies are able to choose a distant good nest over a nearby poor nest, when recruitment latency differences would be expected to be cancelled out by travel time (Fig. 1a) [26,27]. The third possible mechanism of choice is a sequential search strategy, based on a very simple rule of thumb, a ""threshold rule by which an ant assesses a nest against her own fixed quality threshold, and either accepts the nest and begins recruitment, or rejects it and continues searching [26]. Qualitydependent recruitment latency has been demonstrated empirically only when colonies were presented with a single new nest and were not required to make a choice [20,22,24,#CITATION_TAG]. Robinson et al. [26] hypothesized that these apparent recruitment latency effects could emerge as a by-product of a threshold rule, because ants that find a low-quality nest will tend to reject it and continue searching, whereas ants that find a high quality nest will tend to accept it and begin recruitment. In addition, Robinson et al. [26] hypothesized that the apparent comparison phenomenon in which ants that have visited equidistant poor and good nests usually recruit only to the good nest (Fig. 1b; [20]) can be explained more parsimoniously with a threshold rule in which the poor nest is rejected and forgotten, then the good nest is discovered and accepted, rather than requiring individual ants to perform the more cognitively complex task of remembering and comparing the qualities of different nests. We aim to test the hypothesis that this simple parsimonious mechanism (the threshold rule) is sufficient to reproduce observed empirical patterns of collective decision-making."	t
CCT27	"Collective decisions are also made in other contexts, such as choice of foraging site. Here again, comparisons of sites by individuals seems to play little role. Foraging honeybees do not compare food sources [43], nor do they compare the waggle-dances of recruiters at the hive [44]. Rather, multiple sites ""compete"" for foragers, with bees foraging more persistently at high quality sites and recruiting to them more energetically [43,45]. Foragers can also directly inhibit recruitment if they perceive danger at a particular food source by the use of ""stop-signals"" directed at bees recruiting to that source [46]. In trail-laying ants and bees, pheromone trails to better foraging sites are more strongly reinforced and this again leads to a collective choice without any necessity for individuals to visit multiple sites [#CITATION_TAG,48]. Just as for nest-site choice, foraging recruitment can either be graded (laying more pheromone to a better food source, e.g. [47,49]) or a binary decision (all-or-nothing recruitment, e.g. [50,51])."	1	"Foraging honeybees do not compare food sources [43], nor do they compare the waggle-dances of recruiters at the hive [44]. Rather, multiple sites ""compete"" for foragers, with bees foraging more persistently at high quality sites and recruiting to them more energetically [43,45]. Foragers can also directly inhibit recruitment if they perceive danger at a particular food source by the use of ""stop-signals"" directed at bees recruiting to that source [46]. In trail-laying ants and bees, pheromone trails to better foraging sites are more strongly reinforced and this again leads to a collective choice without any necessity for individuals to visit multiple sites [#CITATION_TAG,48]. Just as for nest-site choice, foraging recruitment can either be graded (laying more pheromone to a better food source, e.g. [47,49]) or a binary decision (all-or-nothing recruitment, e.g. [50,51])."	a
CCT28	"A colony emigration by rock ants begins with scouts searching for and assessing new sites. Successful scouts recruit nest-mates using tandem running, in which an informed ant leads another to the new site [17]. When the number of ants at a site reaches a ""quorum threshold the ants switch to rapid transport behaviour to carry the brood, queen and remaining nest-mates to the new nest [18]. Ant colonies discriminate between nest sites on the basis of a range of attributes including cavity dimensions, light level and entrance width [16,#CITATION_TAG]. Three possible mechanisms by which the colony collectively chooses the better of two nests have been proposed: i) comparison ii) recruitment latency iii) threshold rule."	0	"A colony emigration by rock ants begins with scouts searching for and assessing new sites. Successful scouts recruit nest-mates using tandem running, in which an informed ant leads another to the new site [17]. When the number of ants at a site reaches a ""quorum threshold the ants switch to rapid transport behaviour to carry the brood, queen and remaining nest-mates to the new nest [18]. Ant colonies discriminate between nest sites on the basis of a range of attributes including cavity dimensions, light level and entrance width [16,#CITATION_TAG]. Three possible mechanisms by which the colony collectively chooses the better of two nests have been proposed: i) comparison ii) recruitment latency iii) threshold rule."	 
CCT29	"Our simulated ants have no memory of previously visited nests, and yet behaviour previously described as ""comparison"" still emerges in our simulations (Table 2). This clearly shows that empirical data of this sort cannot be used as evidence that an animal is really remembering and comparing. The decision process we propose is ""memoryless"" in the sense that individual ants do not have to remember previously visited alternatives during their search for an acceptable nest. Our model deals only with the decision process up to the point at which an ant accepts a nest. After that point, real ants clearly do use memory of nest location in order to recruit nest-mates to that nest by tandemrunning [20]. Recruitment is the most easily identifiable action indicating commitment, but ants that have accepted a nest may also act on their commitment by making repeat visits to the nest [26,#CITATION_TAG]. By making repeat visits, ants are able to assess nest area more accurately [37] and would also contribute to the accumulation of a quorum at their chosen nest, causing the switch to rapid nest-mate carrying behaviour [18]. Memory is therefore an important part of the implementation of the decision, but ants following the threshold rule do not need to invest in remembering the qualities or locations of multiple nests during the decisionmaking process. S1). For two nests present, either site is equally likely to be discovered first. Nest rediscovery probability r = 0.7 (estimated from data, see Text S1, Table S1). The reduced effect of site A""s quality on expected decision time is robust to variations in site B""s quality, except where this becomes low (see Fig. S1). doi:10.1371/journal.pone.0019981.g006 [20] with permission of Springer Science and Business Media. Recruitment latencies to the poor nest are significantly greater in four of six colonies (generalised logrank test). (G-L) Simulated recruitment latencies, nests presented separately. Recruitment latencies to the poor nest are significantly greater. Empirical number of ants is matched for each colony. Sample graphs are shown; running 100 replicates of each gives the same pattern of results, with significant differences between recruitment latencies in 95% (Colony 5) or 100% (Colonies 1and 6) of simulations. (M-R) Simulated recruitment latencies, nests presented together. There are no longer any significant differences between recruitment latencies. Empirical number of ants is matched for each colony. Sample graphs are shown; running 100 replicates of each gives the same pattern of results, with no significant difference between recruitment latencies in 96% (Colony 1), 93% (Colony 2), 90% (Colony 3) 90% (Colony 4), 96% (Colony 5) 93% (Colony 6) of simulations. doi:10.1371/journal.pone.0019981.g005"	0	"The decision process we propose is ""memoryless"" in the sense that individual ants do not have to remember previously visited alternatives during their search for an acceptable nest. Our model deals only with the decision process up to the point at which an ant accepts a nest. After that point, real ants clearly do use memory of nest location in order to recruit nest-mates to that nest by tandemrunning [20]. Recruitment is the most easily identifiable action indicating commitment, but ants that have accepted a nest may also act on their commitment by making repeat visits to the nest [26,#CITATION_TAG]. By making repeat visits, ants are able to assess nest area more accurately [37] and would also contribute to the accumulation of a quorum at their chosen nest, causing the switch to rapid nest-mate carrying behaviour [18]. Memory is therefore an important part of the implementation of the decision, but ants following the threshold rule do not need to invest in remembering the qualities or locations of multiple nests during the decisionmaking process. S1)."	i
CCT30	Social animals make collective decisions between available options, particularly about where the group spends its time. When making a shared collective decision, a group faces the challenges of integrating information from multiple individuals and managing the different decision-preferences of group members #CITATION_TAG. Such decisions are influenced by individual information, conflicts of interest and time-constraints [12,13]. To understand how a collective decision is reached, the rules followed by contributing members of the group must be identified [14]. Emigrating social insects are a good model system for the study of collective decisionmaking, because all members share the aim of coming to a consensus about a new, good nest site as soon as possible, but the information about available site quality is distributed very unevenly within the colony [15,16]. To investigate the mechanism of decision making, we used models of, and experiments on, emigrating cavity-nesting rock ants, Temnothorax albipennis.	0	Social animals make collective decisions between available options, particularly about where the group spends its time. When making a shared collective decision, a group faces the challenges of integrating information from multiple individuals and managing the different decision-preferences of group members #CITATION_TAG. Such decisions are influenced by individual information, conflicts of interest and time-constraints [12,13]. To understand how a collective decision is reached, the rules followed by contributing members of the group must be identified [14]. Emigrating social insects are a good model system for the study of collective decisionmaking, because all members share the aim of coming to a consensus about a new, good nest site as soon as possible, but the information about available site quality is distributed very unevenly within the colony [15,16].	h
CCT31	"Collective decisions are also made in other contexts, such as choice of foraging site. Here again, comparisons of sites by individuals seems to play little role. Foraging honeybees do not compare food sources #CITATION_TAG, nor do they compare the waggle-dances of recruiters at the hive [44]. Rather, multiple sites ""compete"" for foragers, with bees foraging more persistently at high quality sites and recruiting to them more energetically [43,45]. Foragers can also directly inhibit recruitment if they perceive danger at a particular food source by the use of ""stop-signals"" directed at bees recruiting to that source [46]. In trail-laying ants and bees, pheromone trails to better foraging sites are more strongly reinforced and this again leads to a collective choice without any necessity for individuals to visit multiple sites [47,48]. Just as for nest-site choice, foraging recruitment can either be graded (laying more pheromone to a better food source, e.g. [47,49]) or a binary decision (all-or-nothing recruitment, e.g. [50,51])."	1	"Collective decisions are also made in other contexts, such as choice of foraging site. Here again, comparisons of sites by individuals seems to play little role. Foraging honeybees do not compare food sources #CITATION_TAG, nor do they compare the waggle-dances of recruiters at the hive [44]. Rather, multiple sites ""compete"" for foragers, with bees foraging more persistently at high quality sites and recruiting to them more energetically [43,45]. Foragers can also directly inhibit recruitment if they perceive danger at a particular food source by the use of ""stop-signals"" directed at bees recruiting to that source [46]. In trail-laying ants and bees, pheromone trails to better foraging sites are more strongly reinforced and this again leads to a collective choice without any necessity for individuals to visit multiple sites [47,48]."	r
CCT32	"Direct comparison of alternatives is seen in a range of animals and contexts, including foraging in scrub jays and humans [8,52], mate choice in bower-birds and dance-flies [53,54] and shell assessment by hermit crabs [55]. A best-of-n comparison strategy would maximise decision accuracy [2], so why do neither individual bees nor ants appear to use this strategy when foraging or choosing a new home? One possibility is that multiple comparisons are too cognitively complex for ant and bee brains. However, small insects including bees are competent at related cognitive processes, including contextual learning, discrimination between stimuli and associative recall [56]. Male dance-flies compare the size of potential mates before choosing [54], and there is evidence to suggest that honeybee workers are capable of comparative evaluation of flowers [57] and that lone T. rugatulus ant workers are capable of comparing the attributes of nest-sites which are very close together [25]. There may, therefore, be reasons other than cognitive constraints for why relying on individual best-of-n comparisons to inform collective choices does not appear to have evolved as a decision mechanism in bees or ants. One possible reason is that during their evolutionary history the ants have typically been faced with decisions about whether to accept a single option at a time, rather than simultaneously having information about multiple options, and this has shaped the evolution of their decision process [7]. Another possible reason is the potential speed advantage of avoiding a sampling period. Sampling periods can be costly [2,7] and pose the mathematically complex problem of deciding how long to sample for before starting the decision process #CITATION_TAG. Avoiding best-of-n comparisons allows a potentially vulnerable colony to select the first nest encountered, if it is good enough. Perhaps even more important is distributing the decision-making process, relying less on information-processing by a single individual; rather allowing the decision to emerge from a collective process to which even partly-informed individuals can contribute. In this colony-level cognition, the relevant information about the environment is represented within the individuals in a colony, their actions and interactions. At the collective level this generates new information: which nest the colony should choose [59]. In both bees and ants, the information held by individuals is integrated into a colony choice by means of a quorum threshold, which triggers rapid implementation of the decision [18,60]. Although the colony will usually choose the site which reaches quorum first, this does not mean that the colony as a whole must ""satisfice accepting the first nest surpassing some minimum standard. Using quality-dependent initiation (in Temnothorax ants) or modulation (in honeybees) of the recruitment process leading to the attainment of a quorum, the colony in effect carries out a concurrent but indirect collective comparison process, which may implement optimal decision-making through the actions of partly-informed individuals [61]. This ensures that the nest to reach a quorum first is also likely to be the best option, even when there is an array of possible alternatives [16,42]. Thus without the individuals using a ""best-of-n"" comparison strategy, the colony is able to solve a ""best-of-n"" challenge [16,62]."	0	There may, therefore, be reasons other than cognitive constraints for why relying on individual best-of-n comparisons to inform collective choices does not appear to have evolved as a decision mechanism in bees or ants. One possible reason is that during their evolutionary history the ants have typically been faced with decisions about whether to accept a single option at a time, rather than simultaneously having information about multiple options, and this has shaped the evolution of their decision process [7]. Another possible reason is the potential speed advantage of avoiding a sampling period. Sampling periods can be costly [2,7] and pose the mathematically complex problem of deciding how long to sample for before starting the decision process #CITATION_TAG. Avoiding best-of-n comparisons allows a potentially vulnerable colony to select the first nest encountered, if it is good enough. Perhaps even more important is distributing the decision-making process, relying less on information-processing by a single individual; rather allowing the decision to emerge from a collective process to which even partly-informed individuals can contribute. In this colony-level cognition, the relevant information about the environment is represented within the individuals in a colony, their actions and interactions.	 
CCT33	"Direct comparison of alternatives is seen in a range of animals and contexts, including foraging in scrub jays and humans [8,52], mate choice in bower-birds and dance-flies [53,54] and shell assessment by hermit crabs #CITATION_TAG. A best-of-n comparison strategy would maximise decision accuracy [2], so why do neither individual bees nor ants appear to use this strategy when foraging or choosing a new home? One possibility is that multiple comparisons are too cognitively complex for ant and bee brains. However, small insects including bees are competent at related cognitive processes, including contextual learning, discrimination between stimuli and associative recall [56]. Male dance-flies compare the size of potential mates before choosing [54], and there is evidence to suggest that honeybee workers are capable of comparative evaluation of flowers [57] and that lone T. rugatulus ant workers are capable of comparing the attributes of nest-sites which are very close together [25]. There may, therefore, be reasons other than cognitive constraints for why relying on individual best-of-n comparisons to inform collective choices does not appear to have evolved as a decision mechanism in bees or ants. One possible reason is that during their evolutionary history the ants have typically been faced with decisions about whether to accept a single option at a time, rather than simultaneously having information about multiple options, and this has shaped the evolution of their decision process [7]. Another possible reason is the potential speed advantage of avoiding a sampling period. Sampling periods can be costly [2,7] and pose the mathematically complex problem of deciding how long to sample for before starting the decision process [58]. Avoiding best-of-n comparisons allows a potentially vulnerable colony to select the first nest encountered, if it is good enough. Perhaps even more important is distributing the decision-making process, relying less on information-processing by a single individual; rather allowing the decision to emerge from a collective process to which even partly-informed individuals can contribute. In this colony-level cognition, the relevant information about the environment is represented within the individuals in a colony, their actions and interactions. At the collective level this generates new information: which nest the colony should choose [59]. In both bees and ants, the information held by individuals is integrated into a colony choice by means of a quorum threshold, which triggers rapid implementation of the decision [18,60]. Although the colony will usually choose the site which reaches quorum first, this does not mean that the colony as a whole must ""satisfice accepting the first nest surpassing some minimum standard. Using quality-dependent initiation (in Temnothorax ants) or modulation (in honeybees) of the recruitment process leading to the attainment of a quorum, the colony in effect carries out a concurrent but indirect collective comparison process, which may implement optimal decision-making through the actions of partly-informed individuals [61]. This ensures that the nest to reach a quorum first is also likely to be the best option, even when there is an array of possible alternatives [16,42]. Thus without the individuals using a ""best-of-n"" comparison strategy, the colony is able to solve a ""best-of-n"" challenge [16,62]."	1	Direct comparison of alternatives is seen in a range of animals and contexts, including foraging in scrub jays and humans [8,52], mate choice in bower-birds and dance-flies [53,54] and shell assessment by hermit crabs #CITATION_TAG. A best-of-n comparison strategy would maximise decision accuracy [2], so why do neither individual bees nor ants appear to use this strategy when foraging or choosing a new home? One possibility is that multiple comparisons are too cognitively complex for ant and bee brains. However, small insects including bees are competent at related cognitive processes, including contextual learning, discrimination between stimuli and associative recall [56].	D
CCT34	"Direct comparison of alternatives is seen in a range of animals and contexts, including foraging in scrub jays and humans [8,52], mate choice in bower-birds and dance-flies [53,54] and shell assessment by hermit crabs [55]. A best-of-n comparison strategy would maximise decision accuracy [2], so why do neither individual bees nor ants appear to use this strategy when foraging or choosing a new home? One possibility is that multiple comparisons are too cognitively complex for ant and bee brains. However, small insects including bees are competent at related cognitive processes, including contextual learning, discrimination between stimuli and associative recall #CITATION_TAG. Male dance-flies compare the size of potential mates before choosing [54], and there is evidence to suggest that honeybee workers are capable of comparative evaluation of flowers [57] and that lone T. rugatulus ant workers are capable of comparing the attributes of nest-sites which are very close together [25]. There may, therefore, be reasons other than cognitive constraints for why relying on individual best-of-n comparisons to inform collective choices does not appear to have evolved as a decision mechanism in bees or ants. One possible reason is that during their evolutionary history the ants have typically been faced with decisions about whether to accept a single option at a time, rather than simultaneously having information about multiple options, and this has shaped the evolution of their decision process [7]. Another possible reason is the potential speed advantage of avoiding a sampling period. Sampling periods can be costly [2,7] and pose the mathematically complex problem of deciding how long to sample for before starting the decision process [58]. Avoiding best-of-n comparisons allows a potentially vulnerable colony to select the first nest encountered, if it is good enough. Perhaps even more important is distributing the decision-making process, relying less on information-processing by a single individual; rather allowing the decision to emerge from a collective process to which even partly-informed individuals can contribute. In this colony-level cognition, the relevant information about the environment is represented within the individuals in a colony, their actions and interactions. At the collective level this generates new information: which nest the colony should choose [59]. In both bees and ants, the information held by individuals is integrated into a colony choice by means of a quorum threshold, which triggers rapid implementation of the decision [18,60]. Although the colony will usually choose the site which reaches quorum first, this does not mean that the colony as a whole must ""satisfice accepting the first nest surpassing some minimum standard. Using quality-dependent initiation (in Temnothorax ants) or modulation (in honeybees) of the recruitment process leading to the attainment of a quorum, the colony in effect carries out a concurrent but indirect collective comparison process, which may implement optimal decision-making through the actions of partly-informed individuals [61]. This ensures that the nest to reach a quorum first is also likely to be the best option, even when there is an array of possible alternatives [16,42]. Thus without the individuals using a ""best-of-n"" comparison strategy, the colony is able to solve a ""best-of-n"" challenge [16,62]."	0	Direct comparison of alternatives is seen in a range of animals and contexts, including foraging in scrub jays and humans [8,52], mate choice in bower-birds and dance-flies [53,54] and shell assessment by hermit crabs [55]. A best-of-n comparison strategy would maximise decision accuracy [2], so why do neither individual bees nor ants appear to use this strategy when foraging or choosing a new home? One possibility is that multiple comparisons are too cognitively complex for ant and bee brains. However, small insects including bees are competent at related cognitive processes, including contextual learning, discrimination between stimuli and associative recall #CITATION_TAG. Male dance-flies compare the size of potential mates before choosing [54], and there is evidence to suggest that honeybee workers are capable of comparative evaluation of flowers [57] and that lone T. rugatulus ant workers are capable of comparing the attributes of nest-sites which are very close together [25]. There may, therefore, be reasons other than cognitive constraints for why relying on individual best-of-n comparisons to inform collective choices does not appear to have evolved as a decision mechanism in bees or ants. One possible reason is that during their evolutionary history the ants have typically been faced with decisions about whether to accept a single option at a time, rather than simultaneously having information about multiple options, and this has shaped the evolution of their decision process [7].	e
CCT35	"Direct comparison of alternatives is seen in a range of animals and contexts, including foraging in scrub jays and humans [8,52], mate choice in bower-birds and dance-flies [53,54] and shell assessment by hermit crabs [55]. A best-of-n comparison strategy would maximise decision accuracy [2], so why do neither individual bees nor ants appear to use this strategy when foraging or choosing a new home? One possibility is that multiple comparisons are too cognitively complex for ant and bee brains. However, small insects including bees are competent at related cognitive processes, including contextual learning, discrimination between stimuli and associative recall [56]. Male dance-flies compare the size of potential mates before choosing [54], and there is evidence to suggest that honeybee workers are capable of comparative evaluation of flowers #CITATION_TAG and that lone T. rugatulus ant workers are capable of comparing the attributes of nest-sites which are very close together [25]. There may, therefore, be reasons other than cognitive constraints for why relying on individual best-of-n comparisons to inform collective choices does not appear to have evolved as a decision mechanism in bees or ants. One possible reason is that during their evolutionary history the ants have typically been faced with decisions about whether to accept a single option at a time, rather than simultaneously having information about multiple options, and this has shaped the evolution of their decision process [7]. Another possible reason is the potential speed advantage of avoiding a sampling period. Sampling periods can be costly [2,7] and pose the mathematically complex problem of deciding how long to sample for before starting the decision process [58]. Avoiding best-of-n comparisons allows a potentially vulnerable colony to select the first nest encountered, if it is good enough. Perhaps even more important is distributing the decision-making process, relying less on information-processing by a single individual; rather allowing the decision to emerge from a collective process to which even partly-informed individuals can contribute. In this colony-level cognition, the relevant information about the environment is represented within the individuals in a colony, their actions and interactions. At the collective level this generates new information: which nest the colony should choose [59]. In both bees and ants, the information held by individuals is integrated into a colony choice by means of a quorum threshold, which triggers rapid implementation of the decision [18,60]. Although the colony will usually choose the site which reaches quorum first, this does not mean that the colony as a whole must ""satisfice accepting the first nest surpassing some minimum standard. Using quality-dependent initiation (in Temnothorax ants) or modulation (in honeybees) of the recruitment process leading to the attainment of a quorum, the colony in effect carries out a concurrent but indirect collective comparison process, which may implement optimal decision-making through the actions of partly-informed individuals [61]. This ensures that the nest to reach a quorum first is also likely to be the best option, even when there is an array of possible alternatives [16,42]. Thus without the individuals using a ""best-of-n"" comparison strategy, the colony is able to solve a ""best-of-n"" challenge [16,62]."	1	A best-of-n comparison strategy would maximise decision accuracy [2], so why do neither individual bees nor ants appear to use this strategy when foraging or choosing a new home? One possibility is that multiple comparisons are too cognitively complex for ant and bee brains. However, small insects including bees are competent at related cognitive processes, including contextual learning, discrimination between stimuli and associative recall [56]. Male dance-flies compare the size of potential mates before choosing [54], and there is evidence to suggest that honeybee workers are capable of comparative evaluation of flowers #CITATION_TAG and that lone T. rugatulus ant workers are capable of comparing the attributes of nest-sites which are very close together [25]. There may, therefore, be reasons other than cognitive constraints for why relying on individual best-of-n comparisons to inform collective choices does not appear to have evolved as a decision mechanism in bees or ants. One possible reason is that during their evolutionary history the ants have typically been faced with decisions about whether to accept a single option at a time, rather than simultaneously having information about multiple options, and this has shaped the evolution of their decision process [7]. Another possible reason is the potential speed advantage of avoiding a sampling period.	 
CCT36	"A further possible advantage of avoiding individual direct comparisons is that it would remove the risk of ""irrational"" decision behaviour at the individual level [26], associated with comparative, relative evaluation of options such as best-of-n, or sequential comparisons. Individuals following our proposed threshold rule make an absolute evaluation of quality, and this evaluation of one option is not influenced by the other alternatives available, in contrast to the context-dependent decision-making used by many other animals including humans [8,63,64]. Although at the collective level, a comparison between options is effectively being made, a non-comparative individual-level mechanism for this decision could protect the colony from irrationality in decisionmaking. For example, emigrating T. albipennis colonies follow rational transitivity patterns in decision making [16] and in the related species T. curvispinosus and T. rugatulus, colonies seem to be immune to irrational distractor effects from irrelevant alternatives [25,#CITATION_TAG]. Although work on T. rugatulus suggests that this collective immunity can emerge even if individuals are susceptible to distractor effects provided their individual contribution to the collective decision is small [25], our work suggests this collective rationality can emerge without depending on low numbers of ants visiting both nests -if individual ants follow the threshold rule, then the colony can escape these irrational comparison behaviours."	3	"A further possible advantage of avoiding individual direct comparisons is that it would remove the risk of ""irrational"" decision behaviour at the individual level [26], associated with comparative, relative evaluation of options such as best-of-n, or sequential comparisons. Individuals following our proposed threshold rule make an absolute evaluation of quality, and this evaluation of one option is not influenced by the other alternatives available, in contrast to the context-dependent decision-making used by many other animals including humans [8,63,64]. Although at the collective level, a comparison between options is effectively being made, a non-comparative individual-level mechanism for this decision could protect the colony from irrationality in decisionmaking. For example, emigrating T. albipennis colonies follow rational transitivity patterns in decision making [16] and in the related species T. curvispinosus and T. rugatulus, colonies seem to be immune to irrational distractor effects from irrelevant alternatives [25,#CITATION_TAG]. Although work on T. rugatulus suggests that this collective immunity can emerge even if individuals are susceptible to distractor effects provided their individual contribution to the collective decision is small [25], our work suggests this collective rationality can emerge without depending on low numbers of ants visiting both nests -if individual ants follow the threshold rule, then the colony can escape these irrational comparison behaviours."	 
CCT37	"Using an absolute evaluation method does have a potential drawback, if the acceptance threshold is not appropriate to the environment. When used in individual decision making (e.g. during mate choice in cockroaches, [9]) the success of this sort of sequential search strategy will be highly sensitive to the threshold used. For example, if all available options are poor quality, an animal may reject them all, and end up worse off than if it had accepted a poor option. In contrast, when this strategy is used for group decision making, variation in acceptance thresholds across the group provides protection against this sensitivity. If all options are poor quality, some low-threshold individuals will still accept one, allowing the group to make a choice. Similarly, intra-colony variation in task response thresholds promotes effective division of labour in social insect colonies, with more individuals engaging in a particular task when the stimulus for that task increases #CITATION_TAG[67][68]. Our model assumes that individual thresholds are fixed over the time-scale of the emigration process, however further flexibility would be available if acceptance thresholds were updated based on experience over the course of an individual""s life-time [69,70]. Flexible task thresholds promote flexible division of labour in social insect colonies [71][72][73]. How much acceptance threshold variation actually occurs within a colony, and whether ant acceptance thresholds are fixed throughout life or changed by experience, are issues remaining to be explored."	0	"For example, if all available options are poor quality, an animal may reject them all, and end up worse off than if it had accepted a poor option. In contrast, when this strategy is used for group decision making, variation in acceptance thresholds across the group provides protection against this sensitivity. If all options are poor quality, some low-threshold individuals will still accept one, allowing the group to make a choice. Similarly, intra-colony variation in task response thresholds promotes effective division of labour in social insect colonies, with more individuals engaging in a particular task when the stimulus for that task increases #CITATION_TAG[67][68]. Our model assumes that individual thresholds are fixed over the time-scale of the emigration process, however further flexibility would be available if acceptance thresholds were updated based on experience over the course of an individual""s life-time [69,70]. Flexible task thresholds promote flexible division of labour in social insect colonies [71][72][73]. How much acceptance threshold variation actually occurs within a colony, and whether ant acceptance thresholds are fixed throughout life or changed by experience, are issues remaining to be explored."	a
CCT38	"Using an absolute evaluation method does have a potential drawback, if the acceptance threshold is not appropriate to the environment. When used in individual decision making (e.g. during mate choice in cockroaches, [9]) the success of this sort of sequential search strategy will be highly sensitive to the threshold used. For example, if all available options are poor quality, an animal may reject them all, and end up worse off than if it had accepted a poor option. In contrast, when this strategy is used for group decision making, variation in acceptance thresholds across the group provides protection against this sensitivity. If all options are poor quality, some low-threshold individuals will still accept one, allowing the group to make a choice. Similarly, intra-colony variation in task response thresholds promotes effective division of labour in social insect colonies, with more individuals engaging in a particular task when the stimulus for that task increases [66]#CITATION_TAG[68]. Our model assumes that individual thresholds are fixed over the time-scale of the emigration process, however further flexibility would be available if acceptance thresholds were updated based on experience over the course of an individual""s life-time [69,70]. Flexible task thresholds promote flexible division of labour in social insect colonies [71][72][73]. How much acceptance threshold variation actually occurs within a colony, and whether ant acceptance thresholds are fixed throughout life or changed by experience, are issues remaining to be explored."	0	"For example, if all available options are poor quality, an animal may reject them all, and end up worse off than if it had accepted a poor option. In contrast, when this strategy is used for group decision making, variation in acceptance thresholds across the group provides protection against this sensitivity. If all options are poor quality, some low-threshold individuals will still accept one, allowing the group to make a choice. Similarly, intra-colony variation in task response thresholds promotes effective division of labour in social insect colonies, with more individuals engaging in a particular task when the stimulus for that task increases [66]#CITATION_TAG[68]. Our model assumes that individual thresholds are fixed over the time-scale of the emigration process, however further flexibility would be available if acceptance thresholds were updated based on experience over the course of an individual""s life-time [69,70]. Flexible task thresholds promote flexible division of labour in social insect colonies [71][72][73]. How much acceptance threshold variation actually occurs within a colony, and whether ant acceptance thresholds are fixed throughout life or changed by experience, are issues remaining to be explored."	a
CCT39	"Using an absolute evaluation method does have a potential drawback, if the acceptance threshold is not appropriate to the environment. When used in individual decision making (e.g. during mate choice in cockroaches, [9]) the success of this sort of sequential search strategy will be highly sensitive to the threshold used. For example, if all available options are poor quality, an animal may reject them all, and end up worse off than if it had accepted a poor option. In contrast, when this strategy is used for group decision making, variation in acceptance thresholds across the group provides protection against this sensitivity. If all options are poor quality, some low-threshold individuals will still accept one, allowing the group to make a choice. Similarly, intra-colony variation in task response thresholds promotes effective division of labour in social insect colonies, with more individuals engaging in a particular task when the stimulus for that task increases [66][67]#CITATION_TAG. Our model assumes that individual thresholds are fixed over the time-scale of the emigration process, however further flexibility would be available if acceptance thresholds were updated based on experience over the course of an individual""s life-time [69,70]. Flexible task thresholds promote flexible division of labour in social insect colonies [71][72][73]. How much acceptance threshold variation actually occurs within a colony, and whether ant acceptance thresholds are fixed throughout life or changed by experience, are issues remaining to be explored."	0	"For example, if all available options are poor quality, an animal may reject them all, and end up worse off than if it had accepted a poor option. In contrast, when this strategy is used for group decision making, variation in acceptance thresholds across the group provides protection against this sensitivity. If all options are poor quality, some low-threshold individuals will still accept one, allowing the group to make a choice. Similarly, intra-colony variation in task response thresholds promotes effective division of labour in social insect colonies, with more individuals engaging in a particular task when the stimulus for that task increases [66][67]#CITATION_TAG. Our model assumes that individual thresholds are fixed over the time-scale of the emigration process, however further flexibility would be available if acceptance thresholds were updated based on experience over the course of an individual""s life-time [69,70]. Flexible task thresholds promote flexible division of labour in social insect colonies [71][72][73]. How much acceptance threshold variation actually occurs within a colony, and whether ant acceptance thresholds are fixed throughout life or changed by experience, are issues remaining to be explored."	a
CCT40	"Using an absolute evaluation method does have a potential drawback, if the acceptance threshold is not appropriate to the environment. When used in individual decision making (e.g. during mate choice in cockroaches, [9]) the success of this sort of sequential search strategy will be highly sensitive to the threshold used. For example, if all available options are poor quality, an animal may reject them all, and end up worse off than if it had accepted a poor option. In contrast, when this strategy is used for group decision making, variation in acceptance thresholds across the group provides protection against this sensitivity. If all options are poor quality, some low-threshold individuals will still accept one, allowing the group to make a choice. Similarly, intra-colony variation in task response thresholds promotes effective division of labour in social insect colonies, with more individuals engaging in a particular task when the stimulus for that task increases [66][67][68]. Our model assumes that individual thresholds are fixed over the time-scale of the emigration process, however further flexibility would be available if acceptance thresholds were updated based on experience over the course of an individual""s life-time [69,#CITATION_TAG]. Flexible task thresholds promote flexible division of labour in social insect colonies [71][72][73]. How much acceptance threshold variation actually occurs within a colony, and whether ant acceptance thresholds are fixed throughout life or changed by experience, are issues remaining to be explored."	0	"In contrast, when this strategy is used for group decision making, variation in acceptance thresholds across the group provides protection against this sensitivity. If all options are poor quality, some low-threshold individuals will still accept one, allowing the group to make a choice. Similarly, intra-colony variation in task response thresholds promotes effective division of labour in social insect colonies, with more individuals engaging in a particular task when the stimulus for that task increases [66][67][68]. Our model assumes that individual thresholds are fixed over the time-scale of the emigration process, however further flexibility would be available if acceptance thresholds were updated based on experience over the course of an individual""s life-time [69,#CITATION_TAG]. Flexible task thresholds promote flexible division of labour in social insect colonies [71][72][73]. How much acceptance threshold variation actually occurs within a colony, and whether ant acceptance thresholds are fixed throughout life or changed by experience, are issues remaining to be explored."	d
CCT41	"Using an absolute evaluation method does have a potential drawback, if the acceptance threshold is not appropriate to the environment. When used in individual decision making (e.g. during mate choice in cockroaches, [9]) the success of this sort of sequential search strategy will be highly sensitive to the threshold used. For example, if all available options are poor quality, an animal may reject them all, and end up worse off than if it had accepted a poor option. In contrast, when this strategy is used for group decision making, variation in acceptance thresholds across the group provides protection against this sensitivity. If all options are poor quality, some low-threshold individuals will still accept one, allowing the group to make a choice. Similarly, intra-colony variation in task response thresholds promotes effective division of labour in social insect colonies, with more individuals engaging in a particular task when the stimulus for that task increases [66][67][68]. Our model assumes that individual thresholds are fixed over the time-scale of the emigration process, however further flexibility would be available if acceptance thresholds were updated based on experience over the course of an individual""s life-time [69,70]. Flexible task thresholds promote flexible division of labour in social insect colonies [71][72]#CITATION_TAG. How much acceptance threshold variation actually occurs within a colony, and whether ant acceptance thresholds are fixed throughout life or changed by experience, are issues remaining to be explored."	3	"If all options are poor quality, some low-threshold individuals will still accept one, allowing the group to make a choice. Similarly, intra-colony variation in task response thresholds promotes effective division of labour in social insect colonies, with more individuals engaging in a particular task when the stimulus for that task increases [66][67][68]. Our model assumes that individual thresholds are fixed over the time-scale of the emigration process, however further flexibility would be available if acceptance thresholds were updated based on experience over the course of an individual""s life-time [69,70]. Flexible task thresholds promote flexible division of labour in social insect colonies [71][72]#CITATION_TAG. How much acceptance threshold variation actually occurs within a colony, and whether ant acceptance thresholds are fixed throughout life or changed by experience, are issues remaining to be explored."	e
CCT42	"Collective decisions are also made in other contexts, such as choice of foraging site. Here again, comparisons of sites by individuals seems to play little role. Foraging honeybees do not compare food sources [43], nor do they compare the waggle-dances of recruiters at the hive [44]. Rather, multiple sites ""compete"" for foragers, with bees foraging more persistently at high quality sites and recruiting to them more energetically [43,45]. Foragers can also directly inhibit recruitment if they perceive danger at a particular food source by the use of ""stop-signals"" directed at bees recruiting to that source [46]. In trail-laying ants and bees, pheromone trails to better foraging sites are more strongly reinforced and this again leads to a collective choice without any necessity for individuals to visit multiple sites [47,#CITATION_TAG]. Just as for nest-site choice, foraging recruitment can either be graded (laying more pheromone to a better food source, e.g. [47,49]) or a binary decision (all-or-nothing recruitment, e.g. [50,51])."	1	"Foraging honeybees do not compare food sources [43], nor do they compare the waggle-dances of recruiters at the hive [44]. Rather, multiple sites ""compete"" for foragers, with bees foraging more persistently at high quality sites and recruiting to them more energetically [43,45]. Foragers can also directly inhibit recruitment if they perceive danger at a particular food source by the use of ""stop-signals"" directed at bees recruiting to that source [46]. In trail-laying ants and bees, pheromone trails to better foraging sites are more strongly reinforced and this again leads to a collective choice without any necessity for individuals to visit multiple sites [47,#CITATION_TAG]. Just as for nest-site choice, foraging recruitment can either be graded (laying more pheromone to a better food source, e.g. [47,49]) or a binary decision (all-or-nothing recruitment, e.g. [50,51])."	a
CCT43	The second previously-proposed mechanism, quality dependent recruitment latencies, is an attractive idea -it does not rely on comparisons, and self-organised decisions can emerge because ants finding a poor nest delay before recruiting, effectively giving others that have found a good nest a head-start in the recruitment process. The initial advantage is amplified by recruitment, and this can be shown to be sufficient to account for collective choice [24]. In both the threshold rule and the recruitment latency hypothesis, a scout makes a probabilistic, quality-dependent decision about whether to recruit each time she visits a nest. The difference between these mechanisms come from the assumptions made about what the scout does after leaving the nest, and how this results in a colony decision-mechanism. In our threshold rule, the ant either commits or continues searching. In the recruitment latency hypothesis, ants which do not immediately start recruiting may subsequently recruit, with a quality-dependent latency. In the original formulation of this idea [20] it is mentioned that ants might discover other nests during this latent period, but it is not suggested that the latency is actually a result of the search for other nests. Searching for alternatives has a more prominent role in later versions of the recruitment latency model [24] making it more similar to our threshold model, however, the idea of simple quality-dependent recruitment latencies functioning as a choice mechanism still appears often in discussions of collective decisionmaking [11,#CITATION_TAG,39]. There are two empirical problems with such a mechanism. Firstly, colonies are able to choose a good nest, even when it is so much further away than a poor nest that travel time should cancel out differences in recruitment latency [27]. Secondly, all empirical evidence for quality-dependent recruitment latencies comes from studies offering a colony just one new nest [20,22,24,28]. When recruitment latencies are measured in multiple nest experiments, no quality-dependent recruitment latencies differences are observed [this study and 26]. We used modelling to investigate these empirical results. Our simulation and analytical results reproduce quality-dependent recruitment latency in a single-nest experiment, but show that the presence of an extra nest disrupts the quality-dependence of the latency to commitment and recruitment (Figs. 5-6). When a single poor nest is offered, acceptance times in the model will be geometrically distributed, with few ants accepting the site early due to rare assessment errors or low individual-thresholds, and the remainder continuing to re-assess the same site until they eventually decide it is good enough. When a second higher quality site is introduced, the same small proportion of ants will accept the poor site early due to low-threshold or assessment error, but the remainder will now tend to discover the alternative, superior site, and recruit to this quickly on average because of its increased quality. The same pattern would be observed for a threshold-rule with direct comparison (see Text S1), and also for a quality-dependent recruitment latency-rule, if it is assumed that ants search for alternatives during the latency period and have a high probability of finding other sites [20]. However, these alternative models are less parsimonious, requiring ants to remember the qualities and/or locations of visited sites and evaluate this in making subsequent comparisons or use the information to decide when and where to start recruiting. These results also clearly demonstrate that a phenomenon observed when only one option is available, cannot be assumed to function in the same way when choosing between multiple options (see also [7]). Another well-studied example of collective decision-making is nest-site choice by swarming honeybees (Apis mellifera). Like ant colonies, bee swarms are able to choose between different nest sites, and individual bees do not need to have visited multiple sites for the swarm to be able to choose between them [40]. However, the way the scouts act on this information differs between the two groups. The ants seem to use a binary decision process to either accept that nest or continue searching. Ants accepting a nest recruit others, causing a positive feedback process, but ant scouts do not modulate their recruitment according to nest quality, e.g. by recruiting at a faster rate or for longer to a higher quality nest [20,26]. In contrast, bees use a graded process, whereby scouts initially discovering a new nest-site almost always recruit [41], but the duration and rate of the recruiting waggle-dances are dependent on nest quality [42]. This means that more recruits are brought to better nest-sites, leading to a positive feedback process usually resulting in a unanimous choice of the better site [42]. One possible reason for this difference in strategy could be differences in nest availability: if suitable honeybee nest sites are relatively rare, then it might be better for scouts to avoid ever rejecting a potential nest outright.	0	In our threshold rule, the ant either commits or continues searching. In the recruitment latency hypothesis, ants which do not immediately start recruiting may subsequently recruit, with a quality-dependent latency. In the original formulation of this idea [20] it is mentioned that ants might discover other nests during this latent period, but it is not suggested that the latency is actually a result of the search for other nests. Searching for alternatives has a more prominent role in later versions of the recruitment latency model [24] making it more similar to our threshold model, however, the idea of simple quality-dependent recruitment latencies functioning as a choice mechanism still appears often in discussions of collective decisionmaking [11,#CITATION_TAG,39]. There are two empirical problems with such a mechanism. Firstly, colonies are able to choose a good nest, even when it is so much further away than a poor nest that travel time should cancel out differences in recruitment latency [27]. Secondly, all empirical evidence for quality-dependent recruitment latencies comes from studies offering a colony just one new nest [20,22,24,28].	n
CCT44	"Collective decisions are also made in other contexts, such as choice of foraging site. Here again, comparisons of sites by individuals seems to play little role. Foraging honeybees do not compare food sources [43], nor do they compare the waggle-dances of recruiters at the hive [44]. Rather, multiple sites ""compete"" for foragers, with bees foraging more persistently at high quality sites and recruiting to them more energetically [43,45]. Foragers can also directly inhibit recruitment if they perceive danger at a particular food source by the use of ""stop-signals"" directed at bees recruiting to that source #CITATION_TAG. In trail-laying ants and bees, pheromone trails to better foraging sites are more strongly reinforced and this again leads to a collective choice without any necessity for individuals to visit multiple sites [47,48]. Just as for nest-site choice, foraging recruitment can either be graded (laying more pheromone to a better food source, e.g. [47,49]) or a binary decision (all-or-nothing recruitment, e.g. [50,51])."	0	"Here again, comparisons of sites by individuals seems to play little role. Foraging honeybees do not compare food sources [43], nor do they compare the waggle-dances of recruiters at the hive [44]. Rather, multiple sites ""compete"" for foragers, with bees foraging more persistently at high quality sites and recruiting to them more energetically [43,45]. Foragers can also directly inhibit recruitment if they perceive danger at a particular food source by the use of ""stop-signals"" directed at bees recruiting to that source #CITATION_TAG. In trail-laying ants and bees, pheromone trails to better foraging sites are more strongly reinforced and this again leads to a collective choice without any necessity for individuals to visit multiple sites [47,48]. Just as for nest-site choice, foraging recruitment can either be graded (laying more pheromone to a better food source, e.g. [47,49]) or a binary decision (all-or-nothing recruitment, e.g. [50,51])."	g
CCT45	"Collective decisions are also made in other contexts, such as choice of foraging site. Here again, comparisons of sites by individuals seems to play little role. Foraging honeybees do not compare food sources [43], nor do they compare the waggle-dances of recruiters at the hive [44]. Rather, multiple sites ""compete"" for foragers, with bees foraging more persistently at high quality sites and recruiting to them more energetically [43,#CITATION_TAG]. Foragers can also directly inhibit recruitment if they perceive danger at a particular food source by the use of ""stop-signals"" directed at bees recruiting to that source [46]. In trail-laying ants and bees, pheromone trails to better foraging sites are more strongly reinforced and this again leads to a collective choice without any necessity for individuals to visit multiple sites [47,48]. Just as for nest-site choice, foraging recruitment can either be graded (laying more pheromone to a better food source, e.g. [47,49]) or a binary decision (all-or-nothing recruitment, e.g. [50,51])."	1	"Collective decisions are also made in other contexts, such as choice of foraging site. Here again, comparisons of sites by individuals seems to play little role. Foraging honeybees do not compare food sources [43], nor do they compare the waggle-dances of recruiters at the hive [44]. Rather, multiple sites ""compete"" for foragers, with bees foraging more persistently at high quality sites and recruiting to them more energetically [43,#CITATION_TAG]. Foragers can also directly inhibit recruitment if they perceive danger at a particular food source by the use of ""stop-signals"" directed at bees recruiting to that source [46]. In trail-laying ants and bees, pheromone trails to better foraging sites are more strongly reinforced and this again leads to a collective choice without any necessity for individuals to visit multiple sites [47,48]. Just as for nest-site choice, foraging recruitment can either be graded (laying more pheromone to a better food source, e.g. [47,49]) or a binary decision (all-or-nothing recruitment, e.g. [50,51])."	h
CCT46	"Three-New-Nests"" Experiment. Six T. albipennis colonies were collected from the Dorset coast, England, June-July 2009. Colonies were queenright and contained 80-200 workers and brood of all stages. Colonies were housed in artificial nests [27] and provided with water ad libitum and honey solution and Drosophila melanogaster weekly. We used these colonies to investigate decision-making when a colony was offered a choice of three new nests. Six trials were performed, each with a new colony. One day prior to an emigration trial, we attached an RFID microtransponder (50065006120 mm) with a unique ID to the thorax of every worker ant in the colony [32,33] and housed the colony in a nest formed of a hexagonal glass slide (edge length = 30 mm), a 1.5 mm cardboard perimeter (cavity area 1496 mm ) and an acetate lid with a central entrance hole (1.5 mm diameter) to avoid introducing directional bias. We performed trials in a circular arena with Fluon-coated sides, the floor of which was cleaned with water and alcohol between trials. Three new hexagonal nests with the same dimensions as the original nest were placed in the arena (Fig. 1c). Two nests had clear acetate lids and one had a red filter covering the cavity area, making the nest appear relatively dark to the ants #CITATION_TAG. Ant colonies choose dark over light nests [19]. The position of the good nest was interchanged between trials. The new nests had 1.5 mm wide entrances in the side facing the centre of the arena, over which RFID readers (PharmaSeq, Inc., NJ) were placed vertically. A trial began with the original nest placed in the centre of the arena and then destroyed by removing the lid. The RFID readers detected ants entering and leaving the new nests [86% tag read rate, 26] and we used handheld RFID readers to read the tags on tandem-running ants (94% tag read rate) as they crossed half-way lines (Fig. 1c). The identity of the leader and follower was thus recorded and the direction of the tandem run was noted. This procedure does not disrupt tandem runs [26]. The time at which the transport by carrying of a nest-mate or a brood item first occurred to each nest was recorded (i.e. the time at which the quorum threshold was reached). Once nest-mate transport has commenced, the RFID system becomes less reliable [26], because nest-mates are transported in such a way as to block the RFID tag. We therefore focused our analysis on searching and recruitment by tandem-running during the pre-quorum period. We observed emigrations until complete (old nest empty of brood and workers) and recorded the nest choice of the colony after 24 hours. Colonies were considered to have split if brood was present in two or more nests."	0	One day prior to an emigration trial, we attached an RFID microtransponder (50065006120 mm) with a unique ID to the thorax of every worker ant in the colony [32,33] and housed the colony in a nest formed of a hexagonal glass slide (edge length = 30 mm), a 1.5 mm cardboard perimeter (cavity area 1496 mm ) and an acetate lid with a central entrance hole (1.5 mm diameter) to avoid introducing directional bias. We performed trials in a circular arena with Fluon-coated sides, the floor of which was cleaned with water and alcohol between trials. Three new hexagonal nests with the same dimensions as the original nest were placed in the arena (Fig. 1c). Two nests had clear acetate lids and one had a red filter covering the cavity area, making the nest appear relatively dark to the ants #CITATION_TAG. Ant colonies choose dark over light nests [19]. The position of the good nest was interchanged between trials. The new nests had 1.5 mm wide entrances in the side facing the centre of the arena, over which RFID readers (PharmaSeq, Inc., NJ) were placed vertically.	 
CCT47	"We can subdivide comparison behaviour into two types that can aid decision-making: best-of-n comparisons and sequential comparisons. Best-of-n comparison mechanisms are characterised by a sampling period, and preferential return to the best option #CITATION_TAG. We conducted a multiple-nest experiment to test directly if real ants show these behaviours. Neither is observed. In contrast, the results support the threshold model: if the first nest they encountered was of a high quality, the ants started recruitment immediately without continuing to sample, and those ants which had the opportunity to compare nests did not act on this information by preferential or more direct return to better nests. Sequential comparisons occur when each time an animal encounters a new option, it compares the new option to its memory of previously encountered options and is more likely to accept the new one if it compares favourably. This is similar to the threshold model, but thresholds are influenced by experience. In one variant of this, individuals sample several options and then accept the next option they encounter which exceeds the quality of all previous options. This strategy can be shown to provide the optimal solution to the ""secretary problem""; a sequential search problem in which previously encountered options are subsequently unavailable [36]. We modelled a sequential comparison mechanism (see Text S1) to compare with our threshold model. The results show that this type of comparison model predicts similar recruitment latency results to our threshold model. We therefore cannot rule out this sequential comparison mechanism, but note that it is a less parsimonious solution. Our threshold model is sufficient to explain the data without invoking memory and comparison during the decision process."	5	We can subdivide comparison behaviour into two types that can aid decision-making: best-of-n comparisons and sequential comparisons. Best-of-n comparison mechanisms are characterised by a sampling period, and preferential return to the best option #CITATION_TAG. We conducted a multiple-nest experiment to test directly if real ants show these behaviours. Neither is observed. In contrast, the results support the threshold model: if the first nest they encountered was of a high quality, the ants started recruitment immediately without continuing to sample, and those ants which had the opportunity to compare nests did not act on this information by preferential or more direct return to better nests.	e
CCT48	"We can subdivide comparison behaviour into two types that can aid decision-making: best-of-n comparisons and sequential comparisons. Best-of-n comparison mechanisms are characterised by a sampling period, and preferential return to the best option [35]. We conducted a multiple-nest experiment to test directly if real ants show these behaviours. Neither is observed. In contrast, the results support the threshold model: if the first nest they encountered was of a high quality, the ants started recruitment immediately without continuing to sample, and those ants which had the opportunity to compare nests did not act on this information by preferential or more direct return to better nests. Sequential comparisons occur when each time an animal encounters a new option, it compares the new option to its memory of previously encountered options and is more likely to accept the new one if it compares favourably. This is similar to the threshold model, but thresholds are influenced by experience. In one variant of this, individuals sample several options and then accept the next option they encounter which exceeds the quality of all previous options. This strategy can be shown to provide the optimal solution to the ""secretary problem""; a sequential search problem in which previously encountered options are subsequently unavailable #CITATION_TAG. We modelled a sequential comparison mechanism (see Text S1) to compare with our threshold model. The results show that this type of comparison model predicts similar recruitment latency results to our threshold model. We therefore cannot rule out this sequential comparison mechanism, but note that it is a less parsimonious solution. Our threshold model is sufficient to explain the data without invoking memory and comparison during the decision process."	5	"Sequential comparisons occur when each time an animal encounters a new option, it compares the new option to its memory of previously encountered options and is more likely to accept the new one if it compares favourably. This is similar to the threshold model, but thresholds are influenced by experience. In one variant of this, individuals sample several options and then accept the next option they encounter which exceeds the quality of all previous options. This strategy can be shown to provide the optimal solution to the ""secretary problem""; a sequential search problem in which previously encountered options are subsequently unavailable #CITATION_TAG. We modelled a sequential comparison mechanism (see Text S1) to compare with our threshold model. The results show that this type of comparison model predicts similar recruitment latency results to our threshold model. We therefore cannot rule out this sequential comparison mechanism, but note that it is a less parsimonious solution."	a
CCT49	The second previously-proposed mechanism, quality dependent recruitment latencies, is an attractive idea -it does not rely on comparisons, and self-organised decisions can emerge because ants finding a poor nest delay before recruiting, effectively giving others that have found a good nest a head-start in the recruitment process. The initial advantage is amplified by recruitment, and this can be shown to be sufficient to account for collective choice [24]. In both the threshold rule and the recruitment latency hypothesis, a scout makes a probabilistic, quality-dependent decision about whether to recruit each time she visits a nest. The difference between these mechanisms come from the assumptions made about what the scout does after leaving the nest, and how this results in a colony decision-mechanism. In our threshold rule, the ant either commits or continues searching. In the recruitment latency hypothesis, ants which do not immediately start recruiting may subsequently recruit, with a quality-dependent latency. In the original formulation of this idea [20] it is mentioned that ants might discover other nests during this latent period, but it is not suggested that the latency is actually a result of the search for other nests. Searching for alternatives has a more prominent role in later versions of the recruitment latency model [24] making it more similar to our threshold model, however, the idea of simple quality-dependent recruitment latencies functioning as a choice mechanism still appears often in discussions of collective decisionmaking [11,38,#CITATION_TAG]. There are two empirical problems with such a mechanism. Firstly, colonies are able to choose a good nest, even when it is so much further away than a poor nest that travel time should cancel out differences in recruitment latency [27]. Secondly, all empirical evidence for quality-dependent recruitment latencies comes from studies offering a colony just one new nest [20,22,24,28]. When recruitment latencies are measured in multiple nest experiments, no quality-dependent recruitment latencies differences are observed [this study and 26]. We used modelling to investigate these empirical results. Our simulation and analytical results reproduce quality-dependent recruitment latency in a single-nest experiment, but show that the presence of an extra nest disrupts the quality-dependence of the latency to commitment and recruitment (Figs. 5-6). When a single poor nest is offered, acceptance times in the model will be geometrically distributed, with few ants accepting the site early due to rare assessment errors or low individual-thresholds, and the remainder continuing to re-assess the same site until they eventually decide it is good enough. When a second higher quality site is introduced, the same small proportion of ants will accept the poor site early due to low-threshold or assessment error, but the remainder will now tend to discover the alternative, superior site, and recruit to this quickly on average because of its increased quality. The same pattern would be observed for a threshold-rule with direct comparison (see Text S1), and also for a quality-dependent recruitment latency-rule, if it is assumed that ants search for alternatives during the latency period and have a high probability of finding other sites [20]. However, these alternative models are less parsimonious, requiring ants to remember the qualities and/or locations of visited sites and evaluate this in making subsequent comparisons or use the information to decide when and where to start recruiting. These results also clearly demonstrate that a phenomenon observed when only one option is available, cannot be assumed to function in the same way when choosing between multiple options (see also [7]). Another well-studied example of collective decision-making is nest-site choice by swarming honeybees (Apis mellifera). Like ant colonies, bee swarms are able to choose between different nest sites, and individual bees do not need to have visited multiple sites for the swarm to be able to choose between them [40]. However, the way the scouts act on this information differs between the two groups. The ants seem to use a binary decision process to either accept that nest or continue searching. Ants accepting a nest recruit others, causing a positive feedback process, but ant scouts do not modulate their recruitment according to nest quality, e.g. by recruiting at a faster rate or for longer to a higher quality nest [20,26]. In contrast, bees use a graded process, whereby scouts initially discovering a new nest-site almost always recruit [41], but the duration and rate of the recruiting waggle-dances are dependent on nest quality [42]. This means that more recruits are brought to better nest-sites, leading to a positive feedback process usually resulting in a unanimous choice of the better site [42]. One possible reason for this difference in strategy could be differences in nest availability: if suitable honeybee nest sites are relatively rare, then it might be better for scouts to avoid ever rejecting a potential nest outright.	1	In our threshold rule, the ant either commits or continues searching. In the recruitment latency hypothesis, ants which do not immediately start recruiting may subsequently recruit, with a quality-dependent latency. In the original formulation of this idea [20] it is mentioned that ants might discover other nests during this latent period, but it is not suggested that the latency is actually a result of the search for other nests. Searching for alternatives has a more prominent role in later versions of the recruitment latency model [24] making it more similar to our threshold model, however, the idea of simple quality-dependent recruitment latencies functioning as a choice mechanism still appears often in discussions of collective decisionmaking [11,38,#CITATION_TAG]. There are two empirical problems with such a mechanism. Firstly, colonies are able to choose a good nest, even when it is so much further away than a poor nest that travel time should cancel out differences in recruitment latency [27]. Secondly, all empirical evidence for quality-dependent recruitment latencies comes from studies offering a colony just one new nest [20,22,24,28].	n
CCT50	The second previously-proposed mechanism, quality dependent recruitment latencies, is an attractive idea -it does not rely on comparisons, and self-organised decisions can emerge because ants finding a poor nest delay before recruiting, effectively giving others that have found a good nest a head-start in the recruitment process. The initial advantage is amplified by recruitment, and this can be shown to be sufficient to account for collective choice [24]. In both the threshold rule and the recruitment latency hypothesis, a scout makes a probabilistic, quality-dependent decision about whether to recruit each time she visits a nest. The difference between these mechanisms come from the assumptions made about what the scout does after leaving the nest, and how this results in a colony decision-mechanism. In our threshold rule, the ant either commits or continues searching. In the recruitment latency hypothesis, ants which do not immediately start recruiting may subsequently recruit, with a quality-dependent latency. In the original formulation of this idea [20] it is mentioned that ants might discover other nests during this latent period, but it is not suggested that the latency is actually a result of the search for other nests. Searching for alternatives has a more prominent role in later versions of the recruitment latency model [24] making it more similar to our threshold model, however, the idea of simple quality-dependent recruitment latencies functioning as a choice mechanism still appears often in discussions of collective decisionmaking [11,38,39]. There are two empirical problems with such a mechanism. Firstly, colonies are able to choose a good nest, even when it is so much further away than a poor nest that travel time should cancel out differences in recruitment latency [27]. Secondly, all empirical evidence for quality-dependent recruitment latencies comes from studies offering a colony just one new nest [20,22,24,28]. When recruitment latencies are measured in multiple nest experiments, no quality-dependent recruitment latencies differences are observed [this study and 26]. We used modelling to investigate these empirical results. Our simulation and analytical results reproduce quality-dependent recruitment latency in a single-nest experiment, but show that the presence of an extra nest disrupts the quality-dependence of the latency to commitment and recruitment (Figs. 5-6). When a single poor nest is offered, acceptance times in the model will be geometrically distributed, with few ants accepting the site early due to rare assessment errors or low individual-thresholds, and the remainder continuing to re-assess the same site until they eventually decide it is good enough. When a second higher quality site is introduced, the same small proportion of ants will accept the poor site early due to low-threshold or assessment error, but the remainder will now tend to discover the alternative, superior site, and recruit to this quickly on average because of its increased quality. The same pattern would be observed for a threshold-rule with direct comparison (see Text S1), and also for a quality-dependent recruitment latency-rule, if it is assumed that ants search for alternatives during the latency period and have a high probability of finding other sites [20]. However, these alternative models are less parsimonious, requiring ants to remember the qualities and/or locations of visited sites and evaluate this in making subsequent comparisons or use the information to decide when and where to start recruiting. These results also clearly demonstrate that a phenomenon observed when only one option is available, cannot be assumed to function in the same way when choosing between multiple options (see also [7]). Another well-studied example of collective decision-making is nest-site choice by swarming honeybees (Apis mellifera). Like ant colonies, bee swarms are able to choose between different nest sites, and individual bees do not need to have visited multiple sites for the swarm to be able to choose between them #CITATION_TAG. However, the way the scouts act on this information differs between the two groups. The ants seem to use a binary decision process to either accept that nest or continue searching. Ants accepting a nest recruit others, causing a positive feedback process, but ant scouts do not modulate their recruitment according to nest quality, e.g. by recruiting at a faster rate or for longer to a higher quality nest [20,26]. In contrast, bees use a graded process, whereby scouts initially discovering a new nest-site almost always recruit [41], but the duration and rate of the recruiting waggle-dances are dependent on nest quality [42]. This means that more recruits are brought to better nest-sites, leading to a positive feedback process usually resulting in a unanimous choice of the better site [42]. One possible reason for this difference in strategy could be differences in nest availability: if suitable honeybee nest sites are relatively rare, then it might be better for scouts to avoid ever rejecting a potential nest outright.	1	However, these alternative models are less parsimonious, requiring ants to remember the qualities and/or locations of visited sites and evaluate this in making subsequent comparisons or use the information to decide when and where to start recruiting. These results also clearly demonstrate that a phenomenon observed when only one option is available, cannot be assumed to function in the same way when choosing between multiple options (see also [7]). Another well-studied example of collective decision-making is nest-site choice by swarming honeybees (Apis mellifera). Like ant colonies, bee swarms are able to choose between different nest sites, and individual bees do not need to have visited multiple sites for the swarm to be able to choose between them #CITATION_TAG. However, the way the scouts act on this information differs between the two groups. The ants seem to use a binary decision process to either accept that nest or continue searching. Ants accepting a nest recruit others, causing a positive feedback process, but ant scouts do not modulate their recruitment according to nest quality, e.g. by recruiting at a faster rate or for longer to a higher quality nest [20,26].	e
CCT51	The second previously-proposed mechanism, quality dependent recruitment latencies, is an attractive idea -it does not rely on comparisons, and self-organised decisions can emerge because ants finding a poor nest delay before recruiting, effectively giving others that have found a good nest a head-start in the recruitment process. The initial advantage is amplified by recruitment, and this can be shown to be sufficient to account for collective choice [24]. In both the threshold rule and the recruitment latency hypothesis, a scout makes a probabilistic, quality-dependent decision about whether to recruit each time she visits a nest. The difference between these mechanisms come from the assumptions made about what the scout does after leaving the nest, and how this results in a colony decision-mechanism. In our threshold rule, the ant either commits or continues searching. In the recruitment latency hypothesis, ants which do not immediately start recruiting may subsequently recruit, with a quality-dependent latency. In the original formulation of this idea [20] it is mentioned that ants might discover other nests during this latent period, but it is not suggested that the latency is actually a result of the search for other nests. Searching for alternatives has a more prominent role in later versions of the recruitment latency model [24] making it more similar to our threshold model, however, the idea of simple quality-dependent recruitment latencies functioning as a choice mechanism still appears often in discussions of collective decisionmaking [11,38,39]. There are two empirical problems with such a mechanism. Firstly, colonies are able to choose a good nest, even when it is so much further away than a poor nest that travel time should cancel out differences in recruitment latency [27]. Secondly, all empirical evidence for quality-dependent recruitment latencies comes from studies offering a colony just one new nest [20,22,24,28]. When recruitment latencies are measured in multiple nest experiments, no quality-dependent recruitment latencies differences are observed [this study and 26]. We used modelling to investigate these empirical results. Our simulation and analytical results reproduce quality-dependent recruitment latency in a single-nest experiment, but show that the presence of an extra nest disrupts the quality-dependence of the latency to commitment and recruitment (Figs. 5-6). When a single poor nest is offered, acceptance times in the model will be geometrically distributed, with few ants accepting the site early due to rare assessment errors or low individual-thresholds, and the remainder continuing to re-assess the same site until they eventually decide it is good enough. When a second higher quality site is introduced, the same small proportion of ants will accept the poor site early due to low-threshold or assessment error, but the remainder will now tend to discover the alternative, superior site, and recruit to this quickly on average because of its increased quality. The same pattern would be observed for a threshold-rule with direct comparison (see Text S1), and also for a quality-dependent recruitment latency-rule, if it is assumed that ants search for alternatives during the latency period and have a high probability of finding other sites [20]. However, these alternative models are less parsimonious, requiring ants to remember the qualities and/or locations of visited sites and evaluate this in making subsequent comparisons or use the information to decide when and where to start recruiting. These results also clearly demonstrate that a phenomenon observed when only one option is available, cannot be assumed to function in the same way when choosing between multiple options (see also [7]). Another well-studied example of collective decision-making is nest-site choice by swarming honeybees (Apis mellifera). Like ant colonies, bee swarms are able to choose between different nest sites, and individual bees do not need to have visited multiple sites for the swarm to be able to choose between them [40]. However, the way the scouts act on this information differs between the two groups. The ants seem to use a binary decision process to either accept that nest or continue searching. Ants accepting a nest recruit others, causing a positive feedback process, but ant scouts do not modulate their recruitment according to nest quality, e.g. by recruiting at a faster rate or for longer to a higher quality nest [20,26]. In contrast, bees use a graded process, whereby scouts initially discovering a new nest-site almost always recruit #CITATION_TAG, but the duration and rate of the recruiting waggle-dances are dependent on nest quality [42]. This means that more recruits are brought to better nest-sites, leading to a positive feedback process usually resulting in a unanimous choice of the better site [42]. One possible reason for this difference in strategy could be differences in nest availability: if suitable honeybee nest sites are relatively rare, then it might be better for scouts to avoid ever rejecting a potential nest outright.	1	However, the way the scouts act on this information differs between the two groups. The ants seem to use a binary decision process to either accept that nest or continue searching. Ants accepting a nest recruit others, causing a positive feedback process, but ant scouts do not modulate their recruitment according to nest quality, e.g. by recruiting at a faster rate or for longer to a higher quality nest [20,26]. In contrast, bees use a graded process, whereby scouts initially discovering a new nest-site almost always recruit #CITATION_TAG, but the duration and rate of the recruiting waggle-dances are dependent on nest quality [42]. This means that more recruits are brought to better nest-sites, leading to a positive feedback process usually resulting in a unanimous choice of the better site [42]. One possible reason for this difference in strategy could be differences in nest availability: if suitable honeybee nest sites are relatively rare, then it might be better for scouts to avoid ever rejecting a potential nest outright.	r
CCT52	"Collective decisions are also made in other contexts, such as choice of foraging site. Here again, comparisons of sites by individuals seems to play little role. Foraging honeybees do not compare food sources [43], nor do they compare the waggle-dances of recruiters at the hive #CITATION_TAG. Rather, multiple sites ""compete"" for foragers, with bees foraging more persistently at high quality sites and recruiting to them more energetically [43,45]. Foragers can also directly inhibit recruitment if they perceive danger at a particular food source by the use of ""stop-signals"" directed at bees recruiting to that source [46]. In trail-laying ants and bees, pheromone trails to better foraging sites are more strongly reinforced and this again leads to a collective choice without any necessity for individuals to visit multiple sites [47,48]. Just as for nest-site choice, foraging recruitment can either be graded (laying more pheromone to a better food source, e.g. [47,49]) or a binary decision (all-or-nothing recruitment, e.g. [50,51])."	1	"Collective decisions are also made in other contexts, such as choice of foraging site. Here again, comparisons of sites by individuals seems to play little role. Foraging honeybees do not compare food sources [43], nor do they compare the waggle-dances of recruiters at the hive #CITATION_TAG. Rather, multiple sites ""compete"" for foragers, with bees foraging more persistently at high quality sites and recruiting to them more energetically [43,45]. Foragers can also directly inhibit recruitment if they perceive danger at a particular food source by the use of ""stop-signals"" directed at bees recruiting to that source [46]. In trail-laying ants and bees, pheromone trails to better foraging sites are more strongly reinforced and this again leads to a collective choice without any necessity for individuals to visit multiple sites [47,48]."	r
CCT53	"Animals need to make choices between multiple available options at many stages in their life histories, such as during mate selection, foraging, or when deciding where to shelter or to build a nest. The fitness benefits of choosing the best option mean that decision-making strategies will be subject to natural selection. Multiple comparison or ""best of n"" strategies perform most accurately, and are likely to be optimal when searching and sampling costs are low, e.g. on a lek [1,2] and when long-term fitness implications of the decision are high, e.g. in home range selection [3]. In other situations, e.g. during foraging, there can be substantial time costs to making accurate decisions [#CITATION_TAG,5], and these costs can be so great as to make quicker less accurate decisions more efficient [6]. Animals may be best served by using a simpler ""rule of thumb which reduces sampling time, but still ensures the option they choose is good enough. One simple but effective strategy is sequential search in which the animal keeps searching until it finds an option that exceeds a threshold of acceptability [2,7]. This kind of fixedthreshold strategy is used in foraging [8], mate choice [9] and refuge selection [10]. An intermediate strategy is to allow thresholds to be influenced by experience of previous options; in effect this would cause a ""sequential comparison""."	0	"Animals need to make choices between multiple available options at many stages in their life histories, such as during mate selection, foraging, or when deciding where to shelter or to build a nest. The fitness benefits of choosing the best option mean that decision-making strategies will be subject to natural selection. Multiple comparison or ""best of n"" strategies perform most accurately, and are likely to be optimal when searching and sampling costs are low, e.g. on a lek [1,2] and when long-term fitness implications of the decision are high, e.g. in home range selection [3]. In other situations, e.g. during foraging, there can be substantial time costs to making accurate decisions [#CITATION_TAG,5], and these costs can be so great as to make quicker less accurate decisions more efficient [6]. Animals may be best served by using a simpler ""rule of thumb which reduces sampling time, but still ensures the option they choose is good enough. One simple but effective strategy is sequential search in which the animal keeps searching until it finds an option that exceeds a threshold of acceptability [2,7]. This kind of fixedthreshold strategy is used in foraging [8], mate choice [9] and refuge selection [10]."	o
CCT54	"To illustrate these misunderstandings, we will focus on the socalled Screening and Intervention Program for Sensible drinking (SIPS) project in England. Other research on ABI could have been chosen for this purpose but SIPS is a recent and prominent evaluation, with potentially important implications for policy and practice and from which all the necessary points may be made. The project was funded by the UK Department of Health in 2006 following the publication of the Government""s Alcohol Harm Reduction Strategy for England (AHRSE) (19). In a section on Screening and Brief Interventions, the strategy said: "". . . the research evidence on brief interventions draws heavily on small-scale studies carried out outside the UK. More information is needed on the most effective methods of targeted screening and brief interventions, and whether the successes shown in research studies can be replicated within the health system in England. . .. The Department of Health will set up a number of pilot schemes by Q1/2005 to test how best to use a variety of models of targeted screening and brief intervention in primary and secondary healthcare settings, focusing particularly on value for money and mainstreaming"" [ (19), p. 43]. This led eventually to the funding of SIPS which consisted of a pragmatic, cluster-randomized controlled trial in each of three settings: PHC, accident and emergency services, and the criminal justice system. At the time of writing, only the results for the PHC trial have been published #CITATION_TAG and the other two trials will not be covered here. As was clear in the Government""s remit for this research stated above, the trials looked at issues to do with optimal forms of screening as well as effects of different modes of ABI but only the latter is of interest here."	4	". .. The Department of Health will set up a number of pilot schemes by Q1/2005 to test how best to use a variety of models of targeted screening and brief intervention in primary and secondary healthcare settings, focusing particularly on value for money and mainstreaming"" [ (19), p. 43]. This led eventually to the funding of SIPS which consisted of a pragmatic, cluster-randomized controlled trial in each of three settings: PHC, accident and emergency services, and the criminal justice system. At the time of writing, only the results for the PHC trial have been published #CITATION_TAG and the other two trials will not be covered here. As was clear in the Government""s remit for this research stated above, the trials looked at issues to do with optimal forms of screening as well as effects of different modes of ABI but only the latter is of interest here."	m
CCT55	Control groups in trials of ABI frequently show reductions in mean alcohol consumption from baseline to follow-up and this was certainly the case in the SIPS PHC trial (see Figure 2). In a review of such trials, it was calculated that control group participants reduce their drinking by approximately 20% (#CITATION_TAG,36). A reduction in drinking of this size is larger than overall differences between experimental and control groups at follow-up (2) and it is a reasonable assumption that reductions in control groups of this order may prevent the true effects of ABI from being observed (37). We also saw that the reductions in consumption shown by control group participants in the SIPS trial (or, rather, the increase in the proportion of participants not showing hazardous/harmful drinking -see Figure 2) has been wrongly assumed to have been caused by the control group procedures, i.e., the provision of a PIL and/or the feedback of assessment results. To clarify further why it is a mistake to make this inference, we will now consider other possible reasons for reductions in control group consumption. In recent times, our understanding of these reasons had been greatly assisted by the work of Dr. Jim McCambridge of the London School of Hygiene and Tropical Medicine and his various colleagues.	2	Control groups in trials of ABI frequently show reductions in mean alcohol consumption from baseline to follow-up and this was certainly the case in the SIPS PHC trial (see Figure 2). In a review of such trials, it was calculated that control group participants reduce their drinking by approximately 20% (#CITATION_TAG,36). A reduction in drinking of this size is larger than overall differences between experimental and control groups at follow-up (2) and it is a reasonable assumption that reductions in control groups of this order may prevent the true effects of ABI from being observed (37). We also saw that the reductions in consumption shown by control group participants in the SIPS trial (or, rather, the increase in the proportion of participants not showing hazardous/harmful drinking -see Figure 2) has been wrongly assumed to have been caused by the control group procedures, i.e., the provision of a PIL and/or the feedback of assessment results. To clarify further why it is a mistake to make this inference, we will now consider other possible reasons for reductions in control group consumption.	n
CCT56	"Given that the fallacy of ""proving the null hypothesis"" is taught at an elementary level in courses on research methodology and statistics all over the world, it may be found surprising that such an error is frequently made in relation to the SIPS PHC findings. However, the present author can attest that this error is commonly encountered in commentaries on the SIPS findings in publications of various kinds, in papers given and conversations overheard at scientific conferences and other meetings, and in grant proposals seeking funding to pursue in some way the implications of the misinterpreted SIPS findings. Just one example comes from Pulse, a magazine for health professionals and which claims to be ""at the heart of general practice since 1960"" (#CITATION_TAG). This article is headed, ""Patient leaflet enough to tackle problem drinking, researchers suggest"" and begins ""GPs should give patients with problem drinking a leaflet rather than advise them to reduce their alcohol intake. This is because: ""the SIPS study found informing patients of their drinking levels and offering a leaflet -handed to patients by a practice nurse -was just as effective as giving patient 5-or 10-min of lifestyle counseling."	4	"Given that the fallacy of ""proving the null hypothesis"" is taught at an elementary level in courses on research methodology and statistics all over the world, it may be found surprising that such an error is frequently made in relation to the SIPS PHC findings. However, the present author can attest that this error is commonly encountered in commentaries on the SIPS findings in publications of various kinds, in papers given and conversations overheard at scientific conferences and other meetings, and in grant proposals seeking funding to pursue in some way the implications of the misinterpreted SIPS findings. Just one example comes from Pulse, a magazine for health professionals and which claims to be ""at the heart of general practice since 1960"" (#CITATION_TAG). This article is headed, ""Patient leaflet enough to tackle problem drinking, researchers suggest"" and begins ""GPs should give patients with problem drinking a leaflet rather than advise them to reduce their alcohol intake. This is because: ""the SIPS study found informing patients of their drinking levels and offering a leaflet -handed to patients by a practice nurse -was just as effective as giving patient 5-or 10-min of lifestyle counseling."	s
CCT57	"It should be stressed that the importance of these misunderstandings is not limited to academic debates between scientists in learned journals; they could well affect the future provision of ABI in England and perhaps in other countries. It is well known that there have been considerable difficulties in persuading GPs, nurses, and other healthcare professionals to implement ABI routinely in their practices; there is a copious literature on this problem (#CITATION_TAG) and how it may be redressed (31). In surveys of health professionals\"" attitudes to this work, one of the most commonly encountered obstacles is ""lack of time"" or ""too busy"" (32,33). There has also been resistance in England to the inclusion of ABI in the NHS Quality and Outcomes Framework, under which general practices are reimbursed for preventive activity. This has created considerable pressure on the relevant sections of the Department of Health in London (and now its replacement body for this area of work, Public Health England) to make the interventions that health professionals are being encouraged to implement as short and easy to deliver as possible. So too, given the multitude of demands on their time from a large number of health bodies, it would be expected that many GPs would call for ABI to be whittled down to more manageable forms. In times of austerity, the appeal of shorter, simpler, and less expensive interventions for widespread implementation in practice must be seductive to policy-makers."	0	"It should be stressed that the importance of these misunderstandings is not limited to academic debates between scientists in learned journals; they could well affect the future provision of ABI in England and perhaps in other countries. It is well known that there have been considerable difficulties in persuading GPs, nurses, and other healthcare professionals to implement ABI routinely in their practices; there is a copious literature on this problem (#CITATION_TAG) and how it may be redressed (31). In surveys of health professionals\"" attitudes to this work, one of the most commonly encountered obstacles is ""lack of time"" or ""too busy"" (32,33). There has also been resistance in England to the inclusion of ABI in the NHS Quality and Outcomes Framework, under which general practices are reimbursed for preventive activity. This has created considerable pressure on the relevant sections of the Department of Health in London (and now its replacement body for this area of work, Public Health England) to make the interventions that health professionals are being encouraged to implement as short and easy to deliver as possible."	t
CCT58	As we have seen, despite its apparent shortcomings, NHST continues to be the preferred framework for investigation in much of psychology, psychiatry, and other branches of human science, and is certainly still prevalent in research evaluations of the effectiveness of ABI. (NHST as taught in textbooks today is a hybrid of the Fisher and the Neyman-Pearson approaches and no distinctions between these two approaches will be discussed here.) Opponents of NHST would no doubt attribute the misunderstandings of null findings that we will shortly consider to basic flaws in the logic of NHST (#CITATION_TAG,18).	1	As we have seen, despite its apparent shortcomings, NHST continues to be the preferred framework for investigation in much of psychology, psychiatry, and other branches of human science, and is certainly still prevalent in research evaluations of the effectiveness of ABI. (NHST as taught in textbooks today is a hybrid of the Fisher and the Neyman-Pearson approaches and no distinctions between these two approaches will be discussed here. ) Opponents of NHST would no doubt attribute the misunderstandings of null findings that we will shortly consider to basic flaws in the logic of NHST (#CITATION_TAG,18).	O
CCT59	As we have seen, despite its apparent shortcomings, NHST continues to be the preferred framework for investigation in much of psychology, psychiatry, and other branches of human science, and is certainly still prevalent in research evaluations of the effectiveness of ABI. (NHST as taught in textbooks today is a hybrid of the Fisher and the Neyman-Pearson approaches and no distinctions between these two approaches will be discussed here.) Opponents of NHST would no doubt attribute the misunderstandings of null findings that we will shortly consider to basic flaws in the logic of NHST (17,#CITATION_TAG).	1	As we have seen, despite its apparent shortcomings, NHST continues to be the preferred framework for investigation in much of psychology, psychiatry, and other branches of human science, and is certainly still prevalent in research evaluations of the effectiveness of ABI. (NHST as taught in textbooks today is a hybrid of the Fisher and the Neyman-Pearson approaches and no distinctions between these two approaches will be discussed here. ) Opponents of NHST would no doubt attribute the misunderstandings of null findings that we will shortly consider to basic flaws in the logic of NHST (17,#CITATION_TAG).	O
CCT60	"It should be stressed that the importance of these misunderstandings is not limited to academic debates between scientists in learned journals; they could well affect the future provision of ABI in England and perhaps in other countries. It is well known that there have been considerable difficulties in persuading GPs, nurses, and other healthcare professionals to implement ABI routinely in their practices; there is a copious literature on this problem (30) and how it may be redressed (31). In surveys of health professionals\"" attitudes to this work, one of the most commonly encountered obstacles is ""lack of time"" or ""too busy"" (32,#CITATION_TAG). There has also been resistance in England to the inclusion of ABI in the NHS Quality and Outcomes Framework, under which general practices are reimbursed for preventive activity. This has created considerable pressure on the relevant sections of the Department of Health in London (and now its replacement body for this area of work, Public Health England) to make the interventions that health professionals are being encouraged to implement as short and easy to deliver as possible. So too, given the multitude of demands on their time from a large number of health bodies, it would be expected that many GPs would call for ABI to be whittled down to more manageable forms. In times of austerity, the appeal of shorter, simpler, and less expensive interventions for widespread implementation in practice must be seductive to policy-makers."	0	"It should be stressed that the importance of these misunderstandings is not limited to academic debates between scientists in learned journals; they could well affect the future provision of ABI in England and perhaps in other countries. It is well known that there have been considerable difficulties in persuading GPs, nurses, and other healthcare professionals to implement ABI routinely in their practices; there is a copious literature on this problem (30) and how it may be redressed (31). In surveys of health professionals\"" attitudes to this work, one of the most commonly encountered obstacles is ""lack of time"" or ""too busy"" (32,#CITATION_TAG). There has also been resistance in England to the inclusion of ABI in the NHS Quality and Outcomes Framework, under which general practices are reimbursed for preventive activity. This has created considerable pressure on the relevant sections of the Department of Health in London (and now its replacement body for this area of work, Public Health England) to make the interventions that health professionals are being encouraged to implement as short and easy to deliver as possible. So too, given the multitude of demands on their time from a large number of health bodies, it would be expected that many GPs would call for ABI to be whittled down to more manageable forms."	 
CCT61	"It should be stressed that the importance of these misunderstandings is not limited to academic debates between scientists in learned journals; they could well affect the future provision of ABI in England and perhaps in other countries. It is well known that there have been considerable difficulties in persuading GPs, nurses, and other healthcare professionals to implement ABI routinely in their practices; there is a copious literature on this problem (30) and how it may be redressed (31). In surveys of health professionals\"" attitudes to this work, one of the most commonly encountered obstacles is ""lack of time"" or ""too busy"" (#CITATION_TAG,33). There has also been resistance in England to the inclusion of ABI in the NHS Quality and Outcomes Framework, under which general practices are reimbursed for preventive activity. This has created considerable pressure on the relevant sections of the Department of Health in London (and now its replacement body for this area of work, Public Health England) to make the interventions that health professionals are being encouraged to implement as short and easy to deliver as possible. So too, given the multitude of demands on their time from a large number of health bodies, it would be expected that many GPs would call for ABI to be whittled down to more manageable forms. In times of austerity, the appeal of shorter, simpler, and less expensive interventions for widespread implementation in practice must be seductive to policy-makers."	0	"It should be stressed that the importance of these misunderstandings is not limited to academic debates between scientists in learned journals; they could well affect the future provision of ABI in England and perhaps in other countries. It is well known that there have been considerable difficulties in persuading GPs, nurses, and other healthcare professionals to implement ABI routinely in their practices; there is a copious literature on this problem (30) and how it may be redressed (31). In surveys of health professionals\"" attitudes to this work, one of the most commonly encountered obstacles is ""lack of time"" or ""too busy"" (#CITATION_TAG,33). There has also been resistance in England to the inclusion of ABI in the NHS Quality and Outcomes Framework, under which general practices are reimbursed for preventive activity. This has created considerable pressure on the relevant sections of the Department of Health in London (and now its replacement body for this area of work, Public Health England) to make the interventions that health professionals are being encouraged to implement as short and easy to deliver as possible. So too, given the multitude of demands on their time from a large number of health bodies, it would be expected that many GPs would call for ABI to be whittled down to more manageable forms."	 
CCT62	In more practical terms, in addition to sampling variability and lack of statistical power, there may be many reasons for the failure to observe a statistically significant difference between experimental and control group means. It could be, for example, that the interventions, although shown to be efficacious in randomized controlled trials conducted in ideal research conditions, are not effective in more real-world conditions of routine practice #CITATION_TAG because they have not been faithfully implemented by the practitioners taking part in the trial (27) or because of some other difference between real-world conditions and the ideal research conditions in which efficacy was demonstrated.	2	In more practical terms, in addition to sampling variability and lack of statistical power, there may be many reasons for the failure to observe a statistically significant difference between experimental and control group means. It could be, for example, that the interventions, although shown to be efficacious in randomized controlled trials conducted in ideal research conditions, are not effective in more real-world conditions of routine practice #CITATION_TAG because they have not been faithfully implemented by the practitioners taking part in the trial (27) or because of some other difference between real-world conditions and the ideal research conditions in which efficacy was demonstrated.	t
CCT63	This must be one of the most misunderstood concepts in health care science #CITATION_TAG. It is often thought that because, for example, participants in a trial of an alcohol intervention are recruited at a particularly high point in their alcohol consumption, they make a decision to try to cut down drinking, which is reflected in their lower consumption at follow-up. This is incorrect; regression to the mean is a purely statistical phenomenon with no reference whatever to decisions by trial participants or any other causal factor impinging on the outcome variable of interest.	2	This must be one of the most misunderstood concepts in health care science #CITATION_TAG. It is often thought that because, for example, participants in a trial of an alcohol intervention are recruited at a particularly high point in their alcohol consumption, they make a decision to try to cut down drinking, which is reflected in their lower consumption at follow-up. This is incorrect; regression to the mean is a purely statistical phenomenon with no reference whatever to decisions by trial participants or any other causal factor impinging on the outcome variable of interest.	T
CCT64	If this solution were adopted, when we observed a nonsignificant result from an RCT, it would be possible to conclude that the specific form of ABI being evaluated was ineffective and not worth pursuing further, so that precious resources would not be wasted. On the other hand, we could conclude that it was unclear whether the ABI in question was effective or not and that further research was needed. The difference from the conclusion based on the conventional perspective, however, is that we would already have ruled out the possibility that the intervention was ineffective. [It is also possible that the Bayes Factor could provide evidence for the alternative hypothesis and allow the conclusion that the intervention was effective when the conventional NHST approach had not been able to reject the null hypothesis #CITATION_TAG.] This method could be applied to the non-significant results of trials such as SIPS to reduce uncertainly about and possible misunderstanding of their results. The results of an analysis of SIPS data using the Bayesian approach to null findings will form the basis of a further communication.	1	If this solution were adopted, when we observed a nonsignificant result from an RCT, it would be possible to conclude that the specific form of ABI being evaluated was ineffective and not worth pursuing further, so that precious resources would not be wasted. On the other hand, we could conclude that it was unclear whether the ABI in question was effective or not and that further research was needed. The difference from the conclusion based on the conventional perspective, however, is that we would already have ruled out the possibility that the intervention was ineffective. [It is also possible that the Bayes Factor could provide evidence for the alternative hypothesis and allow the conclusion that the intervention was effective when the conventional NHST approach had not been able to reject the null hypothesis #CITATION_TAG. ] This method could be applied to the non-significant results of trials such as SIPS to reduce uncertainly about and possible misunderstanding of their results. The results of an analysis of SIPS data using the Bayesian approach to null findings will form the basis of a further communication.	 
CCT65	There is, however, a solution to this problem but it means abandoning the NHST handling of null findings in favor of an approach from Bayesian statistics. The Bayesian approach to the problem of interpreting null findings has been developed recently by Dr. Zolt√°n Dienes of the University of Susses (63) and this section will rely heavily on his work. This is not the place to attempt a complete description of Bayesian statistics but good introductions are available (64,#CITATION_TAG), including one by Dienes (66) comparing the Bayesian approach to statistical inference by the orthodox approach.	0	There is, however, a solution to this problem but it means abandoning the NHST handling of null findings in favor of an approach from Bayesian statistics. The Bayesian approach to the problem of interpreting null findings has been developed recently by Dr. Zolt√°n Dienes of the University of Susses (63) and this section will rely heavily on his work. This is not the place to attempt a complete description of Bayesian statistics but good introductions are available (64,#CITATION_TAG), including one by Dienes (66) comparing the Bayesian approach to statistical inference by the orthodox approach.	i
CCT66	There is, however, a solution to this problem but it means abandoning the NHST handling of null findings in favor of an approach from Bayesian statistics. The Bayesian approach to the problem of interpreting null findings has been developed recently by Dr. Zolt√°n Dienes of the University of Susses (63) and this section will rely heavily on his work. This is not the place to attempt a complete description of Bayesian statistics but good introductions are available (#CITATION_TAG,65), including one by Dienes (66) comparing the Bayesian approach to statistical inference by the orthodox approach.	0	There is, however, a solution to this problem but it means abandoning the NHST handling of null findings in favor of an approach from Bayesian statistics. The Bayesian approach to the problem of interpreting null findings has been developed recently by Dr. Zolt√°n Dienes of the University of Susses (63) and this section will rely heavily on his work. This is not the place to attempt a complete description of Bayesian statistics but good introductions are available (#CITATION_TAG,65), including one by Dienes (66) comparing the Bayesian approach to statistical inference by the orthodox approach.	i
CCT67	The possible effects of regression to the mean on control group participants in brief intervention trials were studied empirically by McCambridge and colleagues #CITATION_TAG. These authors gave the AUDIT to a large cohort of university students in New Zealand at baseline and 6 months later, without any attempt to intervene in their drinking. Selecting from this cohort for analysis those individuals with a baseline AUDIT score of 8+, the usual cutpoint for entry to trials of ABI, the observed mean reduction over time was approximately half that obtained in the full sample without selection. When selection was made using a series of higher AUDIT thresholds, the observed reductions in mean alcohol consumption were successively larger. This evidence suggests that a substantial part of the reduction in consumption shown by control groups can be explained by the statistical artifact of regression to the mean.	1	The possible effects of regression to the mean on control group participants in brief intervention trials were studied empirically by McCambridge and colleagues #CITATION_TAG. These authors gave the AUDIT to a large cohort of university students in New Zealand at baseline and 6 months later, without any attempt to intervene in their drinking. Selecting from this cohort for analysis those individuals with a baseline AUDIT score of 8+, the usual cutpoint for entry to trials of ABI, the observed mean reduction over time was approximately half that obtained in the full sample without selection. When selection was made using a series of higher AUDIT thresholds, the observed reductions in mean alcohol consumption were successively larger.	T
CCT68	Dual antiplatelet therapy with aspirin and clopidogrel is associated with a significant reduction in cardiovascular ischemic events after acute coronary syndromes or percutaneous coronary interventions and is recommended in guidelines from the USA [1] and Europe [2]. Clopidogrel is an inactive prodrug that undergoes two oxidative steps involving multiple cytochrome P-450 (CYP) enzymes in its bioactivation to its pharmacologically active metabolite. Among them, CYP2C19, a CYP enzyme whose activity is determined genetically, contributes predominantly to this bioactivation [3,4] and modulates the antiplatelet and therapeutic response to clopidogrel. Patients with loss of function polymorphism in the CYP2C19 gene are less responsive to clopidogrel [5,6], although the importance of this phenomenon remains controversial #CITATION_TAG[8][9][10] and may be limited to the risk of stent thrombosis [11].	0	Dual antiplatelet therapy with aspirin and clopidogrel is associated with a significant reduction in cardiovascular ischemic events after acute coronary syndromes or percutaneous coronary interventions and is recommended in guidelines from the USA [1] and Europe [2]. Clopidogrel is an inactive prodrug that undergoes two oxidative steps involving multiple cytochrome P-450 (CYP) enzymes in its bioactivation to its pharmacologically active metabolite. Among them, CYP2C19, a CYP enzyme whose activity is determined genetically, contributes predominantly to this bioactivation [3,4] and modulates the antiplatelet and therapeutic response to clopidogrel. Patients with loss of function polymorphism in the CYP2C19 gene are less responsive to clopidogrel [5,6], although the importance of this phenomenon remains controversial #CITATION_TAG[8][9][10] and may be limited to the risk of stent thrombosis [11].	i
CCT69	Proton-pump inhibitors (PPIs) are recommended in patients treated with dual antiplatelet therapy who are at high risk of gastrointestinal bleeding [12]. PPIs are metabolized primarily via the CYP2C19 and CYP3A4 isoenzymes [13] and are competitive inhibitors of CYP2C19 activity #CITATION_TAG. However, the contribution of the CYP2C19 isoenzyme to PPI biotransformation and H. pylori eradication rates [15] and the potency of inhibition of CYP2C19 activity [14] vary among different PPIs. CYP2C19 activity appears to affect the response to omeprazole, esomeprazole and lansoprazole [16][17][18] and to be inhibited by these PPIs [14,18]. This does not seem to be the case, at least not to the same extent, with pantoprazole [14,19] and rabeprazole [14,20].	0	Proton-pump inhibitors (PPIs) are recommended in patients treated with dual antiplatelet therapy who are at high risk of gastrointestinal bleeding [12]. PPIs are metabolized primarily via the CYP2C19 and CYP3A4 isoenzymes [13] and are competitive inhibitors of CYP2C19 activity #CITATION_TAG. However, the contribution of the CYP2C19 isoenzyme to PPI biotransformation and H. pylori eradication rates [15] and the potency of inhibition of CYP2C19 activity [14] vary among different PPIs. CYP2C19 activity appears to affect the response to omeprazole, esomeprazole and lansoprazole [16][17][18] and to be inhibited by these PPIs [14,18]. This does not seem to be the case, at least not to the same extent, with pantoprazole [14,19] and rabeprazole [14,20].	P
CCT70	Proton-pump inhibitors (PPIs) are recommended in patients treated with dual antiplatelet therapy who are at high risk of gastrointestinal bleeding [12]. PPIs are metabolized primarily via the CYP2C19 and CYP3A4 isoenzymes [13] and are competitive inhibitors of CYP2C19 activity [14]. However, the contribution of the CYP2C19 isoenzyme to PPI biotransformation and H. pylori eradication rates [15] and the potency of inhibition of CYP2C19 activity [14] vary among different PPIs. CYP2C19 activity appears to affect the response to omeprazole, esomeprazole and lansoprazole [16][17][18] and to be inhibited by these PPIs [14,18]. This does not seem to be the case, at least not to the same extent, with pantoprazole [14,#CITATION_TAG] and rabeprazole [14,20].	0	PPIs are metabolized primarily via the CYP2C19 and CYP3A4 isoenzymes [13] and are competitive inhibitors of CYP2C19 activity [14]. However, the contribution of the CYP2C19 isoenzyme to PPI biotransformation and H. pylori eradication rates [15] and the potency of inhibition of CYP2C19 activity [14] vary among different PPIs. CYP2C19 activity appears to affect the response to omeprazole, esomeprazole and lansoprazole [16][17][18] and to be inhibited by these PPIs [14,18]. This does not seem to be the case, at least not to the same extent, with pantoprazole [14,#CITATION_TAG] and rabeprazole [14,20].	 
CCT71	Dual antiplatelet therapy with aspirin and clopidogrel is associated with a significant reduction in cardiovascular ischemic events after acute coronary syndromes or percutaneous coronary interventions and is recommended in guidelines from the USA [1] and Europe [2]. Clopidogrel is an inactive prodrug that undergoes two oxidative steps involving multiple cytochrome P-450 (CYP) enzymes in its bioactivation to its pharmacologically active metabolite. Among them, CYP2C19, a CYP enzyme whose activity is determined genetically, contributes predominantly to this bioactivation [3,#CITATION_TAG] and modulates the antiplatelet and therapeutic response to clopidogrel. Patients with loss of function polymorphism in the CYP2C19 gene are less responsive to clopidogrel [5,6], although the importance of this phenomenon remains controversial [7][8][9][10] and may be limited to the risk of stent thrombosis [11].	0	Dual antiplatelet therapy with aspirin and clopidogrel is associated with a significant reduction in cardiovascular ischemic events after acute coronary syndromes or percutaneous coronary interventions and is recommended in guidelines from the USA [1] and Europe [2]. Clopidogrel is an inactive prodrug that undergoes two oxidative steps involving multiple cytochrome P-450 (CYP) enzymes in its bioactivation to its pharmacologically active metabolite. Among them, CYP2C19, a CYP enzyme whose activity is determined genetically, contributes predominantly to this bioactivation [3,#CITATION_TAG] and modulates the antiplatelet and therapeutic response to clopidogrel. Patients with loss of function polymorphism in the CYP2C19 gene are less responsive to clopidogrel [5,6], although the importance of this phenomenon remains controversial [7][8][9][10] and may be limited to the risk of stent thrombosis [11].	o
CCT72	The primary test to assess platelet function was based on the VASP phosphorylation level measured in whole blood using a flow cytometric assay (Platelet VASP ¬Æ ; Diagnostica Stago, Biocytex, Asni√®res, France) and a FACScan flow cytometer (Becton Dickinson, Le Pont de Claix, France). Results were expressed as platelet reactivity index (PRI%), calculated from the mean fluorescence intensity (MFI) of samples incubated with prostaglandin E1 (PGE1) alone or with both PGE1 and ADP simultaneously, using the following formula: (MFI PGE1 -MFI PGE1+ADP /MFI PGE1 ) √ó 100, as previously described [3]. This test -also referred to as the VASP index -specifically assesses the activity of the P2Y12 receptor [31] (the target of clopidogrel antiplatelet action), and is widely used for monitoring the responsiveness to clopidogrel [#CITATION_TAG,33]. The percentage change in PRI on study day 7 just before the last administration of study drugs relative to baseline, i.e. prior to drug administrations (percentage change in PRI [%] D7H0), was used as the primary study endpoint. PRI (%) relative to day 1 was also calculated for D7H4.	5	The primary test to assess platelet function was based on the VASP phosphorylation level measured in whole blood using a flow cytometric assay (Platelet VASP ¬Æ ; Diagnostica Stago, Biocytex, Asni√®res, France) and a FACScan flow cytometer (Becton Dickinson, Le Pont de Claix, France). Results were expressed as platelet reactivity index (PRI%), calculated from the mean fluorescence intensity (MFI) of samples incubated with prostaglandin E1 (PGE1) alone or with both PGE1 and ADP simultaneously, using the following formula: (MFI PGE1 -MFI PGE1+ADP /MFI PGE1 ) √ó 100, as previously described [3]. This test -also referred to as the VASP index -specifically assesses the activity of the P2Y12 receptor [31] (the target of clopidogrel antiplatelet action), and is widely used for monitoring the responsiveness to clopidogrel [#CITATION_TAG,33]. The percentage change in PRI on study day 7 just before the last administration of study drugs relative to baseline, i.e. prior to drug administrations (percentage change in PRI [%] D7H0), was used as the primary study endpoint. PRI (%) relative to day 1 was also calculated for D7H4.	i
CCT73	Dual antiplatelet therapy with aspirin and clopidogrel is associated with a significant reduction in cardiovascular ischemic events after acute coronary syndromes or percutaneous coronary interventions and is recommended in guidelines from the USA [1] and Europe [2]. Clopidogrel is an inactive prodrug that undergoes two oxidative steps involving multiple cytochrome P-450 (CYP) enzymes in its bioactivation to its pharmacologically active metabolite. Among them, CYP2C19, a CYP enzyme whose activity is determined genetically, contributes predominantly to this bioactivation [#CITATION_TAG,4] and modulates the antiplatelet and therapeutic response to clopidogrel. Patients with loss of function polymorphism in the CYP2C19 gene are less responsive to clopidogrel [5,6], although the importance of this phenomenon remains controversial [7][8][9][10] and may be limited to the risk of stent thrombosis [11].	0	Dual antiplatelet therapy with aspirin and clopidogrel is associated with a significant reduction in cardiovascular ischemic events after acute coronary syndromes or percutaneous coronary interventions and is recommended in guidelines from the USA [1] and Europe [2]. Clopidogrel is an inactive prodrug that undergoes two oxidative steps involving multiple cytochrome P-450 (CYP) enzymes in its bioactivation to its pharmacologically active metabolite. Among them, CYP2C19, a CYP enzyme whose activity is determined genetically, contributes predominantly to this bioactivation [#CITATION_TAG,4] and modulates the antiplatelet and therapeutic response to clopidogrel. Patients with loss of function polymorphism in the CYP2C19 gene are less responsive to clopidogrel [5,6], although the importance of this phenomenon remains controversial [7][8][9][10] and may be limited to the risk of stent thrombosis [11].	o
CCT74	The primary test to assess platelet function was based on the VASP phosphorylation level measured in whole blood using a flow cytometric assay (Platelet VASP ¬Æ ; Diagnostica Stago, Biocytex, Asni√®res, France) and a FACScan flow cytometer (Becton Dickinson, Le Pont de Claix, France). Results were expressed as platelet reactivity index (PRI%), calculated from the mean fluorescence intensity (MFI) of samples incubated with prostaglandin E1 (PGE1) alone or with both PGE1 and ADP simultaneously, using the following formula: (MFI PGE1 -MFI PGE1+ADP /MFI PGE1 ) √ó 100, as previously described [3]. This test -also referred to as the VASP index -specifically assesses the activity of the P2Y12 receptor #CITATION_TAG (the target of clopidogrel antiplatelet action), and is widely used for monitoring the responsiveness to clopidogrel [32,33]. The percentage change in PRI on study day 7 just before the last administration of study drugs relative to baseline, i.e. prior to drug administrations (percentage change in PRI [%] D7H0), was used as the primary study endpoint. PRI (%) relative to day 1 was also calculated for D7H4.	5	The primary test to assess platelet function was based on the VASP phosphorylation level measured in whole blood using a flow cytometric assay (Platelet VASP ¬Æ ; Diagnostica Stago, Biocytex, Asni√®res, France) and a FACScan flow cytometer (Becton Dickinson, Le Pont de Claix, France). Results were expressed as platelet reactivity index (PRI%), calculated from the mean fluorescence intensity (MFI) of samples incubated with prostaglandin E1 (PGE1) alone or with both PGE1 and ADP simultaneously, using the following formula: (MFI PGE1 -MFI PGE1+ADP /MFI PGE1 ) √ó 100, as previously described [3]. This test -also referred to as the VASP index -specifically assesses the activity of the P2Y12 receptor #CITATION_TAG (the target of clopidogrel antiplatelet action), and is widely used for monitoring the responsiveness to clopidogrel [32,33]. The percentage change in PRI on study day 7 just before the last administration of study drugs relative to baseline, i.e. prior to drug administrations (percentage change in PRI [%] D7H0), was used as the primary study endpoint. PRI (%) relative to day 1 was also calculated for D7H4.	i
CCT75	Dual antiplatelet therapy with aspirin and clopidogrel is associated with a significant reduction in cardiovascular ischemic events after acute coronary syndromes or percutaneous coronary interventions and is recommended in guidelines from the USA [1] and Europe [2]. Clopidogrel is an inactive prodrug that undergoes two oxidative steps involving multiple cytochrome P-450 (CYP) enzymes in its bioactivation to its pharmacologically active metabolite. Among them, CYP2C19, a CYP enzyme whose activity is determined genetically, contributes predominantly to this bioactivation [3,4] and modulates the antiplatelet and therapeutic response to clopidogrel. Patients with loss of function polymorphism in the CYP2C19 gene are less responsive to clopidogrel [5,6], although the importance of this phenomenon remains controversial [7][8]#CITATION_TAG[10] and may be limited to the risk of stent thrombosis [11].	0	Dual antiplatelet therapy with aspirin and clopidogrel is associated with a significant reduction in cardiovascular ischemic events after acute coronary syndromes or percutaneous coronary interventions and is recommended in guidelines from the USA [1] and Europe [2]. Clopidogrel is an inactive prodrug that undergoes two oxidative steps involving multiple cytochrome P-450 (CYP) enzymes in its bioactivation to its pharmacologically active metabolite. Among them, CYP2C19, a CYP enzyme whose activity is determined genetically, contributes predominantly to this bioactivation [3,4] and modulates the antiplatelet and therapeutic response to clopidogrel. Patients with loss of function polymorphism in the CYP2C19 gene are less responsive to clopidogrel [5,6], although the importance of this phenomenon remains controversial [7][8]#CITATION_TAG[10] and may be limited to the risk of stent thrombosis [11].	i
CCT76	Concerns about PPI and clopidogrel interaction were raised when omeprazole was found to inhibit the antiplatelet effect of clopidogrel in an in vivo study of 124 patients undergoing elective coronary stent implantation [21]. Several studies have suggested that omeprazole interacts with clopidogrel efficacy by inhibiting the formation of its active metabolite via CYP2C19 inhibition [22,#CITATION_TAG]. Whether this occurs with all PPIs or is even of significant amplitude with omeprazole remains a matter of debate [9,[24][25][26][27][28][29]. However, it was recently demonstrated that generation of clopidogrel active metabolite and inhibition of platelet function are reduced less by the co-administration of dexlansoprazole or lansoprazole with clopidogrel than by the co-administration of esomeprazole or omeprazole [30].	0	Concerns about PPI and clopidogrel interaction were raised when omeprazole was found to inhibit the antiplatelet effect of clopidogrel in an in vivo study of 124 patients undergoing elective coronary stent implantation [21]. Several studies have suggested that omeprazole interacts with clopidogrel efficacy by inhibiting the formation of its active metabolite via CYP2C19 inhibition [22,#CITATION_TAG]. Whether this occurs with all PPIs or is even of significant amplitude with omeprazole remains a matter of debate [9,[24][25][26][27][28][29]. However, it was recently demonstrated that generation of clopidogrel active metabolite and inhibition of platelet function are reduced less by the co-administration of dexlansoprazole or lansoprazole with clopidogrel than by the co-administration of esomeprazole or omeprazole [30].	e
CCT77	Concerns about PPI and clopidogrel interaction were raised when omeprazole was found to inhibit the antiplatelet effect of clopidogrel in an in vivo study of 124 patients undergoing elective coronary stent implantation #CITATION_TAG. Several studies have suggested that omeprazole interacts with clopidogrel efficacy by inhibiting the formation of its active metabolite via CYP2C19 inhibition [22,23]. Whether this occurs with all PPIs or is even of significant amplitude with omeprazole remains a matter of debate [9,[24][25][26][27][28][29]. However, it was recently demonstrated that generation of clopidogrel active metabolite and inhibition of platelet function are reduced less by the co-administration of dexlansoprazole or lansoprazole with clopidogrel than by the co-administration of esomeprazole or omeprazole [30].	4	Concerns about PPI and clopidogrel interaction were raised when omeprazole was found to inhibit the antiplatelet effect of clopidogrel in an in vivo study of 124 patients undergoing elective coronary stent implantation #CITATION_TAG. Several studies have suggested that omeprazole interacts with clopidogrel efficacy by inhibiting the formation of its active metabolite via CYP2C19 inhibition [22,23]. Whether this occurs with all PPIs or is even of significant amplitude with omeprazole remains a matter of debate [9,[24][25][26][27][28][29]. However, it was recently demonstrated that generation of clopidogrel active metabolite and inhibition of platelet function are reduced less by the co-administration of dexlansoprazole or lansoprazole with clopidogrel than by the co-administration of esomeprazole or omeprazole [30].	C
CCT78	Sample size was calculated with the assumption that approximately 66% of subjects would be good antiplatelet responders, defined as subjects in whom the VASP index on study day 7 relative to study day 1 would decrease by ‚â• 30%, with an expected intrasubject standard deviation of differences in PRI of ‚â§ 14% #CITATION_TAG or a PRI value at day 7 below a cut-off value of 60%, as recently proposed for clopidogrel 75 mg daily maintenance dose [38]. With these assumptions, 36 subjects are sufficient to conclude non-inferiority of rabeprazole to placebo with 10% PRI as the limit of non-inferiority with > 95% power when true difference in treatment means is equal to 2%. Pharmacodynamic analyses were first performed on good antiplatelet responders as defined above, then on all 36 subjects.	5	Sample size was calculated with the assumption that approximately 66% of subjects would be good antiplatelet responders, defined as subjects in whom the VASP index on study day 7 relative to study day 1 would decrease by ‚â• 30%, with an expected intrasubject standard deviation of differences in PRI of ‚â§ 14% #CITATION_TAG or a PRI value at day 7 below a cut-off value of 60%, as recently proposed for clopidogrel 75 mg daily maintenance dose [38]. With these assumptions, 36 subjects are sufficient to conclude non-inferiority of rabeprazole to placebo with 10% PRI as the limit of non-inferiority with > 95% power when true difference in treatment means is equal to 2%. Pharmacodynamic analyses were first performed on good antiplatelet responders as defined above, then on all 36 subjects.	S
CCT79	The primary test to assess platelet function was based on the VASP phosphorylation level measured in whole blood using a flow cytometric assay (Platelet VASP ¬Æ ; Diagnostica Stago, Biocytex, Asni√®res, France) and a FACScan flow cytometer (Becton Dickinson, Le Pont de Claix, France). Results were expressed as platelet reactivity index (PRI%), calculated from the mean fluorescence intensity (MFI) of samples incubated with prostaglandin E1 (PGE1) alone or with both PGE1 and ADP simultaneously, using the following formula: (MFI PGE1 -MFI PGE1+ADP /MFI PGE1 ) √ó 100, as previously described [3]. This test -also referred to as the VASP index -specifically assesses the activity of the P2Y12 receptor [31] (the target of clopidogrel antiplatelet action), and is widely used for monitoring the responsiveness to clopidogrel [32,#CITATION_TAG]. The percentage change in PRI on study day 7 just before the last administration of study drugs relative to baseline, i.e. prior to drug administrations (percentage change in PRI [%] D7H0), was used as the primary study endpoint. PRI (%) relative to day 1 was also calculated for D7H4.	5	The primary test to assess platelet function was based on the VASP phosphorylation level measured in whole blood using a flow cytometric assay (Platelet VASP ¬Æ ; Diagnostica Stago, Biocytex, Asni√®res, France) and a FACScan flow cytometer (Becton Dickinson, Le Pont de Claix, France). Results were expressed as platelet reactivity index (PRI%), calculated from the mean fluorescence intensity (MFI) of samples incubated with prostaglandin E1 (PGE1) alone or with both PGE1 and ADP simultaneously, using the following formula: (MFI PGE1 -MFI PGE1+ADP /MFI PGE1 ) √ó 100, as previously described [3]. This test -also referred to as the VASP index -specifically assesses the activity of the P2Y12 receptor [31] (the target of clopidogrel antiplatelet action), and is widely used for monitoring the responsiveness to clopidogrel [32,#CITATION_TAG]. The percentage change in PRI on study day 7 just before the last administration of study drugs relative to baseline, i.e. prior to drug administrations (percentage change in PRI [%] D7H0), was used as the primary study endpoint. PRI (%) relative to day 1 was also calculated for D7H4.	i
CCT80	The molar omeprazole/5-hydroxyomeprazole metabolic ratio in plasma samples at 3 hours was calculated as an index of CYP2C19 activity [34]#CITATION_TAG[36]. In one EM subject, this ratio was calculated from the blood sample taken at 4 hours because 5-hydroxyomeprazole was not detectable at 3 hours.	5	The molar omeprazole/5-hydroxyomeprazole metabolic ratio in plasma samples at 3 hours was calculated as an index of CYP2C19 activity [34]#CITATION_TAG[36]. In one EM subject, this ratio was calculated from the blood sample taken at 4 hours because 5-hydroxyomeprazole was not detectable at 3 hours.	T
CCT81	The molar omeprazole/5-hydroxyomeprazole metabolic ratio in plasma samples at 3 hours was calculated as an index of CYP2C19 activity #CITATION_TAG[35][36]. In one EM subject, this ratio was calculated from the blood sample taken at 4 hours because 5-hydroxyomeprazole was not detectable at 3 hours.	5	The molar omeprazole/5-hydroxyomeprazole metabolic ratio in plasma samples at 3 hours was calculated as an index of CYP2C19 activity #CITATION_TAG[35][36]. In one EM subject, this ratio was calculated from the blood sample taken at 4 hours because 5-hydroxyomeprazole was not detectable at 3 hours.	T
CCT82	Sample size was calculated with the assumption that approximately 66% of subjects would be good antiplatelet responders, defined as subjects in whom the VASP index on study day 7 relative to study day 1 would decrease by ‚â• 30%, with an expected intrasubject standard deviation of differences in PRI of ‚â§ 14% [37] or a PRI value at day 7 below a cut-off value of 60%, as recently proposed for clopidogrel 75 mg daily maintenance dose #CITATION_TAG. With these assumptions, 36 subjects are sufficient to conclude non-inferiority of rabeprazole to placebo with 10% PRI as the limit of non-inferiority with > 95% power when true difference in treatment means is equal to 2%. Pharmacodynamic analyses were first performed on good antiplatelet responders as defined above, then on all 36 subjects.	5	Sample size was calculated with the assumption that approximately 66% of subjects would be good antiplatelet responders, defined as subjects in whom the VASP index on study day 7 relative to study day 1 would decrease by ‚â• 30%, with an expected intrasubject standard deviation of differences in PRI of ‚â§ 14% [37] or a PRI value at day 7 below a cut-off value of 60%, as recently proposed for clopidogrel 75 mg daily maintenance dose #CITATION_TAG. With these assumptions, 36 subjects are sufficient to conclude non-inferiority of rabeprazole to placebo with 10% PRI as the limit of non-inferiority with > 95% power when true difference in treatment means is equal to 2%. Pharmacodynamic analyses were first performed on good antiplatelet responders as defined above, then on all 36 subjects.	S
CCT83	Dual antiplatelet therapy with aspirin and clopidogrel is associated with a significant reduction in cardiovascular ischemic events after acute coronary syndromes or percutaneous coronary interventions and is recommended in guidelines from the USA [1] and Europe #CITATION_TAG. Clopidogrel is an inactive prodrug that undergoes two oxidative steps involving multiple cytochrome P-450 (CYP) enzymes in its bioactivation to its pharmacologically active metabolite. Among them, CYP2C19, a CYP enzyme whose activity is determined genetically, contributes predominantly to this bioactivation [3,4] and modulates the antiplatelet and therapeutic response to clopidogrel. Patients with loss of function polymorphism in the CYP2C19 gene are less responsive to clopidogrel [5,6], although the importance of this phenomenon remains controversial [7][8][9][10] and may be limited to the risk of stent thrombosis [11].	0	Dual antiplatelet therapy with aspirin and clopidogrel is associated with a significant reduction in cardiovascular ischemic events after acute coronary syndromes or percutaneous coronary interventions and is recommended in guidelines from the USA [1] and Europe #CITATION_TAG. Clopidogrel is an inactive prodrug that undergoes two oxidative steps involving multiple cytochrome P-450 (CYP) enzymes in its bioactivation to its pharmacologically active metabolite. Among them, CYP2C19, a CYP enzyme whose activity is determined genetically, contributes predominantly to this bioactivation [3,4] and modulates the antiplatelet and therapeutic response to clopidogrel. Patients with loss of function polymorphism in the CYP2C19 gene are less responsive to clopidogrel [5,6], although the importance of this phenomenon remains controversial [7][8][9][10] and may be limited to the risk of stent thrombosis [11].	D
CCT84	As an inhibitory interaction is not expected to occur in subjects who do not have an adequate response in the absence of inhibitor, the predefined group of VASP good antiplatelet responders was chosen to examine the pharmacodynamic interactions between rabeprazole and clopidogrel. The VASP index is considered as a specific test for evaluating P2Y12 inhibition, while light-transmission aggregometry is used to predict outcome during dual  antiplatelet therapy, although both tests have a predictive value [31,33,39,#CITATION_TAG]. In the group of good VASP antiplatelet responders, the clopidogrel antiplatelet effect remained non-inferior to placebo at D7H0 and D7H4 during rabeprazole co-administration, whereas it crossed the limit of noninferiority during omeprazole co-administration. Therefore, from a pharmacodynamic point of view, in subjects in whom clopidogrel elicits a marked antiplatelet effect, inhibition of clopidogrel antiplatelet action is minimal with rabeprazole, whereas a statistically significant reversal of clopidogrel effects is observed with omeprazole.	5	As an inhibitory interaction is not expected to occur in subjects who do not have an adequate response in the absence of inhibitor, the predefined group of VASP good antiplatelet responders was chosen to examine the pharmacodynamic interactions between rabeprazole and clopidogrel. The VASP index is considered as a specific test for evaluating P2Y12 inhibition, while light-transmission aggregometry is used to predict outcome during dual  antiplatelet therapy, although both tests have a predictive value [31,33,39,#CITATION_TAG]. In the group of good VASP antiplatelet responders, the clopidogrel antiplatelet effect remained non-inferior to placebo at D7H0 and D7H4 during rabeprazole co-administration, whereas it crossed the limit of noninferiority during omeprazole co-administration. Therefore, from a pharmacodynamic point of view, in subjects in whom clopidogrel elicits a marked antiplatelet effect, inhibition of clopidogrel antiplatelet action is minimal with rabeprazole, whereas a statistically significant reversal of clopidogrel effects is observed with omeprazole.	h
CCT85	Concerns about PPI and clopidogrel interaction were raised when omeprazole was found to inhibit the antiplatelet effect of clopidogrel in an in vivo study of 124 patients undergoing elective coronary stent implantation [21]. Several studies have suggested that omeprazole interacts with clopidogrel efficacy by inhibiting the formation of its active metabolite via CYP2C19 inhibition [22,23]. Whether this occurs with all PPIs or is even of significant amplitude with omeprazole remains a matter of debate [9,[24][25][26][27][28][29]. However, it was recently demonstrated that generation of clopidogrel active metabolite and inhibition of platelet function are reduced less by the co-administration of dexlansoprazole or lansoprazole with clopidogrel than by the co-administration of esomeprazole or omeprazole #CITATION_TAG.	2	Concerns about PPI and clopidogrel interaction were raised when omeprazole was found to inhibit the antiplatelet effect of clopidogrel in an in vivo study of 124 patients undergoing elective coronary stent implantation [21]. Several studies have suggested that omeprazole interacts with clopidogrel efficacy by inhibiting the formation of its active metabolite via CYP2C19 inhibition [22,23]. Whether this occurs with all PPIs or is even of significant amplitude with omeprazole remains a matter of debate [9,[24][25][26][27][28][29]. However, it was recently demonstrated that generation of clopidogrel active metabolite and inhibition of platelet function are reduced less by the co-administration of dexlansoprazole or lansoprazole with clopidogrel than by the co-administration of esomeprazole or omeprazole #CITATION_TAG.	e
CCT86	As expected [22,23], CYP2C19 genotype and activity influenced clopidogrel antiplatelet activity in the absence of PPI, with greater inhibition of platelet aggregation in homozygous EM subjects compared with subjects with at least one non-functional CYP2C19 allele. Also, during the placebo study period, clopidogrel-induced change in VASP index and platelet aggregation induced by 10 M (but not 20 M) ADP correlated with CYP2C19 activity, as assessed by the use of the omeprazole metabolic ratio. However, the association was weak, with only about 18% of antiplatelet effect explained by the omeprazole metabolic ratio. During PPI administrations, no significant correlation was found between the change in VASP index or the change in the AUC of clopidogrel active metabolite and CYP2C19 activity as assessed by the omeprazole metabolic ratio. Such an absence of association by regression analysis raises the question of the role of CYP2C19 inhibition in explaining our findings. Rabeprazole is mainly metabolized by nonenzymatic reduction to rabeprazole thioether [41] and is a less potent inhibitor of CYP2C19 than omeprazole [14,#CITATION_TAG,43]. This may explain why rabeprazole had less effect than omeprazole on the clopidogrel-induced change in VASP index, although the study was not powered to test the statistical significance of this difference. However, this does not explain the similarity of the pharmacokinetic interaction of clopidogrel active metabolite with both PPIs. In this respect, pantoprazole [19] and rabeprazole appear to have similar profiles. Also, rabeprazole thioether, the main circulating metabolite of rabeprazole, is a CYP2C19 inhibitor [14] and could have contributed to the observed effects. Finally, CYP2C19 is not the only CYP that contributes to the bioactivation of clopidogrel to its active metabolite [4]. CYP2C19 contributes to the first step of clopidogrel metabolism to its 2-oxo unstable metabolite by 45% while CYP1A2 and CYP2B6 contribute by 36% and 19%, respectively. CYP2C19 contributes to the final step of clopidogrel active metabolite formation from 2-oxoclopidogrel by only 20% while CYP3A4, CYP2B6 and CYP2C9 contribute by 40%, 33% and 7%, respectively [4]. It is therefore conceivable that non-CYP2C19-mediated mechanisms may contribute to the interaction between PPIs and clopidogrel.	4	However, the association was weak, with only about 18% of antiplatelet effect explained by the omeprazole metabolic ratio. During PPI administrations, no significant correlation was found between the change in VASP index or the change in the AUC of clopidogrel active metabolite and CYP2C19 activity as assessed by the omeprazole metabolic ratio. Such an absence of association by regression analysis raises the question of the role of CYP2C19 inhibition in explaining our findings. Rabeprazole is mainly metabolized by nonenzymatic reduction to rabeprazole thioether [41] and is a less potent inhibitor of CYP2C19 than omeprazole [14,#CITATION_TAG,43]. This may explain why rabeprazole had less effect than omeprazole on the clopidogrel-induced change in VASP index, although the study was not powered to test the statistical significance of this difference. However, this does not explain the similarity of the pharmacokinetic interaction of clopidogrel active metabolite with both PPIs. In this respect, pantoprazole [19] and rabeprazole appear to have similar profiles.	r
CCT87	As expected [22,23], CYP2C19 genotype and activity influenced clopidogrel antiplatelet activity in the absence of PPI, with greater inhibition of platelet aggregation in homozygous EM subjects compared with subjects with at least one non-functional CYP2C19 allele. Also, during the placebo study period, clopidogrel-induced change in VASP index and platelet aggregation induced by 10 M (but not 20 M) ADP correlated with CYP2C19 activity, as assessed by the use of the omeprazole metabolic ratio. However, the association was weak, with only about 18% of antiplatelet effect explained by the omeprazole metabolic ratio. During PPI administrations, no significant correlation was found between the change in VASP index or the change in the AUC of clopidogrel active metabolite and CYP2C19 activity as assessed by the omeprazole metabolic ratio. Such an absence of association by regression analysis raises the question of the role of CYP2C19 inhibition in explaining our findings. Rabeprazole is mainly metabolized by nonenzymatic reduction to rabeprazole thioether [41] and is a less potent inhibitor of CYP2C19 than omeprazole [14,#CITATION_TAG,43]. This may explain why rabeprazole had less effect than omeprazole on the clopidogrel-induced change in VASP index, although the study was not powered to test the statistical significance of this difference. However, this does not explain the similarity of the pharmacokinetic interaction of clopidogrel active metabolite with both PPIs. In this respect, pantoprazole [19] and rabeprazole appear to have similar profiles. Also, rabeprazole thioether, the main circulating metabolite of rabeprazole, is a CYP2C19 inhibitor [14] and could have contributed to the observed effects. Finally, CYP2C19 is not the only CYP that contributes to the bioactivation of clopidogrel to its active metabolite [4]. CYP2C19 contributes to the first step of clopidogrel metabolism to its 2-oxo unstable metabolite by 45% while CYP1A2 and CYP2B6 contribute by 36% and 19%, respectively. CYP2C19 contributes to the final step of clopidogrel active metabolite formation from 2-oxoclopidogrel by only 20% while CYP3A4, CYP2B6 and CYP2C9 contribute by 40%, 33% and 7%, respectively [4]. It is therefore conceivable that non-CYP2C19-mediated mechanisms may contribute to the interaction between PPIs and clopidogrel.	4	However, the association was weak, with only about 18% of antiplatelet effect explained by the omeprazole metabolic ratio. During PPI administrations, no significant correlation was found between the change in VASP index or the change in the AUC of clopidogrel active metabolite and CYP2C19 activity as assessed by the omeprazole metabolic ratio. Such an absence of association by regression analysis raises the question of the role of CYP2C19 inhibition in explaining our findings. Rabeprazole is mainly metabolized by nonenzymatic reduction to rabeprazole thioether [41] and is a less potent inhibitor of CYP2C19 than omeprazole [14,#CITATION_TAG,43]. This may explain why rabeprazole had less effect than omeprazole on the clopidogrel-induced change in VASP index, although the study was not powered to test the statistical significance of this difference. However, this does not explain the similarity of the pharmacokinetic interaction of clopidogrel active metabolite with both PPIs. In this respect, pantoprazole [19] and rabeprazole appear to have similar profiles.	r
CCT88	As expected [22,23], CYP2C19 genotype and activity influenced clopidogrel antiplatelet activity in the absence of PPI, with greater inhibition of platelet aggregation in homozygous EM subjects compared with subjects with at least one non-functional CYP2C19 allele. Also, during the placebo study period, clopidogrel-induced change in VASP index and platelet aggregation induced by 10 M (but not 20 M) ADP correlated with CYP2C19 activity, as assessed by the use of the omeprazole metabolic ratio. However, the association was weak, with only about 18% of antiplatelet effect explained by the omeprazole metabolic ratio. During PPI administrations, no significant correlation was found between the change in VASP index or the change in the AUC of clopidogrel active metabolite and CYP2C19 activity as assessed by the omeprazole metabolic ratio. Such an absence of association by regression analysis raises the question of the role of CYP2C19 inhibition in explaining our findings. Rabeprazole is mainly metabolized by nonenzymatic reduction to rabeprazole thioether [41] and is a less potent inhibitor of CYP2C19 than omeprazole [14,42,#CITATION_TAG]. This may explain why rabeprazole had less effect than omeprazole on the clopidogrel-induced change in VASP index, although the study was not powered to test the statistical significance of this difference. However, this does not explain the similarity of the pharmacokinetic interaction of clopidogrel active metabolite with both PPIs. In this respect, pantoprazole [19] and rabeprazole appear to have similar profiles. Also, rabeprazole thioether, the main circulating metabolite of rabeprazole, is a CYP2C19 inhibitor [14] and could have contributed to the observed effects. Finally, CYP2C19 is not the only CYP that contributes to the bioactivation of clopidogrel to its active metabolite [4]. CYP2C19 contributes to the first step of clopidogrel metabolism to its 2-oxo unstable metabolite by 45% while CYP1A2 and CYP2B6 contribute by 36% and 19%, respectively. CYP2C19 contributes to the final step of clopidogrel active metabolite formation from 2-oxoclopidogrel by only 20% while CYP3A4, CYP2B6 and CYP2C9 contribute by 40%, 33% and 7%, respectively [4]. It is therefore conceivable that non-CYP2C19-mediated mechanisms may contribute to the interaction between PPIs and clopidogrel.	4	However, the association was weak, with only about 18% of antiplatelet effect explained by the omeprazole metabolic ratio. During PPI administrations, no significant correlation was found between the change in VASP index or the change in the AUC of clopidogrel active metabolite and CYP2C19 activity as assessed by the omeprazole metabolic ratio. Such an absence of association by regression analysis raises the question of the role of CYP2C19 inhibition in explaining our findings. Rabeprazole is mainly metabolized by nonenzymatic reduction to rabeprazole thioether [41] and is a less potent inhibitor of CYP2C19 than omeprazole [14,42,#CITATION_TAG]. This may explain why rabeprazole had less effect than omeprazole on the clopidogrel-induced change in VASP index, although the study was not powered to test the statistical significance of this difference. However, this does not explain the similarity of the pharmacokinetic interaction of clopidogrel active metabolite with both PPIs. In this respect, pantoprazole [19] and rabeprazole appear to have similar profiles.	r
CCT89	For uniformity, our study included only young male volunteers, a population that does not reflect the diversity of patients with ischaemic heart disease who usually receive dual antiplatelet therapy and an initial loading dose of clopidogrel. In the target population, clopidogrel is usually prescribed with aspirin, and it has been suggested that inhibition of antiplatelet effect may result from an interaction of PPIs with aspirin absorption [#CITATION_TAG,45], independent of the interaction with clopidogrel [46,47]. Inhibition of clopidogrel absorption by PPIs is unlikely to occur because clopidogrel is a weak base that is not absorbed from the stomach, unlike aspirin. To our knowledge, only one study has compared the effects of omeprazole and rabeprazole on the antiplatelet action of clopidogrel in patients on dual antiplatelet therapy [48]. In this open-label study in a limited number of patients, both omeprazole and rabeprazole reduced the effects of clopidogrel on platelet aggregation induced by 10 M ADP. However, the authors acknowledged that their study was not placebo controlled and did not have the power to detect a difference between omeprazole and rabeprazole. Another recent study reported on the interaction between a single 300 mg dose of clopidogrel and rabeprazole (20 mg) and did not find an interaction [49].	2	For uniformity, our study included only young male volunteers, a population that does not reflect the diversity of patients with ischaemic heart disease who usually receive dual antiplatelet therapy and an initial loading dose of clopidogrel. In the target population, clopidogrel is usually prescribed with aspirin, and it has been suggested that inhibition of antiplatelet effect may result from an interaction of PPIs with aspirin absorption [#CITATION_TAG,45], independent of the interaction with clopidogrel [46,47]. Inhibition of clopidogrel absorption by PPIs is unlikely to occur because clopidogrel is a weak base that is not absorbed from the stomach, unlike aspirin. To our knowledge, only one study has compared the effects of omeprazole and rabeprazole on the antiplatelet action of clopidogrel in patients on dual antiplatelet therapy [48]. In this open-label study in a limited number of patients, both omeprazole and rabeprazole reduced the effects of clopidogrel on platelet aggregation induced by 10 M ADP.	n
CCT90	For uniformity, our study included only young male volunteers, a population that does not reflect the diversity of patients with ischaemic heart disease who usually receive dual antiplatelet therapy and an initial loading dose of clopidogrel. In the target population, clopidogrel is usually prescribed with aspirin, and it has been suggested that inhibition of antiplatelet effect may result from an interaction of PPIs with aspirin absorption [44,#CITATION_TAG], independent of the interaction with clopidogrel [46,47]. Inhibition of clopidogrel absorption by PPIs is unlikely to occur because clopidogrel is a weak base that is not absorbed from the stomach, unlike aspirin. To our knowledge, only one study has compared the effects of omeprazole and rabeprazole on the antiplatelet action of clopidogrel in patients on dual antiplatelet therapy [48]. In this open-label study in a limited number of patients, both omeprazole and rabeprazole reduced the effects of clopidogrel on platelet aggregation induced by 10 M ADP. However, the authors acknowledged that their study was not placebo controlled and did not have the power to detect a difference between omeprazole and rabeprazole. Another recent study reported on the interaction between a single 300 mg dose of clopidogrel and rabeprazole (20 mg) and did not find an interaction [49].	2	For uniformity, our study included only young male volunteers, a population that does not reflect the diversity of patients with ischaemic heart disease who usually receive dual antiplatelet therapy and an initial loading dose of clopidogrel. In the target population, clopidogrel is usually prescribed with aspirin, and it has been suggested that inhibition of antiplatelet effect may result from an interaction of PPIs with aspirin absorption [44,#CITATION_TAG], independent of the interaction with clopidogrel [46,47]. Inhibition of clopidogrel absorption by PPIs is unlikely to occur because clopidogrel is a weak base that is not absorbed from the stomach, unlike aspirin. To our knowledge, only one study has compared the effects of omeprazole and rabeprazole on the antiplatelet action of clopidogrel in patients on dual antiplatelet therapy [48]. In this open-label study in a limited number of patients, both omeprazole and rabeprazole reduced the effects of clopidogrel on platelet aggregation induced by 10 M ADP.	n
CCT91	For uniformity, our study included only young male volunteers, a population that does not reflect the diversity of patients with ischaemic heart disease who usually receive dual antiplatelet therapy and an initial loading dose of clopidogrel. In the target population, clopidogrel is usually prescribed with aspirin, and it has been suggested that inhibition of antiplatelet effect may result from an interaction of PPIs with aspirin absorption [44,45], independent of the interaction with clopidogrel [#CITATION_TAG,47]. Inhibition of clopidogrel absorption by PPIs is unlikely to occur because clopidogrel is a weak base that is not absorbed from the stomach, unlike aspirin. To our knowledge, only one study has compared the effects of omeprazole and rabeprazole on the antiplatelet action of clopidogrel in patients on dual antiplatelet therapy [48]. In this open-label study in a limited number of patients, both omeprazole and rabeprazole reduced the effects of clopidogrel on platelet aggregation induced by 10 M ADP. However, the authors acknowledged that their study was not placebo controlled and did not have the power to detect a difference between omeprazole and rabeprazole. Another recent study reported on the interaction between a single 300 mg dose of clopidogrel and rabeprazole (20 mg) and did not find an interaction [49].	2	For uniformity, our study included only young male volunteers, a population that does not reflect the diversity of patients with ischaemic heart disease who usually receive dual antiplatelet therapy and an initial loading dose of clopidogrel. In the target population, clopidogrel is usually prescribed with aspirin, and it has been suggested that inhibition of antiplatelet effect may result from an interaction of PPIs with aspirin absorption [44,45], independent of the interaction with clopidogrel [#CITATION_TAG,47]. Inhibition of clopidogrel absorption by PPIs is unlikely to occur because clopidogrel is a weak base that is not absorbed from the stomach, unlike aspirin. To our knowledge, only one study has compared the effects of omeprazole and rabeprazole on the antiplatelet action of clopidogrel in patients on dual antiplatelet therapy [48]. In this open-label study in a limited number of patients, both omeprazole and rabeprazole reduced the effects of clopidogrel on platelet aggregation induced by 10 M ADP.	n
CCT92	For uniformity, our study included only young male volunteers, a population that does not reflect the diversity of patients with ischaemic heart disease who usually receive dual antiplatelet therapy and an initial loading dose of clopidogrel. In the target population, clopidogrel is usually prescribed with aspirin, and it has been suggested that inhibition of antiplatelet effect may result from an interaction of PPIs with aspirin absorption [44,45], independent of the interaction with clopidogrel [46,#CITATION_TAG]. Inhibition of clopidogrel absorption by PPIs is unlikely to occur because clopidogrel is a weak base that is not absorbed from the stomach, unlike aspirin. To our knowledge, only one study has compared the effects of omeprazole and rabeprazole on the antiplatelet action of clopidogrel in patients on dual antiplatelet therapy [48]. In this open-label study in a limited number of patients, both omeprazole and rabeprazole reduced the effects of clopidogrel on platelet aggregation induced by 10 M ADP. However, the authors acknowledged that their study was not placebo controlled and did not have the power to detect a difference between omeprazole and rabeprazole. Another recent study reported on the interaction between a single 300 mg dose of clopidogrel and rabeprazole (20 mg) and did not find an interaction [49].	2	For uniformity, our study included only young male volunteers, a population that does not reflect the diversity of patients with ischaemic heart disease who usually receive dual antiplatelet therapy and an initial loading dose of clopidogrel. In the target population, clopidogrel is usually prescribed with aspirin, and it has been suggested that inhibition of antiplatelet effect may result from an interaction of PPIs with aspirin absorption [44,45], independent of the interaction with clopidogrel [46,#CITATION_TAG]. Inhibition of clopidogrel absorption by PPIs is unlikely to occur because clopidogrel is a weak base that is not absorbed from the stomach, unlike aspirin. To our knowledge, only one study has compared the effects of omeprazole and rabeprazole on the antiplatelet action of clopidogrel in patients on dual antiplatelet therapy [48]. In this open-label study in a limited number of patients, both omeprazole and rabeprazole reduced the effects of clopidogrel on platelet aggregation induced by 10 M ADP.	n
CCT93	For uniformity, our study included only young male volunteers, a population that does not reflect the diversity of patients with ischaemic heart disease who usually receive dual antiplatelet therapy and an initial loading dose of clopidogrel. In the target population, clopidogrel is usually prescribed with aspirin, and it has been suggested that inhibition of antiplatelet effect may result from an interaction of PPIs with aspirin absorption [44,45], independent of the interaction with clopidogrel [46,47]. Inhibition of clopidogrel absorption by PPIs is unlikely to occur because clopidogrel is a weak base that is not absorbed from the stomach, unlike aspirin. To our knowledge, only one study has compared the effects of omeprazole and rabeprazole on the antiplatelet action of clopidogrel in patients on dual antiplatelet therapy #CITATION_TAG. In this open-label study in a limited number of patients, both omeprazole and rabeprazole reduced the effects of clopidogrel on platelet aggregation induced by 10 M ADP. However, the authors acknowledged that their study was not placebo controlled and did not have the power to detect a difference between omeprazole and rabeprazole. Another recent study reported on the interaction between a single 300 mg dose of clopidogrel and rabeprazole (20 mg) and did not find an interaction [49].	1	For uniformity, our study included only young male volunteers, a population that does not reflect the diversity of patients with ischaemic heart disease who usually receive dual antiplatelet therapy and an initial loading dose of clopidogrel. In the target population, clopidogrel is usually prescribed with aspirin, and it has been suggested that inhibition of antiplatelet effect may result from an interaction of PPIs with aspirin absorption [44,45], independent of the interaction with clopidogrel [46,47]. Inhibition of clopidogrel absorption by PPIs is unlikely to occur because clopidogrel is a weak base that is not absorbed from the stomach, unlike aspirin. To our knowledge, only one study has compared the effects of omeprazole and rabeprazole on the antiplatelet action of clopidogrel in patients on dual antiplatelet therapy #CITATION_TAG. In this open-label study in a limited number of patients, both omeprazole and rabeprazole reduced the effects of clopidogrel on platelet aggregation induced by 10 M ADP. However, the authors acknowledged that their study was not placebo controlled and did not have the power to detect a difference between omeprazole and rabeprazole. Another recent study reported on the interaction between a single 300 mg dose of clopidogrel and rabeprazole (20 mg) and did not find an interaction [49].	o
CCT94	As an inhibitory interaction is not expected to occur in subjects who do not have an adequate response in the absence of inhibitor, the predefined group of VASP good antiplatelet responders was chosen to examine the pharmacodynamic interactions between rabeprazole and clopidogrel. The VASP index is considered as a specific test for evaluating P2Y12 inhibition, while light-transmission aggregometry is used to predict outcome during dual  antiplatelet therapy, although both tests have a predictive value [31,33,#CITATION_TAG,40]. In the group of good VASP antiplatelet responders, the clopidogrel antiplatelet effect remained non-inferior to placebo at D7H0 and D7H4 during rabeprazole co-administration, whereas it crossed the limit of noninferiority during omeprazole co-administration. Therefore, from a pharmacodynamic point of view, in subjects in whom clopidogrel elicits a marked antiplatelet effect, inhibition of clopidogrel antiplatelet action is minimal with rabeprazole, whereas a statistically significant reversal of clopidogrel effects is observed with omeprazole.	0	As an inhibitory interaction is not expected to occur in subjects who do not have an adequate response in the absence of inhibitor, the predefined group of VASP good antiplatelet responders was chosen to examine the pharmacodynamic interactions between rabeprazole and clopidogrel. The VASP index is considered as a specific test for evaluating P2Y12 inhibition, while light-transmission aggregometry is used to predict outcome during dual  antiplatelet therapy, although both tests have a predictive value [31,33,#CITATION_TAG,40]. In the group of good VASP antiplatelet responders, the clopidogrel antiplatelet effect remained non-inferior to placebo at D7H0 and D7H4 during rabeprazole co-administration, whereas it crossed the limit of noninferiority during omeprazole co-administration. Therefore, from a pharmacodynamic point of view, in subjects in whom clopidogrel elicits a marked antiplatelet effect, inhibition of clopidogrel antiplatelet action is minimal with rabeprazole, whereas a statistically significant reversal of clopidogrel effects is observed with omeprazole.	h
CCT95	Concerns about PPI and clopidogrel interaction were raised when omeprazole was found to inhibit the antiplatelet effect of clopidogrel in an in vivo study of 124 patients undergoing elective coronary stent implantation [21]. Several studies have suggested that omeprazole interacts with clopidogrel efficacy by inhibiting the formation of its active metabolite via CYP2C19 inhibition [22,23]. Whether this occurs with all PPIs or is even of significant amplitude with omeprazole remains a matter of debate [9,[24]#CITATION_TAG[26][27][28][29]. However, it was recently demonstrated that generation of clopidogrel active metabolite and inhibition of platelet function are reduced less by the co-administration of dexlansoprazole or lansoprazole with clopidogrel than by the co-administration of esomeprazole or omeprazole [30].	4	Concerns about PPI and clopidogrel interaction were raised when omeprazole was found to inhibit the antiplatelet effect of clopidogrel in an in vivo study of 124 patients undergoing elective coronary stent implantation [21]. Several studies have suggested that omeprazole interacts with clopidogrel efficacy by inhibiting the formation of its active metabolite via CYP2C19 inhibition [22,23]. Whether this occurs with all PPIs or is even of significant amplitude with omeprazole remains a matter of debate [9,[24]#CITATION_TAG[26][27][28][29]. However, it was recently demonstrated that generation of clopidogrel active metabolite and inhibition of platelet function are reduced less by the co-administration of dexlansoprazole or lansoprazole with clopidogrel than by the co-administration of esomeprazole or omeprazole [30].	e
CCT96	Concerns about PPI and clopidogrel interaction were raised when omeprazole was found to inhibit the antiplatelet effect of clopidogrel in an in vivo study of 124 patients undergoing elective coronary stent implantation [21]. Several studies have suggested that omeprazole interacts with clopidogrel efficacy by inhibiting the formation of its active metabolite via CYP2C19 inhibition [22,23]. Whether this occurs with all PPIs or is even of significant amplitude with omeprazole remains a matter of debate [9,[24][25][26][27][28]#CITATION_TAG. However, it was recently demonstrated that generation of clopidogrel active metabolite and inhibition of platelet function are reduced less by the co-administration of dexlansoprazole or lansoprazole with clopidogrel than by the co-administration of esomeprazole or omeprazole [30].	4	Concerns about PPI and clopidogrel interaction were raised when omeprazole was found to inhibit the antiplatelet effect of clopidogrel in an in vivo study of 124 patients undergoing elective coronary stent implantation [21]. Several studies have suggested that omeprazole interacts with clopidogrel efficacy by inhibiting the formation of its active metabolite via CYP2C19 inhibition [22,23]. Whether this occurs with all PPIs or is even of significant amplitude with omeprazole remains a matter of debate [9,[24][25][26][27][28]#CITATION_TAG. However, it was recently demonstrated that generation of clopidogrel active metabolite and inhibition of platelet function are reduced less by the co-administration of dexlansoprazole or lansoprazole with clopidogrel than by the co-administration of esomeprazole or omeprazole [30].	e
CCT97	Concerns about PPI and clopidogrel interaction were raised when omeprazole was found to inhibit the antiplatelet effect of clopidogrel in an in vivo study of 124 patients undergoing elective coronary stent implantation [21]. Several studies have suggested that omeprazole interacts with clopidogrel efficacy by inhibiting the formation of its active metabolite via CYP2C19 inhibition [22,23]. Whether this occurs with all PPIs or is even of significant amplitude with omeprazole remains a matter of debate [9,[24][25][26][27]#CITATION_TAG[29]. However, it was recently demonstrated that generation of clopidogrel active metabolite and inhibition of platelet function are reduced less by the co-administration of dexlansoprazole or lansoprazole with clopidogrel than by the co-administration of esomeprazole or omeprazole [30].	4	Concerns about PPI and clopidogrel interaction were raised when omeprazole was found to inhibit the antiplatelet effect of clopidogrel in an in vivo study of 124 patients undergoing elective coronary stent implantation [21]. Several studies have suggested that omeprazole interacts with clopidogrel efficacy by inhibiting the formation of its active metabolite via CYP2C19 inhibition [22,23]. Whether this occurs with all PPIs or is even of significant amplitude with omeprazole remains a matter of debate [9,[24][25][26][27]#CITATION_TAG[29]. However, it was recently demonstrated that generation of clopidogrel active metabolite and inhibition of platelet function are reduced less by the co-administration of dexlansoprazole or lansoprazole with clopidogrel than by the co-administration of esomeprazole or omeprazole [30].	e
CCT98	Dual antiplatelet therapy with aspirin and clopidogrel is associated with a significant reduction in cardiovascular ischemic events after acute coronary syndromes or percutaneous coronary interventions and is recommended in guidelines from the USA [1] and Europe [2]. Clopidogrel is an inactive prodrug that undergoes two oxidative steps involving multiple cytochrome P-450 (CYP) enzymes in its bioactivation to its pharmacologically active metabolite. Among them, CYP2C19, a CYP enzyme whose activity is determined genetically, contributes predominantly to this bioactivation [3,4] and modulates the antiplatelet and therapeutic response to clopidogrel. Patients with loss of function polymorphism in the CYP2C19 gene are less responsive to clopidogrel [#CITATION_TAG,6], although the importance of this phenomenon remains controversial [7][8][9][10] and may be limited to the risk of stent thrombosis [11].	0	Dual antiplatelet therapy with aspirin and clopidogrel is associated with a significant reduction in cardiovascular ischemic events after acute coronary syndromes or percutaneous coronary interventions and is recommended in guidelines from the USA [1] and Europe [2]. Clopidogrel is an inactive prodrug that undergoes two oxidative steps involving multiple cytochrome P-450 (CYP) enzymes in its bioactivation to its pharmacologically active metabolite. Among them, CYP2C19, a CYP enzyme whose activity is determined genetically, contributes predominantly to this bioactivation [3,4] and modulates the antiplatelet and therapeutic response to clopidogrel. Patients with loss of function polymorphism in the CYP2C19 gene are less responsive to clopidogrel [#CITATION_TAG,6], although the importance of this phenomenon remains controversial [7][8][9][10] and may be limited to the risk of stent thrombosis [11].	i
CCT99	Dual antiplatelet therapy with aspirin and clopidogrel is associated with a significant reduction in cardiovascular ischemic events after acute coronary syndromes or percutaneous coronary interventions and is recommended in guidelines from the USA [1] and Europe [2]. Clopidogrel is an inactive prodrug that undergoes two oxidative steps involving multiple cytochrome P-450 (CYP) enzymes in its bioactivation to its pharmacologically active metabolite. Among them, CYP2C19, a CYP enzyme whose activity is determined genetically, contributes predominantly to this bioactivation [3,4] and modulates the antiplatelet and therapeutic response to clopidogrel. Patients with loss of function polymorphism in the CYP2C19 gene are less responsive to clopidogrel [5,#CITATION_TAG], although the importance of this phenomenon remains controversial [7][8][9][10] and may be limited to the risk of stent thrombosis [11].	0	Dual antiplatelet therapy with aspirin and clopidogrel is associated with a significant reduction in cardiovascular ischemic events after acute coronary syndromes or percutaneous coronary interventions and is recommended in guidelines from the USA [1] and Europe [2]. Clopidogrel is an inactive prodrug that undergoes two oxidative steps involving multiple cytochrome P-450 (CYP) enzymes in its bioactivation to its pharmacologically active metabolite. Among them, CYP2C19, a CYP enzyme whose activity is determined genetically, contributes predominantly to this bioactivation [3,4] and modulates the antiplatelet and therapeutic response to clopidogrel. Patients with loss of function polymorphism in the CYP2C19 gene are less responsive to clopidogrel [5,#CITATION_TAG], although the importance of this phenomenon remains controversial [7][8][9][10] and may be limited to the risk of stent thrombosis [11].	i
CCT100	Dual antiplatelet therapy with aspirin and clopidogrel is associated with a significant reduction in cardiovascular ischemic events after acute coronary syndromes or percutaneous coronary interventions and is recommended in guidelines from the USA [1] and Europe [2]. Clopidogrel is an inactive prodrug that undergoes two oxidative steps involving multiple cytochrome P-450 (CYP) enzymes in its bioactivation to its pharmacologically active metabolite. Among them, CYP2C19, a CYP enzyme whose activity is determined genetically, contributes predominantly to this bioactivation [3,4] and modulates the antiplatelet and therapeutic response to clopidogrel. Patients with loss of function polymorphism in the CYP2C19 gene are less responsive to clopidogrel [5,6], although the importance of this phenomenon remains controversial [7]#CITATION_TAG[9][10] and may be limited to the risk of stent thrombosis [11].	0	Dual antiplatelet therapy with aspirin and clopidogrel is associated with a significant reduction in cardiovascular ischemic events after acute coronary syndromes or percutaneous coronary interventions and is recommended in guidelines from the USA [1] and Europe [2]. Clopidogrel is an inactive prodrug that undergoes two oxidative steps involving multiple cytochrome P-450 (CYP) enzymes in its bioactivation to its pharmacologically active metabolite. Among them, CYP2C19, a CYP enzyme whose activity is determined genetically, contributes predominantly to this bioactivation [3,4] and modulates the antiplatelet and therapeutic response to clopidogrel. Patients with loss of function polymorphism in the CYP2C19 gene are less responsive to clopidogrel [5,6], although the importance of this phenomenon remains controversial [7]#CITATION_TAG[9][10] and may be limited to the risk of stent thrombosis [11].	i
CCT101	Dual antiplatelet therapy with aspirin and clopidogrel is associated with a significant reduction in cardiovascular ischemic events after acute coronary syndromes or percutaneous coronary interventions and is recommended in guidelines from the USA [1] and Europe [2]. Clopidogrel is an inactive prodrug that undergoes two oxidative steps involving multiple cytochrome P-450 (CYP) enzymes in its bioactivation to its pharmacologically active metabolite. Among them, CYP2C19, a CYP enzyme whose activity is determined genetically, contributes predominantly to this bioactivation [3,4] and modulates the antiplatelet and therapeutic response to clopidogrel. Patients with loss of function polymorphism in the CYP2C19 gene are less responsive to clopidogrel [5,6], although the importance of this phenomenon remains controversial [7][8][9]#CITATION_TAG and may be limited to the risk of stent thrombosis [11].	0	Dual antiplatelet therapy with aspirin and clopidogrel is associated with a significant reduction in cardiovascular ischemic events after acute coronary syndromes or percutaneous coronary interventions and is recommended in guidelines from the USA [1] and Europe [2]. Clopidogrel is an inactive prodrug that undergoes two oxidative steps involving multiple cytochrome P-450 (CYP) enzymes in its bioactivation to its pharmacologically active metabolite. Among them, CYP2C19, a CYP enzyme whose activity is determined genetically, contributes predominantly to this bioactivation [3,4] and modulates the antiplatelet and therapeutic response to clopidogrel. Patients with loss of function polymorphism in the CYP2C19 gene are less responsive to clopidogrel [5,6], although the importance of this phenomenon remains controversial [7][8][9]#CITATION_TAG and may be limited to the risk of stent thrombosis [11].	i
CCT102	Dual antiplatelet therapy with aspirin and clopidogrel is associated with a significant reduction in cardiovascular ischemic events after acute coronary syndromes or percutaneous coronary interventions and is recommended in guidelines from the USA [1] and Europe [2]. Clopidogrel is an inactive prodrug that undergoes two oxidative steps involving multiple cytochrome P-450 (CYP) enzymes in its bioactivation to its pharmacologically active metabolite. Among them, CYP2C19, a CYP enzyme whose activity is determined genetically, contributes predominantly to this bioactivation [3,4] and modulates the antiplatelet and therapeutic response to clopidogrel. Patients with loss of function polymorphism in the CYP2C19 gene are less responsive to clopidogrel [5,6], although the importance of this phenomenon remains controversial [7][8][9][10] and may be limited to the risk of stent thrombosis #CITATION_TAG.	0	Dual antiplatelet therapy with aspirin and clopidogrel is associated with a significant reduction in cardiovascular ischemic events after acute coronary syndromes or percutaneous coronary interventions and is recommended in guidelines from the USA [1] and Europe [2]. Clopidogrel is an inactive prodrug that undergoes two oxidative steps involving multiple cytochrome P-450 (CYP) enzymes in its bioactivation to its pharmacologically active metabolite. Among them, CYP2C19, a CYP enzyme whose activity is determined genetically, contributes predominantly to this bioactivation [3,4] and modulates the antiplatelet and therapeutic response to clopidogrel. Patients with loss of function polymorphism in the CYP2C19 gene are less responsive to clopidogrel [5,6], although the importance of this phenomenon remains controversial [7][8][9][10] and may be limited to the risk of stent thrombosis #CITATION_TAG.	i
CCT103	Proton-pump inhibitors (PPIs) are recommended in patients treated with dual antiplatelet therapy who are at high risk of gastrointestinal bleeding #CITATION_TAG. PPIs are metabolized primarily via the CYP2C19 and CYP3A4 isoenzymes [13] and are competitive inhibitors of CYP2C19 activity [14]. However, the contribution of the CYP2C19 isoenzyme to PPI biotransformation and H. pylori eradication rates [15] and the potency of inhibition of CYP2C19 activity [14] vary among different PPIs. CYP2C19 activity appears to affect the response to omeprazole, esomeprazole and lansoprazole [16][17][18] and to be inhibited by these PPIs [14,18]. This does not seem to be the case, at least not to the same extent, with pantoprazole [14,19] and rabeprazole [14,20].	0	Proton-pump inhibitors (PPIs) are recommended in patients treated with dual antiplatelet therapy who are at high risk of gastrointestinal bleeding #CITATION_TAG. PPIs are metabolized primarily via the CYP2C19 and CYP3A4 isoenzymes [13] and are competitive inhibitors of CYP2C19 activity [14]. However, the contribution of the CYP2C19 isoenzyme to PPI biotransformation and H. pylori eradication rates [15] and the potency of inhibition of CYP2C19 activity [14] vary among different PPIs. CYP2C19 activity appears to affect the response to omeprazole, esomeprazole and lansoprazole [16][17][18] and to be inhibited by these PPIs [14,18].	P
CCT104	Proton-pump inhibitors (PPIs) are recommended in patients treated with dual antiplatelet therapy who are at high risk of gastrointestinal bleeding [12]. PPIs are metabolized primarily via the CYP2C19 and CYP3A4 isoenzymes [13] and are competitive inhibitors of CYP2C19 activity [14]. However, the contribution of the CYP2C19 isoenzyme to PPI biotransformation and H. pylori eradication rates #CITATION_TAG and the potency of inhibition of CYP2C19 activity [14] vary among different PPIs. CYP2C19 activity appears to affect the response to omeprazole, esomeprazole and lansoprazole [16][17][18] and to be inhibited by these PPIs [14,18]. This does not seem to be the case, at least not to the same extent, with pantoprazole [14,19] and rabeprazole [14,20].	0	Proton-pump inhibitors (PPIs) are recommended in patients treated with dual antiplatelet therapy who are at high risk of gastrointestinal bleeding [12]. PPIs are metabolized primarily via the CYP2C19 and CYP3A4 isoenzymes [13] and are competitive inhibitors of CYP2C19 activity [14]. However, the contribution of the CYP2C19 isoenzyme to PPI biotransformation and H. pylori eradication rates #CITATION_TAG and the potency of inhibition of CYP2C19 activity [14] vary among different PPIs. CYP2C19 activity appears to affect the response to omeprazole, esomeprazole and lansoprazole [16][17][18] and to be inhibited by these PPIs [14,18]. This does not seem to be the case, at least not to the same extent, with pantoprazole [14,19] and rabeprazole [14,20].	w
CCT105	Proton-pump inhibitors (PPIs) are recommended in patients treated with dual antiplatelet therapy who are at high risk of gastrointestinal bleeding [12]. PPIs are metabolized primarily via the CYP2C19 and CYP3A4 isoenzymes [13] and are competitive inhibitors of CYP2C19 activity [14]. However, the contribution of the CYP2C19 isoenzyme to PPI biotransformation and H. pylori eradication rates [15] and the potency of inhibition of CYP2C19 activity [14] vary among different PPIs. CYP2C19 activity appears to affect the response to omeprazole, esomeprazole and lansoprazole #CITATION_TAG[17][18] and to be inhibited by these PPIs [14,18]. This does not seem to be the case, at least not to the same extent, with pantoprazole [14,19] and rabeprazole [14,20].	0	Proton-pump inhibitors (PPIs) are recommended in patients treated with dual antiplatelet therapy who are at high risk of gastrointestinal bleeding [12]. PPIs are metabolized primarily via the CYP2C19 and CYP3A4 isoenzymes [13] and are competitive inhibitors of CYP2C19 activity [14]. However, the contribution of the CYP2C19 isoenzyme to PPI biotransformation and H. pylori eradication rates [15] and the potency of inhibition of CYP2C19 activity [14] vary among different PPIs. CYP2C19 activity appears to affect the response to omeprazole, esomeprazole and lansoprazole #CITATION_TAG[17][18] and to be inhibited by these PPIs [14,18]. This does not seem to be the case, at least not to the same extent, with pantoprazole [14,19] and rabeprazole [14,20].	2
CCT106	Proton-pump inhibitors (PPIs) are recommended in patients treated with dual antiplatelet therapy who are at high risk of gastrointestinal bleeding [12]. PPIs are metabolized primarily via the CYP2C19 and CYP3A4 isoenzymes [13] and are competitive inhibitors of CYP2C19 activity [14]. However, the contribution of the CYP2C19 isoenzyme to PPI biotransformation and H. pylori eradication rates [15] and the potency of inhibition of CYP2C19 activity [14] vary among different PPIs. CYP2C19 activity appears to affect the response to omeprazole, esomeprazole and lansoprazole [16]#CITATION_TAG[18] and to be inhibited by these PPIs [14,18]. This does not seem to be the case, at least not to the same extent, with pantoprazole [14,19] and rabeprazole [14,20].	0	Proton-pump inhibitors (PPIs) are recommended in patients treated with dual antiplatelet therapy who are at high risk of gastrointestinal bleeding [12]. PPIs are metabolized primarily via the CYP2C19 and CYP3A4 isoenzymes [13] and are competitive inhibitors of CYP2C19 activity [14]. However, the contribution of the CYP2C19 isoenzyme to PPI biotransformation and H. pylori eradication rates [15] and the potency of inhibition of CYP2C19 activity [14] vary among different PPIs. CYP2C19 activity appears to affect the response to omeprazole, esomeprazole and lansoprazole [16]#CITATION_TAG[18] and to be inhibited by these PPIs [14,18]. This does not seem to be the case, at least not to the same extent, with pantoprazole [14,19] and rabeprazole [14,20].	2
CCT107	Proton-pump inhibitors (PPIs) are recommended in patients treated with dual antiplatelet therapy who are at high risk of gastrointestinal bleeding [12]. PPIs are metabolized primarily via the CYP2C19 and CYP3A4 isoenzymes [13] and are competitive inhibitors of CYP2C19 activity [14]. However, the contribution of the CYP2C19 isoenzyme to PPI biotransformation and H. pylori eradication rates [15] and the potency of inhibition of CYP2C19 activity [14] vary among different PPIs. CYP2C19 activity appears to affect the response to omeprazole, esomeprazole and lansoprazole [16][17]#CITATION_TAG and to be inhibited by these PPIs [14,18]. This does not seem to be the case, at least not to the same extent, with pantoprazole [14,19] and rabeprazole [14,20].	0	Proton-pump inhibitors (PPIs) are recommended in patients treated with dual antiplatelet therapy who are at high risk of gastrointestinal bleeding [12]. PPIs are metabolized primarily via the CYP2C19 and CYP3A4 isoenzymes [13] and are competitive inhibitors of CYP2C19 activity [14]. However, the contribution of the CYP2C19 isoenzyme to PPI biotransformation and H. pylori eradication rates [15] and the potency of inhibition of CYP2C19 activity [14] vary among different PPIs. CYP2C19 activity appears to affect the response to omeprazole, esomeprazole and lansoprazole [16][17]#CITATION_TAG and to be inhibited by these PPIs [14,18]. This does not seem to be the case, at least not to the same extent, with pantoprazole [14,19] and rabeprazole [14,20].	2
CCT108	Proton-pump inhibitors (PPIs) are recommended in patients treated with dual antiplatelet therapy who are at high risk of gastrointestinal bleeding [12]. PPIs are metabolized primarily via the CYP2C19 and CYP3A4 isoenzymes [13] and are competitive inhibitors of CYP2C19 activity [14]. However, the contribution of the CYP2C19 isoenzyme to PPI biotransformation and H. pylori eradication rates [15] and the potency of inhibition of CYP2C19 activity [14] vary among different PPIs. CYP2C19 activity appears to affect the response to omeprazole, esomeprazole and lansoprazole [16][17][18] and to be inhibited by these PPIs [14,18]. This does not seem to be the case, at least not to the same extent, with pantoprazole [14,19] and rabeprazole [14,#CITATION_TAG].	4	PPIs are metabolized primarily via the CYP2C19 and CYP3A4 isoenzymes [13] and are competitive inhibitors of CYP2C19 activity [14]. However, the contribution of the CYP2C19 isoenzyme to PPI biotransformation and H. pylori eradication rates [15] and the potency of inhibition of CYP2C19 activity [14] vary among different PPIs. CYP2C19 activity appears to affect the response to omeprazole, esomeprazole and lansoprazole [16][17][18] and to be inhibited by these PPIs [14,18]. This does not seem to be the case, at least not to the same extent, with pantoprazole [14,19] and rabeprazole [14,#CITATION_TAG].	 
CCT109	Concerns about PPI and clopidogrel interaction were raised when omeprazole was found to inhibit the antiplatelet effect of clopidogrel in an in vivo study of 124 patients undergoing elective coronary stent implantation [21]. Several studies have suggested that omeprazole interacts with clopidogrel efficacy by inhibiting the formation of its active metabolite via CYP2C19 inhibition [22,23]. Whether this occurs with all PPIs or is even of significant amplitude with omeprazole remains a matter of debate [9,#CITATION_TAG[25][26][27][28][29]. However, it was recently demonstrated that generation of clopidogrel active metabolite and inhibition of platelet function are reduced less by the co-administration of dexlansoprazole or lansoprazole with clopidogrel than by the co-administration of esomeprazole or omeprazole [30].	4	Concerns about PPI and clopidogrel interaction were raised when omeprazole was found to inhibit the antiplatelet effect of clopidogrel in an in vivo study of 124 patients undergoing elective coronary stent implantation [21]. Several studies have suggested that omeprazole interacts with clopidogrel efficacy by inhibiting the formation of its active metabolite via CYP2C19 inhibition [22,23]. Whether this occurs with all PPIs or is even of significant amplitude with omeprazole remains a matter of debate [9,#CITATION_TAG[25][26][27][28][29]. However, it was recently demonstrated that generation of clopidogrel active metabolite and inhibition of platelet function are reduced less by the co-administration of dexlansoprazole or lansoprazole with clopidogrel than by the co-administration of esomeprazole or omeprazole [30].	e
CCT110	Dual antiplatelet therapy with aspirin and clopidogrel is associated with a significant reduction in cardiovascular ischemic events after acute coronary syndromes or percutaneous coronary interventions and is recommended in guidelines from the USA [1] and Europe #CITATION_TAG. Clopidogrel is an inactive prodrug that undergoes two oxidative steps involving multiple cytochrome P-450 (CYP) enzymes in its bioactivation to its pharmacologically active metabolite. Among them, CYP2C19, a CYP enzyme whose activity is determined genetically, contributes predominantly to this bioactivation [3,4] and modulates the antiplatelet and therapeutic response to clopidogrel. Patients with loss of function polymorphism in the CYP2C19 gene are less responsive to clopidogrel [5,6], although the importance of this phenomenon remains controversial [7][8][9][10] and may be limited to the risk of stent thrombosis [11].	0	Dual antiplatelet therapy with aspirin and clopidogrel is associated with a significant reduction in cardiovascular ischemic events after acute coronary syndromes or percutaneous coronary interventions and is recommended in guidelines from the USA [1] and Europe #CITATION_TAG. Clopidogrel is an inactive prodrug that undergoes two oxidative steps involving multiple cytochrome P-450 (CYP) enzymes in its bioactivation to its pharmacologically active metabolite. Among them, CYP2C19, a CYP enzyme whose activity is determined genetically, contributes predominantly to this bioactivation [3,4] and modulates the antiplatelet and therapeutic response to clopidogrel. Patients with loss of function polymorphism in the CYP2C19 gene are less responsive to clopidogrel [5,6], although the importance of this phenomenon remains controversial [7][8][9][10] and may be limited to the risk of stent thrombosis [11].	D
CCT111	Concerns about PPI and clopidogrel interaction were raised when omeprazole was found to inhibit the antiplatelet effect of clopidogrel in an in vivo study of 124 patients undergoing elective coronary stent implantation [21]. Several studies have suggested that omeprazole interacts with clopidogrel efficacy by inhibiting the formation of its active metabolite via CYP2C19 inhibition [22,23]. Whether this occurs with all PPIs or is even of significant amplitude with omeprazole remains a matter of debate [9,[24][25]#CITATION_TAG[27][28][29]. However, it was recently demonstrated that generation of clopidogrel active metabolite and inhibition of platelet function are reduced less by the co-administration of dexlansoprazole or lansoprazole with clopidogrel than by the co-administration of esomeprazole or omeprazole [30].	0	Concerns about PPI and clopidogrel interaction were raised when omeprazole was found to inhibit the antiplatelet effect of clopidogrel in an in vivo study of 124 patients undergoing elective coronary stent implantation [21]. Several studies have suggested that omeprazole interacts with clopidogrel efficacy by inhibiting the formation of its active metabolite via CYP2C19 inhibition [22,23]. Whether this occurs with all PPIs or is even of significant amplitude with omeprazole remains a matter of debate [9,[24][25]#CITATION_TAG[27][28][29]. However, it was recently demonstrated that generation of clopidogrel active metabolite and inhibition of platelet function are reduced less by the co-administration of dexlansoprazole or lansoprazole with clopidogrel than by the co-administration of esomeprazole or omeprazole [30].	e
CCT112	Concerns about PPI and clopidogrel interaction were raised when omeprazole was found to inhibit the antiplatelet effect of clopidogrel in an in vivo study of 124 patients undergoing elective coronary stent implantation [21]. Several studies have suggested that omeprazole interacts with clopidogrel efficacy by inhibiting the formation of its active metabolite via CYP2C19 inhibition [22,23]. Whether this occurs with all PPIs or is even of significant amplitude with omeprazole remains a matter of debate [9,[24][25][26]#CITATION_TAG[28][29]. However, it was recently demonstrated that generation of clopidogrel active metabolite and inhibition of platelet function are reduced less by the co-administration of dexlansoprazole or lansoprazole with clopidogrel than by the co-administration of esomeprazole or omeprazole [30].	0	Concerns about PPI and clopidogrel interaction were raised when omeprazole was found to inhibit the antiplatelet effect of clopidogrel in an in vivo study of 124 patients undergoing elective coronary stent implantation [21]. Several studies have suggested that omeprazole interacts with clopidogrel efficacy by inhibiting the formation of its active metabolite via CYP2C19 inhibition [22,23]. Whether this occurs with all PPIs or is even of significant amplitude with omeprazole remains a matter of debate [9,[24][25][26]#CITATION_TAG[28][29]. However, it was recently demonstrated that generation of clopidogrel active metabolite and inhibition of platelet function are reduced less by the co-administration of dexlansoprazole or lansoprazole with clopidogrel than by the co-administration of esomeprazole or omeprazole [30].	e
CCT113	We regressed mean dominance durations against resting state connectivity from our two seed regions to determine which areas of cortex were involved in determining the dynamics of bistable alternations. We found that the coupling between the aSPL seed and regions of the striatum (green regions in Figure 3a) showed a greater association with faster alternations for the binocular rivalry stimulus (i.e. shorter durations). The striatum is known to be important in relaying prediction error signals to primary regions of cortex (#CITATION_TAG et al., 2011) and might play this role in perceptual decision making (Forstmann et al., 2010; though see also Boekel et al., 2015).	0	We regressed mean dominance durations against resting state connectivity from our two seed regions to determine which areas of cortex were involved in determining the dynamics of bistable alternations. We found that the coupling between the aSPL seed and regions of the striatum (green regions in Figure 3a) showed a greater association with faster alternations for the binocular rivalry stimulus (i.e. shorter durations). The striatum is known to be important in relaying prediction error signals to primary regions of cortex (#CITATION_TAG et al., 2011) and might play this role in perceptual decision making (Forstmann et al., 2010; though see also Boekel et al., 2015).	e
CCT114	The current study explores the functional connectivity of two regions of the superior parietal lobule (SPL) that have been shown to play a key role in bistable perception in studies using repetitive transcranial magnetic stimulation (rTMS). Application of TMS to the anterior region of the superior parietal lobule (aSPL) in the right hemisphere causes binocular rivalry and bistable motion alternations to speed up (Carmel et al., 2010;Kanai et al., 2011). By contrast, a more posterior region of the same structure (pSPL) slows down the alternations of a bistable structure from motion stimulus when targeted with TMS (Kanai et al., 2010). The apparently opposing functions of these two regions of the SPL is surprising given their physical proximity (see Figure 2). Recent fMRI work has demonstrated that the regions interact with visual areas involved in processing motion to resolve bistable motion percepts, and the strengths of connections are able to predict individual alternation rates accurately (#CITATION_TAG et al., 2015).	4	Application of TMS to the anterior region of the superior parietal lobule (aSPL) in the right hemisphere causes binocular rivalry and bistable motion alternations to speed up (Carmel et al., 2010;Kanai et al., 2011). By contrast, a more posterior region of the same structure (pSPL) slows down the alternations of a bistable structure from motion stimulus when targeted with TMS (Kanai et al., 2010). The apparently opposing functions of these two regions of the SPL is surprising given their physical proximity (see Figure 2). Recent fMRI work has demonstrated that the regions interact with visual areas involved in processing motion to resolve bistable motion percepts, and the strengths of connections are able to predict individual alternation rates accurately (#CITATION_TAG et al., 2015).	n
CCT115	Identifying the neural correlates of bistable perception by recording online activity, however, may confound activity that is causally linked to bistable alternations with activity that is merely correlated with it. The finding that activity in a given brain region (e.g. frontoparietal cortex Kleinschmidt et al., 1998;Lumer and Rees, 1999;Sterzer and Kleinschmidt, 2007;Weilnhammer et al., 2013) correlates with perception does not reveal whether that region drives the alternations, or reflects a consequence of processes occurring elsewhere. Carefully controlling for the character of perceptual transitions has been shown to dramatically reduce the number of brain regions that are viable candidates for determining alternations (#CITATION_TAG et al., 2011). Consequently, it is still a matter of debate whether different forms of bistable stimuli depend on bottom-up or top down influences, and which specific neural systems support these aspects of conscious experience. The current work capitalizes on the fact that stimulus-independent changes in neural processing occur naturally during wakeful rest. Neuroimaging has revealed that almost all functional networks that support aspects of task related processing have a comparable resting state network (Smith et al., 2009), and the integrity of these networks varies across individuals in a manner that is predictive of complex forms of cognition such as meta cognitive accuracy (Baird et al., 2013), spontaneous thought (Gorgolewski et al., 2014), reading comprehension (Smallwood et al., 2013) and executive control (Reineberg et al., 2015). As the neural activity at rest is uncontaminated by external input, it provides a relatively pure method to explore stimulusindependent neural processes and so a useful tool to understand the functional architecture of bistable perception.	4	Identifying the neural correlates of bistable perception by recording online activity, however, may confound activity that is causally linked to bistable alternations with activity that is merely correlated with it. The finding that activity in a given brain region (e.g. frontoparietal cortex Kleinschmidt et al., 1998;Lumer and Rees, 1999;Sterzer and Kleinschmidt, 2007;Weilnhammer et al., 2013) correlates with perception does not reveal whether that region drives the alternations, or reflects a consequence of processes occurring elsewhere. Carefully controlling for the character of perceptual transitions has been shown to dramatically reduce the number of brain regions that are viable candidates for determining alternations (#CITATION_TAG et al., 2011). Consequently, it is still a matter of debate whether different forms of bistable stimuli depend on bottom-up or top down influences, and which specific neural systems support these aspects of conscious experience. The current work capitalizes on the fact that stimulus-independent changes in neural processing occur naturally during wakeful rest. Neuroimaging has revealed that almost all functional networks that support aspects of task related processing have a comparable resting state network (Smith et al., 2009), and the integrity of these networks varies across individuals in a manner that is predictive of complex forms of cognition such as meta cognitive accuracy (Baird et al., 2013), spontaneous thought (Gorgolewski et al., 2014), reading comprehension (Smallwood et al., 2013) and executive control (Reineberg et al., 2015).	r
CCT116	A remarkable feature of the human mind is its capacity to process information that is independent of environmental input. We often lose ourselves in our thoughts, decoupling experience from the here and now (Baird et al., 2014). At other times we suddenly realize that we having been looking at the world from the wrong perspective: many famous visual illusions depend upon the resolution of uncertain perceptual input (#CITATION_TAG et al., 2009). These examples demonstrate that our conscious experience of our surroundings does not depend solely on the sensory information we receive at any moment in time, an observation that allows insight into the stimulus-independent basis of conscious perception. A popular way to study this dissociation between sensory inputs and conscious experience is to use stimuli that are ambiguous in their interpretation, and for which perception alternates over time. Classic examples include binocular rivalry (Figure 1a), in which incompatible images shown to the two eyes compete for awareness, and the Necker cube (see Figure 1b), in which a wire-frame cube can be perceived from multiple perspectives. Understanding the neural architecture that mediates these alternations is considered a critical step in uncovering neural correlates of consciousness (Crick and Koch, 1998).	0	A remarkable feature of the human mind is its capacity to process information that is independent of environmental input. We often lose ourselves in our thoughts, decoupling experience from the here and now (Baird et al., 2014). At other times we suddenly realize that we having been looking at the world from the wrong perspective: many famous visual illusions depend upon the resolution of uncertain perceptual input (#CITATION_TAG et al., 2009). These examples demonstrate that our conscious experience of our surroundings does not depend solely on the sensory information we receive at any moment in time, an observation that allows insight into the stimulus-independent basis of conscious perception. A popular way to study this dissociation between sensory inputs and conscious experience is to use stimuli that are ambiguous in their interpretation, and for which perception alternates over time. Classic examples include binocular rivalry (Figure 1a), in which incompatible images shown to the two eyes compete for awareness, and the Necker cube (see Figure 1b), in which a wire-frame cube can be perceived from multiple perspectives.	 
CCT117	The current study explores the functional connectivity of two regions of the superior parietal lobule (SPL) that have been shown to play a key role in bistable perception in studies using repetitive transcranial magnetic stimulation (rTMS). Application of TMS to the anterior region of the superior parietal lobule (aSPL) in the right hemisphere causes binocular rivalry and bistable motion alternations to speed up (Carmel et al., 2010;#CITATION_TAG et al., 2011). By contrast, a more posterior region of the same structure (pSPL) slows down the alternations of a bistable structure from motion stimulus when targeted with TMS (Kanai et al., 2010). The apparently opposing functions of these two regions of the SPL is surprising given their physical proximity (see Figure 2). Recent fMRI work has demonstrated that the regions interact with visual areas involved in processing motion to resolve bistable motion percepts, and the strengths of connections are able to predict individual alternation rates accurately (Megumi et al., 2015).	4	The current study explores the functional connectivity of two regions of the superior parietal lobule (SPL) that have been shown to play a key role in bistable perception in studies using repetitive transcranial magnetic stimulation (rTMS). Application of TMS to the anterior region of the superior parietal lobule (aSPL) in the right hemisphere causes binocular rivalry and bistable motion alternations to speed up (Carmel et al., 2010;#CITATION_TAG et al., 2011). By contrast, a more posterior region of the same structure (pSPL) slows down the alternations of a bistable structure from motion stimulus when targeted with TMS (Kanai et al., 2010). The apparently opposing functions of these two regions of the SPL is surprising given their physical proximity (see Figure 2). Recent fMRI work has demonstrated that the regions interact with visual areas involved in processing motion to resolve bistable motion percepts, and the strengths of connections are able to predict individual alternation rates accurately (Megumi et al., 2015).	p
CCT118	The current study explores the functional connectivity of two regions of the superior parietal lobule (SPL) that have been shown to play a key role in bistable perception in studies using repetitive transcranial magnetic stimulation (rTMS). Application of TMS to the anterior region of the superior parietal lobule (aSPL) in the right hemisphere causes binocular rivalry and bistable motion alternations to speed up (Carmel et al., 2010;Kanai et al., 2011). By contrast, a more posterior region of the same structure (pSPL) slows down the alternations of a bistable structure from motion stimulus when targeted with TMS (#CITATION_TAG et al., 2010). The apparently opposing functions of these two regions of the SPL is surprising given their physical proximity (see Figure 2). Recent fMRI work has demonstrated that the regions interact with visual areas involved in processing motion to resolve bistable motion percepts, and the strengths of connections are able to predict individual alternation rates accurately (Megumi et al., 2015).	4	The current study explores the functional connectivity of two regions of the superior parietal lobule (SPL) that have been shown to play a key role in bistable perception in studies using repetitive transcranial magnetic stimulation (rTMS). Application of TMS to the anterior region of the superior parietal lobule (aSPL) in the right hemisphere causes binocular rivalry and bistable motion alternations to speed up (Carmel et al., 2010;Kanai et al., 2011). By contrast, a more posterior region of the same structure (pSPL) slows down the alternations of a bistable structure from motion stimulus when targeted with TMS (#CITATION_TAG et al., 2010). The apparently opposing functions of these two regions of the SPL is surprising given their physical proximity (see Figure 2). Recent fMRI work has demonstrated that the regions interact with visual areas involved in processing motion to resolve bistable motion percepts, and the strengths of connections are able to predict individual alternation rates accurately (Megumi et al., 2015).	 
CCT119	Identifying the neural correlates of bistable perception by recording online activity, however, may confound activity that is causally linked to bistable alternations with activity that is merely correlated with it. The finding that activity in a given brain region (e.g. frontoparietal cortex Kleinschmidt et al., 1998;#CITATION_TAG and Rees, 1999;Sterzer and Kleinschmidt, 2007;Weilnhammer et al., 2013) correlates with perception does not reveal whether that region drives the alternations, or reflects a consequence of processes occurring elsewhere. Carefully controlling for the character of perceptual transitions has been shown to dramatically reduce the number of brain regions that are viable candidates for determining alternations (Knapen et al., 2011). Consequently, it is still a matter of debate whether different forms of bistable stimuli depend on bottom-up or top down influences, and which specific neural systems support these aspects of conscious experience. The current work capitalizes on the fact that stimulus-independent changes in neural processing occur naturally during wakeful rest. Neuroimaging has revealed that almost all functional networks that support aspects of task related processing have a comparable resting state network (Smith et al., 2009), and the integrity of these networks varies across individuals in a manner that is predictive of complex forms of cognition such as meta cognitive accuracy (Baird et al., 2013), spontaneous thought (Gorgolewski et al., 2014), reading comprehension (Smallwood et al., 2013) and executive control (Reineberg et al., 2015). As the neural activity at rest is uncontaminated by external input, it provides a relatively pure method to explore stimulusindependent neural processes and so a useful tool to understand the functional architecture of bistable perception.	0	Identifying the neural correlates of bistable perception by recording online activity, however, may confound activity that is causally linked to bistable alternations with activity that is merely correlated with it. The finding that activity in a given brain region (e.g. frontoparietal cortex Kleinschmidt et al., 1998;#CITATION_TAG and Rees, 1999;Sterzer and Kleinschmidt, 2007;Weilnhammer et al., 2013) correlates with perception does not reveal whether that region drives the alternations, or reflects a consequence of processes occurring elsewhere. Carefully controlling for the character of perceptual transitions has been shown to dramatically reduce the number of brain regions that are viable candidates for determining alternations (Knapen et al., 2011). Consequently, it is still a matter of debate whether different forms of bistable stimuli depend on bottom-up or top down influences, and which specific neural systems support these aspects of conscious experience. The current work capitalizes on the fact that stimulus-independent changes in neural processing occur naturally during wakeful rest.	h
CCT120	We regressed mean dominance durations against resting state connectivity from our two seed regions to determine which areas of cortex were involved in determining the dynamics of bistable alternations. We found that the coupling between the aSPL seed and regions of the striatum (green regions in Figure 3a) showed a greater association with faster alternations for the binocular rivalry stimulus (i.e. shorter durations). The striatum is known to be important in relaying prediction error signals to primary regions of cortex (Daw et al., 2011) and might play this role in perceptual decision making (#CITATION_TAG et al., 2010; though see also Boekel et al., 2015).	0	We regressed mean dominance durations against resting state connectivity from our two seed regions to determine which areas of cortex were involved in determining the dynamics of bistable alternations. We found that the coupling between the aSPL seed and regions of the striatum (green regions in Figure 3a) showed a greater association with faster alternations for the binocular rivalry stimulus (i.e. shorter durations). The striatum is known to be important in relaying prediction error signals to primary regions of cortex (Daw et al., 2011) and might play this role in perceptual decision making (#CITATION_TAG et al., 2010; though see also Boekel et al., 2015).	e
CCT121	Identifying the neural correlates of bistable perception by recording online activity, however, may confound activity that is causally linked to bistable alternations with activity that is merely correlated with it. The finding that activity in a given brain region (e.g. frontoparietal cortex #CITATION_TAG et al., 1998;Lumer and Rees, 1999;Sterzer and Kleinschmidt, 2007;Weilnhammer et al., 2013) correlates with perception does not reveal whether that region drives the alternations, or reflects a consequence of processes occurring elsewhere. Carefully controlling for the character of perceptual transitions has been shown to dramatically reduce the number of brain regions that are viable candidates for determining alternations (Knapen et al., 2011). Consequently, it is still a matter of debate whether different forms of bistable stimuli depend on bottom-up or top down influences, and which specific neural systems support these aspects of conscious experience. The current work capitalizes on the fact that stimulus-independent changes in neural processing occur naturally during wakeful rest. Neuroimaging has revealed that almost all functional networks that support aspects of task related processing have a comparable resting state network (Smith et al., 2009), and the integrity of these networks varies across individuals in a manner that is predictive of complex forms of cognition such as meta cognitive accuracy (Baird et al., 2013), spontaneous thought (Gorgolewski et al., 2014), reading comprehension (Smallwood et al., 2013) and executive control (Reineberg et al., 2015). As the neural activity at rest is uncontaminated by external input, it provides a relatively pure method to explore stimulusindependent neural processes and so a useful tool to understand the functional architecture of bistable perception.	0	Identifying the neural correlates of bistable perception by recording online activity, however, may confound activity that is causally linked to bistable alternations with activity that is merely correlated with it. The finding that activity in a given brain region (e.g. frontoparietal cortex #CITATION_TAG et al., 1998;Lumer and Rees, 1999;Sterzer and Kleinschmidt, 2007;Weilnhammer et al., 2013) correlates with perception does not reveal whether that region drives the alternations, or reflects a consequence of processes occurring elsewhere. Carefully controlling for the character of perceptual transitions has been shown to dramatically reduce the number of brain regions that are viable candidates for determining alternations (Knapen et al., 2011). Consequently, it is still a matter of debate whether different forms of bistable stimuli depend on bottom-up or top down influences, and which specific neural systems support these aspects of conscious experience. The current work capitalizes on the fact that stimulus-independent changes in neural processing occur naturally during wakeful rest.	h
CCT122	Identifying the neural correlates of bistable perception by recording online activity, however, may confound activity that is causally linked to bistable alternations with activity that is merely correlated with it. The finding that activity in a given brain region (e.g. frontoparietal cortex Kleinschmidt et al., 1998;Lumer and Rees, 1999;Sterzer and Kleinschmidt, 2007;#CITATION_TAG et al., 2013) correlates with perception does not reveal whether that region drives the alternations, or reflects a consequence of processes occurring elsewhere. Carefully controlling for the character of perceptual transitions has been shown to dramatically reduce the number of brain regions that are viable candidates for determining alternations (Knapen et al., 2011). Consequently, it is still a matter of debate whether different forms of bistable stimuli depend on bottom-up or top down influences, and which specific neural systems support these aspects of conscious experience. The current work capitalizes on the fact that stimulus-independent changes in neural processing occur naturally during wakeful rest. Neuroimaging has revealed that almost all functional networks that support aspects of task related processing have a comparable resting state network (Smith et al., 2009), and the integrity of these networks varies across individuals in a manner that is predictive of complex forms of cognition such as meta cognitive accuracy (Baird et al., 2013), spontaneous thought (Gorgolewski et al., 2014), reading comprehension (Smallwood et al., 2013) and executive control (Reineberg et al., 2015). As the neural activity at rest is uncontaminated by external input, it provides a relatively pure method to explore stimulusindependent neural processes and so a useful tool to understand the functional architecture of bistable perception.	0	Identifying the neural correlates of bistable perception by recording online activity, however, may confound activity that is causally linked to bistable alternations with activity that is merely correlated with it. The finding that activity in a given brain region (e.g. frontoparietal cortex Kleinschmidt et al., 1998;Lumer and Rees, 1999;Sterzer and Kleinschmidt, 2007;#CITATION_TAG et al., 2013) correlates with perception does not reveal whether that region drives the alternations, or reflects a consequence of processes occurring elsewhere. Carefully controlling for the character of perceptual transitions has been shown to dramatically reduce the number of brain regions that are viable candidates for determining alternations (Knapen et al., 2011). Consequently, it is still a matter of debate whether different forms of bistable stimuli depend on bottom-up or top down influences, and which specific neural systems support these aspects of conscious experience. The current work capitalizes on the fact that stimulus-independent changes in neural processing occur naturally during wakeful rest.	h
CCT123	We found evidence that anterior and posterior regions of superior parietal cortex which influence bistable perception in opposing directions do so because of differences in their functional architecture. Our seed region in the pSPL exhibited connectivity with regions of parietal and lateral prefrontal cortex whose specialism is in the extraction of higher order features of sensory input (Duncan, 2010;Goldman-Rakic, 1988). This functional network is consistent with prior fMRI studies that have found a relationship between alternations and activity in similar regions of fronto-parietal cortex (Kleinschmidt et al., 1998;Knapen et al., 2011;Lumer and Rees, 1999;Sterzer and Kleinschmidt, 2007;Watanabe et al., 2014;Weilnhammer et al., 2013). Importantly, Experiment Two found that connectivity between pSPL and ventral aspects of the temporal lobe was enhanced for individuals who experienced slower rivalry alternations. This brain region is important in visual aspects of semantics (#CITATION_TAG et al., 2004;Visser et al., 2010) and activity there is suppressed when an image is rendered invisible by rivalry suppression (Fang and He, 2005). Together these data are consistent with the claim that the pSPL is part of a distributed functional system that helps stabilize a specific interpretation of low-level perceptual input.	0	Our seed region in the pSPL exhibited connectivity with regions of parietal and lateral prefrontal cortex whose specialism is in the extraction of higher order features of sensory input (Duncan, 2010;Goldman-Rakic, 1988). This functional network is consistent with prior fMRI studies that have found a relationship between alternations and activity in similar regions of fronto-parietal cortex (Kleinschmidt et al., 1998;Knapen et al., 2011;Lumer and Rees, 1999;Sterzer and Kleinschmidt, 2007;Watanabe et al., 2014;Weilnhammer et al., 2013). Importantly, Experiment Two found that connectivity between pSPL and ventral aspects of the temporal lobe was enhanced for individuals who experienced slower rivalry alternations. This brain region is important in visual aspects of semantics (#CITATION_TAG et al., 2004;Visser et al., 2010) and activity there is suppressed when an image is rendered invisible by rivalry suppression (Fang and He, 2005). Together these data are consistent with the claim that the pSPL is part of a distributed functional system that helps stabilize a specific interpretation of low-level perceptual input.	 
CCT124	Slower alternations during binocular rivalry were associated with stronger connectivity between the pSPL and regions of the left temporal lobe primarily in the inferior temporal gyrus (ITG, Figure 3b). The ITG constitutes the most anterior aspect of the ventral stream and is hypothesized to code relatively high-level information about stable properties of a stimulus, specifically in the visual modality (#CITATION_TAG et al., 2013).	0	Slower alternations during binocular rivalry were associated with stronger connectivity between the pSPL and regions of the left temporal lobe primarily in the inferior temporal gyrus (ITG, Figure 3b). The ITG constitutes the most anterior aspect of the ventral stream and is hypothesized to code relatively high-level information about stable properties of a stimulus, specifically in the visual modality (#CITATION_TAG et al., 2013).	h
CCT125	Identifying the neural correlates of bistable perception by recording online activity, however, may confound activity that is causally linked to bistable alternations with activity that is merely correlated with it. The finding that activity in a given brain region (e.g. frontoparietal cortex Kleinschmidt et al., 1998;Lumer and Rees, 1999;Sterzer and Kleinschmidt, 2007;Weilnhammer et al., 2013) correlates with perception does not reveal whether that region drives the alternations, or reflects a consequence of processes occurring elsewhere. Carefully controlling for the character of perceptual transitions has been shown to dramatically reduce the number of brain regions that are viable candidates for determining alternations (Knapen et al., 2011). Consequently, it is still a matter of debate whether different forms of bistable stimuli depend on bottom-up or top down influences, and which specific neural systems support these aspects of conscious experience. The current work capitalizes on the fact that stimulus-independent changes in neural processing occur naturally during wakeful rest. Neuroimaging has revealed that almost all functional networks that support aspects of task related processing have a comparable resting state network (Smith et al., 2009), and the integrity of these networks varies across individuals in a manner that is predictive of complex forms of cognition such as meta cognitive accuracy (Baird et al., 2013), spontaneous thought (Gorgolewski et al., 2014), reading comprehension (#CITATION_TAG et al., 2013) and executive control (Reineberg et al., 2015). As the neural activity at rest is uncontaminated by external input, it provides a relatively pure method to explore stimulusindependent neural processes and so a useful tool to understand the functional architecture of bistable perception.	0	Carefully controlling for the character of perceptual transitions has been shown to dramatically reduce the number of brain regions that are viable candidates for determining alternations (Knapen et al., 2011). Consequently, it is still a matter of debate whether different forms of bistable stimuli depend on bottom-up or top down influences, and which specific neural systems support these aspects of conscious experience. The current work capitalizes on the fact that stimulus-independent changes in neural processing occur naturally during wakeful rest. Neuroimaging has revealed that almost all functional networks that support aspects of task related processing have a comparable resting state network (Smith et al., 2009), and the integrity of these networks varies across individuals in a manner that is predictive of complex forms of cognition such as meta cognitive accuracy (Baird et al., 2013), spontaneous thought (Gorgolewski et al., 2014), reading comprehension (#CITATION_TAG et al., 2013) and executive control (Reineberg et al., 2015). As the neural activity at rest is uncontaminated by external input, it provides a relatively pure method to explore stimulusindependent neural processes and so a useful tool to understand the functional architecture of bistable perception.	i
CCT126	Identifying the neural correlates of bistable perception by recording online activity, however, may confound activity that is causally linked to bistable alternations with activity that is merely correlated with it. The finding that activity in a given brain region (e.g. frontoparietal cortex Kleinschmidt et al., 1998;Lumer and Rees, 1999;#CITATION_TAG and Kleinschmidt, 2007;Weilnhammer et al., 2013) correlates with perception does not reveal whether that region drives the alternations, or reflects a consequence of processes occurring elsewhere. Carefully controlling for the character of perceptual transitions has been shown to dramatically reduce the number of brain regions that are viable candidates for determining alternations (Knapen et al., 2011). Consequently, it is still a matter of debate whether different forms of bistable stimuli depend on bottom-up or top down influences, and which specific neural systems support these aspects of conscious experience. The current work capitalizes on the fact that stimulus-independent changes in neural processing occur naturally during wakeful rest. Neuroimaging has revealed that almost all functional networks that support aspects of task related processing have a comparable resting state network (Smith et al., 2009), and the integrity of these networks varies across individuals in a manner that is predictive of complex forms of cognition such as meta cognitive accuracy (Baird et al., 2013), spontaneous thought (Gorgolewski et al., 2014), reading comprehension (Smallwood et al., 2013) and executive control (Reineberg et al., 2015). As the neural activity at rest is uncontaminated by external input, it provides a relatively pure method to explore stimulusindependent neural processes and so a useful tool to understand the functional architecture of bistable perception.	0	Identifying the neural correlates of bistable perception by recording online activity, however, may confound activity that is causally linked to bistable alternations with activity that is merely correlated with it. The finding that activity in a given brain region (e.g. frontoparietal cortex Kleinschmidt et al., 1998;Lumer and Rees, 1999;#CITATION_TAG and Kleinschmidt, 2007;Weilnhammer et al., 2013) correlates with perception does not reveal whether that region drives the alternations, or reflects a consequence of processes occurring elsewhere. Carefully controlling for the character of perceptual transitions has been shown to dramatically reduce the number of brain regions that are viable candidates for determining alternations (Knapen et al., 2011). Consequently, it is still a matter of debate whether different forms of bistable stimuli depend on bottom-up or top down influences, and which specific neural systems support these aspects of conscious experience. The current work capitalizes on the fact that stimulus-independent changes in neural processing occur naturally during wakeful rest.	h
CCT127	Identifying the neural correlates of bistable perception by recording online activity, however, may confound activity that is causally linked to bistable alternations with activity that is merely correlated with it. The finding that activity in a given brain region (e.g. frontoparietal cortex Kleinschmidt et al., 1998;Lumer and Rees, 1999;Sterzer and Kleinschmidt, 2007;Weilnhammer et al., 2013) correlates with perception does not reveal whether that region drives the alternations, or reflects a consequence of processes occurring elsewhere. Carefully controlling for the character of perceptual transitions has been shown to dramatically reduce the number of brain regions that are viable candidates for determining alternations (Knapen et al., 2011). Consequently, it is still a matter of debate whether different forms of bistable stimuli depend on bottom-up or top down influences, and which specific neural systems support these aspects of conscious experience. The current work capitalizes on the fact that stimulus-independent changes in neural processing occur naturally during wakeful rest. Neuroimaging has revealed that almost all functional networks that support aspects of task related processing have a comparable resting state network (Smith et al., 2009), and the integrity of these networks varies across individuals in a manner that is predictive of complex forms of cognition such as meta cognitive accuracy (Baird et al., 2013), spontaneous thought (Gorgolewski et al., 2014), reading comprehension (Smallwood et al., 2013) and executive control (#CITATION_TAG et al., 2015). As the neural activity at rest is uncontaminated by external input, it provides a relatively pure method to explore stimulusindependent neural processes and so a useful tool to understand the functional architecture of bistable perception.	0	Carefully controlling for the character of perceptual transitions has been shown to dramatically reduce the number of brain regions that are viable candidates for determining alternations (Knapen et al., 2011). Consequently, it is still a matter of debate whether different forms of bistable stimuli depend on bottom-up or top down influences, and which specific neural systems support these aspects of conscious experience. The current work capitalizes on the fact that stimulus-independent changes in neural processing occur naturally during wakeful rest. Neuroimaging has revealed that almost all functional networks that support aspects of task related processing have a comparable resting state network (Smith et al., 2009), and the integrity of these networks varies across individuals in a manner that is predictive of complex forms of cognition such as meta cognitive accuracy (Baird et al., 2013), spontaneous thought (Gorgolewski et al., 2014), reading comprehension (Smallwood et al., 2013) and executive control (#CITATION_TAG et al., 2015). As the neural activity at rest is uncontaminated by external input, it provides a relatively pure method to explore stimulusindependent neural processes and so a useful tool to understand the functional architecture of bistable perception.	i
CCT128	"The participation of the larger SPL in a diverse and heterogeneous set of functional networks as our data shows indicates that it acts as a hub regulating the balance of neural processing. It is already known that this region of cortex is a member of a rich ""club"" of regions whose connectivity allows them to integrate neural processing in an influential manner (#CITATION_TAG and Sporns, 2011). The heterogeneous nature of this pattern, coupled with its distinct psychological consequences, explains why disrupting adjacent regions of the SPL using TMS can have different and apparently contradictory consequences on rivalry durations. More generally, its role as a hub would allow the 2.3 4.0"	0	"The participation of the larger SPL in a diverse and heterogeneous set of functional networks as our data shows indicates that it acts as a hub regulating the balance of neural processing. It is already known that this region of cortex is a member of a rich ""club"" of regions whose connectivity allows them to integrate neural processing in an influential manner (#CITATION_TAG and Sporns, 2011). The heterogeneous nature of this pattern, coupled with its distinct psychological consequences, explains why disrupting adjacent regions of the SPL using TMS can have different and apparently contradictory consequences on rivalry durations. More generally, its role as a hub would allow the 2.3 4.0"	t
CCT129	In contrast to the pSPL, the aSPL was connected to regions of sensori motor cortex that are thought to serve functions more closely tethered to sensory input (Buckner and Krienen, 2013). Importantly, our data show that strong aSPL connectivity with the striatum was linked to shorter rivalrous durations. Given the potential role of the striatum in prediction error (Forstmann et al., 2010), this pattern of heightened connectivity suggests that during binocular rivalry, a specific percept may remain dominant as long as the competing low-level input is suppressed. Consistent with this interpretation of our data, recent work has shown that increasing the reward associated with a particular stimulus, a manipulation that increases the magnitude of a prediction error signal, increases the dominance of that particular stimulus (#CITATION_TAG and Einhauser, 2015). Compared with resolving binocular rivalry, viewing a Necker cube involves overcoming incongruency in perceptual input at a relatively higher level. Connectivity between the aSPL and a region of dorso-medial prefrontal cortex was enhanced for participants with relatively longer dominance durations for the Necker cube. This region of pre-frontal cortex is implicated in the top-down coordination of cognition and action (Botvinick et al., 2004). Importantly, this region overlaps with the connectivity patterns of the pSPL (see Figure 4) suggesting that it is functionally connected to information arising in a bottom up manner from sensori-motor cortex and in a top down manner from information in associative cortex (see also Watanabe et al., 2014). This convergence of information would be especially important in allowing perceptual incongruity to be resolved at relatively complex levels such as that which occurs while viewing the Necker Cube.	0	In contrast to the pSPL, the aSPL was connected to regions of sensori motor cortex that are thought to serve functions more closely tethered to sensory input (Buckner and Krienen, 2013). Importantly, our data show that strong aSPL connectivity with the striatum was linked to shorter rivalrous durations. Given the potential role of the striatum in prediction error (Forstmann et al., 2010), this pattern of heightened connectivity suggests that during binocular rivalry, a specific percept may remain dominant as long as the competing low-level input is suppressed. Consistent with this interpretation of our data, recent work has shown that increasing the reward associated with a particular stimulus, a manipulation that increases the magnitude of a prediction error signal, increases the dominance of that particular stimulus (#CITATION_TAG and Einhauser, 2015). Compared with resolving binocular rivalry, viewing a Necker cube involves overcoming incongruency in perceptual input at a relatively higher level. Connectivity between the aSPL and a region of dorso-medial prefrontal cortex was enhanced for participants with relatively longer dominance durations for the Necker cube. This region of pre-frontal cortex is implicated in the top-down coordination of cognition and action (Botvinick et al., 2004).	s
CCT130	In Experiment One, we examined the functional architecture associated with these regions in a large group of participants with the aim of identifying the large-scale networks that these areas participate in. Building on prior work linking individual differences in perception to neural organisation (Kanai et al., 2011(Kanai et al., , 2010Megumi et al., 2015;Song et al., 2013a;2013b;#CITATION_TAG et al., 2013;Watanabe et al., 2014), in Experiment Two we probed the functions of these networks by examining whether modulations in the connectivity across individuals contains explanatory information on their rate of perceptual alternations. We did this for two different bistable stimuli, selected for their reliance on either lower-level stimulus features (binocular rivalry between two orthogonal gratings) and higher-level stimulus features (alternations between two interpretations of the Necker cube). By selecting contexts in which bistability occurs at either lower or higher levels of analysis we hoped to be able to reveal neural processes that contribute to top down and bottom up processing in bistable perception. We were especially interested whether the different regions of the SPL had different functional architectures at rest, and whether such differences could explain the heterogeneous relationship between rivalrous experience in this region of cortex.	4	In Experiment One, we examined the functional architecture associated with these regions in a large group of participants with the aim of identifying the large-scale networks that these areas participate in. Building on prior work linking individual differences in perception to neural organisation (Kanai et al., 2011(Kanai et al., , 2010Megumi et al., 2015;Song et al., 2013a;2013b;#CITATION_TAG et al., 2013;Watanabe et al., 2014), in Experiment Two we probed the functions of these networks by examining whether modulations in the connectivity across individuals contains explanatory information on their rate of perceptual alternations. We did this for two different bistable stimuli, selected for their reliance on either lower-level stimulus features (binocular rivalry between two orthogonal gratings) and higher-level stimulus features (alternations between two interpretations of the Necker cube). By selecting contexts in which bistability occurs at either lower or higher levels of analysis we hoped to be able to reveal neural processes that contribute to top down and bottom up processing in bistable perception. We were especially interested whether the different regions of the SPL had different functional architectures at rest, and whether such differences could explain the heterogeneous relationship between rivalrous experience in this region of cortex.	u
CCT131	We found evidence that anterior and posterior regions of superior parietal cortex which influence bistable perception in opposing directions do so because of differences in their functional architecture. Our seed region in the pSPL exhibited connectivity with regions of parietal and lateral prefrontal cortex whose specialism is in the extraction of higher order features of sensory input (Duncan, 2010;Goldman-Rakic, 1988). This functional network is consistent with prior fMRI studies that have found a relationship between alternations and activity in similar regions of fronto-parietal cortex (Kleinschmidt et al., 1998;Knapen et al., 2011;Lumer and Rees, 1999;Sterzer and Kleinschmidt, 2007;Watanabe et al., 2014;Weilnhammer et al., 2013). Importantly, Experiment Two found that connectivity between pSPL and ventral aspects of the temporal lobe was enhanced for individuals who experienced slower rivalry alternations. This brain region is important in visual aspects of semantics (Squire et al., 2004;#CITATION_TAG et al., 2010) and activity there is suppressed when an image is rendered invisible by rivalry suppression (Fang and He, 2005). Together these data are consistent with the claim that the pSPL is part of a distributed functional system that helps stabilize a specific interpretation of low-level perceptual input.	2	Our seed region in the pSPL exhibited connectivity with regions of parietal and lateral prefrontal cortex whose specialism is in the extraction of higher order features of sensory input (Duncan, 2010;Goldman-Rakic, 1988). This functional network is consistent with prior fMRI studies that have found a relationship between alternations and activity in similar regions of fronto-parietal cortex (Kleinschmidt et al., 1998;Knapen et al., 2011;Lumer and Rees, 1999;Sterzer and Kleinschmidt, 2007;Watanabe et al., 2014;Weilnhammer et al., 2013). Importantly, Experiment Two found that connectivity between pSPL and ventral aspects of the temporal lobe was enhanced for individuals who experienced slower rivalry alternations. This brain region is important in visual aspects of semantics (Squire et al., 2004;#CITATION_TAG et al., 2010) and activity there is suppressed when an image is rendered invisible by rivalry suppression (Fang and He, 2005). Together these data are consistent with the claim that the pSPL is part of a distributed functional system that helps stabilize a specific interpretation of low-level perceptual input.	 
CCT132	Identifying the neural correlates of bistable perception by recording online activity, however, may confound activity that is causally linked to bistable alternations with activity that is merely correlated with it. The finding that activity in a given brain region (e.g. frontoparietal cortex Kleinschmidt et al., 1998;Lumer and Rees, 1999;Sterzer and Kleinschmidt, 2007;Weilnhammer et al., 2013) correlates with perception does not reveal whether that region drives the alternations, or reflects a consequence of processes occurring elsewhere. Carefully controlling for the character of perceptual transitions has been shown to dramatically reduce the number of brain regions that are viable candidates for determining alternations (Knapen et al., 2011). Consequently, it is still a matter of debate whether different forms of bistable stimuli depend on bottom-up or top down influences, and which specific neural systems support these aspects of conscious experience. The current work capitalizes on the fact that stimulus-independent changes in neural processing occur naturally during wakeful rest. Neuroimaging has revealed that almost all functional networks that support aspects of task related processing have a comparable resting state network (#CITATION_TAG et al., 2009), and the integrity of these networks varies across individuals in a manner that is predictive of complex forms of cognition such as meta cognitive accuracy (Baird et al., 2013), spontaneous thought (Gorgolewski et al., 2014), reading comprehension (Smallwood et al., 2013) and executive control (Reineberg et al., 2015). As the neural activity at rest is uncontaminated by external input, it provides a relatively pure method to explore stimulusindependent neural processes and so a useful tool to understand the functional architecture of bistable perception.	5	Carefully controlling for the character of perceptual transitions has been shown to dramatically reduce the number of brain regions that are viable candidates for determining alternations (Knapen et al., 2011). Consequently, it is still a matter of debate whether different forms of bistable stimuli depend on bottom-up or top down influences, and which specific neural systems support these aspects of conscious experience. The current work capitalizes on the fact that stimulus-independent changes in neural processing occur naturally during wakeful rest. Neuroimaging has revealed that almost all functional networks that support aspects of task related processing have a comparable resting state network (#CITATION_TAG et al., 2009), and the integrity of these networks varies across individuals in a manner that is predictive of complex forms of cognition such as meta cognitive accuracy (Baird et al., 2013), spontaneous thought (Gorgolewski et al., 2014), reading comprehension (Smallwood et al., 2013) and executive control (Reineberg et al., 2015). As the neural activity at rest is uncontaminated by external input, it provides a relatively pure method to explore stimulusindependent neural processes and so a useful tool to understand the functional architecture of bistable perception.	i
CCT133	We seeded two adjacent parietal regions in the right hemisphere for a set of resting state fMRI scans collected from 141 participants (Nooner et al., 2012). The network associated with the anterior seed (red button in the upper right panel of Figure 2) involved the occipital lobe, regions of the parietal lobe, and the dorsal surface of the temporal lobe. The network associated with the posterior seed (blue button in the upper right panel of Figure 2) involved lateral regions of temporo-parietal cortex, elements of the temporal lobe, and dorsolateral regions of the prefrontal cortex. We verified the distinctness of these two networks using a large meta-analytic resting state database (www.neurosynth.org; #CITATION_TAG et al., 2011), that produced similar (though less extensive) networks, shown in Supplementary Figure S1. It is noteworthy that the connectivity of the aSPL seed was targeted at primary sensori-motor regions, whereas the connectivity of the pSPL seed region connected with regions of associative cortex (e.g. the temporal lobe and lateral/medial regions of the dorsal prefrontal cortex).	5	The network associated with the anterior seed (red button in the upper right panel of Figure 2) involved the occipital lobe, regions of the parietal lobe, and the dorsal surface of the temporal lobe. The network associated with the posterior seed (blue button in the upper right panel of Figure 2) involved lateral regions of temporo-parietal cortex, elements of the temporal lobe, and dorsolateral regions of the prefrontal cortex. We verified the distinctness of these two networks using a large meta-analytic resting state database (www. neurosynth.org; #CITATION_TAG et al., 2011), that produced similar (though less extensive) networks, shown in Supplementary Figure S1. It is noteworthy that the connectivity of the aSPL seed was targeted at primary sensori-motor regions, whereas the connectivity of the pSPL seed region connected with regions of associative cortex (e.g. the temporal lobe and lateral/medial regions of the dorsal prefrontal cortex).	o
CCT134	A remarkable feature of the human mind is its capacity to process information that is independent of environmental input. We often lose ourselves in our thoughts, decoupling experience from the here and now (#CITATION_TAG et al., 2014). At other times we suddenly realize that we having been looking at the world from the wrong perspective: many famous visual illusions depend upon the resolution of uncertain perceptual input (Sterzer et al., 2009). These examples demonstrate that our conscious experience of our surroundings does not depend solely on the sensory information we receive at any moment in time, an observation that allows insight into the stimulus-independent basis of conscious perception. A popular way to study this dissociation between sensory inputs and conscious experience is to use stimuli that are ambiguous in their interpretation, and for which perception alternates over time. Classic examples include binocular rivalry (Figure 1a), in which incompatible images shown to the two eyes compete for awareness, and the Necker cube (see Figure 1b), in which a wire-frame cube can be perceived from multiple perspectives. Understanding the neural architecture that mediates these alternations is considered a critical step in uncovering neural correlates of consciousness (Crick and Koch, 1998).	0	A remarkable feature of the human mind is its capacity to process information that is independent of environmental input. We often lose ourselves in our thoughts, decoupling experience from the here and now (#CITATION_TAG et al., 2014). At other times we suddenly realize that we having been looking at the world from the wrong perspective: many famous visual illusions depend upon the resolution of uncertain perceptual input (Sterzer et al., 2009). These examples demonstrate that our conscious experience of our surroundings does not depend solely on the sensory information we receive at any moment in time, an observation that allows insight into the stimulus-independent basis of conscious perception. A popular way to study this dissociation between sensory inputs and conscious experience is to use stimuli that are ambiguous in their interpretation, and for which perception alternates over time.	e
CCT135	In contrast to the pSPL, the aSPL was connected to regions of sensori motor cortex that are thought to serve functions more closely tethered to sensory input (Buckner and Krienen, 2013). Importantly, our data show that strong aSPL connectivity with the striatum was linked to shorter rivalrous durations. Given the potential role of the striatum in prediction error (Forstmann et al., 2010), this pattern of heightened connectivity suggests that during binocular rivalry, a specific percept may remain dominant as long as the competing low-level input is suppressed. Consistent with this interpretation of our data, recent work has shown that increasing the reward associated with a particular stimulus, a manipulation that increases the magnitude of a prediction error signal, increases the dominance of that particular stimulus (Marx and Einhauser, 2015). Compared with resolving binocular rivalry, viewing a Necker cube involves overcoming incongruency in perceptual input at a relatively higher level. Connectivity between the aSPL and a region of dorso-medial prefrontal cortex was enhanced for participants with relatively longer dominance durations for the Necker cube. This region of pre-frontal cortex is implicated in the top-down coordination of cognition and action (#CITATION_TAG et al., 2004). Importantly, this region overlaps with the connectivity patterns of the pSPL (see Figure 4) suggesting that it is functionally connected to information arising in a bottom up manner from sensori-motor cortex and in a top down manner from information in associative cortex (see also Watanabe et al., 2014). This convergence of information would be especially important in allowing perceptual incongruity to be resolved at relatively complex levels such as that which occurs while viewing the Necker Cube.	0	Consistent with this interpretation of our data, recent work has shown that increasing the reward associated with a particular stimulus, a manipulation that increases the magnitude of a prediction error signal, increases the dominance of that particular stimulus (Marx and Einhauser, 2015). Compared with resolving binocular rivalry, viewing a Necker cube involves overcoming incongruency in perceptual input at a relatively higher level. Connectivity between the aSPL and a region of dorso-medial prefrontal cortex was enhanced for participants with relatively longer dominance durations for the Necker cube. This region of pre-frontal cortex is implicated in the top-down coordination of cognition and action (#CITATION_TAG et al., 2004). Importantly, this region overlaps with the connectivity patterns of the pSPL (see Figure 4) suggesting that it is functionally connected to information arising in a bottom up manner from sensori-motor cortex and in a top down manner from information in associative cortex (see also Watanabe et al., 2014). This convergence of information would be especially important in allowing perceptual incongruity to be resolved at relatively complex levels such as that which occurs while viewing the Necker Cube.	e
CCT136	Identifying the neural correlates of bistable perception by recording online activity, however, may confound activity that is causally linked to bistable alternations with activity that is merely correlated with it. The finding that activity in a given brain region (e.g. frontoparietal cortex Kleinschmidt et al., 1998;Lumer and Rees, 1999;Sterzer and Kleinschmidt, 2007;Weilnhammer et al., 2013) correlates with perception does not reveal whether that region drives the alternations, or reflects a consequence of processes occurring elsewhere. Carefully controlling for the character of perceptual transitions has been shown to dramatically reduce the number of brain regions that are viable candidates for determining alternations (Knapen et al., 2011). Consequently, it is still a matter of debate whether different forms of bistable stimuli depend on bottom-up or top down influences, and which specific neural systems support these aspects of conscious experience. The current work capitalizes on the fact that stimulus-independent changes in neural processing occur naturally during wakeful rest. Neuroimaging has revealed that almost all functional networks that support aspects of task related processing have a comparable resting state network (Smith et al., 2009), and the integrity of these networks varies across individuals in a manner that is predictive of complex forms of cognition such as meta cognitive accuracy (Baird et al., 2013), spontaneous thought (#CITATION_TAG et al., 2014), reading comprehension (Smallwood et al., 2013) and executive control (Reineberg et al., 2015). As the neural activity at rest is uncontaminated by external input, it provides a relatively pure method to explore stimulusindependent neural processes and so a useful tool to understand the functional architecture of bistable perception.	0	Carefully controlling for the character of perceptual transitions has been shown to dramatically reduce the number of brain regions that are viable candidates for determining alternations (Knapen et al., 2011). Consequently, it is still a matter of debate whether different forms of bistable stimuli depend on bottom-up or top down influences, and which specific neural systems support these aspects of conscious experience. The current work capitalizes on the fact that stimulus-independent changes in neural processing occur naturally during wakeful rest. Neuroimaging has revealed that almost all functional networks that support aspects of task related processing have a comparable resting state network (Smith et al., 2009), and the integrity of these networks varies across individuals in a manner that is predictive of complex forms of cognition such as meta cognitive accuracy (Baird et al., 2013), spontaneous thought (#CITATION_TAG et al., 2014), reading comprehension (Smallwood et al., 2013) and executive control (Reineberg et al., 2015). As the neural activity at rest is uncontaminated by external input, it provides a relatively pure method to explore stimulusindependent neural processes and so a useful tool to understand the functional architecture of bistable perception.	i
CCT137	We found evidence that anterior and posterior regions of superior parietal cortex which influence bistable perception in opposing directions do so because of differences in their functional architecture. Our seed region in the pSPL exhibited connectivity with regions of parietal and lateral prefrontal cortex whose specialism is in the extraction of higher order features of sensory input (Duncan, 2010;#CITATION_TAG, 1988). This functional network is consistent with prior fMRI studies that have found a relationship between alternations and activity in similar regions of fronto-parietal cortex (Kleinschmidt et al., 1998;Knapen et al., 2011;Lumer and Rees, 1999;Sterzer and Kleinschmidt, 2007;Watanabe et al., 2014;Weilnhammer et al., 2013). Importantly, Experiment Two found that connectivity between pSPL and ventral aspects of the temporal lobe was enhanced for individuals who experienced slower rivalry alternations. This brain region is important in visual aspects of semantics (Squire et al., 2004;Visser et al., 2010) and activity there is suppressed when an image is rendered invisible by rivalry suppression (Fang and He, 2005). Together these data are consistent with the claim that the pSPL is part of a distributed functional system that helps stabilize a specific interpretation of low-level perceptual input.	0	We found evidence that anterior and posterior regions of superior parietal cortex which influence bistable perception in opposing directions do so because of differences in their functional architecture. Our seed region in the pSPL exhibited connectivity with regions of parietal and lateral prefrontal cortex whose specialism is in the extraction of higher order features of sensory input (Duncan, 2010;#CITATION_TAG, 1988). This functional network is consistent with prior fMRI studies that have found a relationship between alternations and activity in similar regions of fronto-parietal cortex (Kleinschmidt et al., 1998;Knapen et al., 2011;Lumer and Rees, 1999;Sterzer and Kleinschmidt, 2007;Watanabe et al., 2014;Weilnhammer et al., 2013). Importantly, Experiment Two found that connectivity between pSPL and ventral aspects of the temporal lobe was enhanced for individuals who experienced slower rivalry alternations. This brain region is important in visual aspects of semantics (Squire et al., 2004;Visser et al., 2010) and activity there is suppressed when an image is rendered invisible by rivalry suppression (Fang and He, 2005).	u
CCT138	To understand the function these networks play in bistable perception, we analyzed resting state scans from a further 26 individuals who also took part in an experiment outside of the scanner to measure their dominance durations for two bistable stimuli (Figure 1a,b). We verified that the same networks were produced from our two parietal seed regions for this independent group of participants (see Supplementary Figure S2). Dominance durations for both rivalry and the Necker cube conformed to the gamma distribution typically observed with bistable stimuli (Figure 1c). There was a clear correlation (r=0.46, There was a clear correlation (r=0.46, p<0.05) between the geometric mean dominance durations for the two tasks, consistent with previous work (Carter and Pettigrew, 2003) (though see also #CITATION_TAG and Arnold, 2014), as shown in Figure 1d.	1	To understand the function these networks play in bistable perception, we analyzed resting state scans from a further 26 individuals who also took part in an experiment outside of the scanner to measure their dominance durations for two bistable stimuli (Figure 1a,b). We verified that the same networks were produced from our two parietal seed regions for this independent group of participants (see Supplementary Figure S2). Dominance durations for both rivalry and the Necker cube conformed to the gamma distribution typically observed with bistable stimuli (Figure 1c). There was a clear correlation (r=0.46, There was a clear correlation (r=0.46, p<0.05) between the geometric mean dominance durations for the two tasks, consistent with previous work (Carter and Pettigrew, 2003) (though see also #CITATION_TAG and Arnold, 2014), as shown in Figure 1d.	r
CCT139	We found evidence that anterior and posterior regions of superior parietal cortex which influence bistable perception in opposing directions do so because of differences in their functional architecture. Our seed region in the pSPL exhibited connectivity with regions of parietal and lateral prefrontal cortex whose specialism is in the extraction of higher order features of sensory input (Duncan, 2010;Goldman-Rakic, 1988). This functional network is consistent with prior fMRI studies that have found a relationship between alternations and activity in similar regions of fronto-parietal cortex (Kleinschmidt et al., 1998;Knapen et al., 2011;Lumer and Rees, 1999;Sterzer and Kleinschmidt, 2007;Watanabe et al., 2014;Weilnhammer et al., 2013). Importantly, Experiment Two found that connectivity between pSPL and ventral aspects of the temporal lobe was enhanced for individuals who experienced slower rivalry alternations. This brain region is important in visual aspects of semantics (Squire et al., 2004;Visser et al., 2010) and activity there is suppressed when an image is rendered invisible by rivalry suppression (#CITATION_TAG and He, 2005). Together these data are consistent with the claim that the pSPL is part of a distributed functional system that helps stabilize a specific interpretation of low-level perceptual input.	2	Our seed region in the pSPL exhibited connectivity with regions of parietal and lateral prefrontal cortex whose specialism is in the extraction of higher order features of sensory input (Duncan, 2010;Goldman-Rakic, 1988). This functional network is consistent with prior fMRI studies that have found a relationship between alternations and activity in similar regions of fronto-parietal cortex (Kleinschmidt et al., 1998;Knapen et al., 2011;Lumer and Rees, 1999;Sterzer and Kleinschmidt, 2007;Watanabe et al., 2014;Weilnhammer et al., 2013). Importantly, Experiment Two found that connectivity between pSPL and ventral aspects of the temporal lobe was enhanced for individuals who experienced slower rivalry alternations. This brain region is important in visual aspects of semantics (Squire et al., 2004;Visser et al., 2010) and activity there is suppressed when an image is rendered invisible by rivalry suppression (#CITATION_TAG and He, 2005). Together these data are consistent with the claim that the pSPL is part of a distributed functional system that helps stabilize a specific interpretation of low-level perceptual input.	 
CCT140	We found evidence that anterior and posterior regions of superior parietal cortex which influence bistable perception in opposing directions do so because of differences in their functional architecture. Our seed region in the pSPL exhibited connectivity with regions of parietal and lateral prefrontal cortex whose specialism is in the extraction of higher order features of sensory input (#CITATION_TAG, 2010;Goldman-Rakic, 1988). This functional network is consistent with prior fMRI studies that have found a relationship between alternations and activity in similar regions of fronto-parietal cortex (Kleinschmidt et al., 1998;Knapen et al., 2011;Lumer and Rees, 1999;Sterzer and Kleinschmidt, 2007;Watanabe et al., 2014;Weilnhammer et al., 2013). Importantly, Experiment Two found that connectivity between pSPL and ventral aspects of the temporal lobe was enhanced for individuals who experienced slower rivalry alternations. This brain region is important in visual aspects of semantics (Squire et al., 2004;Visser et al., 2010) and activity there is suppressed when an image is rendered invisible by rivalry suppression (Fang and He, 2005). Together these data are consistent with the claim that the pSPL is part of a distributed functional system that helps stabilize a specific interpretation of low-level perceptual input.	0	We found evidence that anterior and posterior regions of superior parietal cortex which influence bistable perception in opposing directions do so because of differences in their functional architecture. Our seed region in the pSPL exhibited connectivity with regions of parietal and lateral prefrontal cortex whose specialism is in the extraction of higher order features of sensory input (#CITATION_TAG, 2010;Goldman-Rakic, 1988). This functional network is consistent with prior fMRI studies that have found a relationship between alternations and activity in similar regions of fronto-parietal cortex (Kleinschmidt et al., 1998;Knapen et al., 2011;Lumer and Rees, 1999;Sterzer and Kleinschmidt, 2007;Watanabe et al., 2014;Weilnhammer et al., 2013). Importantly, Experiment Two found that connectivity between pSPL and ventral aspects of the temporal lobe was enhanced for individuals who experienced slower rivalry alternations. This brain region is important in visual aspects of semantics (Squire et al., 2004;Visser et al., 2010) and activity there is suppressed when an image is rendered invisible by rivalry suppression (Fang and He, 2005).	u
CCT141	We regressed mean dominance durations against resting state connectivity from our two seed regions to determine which areas of cortex were involved in determining the dynamics of bistable alternations. We found that the coupling between the aSPL seed and regions of the striatum (green regions in Figure 3a) showed a greater association with faster alternations for the binocular rivalry stimulus (i.e. shorter durations). The striatum is known to be important in relaying prediction error signals to primary regions of cortex (Daw et al., 2011) and might play this role in perceptual decision making (Forstmann et al., 2010; though see also #CITATION_TAG et al., 2015).	0	We regressed mean dominance durations against resting state connectivity from our two seed regions to determine which areas of cortex were involved in determining the dynamics of bistable alternations. We found that the coupling between the aSPL seed and regions of the striatum (green regions in Figure 3a) showed a greater association with faster alternations for the binocular rivalry stimulus (i.e. shorter durations). The striatum is known to be important in relaying prediction error signals to primary regions of cortex (Daw et al., 2011) and might play this role in perceptual decision making (Forstmann et al., 2010; though see also #CITATION_TAG et al., 2015).	e
CCT142	All fMRI pre-processing and analyses for Experiment One and Two were performed using FSL. We extracted the brain from the skull using the BET toolbox for both the FLAIR and the structural T1 weighted images and these scans were registered to standard space using FLIRT (#CITATION_TAG and Smith, 2001). Prior to conducting the functional connectivity analysis the following pre-statistics processing was applied to the resting state data; motion correction using MCFLIRT (Jenkinson et al., 2002); slice-timing correction using Fourier-space time-series phase-shifting; non-brain removal using BET (Smith, 2002); spatial smoothing using a Gaussian kernel of FWHM 6mm; grand-mean intensity normalisation of the entire 4D dataset by a single multiplicative factor; highpass temporal filtering (Gaussian-weighted least-squares straight line fitting, with sigma = 100 s); Gaussian lowpass temporal filtering, with sigma = 2.8s.	5	All fMRI pre-processing and analyses for Experiment One and Two were performed using FSL. We extracted the brain from the skull using the BET toolbox for both the FLAIR and the structural T1 weighted images and these scans were registered to standard space using FLIRT (#CITATION_TAG and Smith, 2001). Prior to conducting the functional connectivity analysis the following pre-statistics processing was applied to the resting state data; motion correction using MCFLIRT (Jenkinson et al., 2002); slice-timing correction using Fourier-space time-series phase-shifting; non-brain removal using BET (Smith, 2002); spatial smoothing using a Gaussian kernel of FWHM 6mm; grand-mean intensity normalisation of the entire 4D dataset by a single multiplicative factor; highpass temporal filtering (Gaussian-weighted least-squares straight line fitting, with sigma = 100 s); Gaussian lowpass temporal filtering, with sigma = 2.8s.	e
CCT143	Finally, relatively longer dominance durations in the Necker Cube were associated with stronger coupling between the aSPL and a region of medial cortex in the left hemisphere, at the boundary between the pre-supplementary motor area and the dorsal anterior cingulate cortex (see Figure 3c). This region of cortex is implicated in the coordination of the selection of goal related actions (#CITATION_TAG and Koechlin, 2015) under conditions when stimulus input is stable.	0	Finally, relatively longer dominance durations in the Necker Cube were associated with stronger coupling between the aSPL and a region of medial cortex in the left hemisphere, at the boundary between the pre-supplementary motor area and the dorsal anterior cingulate cortex (see Figure 3c). This region of cortex is implicated in the coordination of the selection of goal related actions (#CITATION_TAG and Koechlin, 2015) under conditions when stimulus input is stable.	h
CCT144	A remarkable feature of the human mind is its capacity to process information that is independent of environmental input. We often lose ourselves in our thoughts, decoupling experience from the here and now (Baird et al., 2014). At other times we suddenly realize that we having been looking at the world from the wrong perspective: many famous visual illusions depend upon the resolution of uncertain perceptual input (Sterzer et al., 2009). These examples demonstrate that our conscious experience of our surroundings does not depend solely on the sensory information we receive at any moment in time, an observation that allows insight into the stimulus-independent basis of conscious perception. A popular way to study this dissociation between sensory inputs and conscious experience is to use stimuli that are ambiguous in their interpretation, and for which perception alternates over time. Classic examples include binocular rivalry (Figure 1a), in which incompatible images shown to the two eyes compete for awareness, and the Necker cube (see Figure 1b), in which a wire-frame cube can be perceived from multiple perspectives. Understanding the neural architecture that mediates these alternations is considered a critical step in uncovering neural correlates of consciousness (#CITATION_TAG and Koch, 1998).	0	These examples demonstrate that our conscious experience of our surroundings does not depend solely on the sensory information we receive at any moment in time, an observation that allows insight into the stimulus-independent basis of conscious perception. A popular way to study this dissociation between sensory inputs and conscious experience is to use stimuli that are ambiguous in their interpretation, and for which perception alternates over time. Classic examples include binocular rivalry (Figure 1a), in which incompatible images shown to the two eyes compete for awareness, and the Necker cube (see Figure 1b), in which a wire-frame cube can be perceived from multiple perspectives. Understanding the neural architecture that mediates these alternations is considered a critical step in uncovering neural correlates of consciousness (#CITATION_TAG and Koch, 1998).	t
CCT145	To understand the function these networks play in bistable perception, we analyzed resting state scans from a further 26 individuals who also took part in an experiment outside of the scanner to measure their dominance durations for two bistable stimuli (Figure 1a,b). We verified that the same networks were produced from our two parietal seed regions for this independent group of participants (see Supplementary Figure S2). Dominance durations for both rivalry and the Necker cube conformed to the gamma distribution typically observed with bistable stimuli (Figure 1c). There was a clear correlation (r=0.46, There was a clear correlation (r=0.46, p<0.05) between the geometric mean dominance durations for the two tasks, consistent with previous work (#CITATION_TAG and Pettigrew, 2003) (though see also Gallagher and Arnold, 2014), as shown in Figure 1d.	1	To understand the function these networks play in bistable perception, we analyzed resting state scans from a further 26 individuals who also took part in an experiment outside of the scanner to measure their dominance durations for two bistable stimuli (Figure 1a,b). We verified that the same networks were produced from our two parietal seed regions for this independent group of participants (see Supplementary Figure S2). Dominance durations for both rivalry and the Necker cube conformed to the gamma distribution typically observed with bistable stimuli (Figure 1c). There was a clear correlation (r=0.46, There was a clear correlation (r=0.46, p<0.05) between the geometric mean dominance durations for the two tasks, consistent with previous work (#CITATION_TAG and Pettigrew, 2003) (though see also Gallagher and Arnold, 2014), as shown in Figure 1d.	r
CCT146	The current study explores the functional connectivity of two regions of the superior parietal lobule (SPL) that have been shown to play a key role in bistable perception in studies using repetitive transcranial magnetic stimulation (rTMS). Application of TMS to the anterior region of the superior parietal lobule (aSPL) in the right hemisphere causes binocular rivalry and bistable motion alternations to speed up (#CITATION_TAG et al., 2010;Kanai et al., 2011). By contrast, a more posterior region of the same structure (pSPL) slows down the alternations of a bistable structure from motion stimulus when targeted with TMS (Kanai et al., 2010). The apparently opposing functions of these two regions of the SPL is surprising given their physical proximity (see Figure 2). Recent fMRI work has demonstrated that the regions interact with visual areas involved in processing motion to resolve bistable motion percepts, and the strengths of connections are able to predict individual alternation rates accurately (Megumi et al., 2015).	4	The current study explores the functional connectivity of two regions of the superior parietal lobule (SPL) that have been shown to play a key role in bistable perception in studies using repetitive transcranial magnetic stimulation (rTMS). Application of TMS to the anterior region of the superior parietal lobule (aSPL) in the right hemisphere causes binocular rivalry and bistable motion alternations to speed up (#CITATION_TAG et al., 2010;Kanai et al., 2011). By contrast, a more posterior region of the same structure (pSPL) slows down the alternations of a bistable structure from motion stimulus when targeted with TMS (Kanai et al., 2010). The apparently opposing functions of these two regions of the SPL is surprising given their physical proximity (see Figure 2). Recent fMRI work has demonstrated that the regions interact with visual areas involved in processing motion to resolve bistable motion percepts, and the strengths of connections are able to predict individual alternation rates accurately (Megumi et al., 2015).	p
CCT147	In contrast to the pSPL, the aSPL was connected to regions of sensori motor cortex that are thought to serve functions more closely tethered to sensory input (#CITATION_TAG and Krienen, 2013). Importantly, our data show that strong aSPL connectivity with the striatum was linked to shorter rivalrous durations. Given the potential role of the striatum in prediction error (Forstmann et al., 2010), this pattern of heightened connectivity suggests that during binocular rivalry, a specific percept may remain dominant as long as the competing low-level input is suppressed. Consistent with this interpretation of our data, recent work has shown that increasing the reward associated with a particular stimulus, a manipulation that increases the magnitude of a prediction error signal, increases the dominance of that particular stimulus (Marx and Einhauser, 2015). Compared with resolving binocular rivalry, viewing a Necker cube involves overcoming incongruency in perceptual input at a relatively higher level. Connectivity between the aSPL and a region of dorso-medial prefrontal cortex was enhanced for participants with relatively longer dominance durations for the Necker cube. This region of pre-frontal cortex is implicated in the top-down coordination of cognition and action (Botvinick et al., 2004). Importantly, this region overlaps with the connectivity patterns of the pSPL (see Figure 4) suggesting that it is functionally connected to information arising in a bottom up manner from sensori-motor cortex and in a top down manner from information in associative cortex (see also Watanabe et al., 2014). This convergence of information would be especially important in allowing perceptual incongruity to be resolved at relatively complex levels such as that which occurs while viewing the Necker Cube.	0	In contrast to the pSPL, the aSPL was connected to regions of sensori motor cortex that are thought to serve functions more closely tethered to sensory input (#CITATION_TAG and Krienen, 2013). Importantly, our data show that strong aSPL connectivity with the striatum was linked to shorter rivalrous durations. Given the potential role of the striatum in prediction error (Forstmann et al., 2010), this pattern of heightened connectivity suggests that during binocular rivalry, a specific percept may remain dominant as long as the competing low-level input is suppressed. Consistent with this interpretation of our data, recent work has shown that increasing the reward associated with a particular stimulus, a manipulation that increases the magnitude of a prediction error signal, increases the dominance of that particular stimulus (Marx and Einhauser, 2015).	I
CCT148	A more sophisticated approach to data integration is illustrated by Dalla Valle, #CITATION_TAG where data from surveys of companies in the north of Italy is combined with official data from the Italian stock exchange so as to calibrate the survey data. The methodology used in data calibration is based on copulas and non-parametric Bayesian networks.	2	A more sophisticated approach to data integration is illustrated by Dalla Valle, #CITATION_TAG where data from surveys of companies in the north of Italy is combined with official data from the Italian stock exchange so as to calibrate the survey data. The methodology used in data calibration is based on copulas and non-parametric Bayesian networks.	A
CCT149	NPBNs originate from probabilistic graphical models, which represent multivariate densities via a combination of a qualitative graph structure that encodes independencies and local quantitative parameters. Bayesian networks (BNs) are directed acyclic graphs (DAGs) whose nodes represent variables and the edges represent causal relationships between the variables. These variables are associated to conditional probability functions that, together with the DAG, are able to provide a compact representation of high-dimensional distributions. For an introduction and for more details about the definitions and main results see, for example, Cowell, 19 Jensen 20,21 or Pearl 22 ; for the use of BNs for problem solving and model building see Fenton and Neil. 23 hese models have been applied in official statistics data analysis by Penny and Reale 10 who used graphical models to identify relevant components in a saturated structural VAR model of the quarterly gross domestic product that aggregates a large number of economic time series. More recently, Vicard and Scanu 4 also applied Bayesian networks to official statistics, showing that the use of post-stratification allows integration and missing data imputation. For general applications of Bayesian networks see Kenett. 12 For general applications of Bayesian networks see #CITATION_TAG. 12 owever the main classes of BNs are discrete, normal or discrete-normal, where discrete BNs are limited to small-sized datasets, and normal BNs are limited by the joint normality assumption. For this reason, researchers proposed alternative methodologies. Elidan 24 points out the need for a synergy between the copula framework and the field of machine learning. Kurowica and Cooke 25 and Hanea et al. 26 introduced continuous NPBNs, using copulas to realize rank correlations in directed acyclic graphs. Their approach is based on nonparametric statistical inference and elicited expert knowledge to understand the dependencies among the variables, and uses conditionalization for diagnosis and prediction.	2	23 hese models have been applied in official statistics data analysis by Penny and Reale 10 who used graphical models to identify relevant components in a saturated structural VAR model of the quarterly gross domestic product that aggregates a large number of economic time series. More recently, Vicard and Scanu 4 also applied Bayesian networks to official statistics, showing that the use of post-stratification allows integration and missing data imputation. For general applications of Bayesian networks see Kenett. 12 For general applications of Bayesian networks see #CITATION_TAG. 12 owever the main classes of BNs are discrete, normal or discrete-normal, where discrete BNs are limited to small-sized datasets, and normal BNs are limited by the joint normality assumption. For this reason, researchers proposed alternative methodologies. Elidan 24 points out the need for a synergy between the copula framework and the field of machine learning.	g
CCT150	NPBNs originate from probabilistic graphical models, which represent multivariate densities via a combination of a qualitative graph structure that encodes independencies and local quantitative parameters. Bayesian networks (BNs) are directed acyclic graphs (DAGs) whose nodes represent variables and the edges represent causal relationships between the variables. These variables are associated to conditional probability functions that, together with the DAG, are able to provide a compact representation of high-dimensional distributions. For an introduction and for more details about the definitions and main results see, for example, Cowell, 19 Jensen 20,21 or Pearl 22 ; for the use of BNs for problem solving and model building see Fenton and Neil. 23 hese models have been applied in official statistics data analysis by Penny and Reale 10 who used graphical models to identify relevant components in a saturated structural VAR model of the quarterly gross domestic product that aggregates a large number of economic time series. More recently, Vicard and Scanu 4 also applied Bayesian networks to official statistics, showing that the use of post-stratification allows integration and missing data imputation. For general applications of Bayesian networks see Kenett. 12 owever the main classes of BNs are discrete, normal or discrete-normal, where discrete BNs are limited to small-sized datasets, and normal BNs are limited by the joint normality assumption. For this reason, researchers proposed alternative methodologies. Elidan 24 points out the need for a synergy between the copula framework and the field of machine learning. Kurowica and Cooke 25 and #CITATION_TAG et al. 26 introduced continuous NPBNs, using copulas to realize rank correlations in directed acyclic graphs. Their approach is based on nonparametric statistical inference and elicited expert knowledge to understand the dependencies among the variables, and uses conditionalization for diagnosis and prediction.	5	12 owever the main classes of BNs are discrete, normal or discrete-normal, where discrete BNs are limited to small-sized datasets, and normal BNs are limited by the joint normality assumption. For this reason, researchers proposed alternative methodologies. Elidan 24 points out the need for a synergy between the copula framework and the field of machine learning. Kurowica and Cooke 25 and #CITATION_TAG et al. 26 introduced continuous NPBNs, using copulas to realize rank correlations in directed acyclic graphs. Their approach is based on nonparametric statistical inference and elicited expert knowledge to understand the dependencies among the variables, and uses conditionalization for diagnosis and prediction.	n
CCT151	An example of data integration is provided by #CITATION_TAG et al., 5 who state that the matching of public with private databases is crucial for implementing new analyses that are functional to a new approach to business. The authors describe the integrated data base maintained by Intesa Sanpaolo Bank in Italy for supporting analytic research requests by management and various decision makers. The bank uses regression models applied to internal data integrated with data from a range of official statistics providers such as:	1	An example of data integration is provided by #CITATION_TAG et al., 5 who state that the matching of public with private databases is crucial for implementing new analyses that are functional to a new approach to business. The authors describe the integrated data base maintained by Intesa Sanpaolo Bank in Italy for supporting analytic research requests by management and various decision makers. The bank uses regression models applied to internal data integrated with data from a range of official statistics providers such as:	A
CCT152	NPBNs originate from probabilistic graphical models, which represent multivariate densities via a combination of a qualitative graph structure that encodes independencies and local quantitative parameters. Bayesian networks (BNs) are directed acyclic graphs (DAGs) whose nodes represent variables and the edges represent causal relationships between the variables. These variables are associated to conditional probability functions that, together with the DAG, are able to provide a compact representation of high-dimensional distributions. For an introduction and for more details about the definitions and main results see, for example, Cowell, 19 Jensen 20,21 or #CITATION_TAG 22 ; for the use of BNs for problem solving and model building see Fenton and Neil. 23 hese models have been applied in official statistics data analysis by Penny and Reale 10 who used graphical models to identify relevant components in a saturated structural VAR model of the quarterly gross domestic product that aggregates a large number of economic time series. More recently, Vicard and Scanu 4 also applied Bayesian networks to official statistics, showing that the use of post-stratification allows integration and missing data imputation. For general applications of Bayesian networks see Kenett. 12 owever the main classes of BNs are discrete, normal or discrete-normal, where discrete BNs are limited to small-sized datasets, and normal BNs are limited by the joint normality assumption. For this reason, researchers proposed alternative methodologies. Elidan 24 points out the need for a synergy between the copula framework and the field of machine learning. Kurowica and Cooke 25 and Hanea et al. 26 introduced continuous NPBNs, using copulas to realize rank correlations in directed acyclic graphs. Their approach is based on nonparametric statistical inference and elicited expert knowledge to understand the dependencies among the variables, and uses conditionalization for diagnosis and prediction.	0	NPBNs originate from probabilistic graphical models, which represent multivariate densities via a combination of a qualitative graph structure that encodes independencies and local quantitative parameters. Bayesian networks (BNs) are directed acyclic graphs (DAGs) whose nodes represent variables and the edges represent causal relationships between the variables. These variables are associated to conditional probability functions that, together with the DAG, are able to provide a compact representation of high-dimensional distributions. For an introduction and for more details about the definitions and main results see, for example, Cowell, 19 Jensen 20,21 or #CITATION_TAG 22 ; for the use of BNs for problem solving and model building see Fenton and Neil. 23 hese models have been applied in official statistics data analysis by Penny and Reale 10 who used graphical models to identify relevant components in a saturated structural VAR model of the quarterly gross domestic product that aggregates a large number of economic time series. More recently, Vicard and Scanu 4 also applied Bayesian networks to official statistics, showing that the use of post-stratification allows integration and missing data imputation. For general applications of Bayesian networks see Kenett.	 
CCT153	The traversal of the quantum phase transition between the Mott insulating and superfluid phases achieved by Greiner et al. [6] provided a dramatic experimental demonstration of the realization of the BHM in a three-dimensional optical lattice. This followed earlier work by Orzel et al. [139] showing number squeezing in a two-well system and was quickly followed by a number of other realizations of the BHM and quantum phase transitions of bosons in optical lattices [57,58,[179][180][181][182][183][184][185]. These results and more recent experiments on out-of-equilibrium dynamics in the BHM [138,#CITATION_TAG,[186][187][188] are discussed in this section.	4	The traversal of the quantum phase transition between the Mott insulating and superfluid phases achieved by Greiner et al. [6] provided a dramatic experimental demonstration of the realization of the BHM in a three-dimensional optical lattice. This followed earlier work by Orzel et al. [139] showing number squeezing in a two-well system and was quickly followed by a number of other realizations of the BHM and quantum phase transitions of bosons in optical lattices [57,58,[179][180][181][182][183][184][185]. These results and more recent experiments on out-of-equilibrium dynamics in the BHM [138,#CITATION_TAG,[186][187][188] are discussed in this section.	e
CCT154	Several authors have used these approaches to study the BHM both from the weakly interacting limit (large / ) [162][163][164][165][166] and the strongly interacting limit (small / ) [#CITATION_TAG,120,167,168]. The Schwinger-Keldysh approach has also been used to study out-of-equilibrium dynamics for the BHM with periodic driving [20], including allowing for the possibility of ohmic dissipation [20,169]. I first discuss the two-particle irreducible formalism which has a weak interaction starting point and then discuss the strongly interacting approach.	4	Several authors have used these approaches to study the BHM both from the weakly interacting limit (large / ) [162][163][164][165][166] and the strongly interacting limit (small / ) [#CITATION_TAG,120,167,168]. The Schwinger-Keldysh approach has also been used to study out-of-equilibrium dynamics for the BHM with periodic driving [20], including allowing for the possibility of ohmic dissipation [20,169]. I first discuss the two-particle irreducible formalism which has a weak interaction starting point and then discuss the strongly interacting approach.	S
CCT155	Several authors have used these approaches to study the BHM both from the weakly interacting limit (large / ) #CITATION_TAG[163][164][165][166] and the strongly interacting limit (small / ) [112,120,167,168]. The Schwinger-Keldysh approach has also been used to study out-of-equilibrium dynamics for the BHM with periodic driving [20], including allowing for the possibility of ohmic dissipation [20,169]. I first discuss the two-particle irreducible formalism which has a weak interaction starting point and then discuss the strongly interacting approach.	4	Several authors have used these approaches to study the BHM both from the weakly interacting limit (large / ) #CITATION_TAG[163][164][165][166] and the strongly interacting limit (small / ) [112,120,167,168]. The Schwinger-Keldysh approach has also been used to study out-of-equilibrium dynamics for the BHM with periodic driving [20], including allowing for the possibility of ohmic dissipation [20,169]. I first discuss the two-particle irreducible formalism which has a weak interaction starting point and then discuss the strongly interacting approach.	S
CCT156	The traversal of the quantum phase transition between the Mott insulating and superfluid phases achieved by Greiner et al. [6] provided a dramatic experimental demonstration of the realization of the BHM in a three-dimensional optical lattice. This followed earlier work by Orzel et al. [139] showing number squeezing in a two-well system and was quickly followed by a number of other realizations of the BHM and quantum phase transitions of bosons in optical lattices [57,58,[179][180][181][182][183][184][185]. These results and more recent experiments on out-of-equilibrium dynamics in the BHM [138,146,#CITATION_TAG[187][188] are discussed in this section.	4	The traversal of the quantum phase transition between the Mott insulating and superfluid phases achieved by Greiner et al. [6] provided a dramatic experimental demonstration of the realization of the BHM in a three-dimensional optical lattice. This followed earlier work by Orzel et al. [139] showing number squeezing in a two-well system and was quickly followed by a number of other realizations of the BHM and quantum phase transitions of bosons in optical lattices [57,58,[179][180][181][182][183][184][185]. These results and more recent experiments on out-of-equilibrium dynamics in the BHM [138,146,#CITATION_TAG[187][188] are discussed in this section.	e
CCT157	The Bose-Hubbard model (BHM) is a minimal model of interacting bosons on a lattice. The original focus of work on the BHM #CITATION_TAG was in the context of experiments on superconductor-insulator transitions in granular superconductors [2] and Josephson junction arrays [3] and for 4 He in porous media [4]. The proposal by Jaksch et al. [5] that the BHM could be realized by cold atoms in an optical lattice and the subsequent experimental demonstration of a superfluid to Mott insulator transition in this system by Greiner et al. [6] has lead the focus of work on this model to shift to cold atoms. The tunability of parameters in cold atom systems [7,8], particularly as a function of time, naturally leads to interest in the out-of-equilibrium dynamics of the BHM especially in the vicinity of a quantum critical point [6].	0	The Bose-Hubbard model (BHM) is a minimal model of interacting bosons on a lattice. The original focus of work on the BHM #CITATION_TAG was in the context of experiments on superconductor-insulator transitions in granular superconductors [2] and Josephson junction arrays [3] and for 4 He in porous media [4]. The proposal by Jaksch et al. [5] that the BHM could be realized by cold atoms in an optical lattice and the subsequent experimental demonstration of a superfluid to Mott insulator transition in this system by Greiner et al. [6] has lead the focus of work on this model to shift to cold atoms. The tunability of parameters in cold atom systems [7,8], particularly as a function of time, naturally leads to interest in the out-of-equilibrium dynamics of the BHM especially in the vicinity of a quantum critical point [6].	h
CCT158	Kollath et al. #CITATION_TAG rationalized the slow relaxation they found for large by focusing on the particle and hole excitations of the Mott insulator. If quasiparticle interactions are ignored, then the effective Hamiltonian in the Mott regime may be written in the form = ‚àë k, k ‚Ä† k k , with ‚Ä† k a creation operator for a quasiparticle in the Mott insulator. Thermalization then proceeds through the relaxation of the quasiparticle distribution given by the initial conditions. This requires processes in which quasiparticle number is not conserved, which are strongly suppressed if the gap Œî is larger than /2 where ‚àº 4 is the quasiparticle bandwidth. Higher order processes could still lead to thermalization, but on much longer timescales than accessible numerically. This picture relies on having a dilute quasiparticle population, that is, an initial state close to the transition, but at least in their numerics, = 2 , appear to have been sufficiently close to the transition ( = 3.37 in 1 dimension [44] and = 16.7 in 2 dimensions [41]) for this physics to be observable.	4	Kollath et al. #CITATION_TAG rationalized the slow relaxation they found for large by focusing on the particle and hole excitations of the Mott insulator. If quasiparticle interactions are ignored, then the effective Hamiltonian in the Mott regime may be written in the form = ‚àë k, k ‚Ä† k k , with ‚Ä† k a creation operator for a quasiparticle in the Mott insulator. Thermalization then proceeds through the relaxation of the quasiparticle distribution given by the initial conditions. This requires processes in which quasiparticle number is not conserved, which are strongly suppressed if the gap Œî is larger than /2 where ‚àº 4 is the quasiparticle bandwidth.	K
CCT159	In the simplest mean field theory [1,#CITATION_TAG,47], one introduces the superfluid order parameter as = ‚ü®ÃÇ ‚Ä†‚ü© = ‚ü®ÃÇ‚ü©, then the hopping terms in the Hamiltonian simplify toÃÇ ‚Ä†ÃÇ‚âÉ	0	In the simplest mean field theory [1,#CITATION_TAG,47], one introduces the superfluid order parameter as = ‚ü®ÃÇ ‚Ä†‚ü© = ‚ü®ÃÇ‚ü©, then the hopping terms in the Hamiltonian simplify toÃÇ ‚Ä†ÃÇ‚âÉ	I
CCT160	A phase diagram which is qualitatively correct in dimensions higher than one can be determined from simple considerations and mean field theory. If ‚â™ , then the model describes weakly interacting bosons hopping on a lattice, ISRN Condensed Matter Physics 3 which will condense and lead to a superfluid at low temperatures. In the opposite limit of = 0, the ground state can be determined by considering the single site Hamiltonian 0 . Working in the grand canonical ensemble (results in the canonical ensemble can be obtained by a Legendre transformation), the ground state energy is minimized for 0 bosons on each site when the chemical potential satisfies 0 ‚â§ / ‚â§ + 1. This phase with an integer number of bosons per site is the incompressible Mott insulator. For finite / , there is generically a transition between the Mott insulator and superfluid phases. It is relatively straightforward to calculate the mean field phase diagram as a function of / and / [1, [30][31][32] as described in Section 2.1 which leads to the well-known Mott insulator lobes illustrated in Figure 1. Considerable effort has been expended to obtain more accurate determinations of the phase boundaries, using quantum Monte Carlo [33][34][35][36][37][38][39][40], series expansions #CITATION_TAG[42][43], and the density matrix renormalization group [44,45]. The mean field phase diagram is qualitatively similar to more exact calculations in dimensions 2 and higher but differs greatly from accurate determinations of the phase boundary in 1 dimension, as illustrated in Figure 2.	5	This phase with an integer number of bosons per site is the incompressible Mott insulator. For finite / , there is generically a transition between the Mott insulator and superfluid phases. It is relatively straightforward to calculate the mean field phase diagram as a function of / and / [1, [30][31][32] as described in Section 2.1 which leads to the well-known Mott insulator lobes illustrated in Figure 1. Considerable effort has been expended to obtain more accurate determinations of the phase boundaries, using quantum Monte Carlo [33][34][35][36][37][38][39][40], series expansions #CITATION_TAG[42][43], and the density matrix renormalization group [44,45]. The mean field phase diagram is qualitatively similar to more exact calculations in dimensions 2 and higher but differs greatly from accurate determinations of the phase boundary in 1 dimension, as illustrated in Figure 2.	e
CCT161	A phase diagram which is qualitatively correct in dimensions higher than one can be determined from simple considerations and mean field theory. If ‚â™ , then the model describes weakly interacting bosons hopping on a lattice, ISRN Condensed Matter Physics 3 which will condense and lead to a superfluid at low temperatures. In the opposite limit of = 0, the ground state can be determined by considering the single site Hamiltonian 0 . Working in the grand canonical ensemble (results in the canonical ensemble can be obtained by a Legendre transformation), the ground state energy is minimized for 0 bosons on each site when the chemical potential satisfies 0 ‚â§ / ‚â§ + 1. This phase with an integer number of bosons per site is the incompressible Mott insulator. For finite / , there is generically a transition between the Mott insulator and superfluid phases. It is relatively straightforward to calculate the mean field phase diagram as a function of / and / [1, [30]#CITATION_TAG[32] as described in Section 2.1 which leads to the well-known Mott insulator lobes illustrated in Figure 1. Considerable effort has been expended to obtain more accurate determinations of the phase boundaries, using quantum Monte Carlo [33][34][35][36][37][38][39][40], series expansions [41][42][43], and the density matrix renormalization group [44,45]. The mean field phase diagram is qualitatively similar to more exact calculations in dimensions 2 and higher but differs greatly from accurate determinations of the phase boundary in 1 dimension, as illustrated in Figure 2.	0	In the opposite limit of = 0, the ground state can be determined by considering the single site Hamiltonian 0 . Working in the grand canonical ensemble (results in the canonical ensemble can be obtained by a Legendre transformation), the ground state energy is minimized for 0 bosons on each site when the chemical potential satisfies 0 ‚â§ / ‚â§ + 1. This phase with an integer number of bosons per site is the incompressible Mott insulator. For finite / , there is generically a transition between the Mott insulator and superfluid phases. It is relatively straightforward to calculate the mean field phase diagram as a function of / and / [1, [30]#CITATION_TAG[32] as described in Section 2.1 which leads to the well-known Mott insulator lobes illustrated in Figure 1. Considerable effort has been expended to obtain more accurate determinations of the phase boundaries, using quantum Monte Carlo [33][34][35][36][37][38][39][40], series expansions [41][42][43], and the density matrix renormalization group [44,45]. The mean field phase diagram is qualitatively similar to more exact calculations in dimensions 2 and higher but differs greatly from accurate determinations of the phase boundary in 1 dimension, as illustrated in Figure 2.	 
CCT162	"As with any mean field theory, the estimate of the critical coupling for the phase transition is not particularly accurate within the Gutzwiller approach. A more important failing is that due to the assumption of a variational state which has a product form, two site correlations factorize into single-site quantities and so the method does not capture correlations involving different sites. This is most problematic for intermediate values of / where the ground state is not close to product form, unlike the two limits = 0 and = 0. Improvements to the Gutzwiller mean field have been made using a variety of approaches #CITATION_TAG[92][93]136] and can allow for perturbative corrections to short-range correlations [136]. Nevertheless, because of its simplicity, it is a very useful method for gaining an understanding of physics for regimes where exact numerical results are not easily obtained. For example, for out-of-equilibrium dynamics in dimensions higher than 1, for example, [94] (Section 4.2.3), or in the presence of complicated space and time-dependent potentials such as the ""Gaussian spoon"" consisting of a usual harmonic trap 0 with a Gaussian with velocity V:"	5	"As with any mean field theory, the estimate of the critical coupling for the phase transition is not particularly accurate within the Gutzwiller approach. A more important failing is that due to the assumption of a variational state which has a product form, two site correlations factorize into single-site quantities and so the method does not capture correlations involving different sites. This is most problematic for intermediate values of / where the ground state is not close to product form, unlike the two limits = 0 and = 0. Improvements to the Gutzwiller mean field have been made using a variety of approaches #CITATION_TAG[92][93]136] and can allow for perturbative corrections to short-range correlations [136]. Nevertheless, because of its simplicity, it is a very useful method for gaining an understanding of physics for regimes where exact numerical results are not easily obtained. For example, for out-of-equilibrium dynamics in dimensions higher than 1, for example, [94] (Section 4.2. 3), or in the presence of complicated space and time-dependent potentials such as the ""Gaussian spoon"" consisting of a usual harmonic trap 0 with a Gaussian with velocity V:"	r
CCT163	A manifestation of quantum criticality more in line with the theme of this paper is in the dynamic passage through a quantum critical point [59]. This should leave signatures in density and entropy currents and may also give access to the Kibble-Zurek mechanism (KZM) [63,64]. The KZM predicts defect formation after a system crosses a second-order thermodynamic phase transition and has been  #CITATION_TAG. This derivation of the number density of excitations after a quench assumes a picture in which there is adiabatic evolution up to some distance | ( * ) ‚àí | from the transition at which point the relaxation time diverges and the defects are frozen until the system has passed through the critical region. As recently pointed out [68,69] for a sufficiently slow quench, there can still be evolution of the defect configuration as the system passes through the critical region, which can modify the Kibble-Zurek predictions and may be relevant to slow quenches in the BHM. These considerations are all for a uniform system and do not consider the possible presence of a trap.	5	A manifestation of quantum criticality more in line with the theme of this paper is in the dynamic passage through a quantum critical point [59]. This should leave signatures in density and entropy currents and may also give access to the Kibble-Zurek mechanism (KZM) [63,64]. The KZM predicts defect formation after a system crosses a second-order thermodynamic phase transition and has been  #CITATION_TAG. This derivation of the number density of excitations after a quench assumes a picture in which there is adiabatic evolution up to some distance | ( * ) ‚àí | from the transition at which point the relaxation time diverges and the defects are frozen until the system has passed through the critical region. As recently pointed out [68,69] for a sufficiently slow quench, there can still be evolution of the defect configuration as the system passes through the critical region, which can modify the Kibble-Zurek predictions and may be relevant to slow quenches in the BHM. These considerations are all for a uniform system and do not consider the possible presence of a trap.	e
CCT164	The Bose-Hubbard model (BHM) is a minimal model of interacting bosons on a lattice. The original focus of work on the BHM [1] was in the context of experiments on superconductor-insulator transitions in granular superconductors [2] and Josephson junction arrays [3] and for 4 He in porous media [4]. The proposal by Jaksch et al. [5] that the BHM could be realized by cold atoms in an optical lattice and the subsequent experimental demonstration of a superfluid to Mott insulator transition in this system by Greiner et al. #CITATION_TAG has lead the focus of work on this model to shift to cold atoms. The tunability of parameters in cold atom systems [7,8], particularly as a function of time, naturally leads to interest in the out-of-equilibrium dynamics of the BHM especially in the vicinity of a quantum critical point [6].	4	The Bose-Hubbard model (BHM) is a minimal model of interacting bosons on a lattice. The original focus of work on the BHM [1] was in the context of experiments on superconductor-insulator transitions in granular superconductors [2] and Josephson junction arrays [3] and for 4 He in porous media [4]. The proposal by Jaksch et al. [5] that the BHM could be realized by cold atoms in an optical lattice and the subsequent experimental demonstration of a superfluid to Mott insulator transition in this system by Greiner et al. #CITATION_TAG has lead the focus of work on this model to shift to cold atoms. The tunability of parameters in cold atom systems [7,8], particularly as a function of time, naturally leads to interest in the out-of-equilibrium dynamics of the BHM especially in the vicinity of a quantum critical point [6].	e
CCT165	The traversal of the quantum phase transition between the Mott insulating and superfluid phases achieved by Greiner et al. [6] provided a dramatic experimental demonstration of the realization of the BHM in a three-dimensional optical lattice. This followed earlier work by Orzel et al. [139] showing number squeezing in a two-well system and was quickly followed by a number of other realizations of the BHM and quantum phase transitions of bosons in optical lattices [57,58,[179][180][181][182][183][184]#CITATION_TAG. These results and more recent experiments on out-of-equilibrium dynamics in the BHM [138,146,[186][187][188] are discussed in this section.	4	The traversal of the quantum phase transition between the Mott insulating and superfluid phases achieved by Greiner et al. [6] provided a dramatic experimental demonstration of the realization of the BHM in a three-dimensional optical lattice. This followed earlier work by Orzel et al. [139] showing number squeezing in a two-well system and was quickly followed by a number of other realizations of the BHM and quantum phase transitions of bosons in optical lattices [57,58,[179][180][181][182][183][184]#CITATION_TAG. These results and more recent experiments on out-of-equilibrium dynamics in the BHM [138,146,[186][187][188] are discussed in this section.	h
CCT166	"As with any mean field theory, the estimate of the critical coupling for the phase transition is not particularly accurate within the Gutzwiller approach. A more important failing is that due to the assumption of a variational state which has a product form, two site correlations factorize into single-site quantities and so the method does not capture correlations involving different sites. This is most problematic for intermediate values of / where the ground state is not close to product form, unlike the two limits = 0 and = 0. Improvements to the Gutzwiller mean field have been made using a variety of approaches [91][92][93]136] and can allow for perturbative corrections to short-range correlations [136]. Nevertheless, because of its simplicity, it is a very useful method for gaining an understanding of physics for regimes where exact numerical results are not easily obtained. For example, for out-of-equilibrium dynamics in dimensions higher than 1, for example, #CITATION_TAG (Section 4.2.3), or in the presence of complicated space and time-dependent potentials such as the ""Gaussian spoon"" consisting of a usual harmonic trap 0 with a Gaussian with velocity V: suggested by Lundh [95] as a means to excite Mott insulating states."	5	"This is most problematic for intermediate values of / where the ground state is not close to product form, unlike the two limits = 0 and = 0. Improvements to the Gutzwiller mean field have been made using a variety of approaches [91][92][93]136] and can allow for perturbative corrections to short-range correlations [136]. Nevertheless, because of its simplicity, it is a very useful method for gaining an understanding of physics for regimes where exact numerical results are not easily obtained. For example, for out-of-equilibrium dynamics in dimensions higher than 1, for example, #CITATION_TAG (Section 4.2. 3), or in the presence of complicated space and time-dependent potentials such as the ""Gaussian spoon"" consisting of a usual harmonic trap 0 with a Gaussian with velocity V: suggested by Lundh [95] as a means to excite Mott insulating states."	x
CCT167	A phase diagram which is qualitatively correct in dimensions higher than one can be determined from simple considerations and mean field theory. If ‚â™ , then the model describes weakly interacting bosons hopping on a lattice, ISRN Condensed Matter Physics 3 which will condense and lead to a superfluid at low temperatures. In the opposite limit of = 0, the ground state can be determined by considering the single site Hamiltonian 0 . Working in the grand canonical ensemble (results in the canonical ensemble can be obtained by a Legendre transformation), the ground state energy is minimized for 0 bosons on each site when the chemical potential satisfies 0 ‚â§ / ‚â§ + 1. This phase with an integer number of bosons per site is the incompressible Mott insulator. For finite / , there is generically a transition between the Mott insulator and superfluid phases. It is relatively straightforward to calculate the mean field phase diagram as a function of / and / [1, [30][31][32] as described in Section 2.1 which leads to the well-known Mott insulator lobes illustrated in Figure 1. Considerable effort has been expended to obtain more accurate determinations of the phase boundaries, using quantum Monte Carlo [33][34][35][36][37][38][39][40], series expansions [41][42][43], and the density matrix renormalization group [#CITATION_TAG,45]. The mean field phase diagram is qualitatively similar to more exact calculations in dimensions 2 and higher but differs greatly from accurate determinations of the phase boundary in 1 dimension, as illustrated in Figure 2.	0	This phase with an integer number of bosons per site is the incompressible Mott insulator. For finite / , there is generically a transition between the Mott insulator and superfluid phases. It is relatively straightforward to calculate the mean field phase diagram as a function of / and / [1, [30][31][32] as described in Section 2.1 which leads to the well-known Mott insulator lobes illustrated in Figure 1. Considerable effort has been expended to obtain more accurate determinations of the phase boundaries, using quantum Monte Carlo [33][34][35][36][37][38][39][40], series expansions [41][42][43], and the density matrix renormalization group [#CITATION_TAG,45]. The mean field phase diagram is qualitatively similar to more exact calculations in dimensions 2 and higher but differs greatly from accurate determinations of the phase boundary in 1 dimension, as illustrated in Figure 2.	e
CCT168	The traversal of the quantum phase transition between the Mott insulating and superfluid phases achieved by Greiner et al. [6] provided a dramatic experimental demonstration of the realization of the BHM in a three-dimensional optical lattice. This followed earlier work by Orzel et al. [139] showing number squeezing in a two-well system and was quickly followed by a number of other realizations of the BHM and quantum phase transitions of bosons in optical lattices [57,58,[179][180][181][182]#CITATION_TAG[184][185]. These results and more recent experiments on out-of-equilibrium dynamics in the BHM [138,146,[186][187][188] are discussed in this section.	4	The traversal of the quantum phase transition between the Mott insulating and superfluid phases achieved by Greiner et al. [6] provided a dramatic experimental demonstration of the realization of the BHM in a three-dimensional optical lattice. This followed earlier work by Orzel et al. [139] showing number squeezing in a two-well system and was quickly followed by a number of other realizations of the BHM and quantum phase transitions of bosons in optical lattices [57,58,[179][180][181][182]#CITATION_TAG[184][185]. These results and more recent experiments on out-of-equilibrium dynamics in the BHM [138,146,[186][187][188] are discussed in this section.	h
CCT169	There are several features that are desirable for any theory of equilibrium or out-of-equilibrium dynamics of the Bose-Hubbard model. First, it should allow for both superfluid and Mott insulating ground states (the Bogoliubov theory fails in this instance). Second, a variety of methods concur on the nature of the collective excitation spectrum in the two phases. In the superfluid phase, there is a gapless sound mode that ISRN Condensed Matter Physics 7 arises from phase fluctuations of the superfluid order parameter. Near the fixed density quantum critical point (QCP) there is also a gapped (Higgs) mode corresponding to amplitude fluctuations of the superfluid order parameter that has been predicted in a variety of calculations [118][119]#CITATION_TAG[121][122] and observed experimentally for bosons in two-and-three dimensional optical lattices [123,124]. In the Mott phase, the collective modes are particle-hole excitations. Third, the approach should be capable of describing nonlocal correlations in space and time.	5	First, it should allow for both superfluid and Mott insulating ground states (the Bogoliubov theory fails in this instance). Second, a variety of methods concur on the nature of the collective excitation spectrum in the two phases. In the superfluid phase, there is a gapless sound mode that ISRN Condensed Matter Physics 7 arises from phase fluctuations of the superfluid order parameter. Near the fixed density quantum critical point (QCP) there is also a gapped (Higgs) mode corresponding to amplitude fluctuations of the superfluid order parameter that has been predicted in a variety of calculations [118][119]#CITATION_TAG[121][122] and observed experimentally for bosons in two-and-three dimensional optical lattices [123,124]. In the Mott phase, the collective modes are particle-hole excitations. Third, the approach should be capable of describing nonlocal correlations in space and time.	 
CCT170	where N( ) is weakly time dependent compared to the exponential, ‚àº ‚àö ‚àí , and 2 = 3 ( ‚àí )/ * with a velocity scale. This form gives a constant propagation speed of the correlations, as found in the Lieb-Robinson bound #CITATION_TAG. The exponent in ( 56) also shows scaling behaviour in the vicinity of the critical point: as ‚Üí = , the form is invariant under ‚Üí = / and r ‚Üí r = r/ . In addition to the growth of off-diagonal long range order, Navez and Sch√ºtzhold also considered the growth of phase coherence by looking at the condensate fraction within a region S with |S| ‚â™ 1. Defining the coarse-grained operatorÃÇS = ‚àë ‚ààSÃÇ/ ‚àö|S|, which is the homogeneous mode which will give the largest eigenvalue of ‚ü®ÃÇ ‚Ä†ÃÇ]‚ü©, this mode will have a macroscopic occupation S = ‚ü®ÃÇ ‚Ä† SÃÇS ‚ü© ‚â´ 1 corresponding to the condensate fraction in the region S after time . For 2 2 ‚â™ |S|, S /|S| ‚àº 1/|S| and for |S| ‚â™ 2 2 , S /|S| ‚àº . This suggests that for distinct regions S and S with 1 ‚â™ |S|, |S | ‚â™ 2 2 , the relative phase between the regions correlates as	0	where N( ) is weakly time dependent compared to the exponential, ‚àº ‚àö ‚àí , and 2 = 3 ( ‚àí )/ * with a velocity scale. This form gives a constant propagation speed of the correlations, as found in the Lieb-Robinson bound #CITATION_TAG. The exponent in ( 56) also shows scaling behaviour in the vicinity of the critical point: as ‚Üí = , the form is invariant under ‚Üí = / and r ‚Üí r = r/ . In addition to the growth of off-diagonal long range order, Navez and Sch√ºtzhold also considered the growth of phase coherence by looking at the condensate fraction within a region S with |S| ‚â™ 1. Defining the coarse-grained operatorÃÇS = ‚àë ‚ààSÃÇ/ ‚àö|S|, which is the homogeneous mode which will give the largest eigenvalue of ‚ü®ÃÇ ‚Ä†ÃÇ]‚ü©, this mode will have a macroscopic occupation S = ‚ü®ÃÇ ‚Ä† SÃÇS ‚ü© ‚â´ 1 corresponding to the condensate fraction in the region S after time . For 2 2 ‚â™ |S|, S /|S| ‚àº 1/|S| and for |S| ‚â™ 2 2 , S /|S| ‚àº This suggests that for distinct regions S and S with 1 ‚â™ |S|, |S | ‚â™ 2 2 , the relative phase between the regions correlates as	h
CCT171	The solution of this equation when Œ® is assumed to be spatially uniform shows oscillations as a function of time for a system prepared in the Mott state, as illustrated in Figure 5 (although these oscillations were not observed in a recent quench experiment #CITATION_TAG) Altman and Auerbach noted some caveats to their results: the assumption of a uniform system may be spoiled by topological defects that get trapped by the Kibble-Zurek mechanism [63,64]. For initial states near the transition, the correlation length should be large enough that such defects are	5	The solution of this equation when Œ® is assumed to be spatially uniform shows oscillations as a function of time for a system prepared in the Mott state, as illustrated in Figure 5 (although these oscillations were not observed in a recent quench experiment #CITATION_TAG) Altman and Auerbach noted some caveats to their results: the assumption of a uniform system may be spoiled by topological defects that get trapped by the Kibble-Zurek mechanism [63,64]. For initial states near the transition, the correlation length should be large enough that such defects are	T
CCT172	"As with any mean field theory, the estimate of the critical coupling for the phase transition is not particularly accurate within the Gutzwiller approach. A more important failing is that due to the assumption of a variational state which has a product form, two site correlations factorize into single-site quantities and so the method does not capture correlations involving different sites. This is most problematic for intermediate values of / where the ground state is not close to product form, unlike the two limits = 0 and = 0. Improvements to the Gutzwiller mean field have been made using a variety of approaches [91][92]#CITATION_TAG136] and can allow for perturbative corrections to short-range correlations [136]. Nevertheless, because of its simplicity, it is a very useful method for gaining an understanding of physics for regimes where exact numerical results are not easily obtained. For example, for out-of-equilibrium dynamics in dimensions higher than 1, for example, [94] (Section 4.2.3), or in the presence of complicated space and time-dependent potentials such as the ""Gaussian spoon"" consisting of a usual harmonic trap 0 with a Gaussian with velocity V:"	5	"As with any mean field theory, the estimate of the critical coupling for the phase transition is not particularly accurate within the Gutzwiller approach. A more important failing is that due to the assumption of a variational state which has a product form, two site correlations factorize into single-site quantities and so the method does not capture correlations involving different sites. This is most problematic for intermediate values of / where the ground state is not close to product form, unlike the two limits = 0 and = 0. Improvements to the Gutzwiller mean field have been made using a variety of approaches [91][92]#CITATION_TAG136] and can allow for perturbative corrections to short-range correlations [136]. Nevertheless, because of its simplicity, it is a very useful method for gaining an understanding of physics for regimes where exact numerical results are not easily obtained. For example, for out-of-equilibrium dynamics in dimensions higher than 1, for example, [94] (Section 4.2. 3), or in the presence of complicated space and time-dependent potentials such as the ""Gaussian spoon"" consisting of a usual harmonic trap 0 with a Gaussian with velocity V:"	r
CCT173	which is in accordance with calculations using QMC #CITATION_TAG and an analytic strong coupling approach [198] both of which suggest V ‚àº ( / ) ‚àí1 . Gerbier et al. [185] found good experimental agreement with this form up to a lattice depth of = 30 corresponding to / ‚âÉ 200, where they suggested that adiabaticity in the preparation of the state may have broken down.	5	which is in accordance with calculations using QMC #CITATION_TAG and an analytic strong coupling approach [198] both of which suggest V ‚àº ( / ) ‚àí1 . Gerbier et al. [185] found good experimental agreement with this form up to a lattice depth of = 30 corresponding to / ‚âÉ 200, where they suggested that adiabaticity in the preparation of the state may have broken down.	w
CCT174	The Bose-Hubbard model (BHM) is a minimal model of interacting bosons on a lattice. The original focus of work on the BHM [1] was in the context of experiments on superconductor-insulator transitions in granular superconductors [2] and Josephson junction arrays [3] and for 4 He in porous media [4]. The proposal by Jaksch et al. #CITATION_TAG that the BHM could be realized by cold atoms in an optical lattice and the subsequent experimental demonstration of a superfluid to Mott insulator transition in this system by Greiner et al. [6] has lead the focus of work on this model to shift to cold atoms. The tunability of parameters in cold atom systems [7,8], particularly as a function of time, naturally leads to interest in the out-of-equilibrium dynamics of the BHM especially in the vicinity of a quantum critical point [6].	4	The Bose-Hubbard model (BHM) is a minimal model of interacting bosons on a lattice. The original focus of work on the BHM [1] was in the context of experiments on superconductor-insulator transitions in granular superconductors [2] and Josephson junction arrays [3] and for 4 He in porous media [4]. The proposal by Jaksch et al. #CITATION_TAG that the BHM could be realized by cold atoms in an optical lattice and the subsequent experimental demonstration of a superfluid to Mott insulator transition in this system by Greiner et al. [6] has lead the focus of work on this model to shift to cold atoms. The tunability of parameters in cold atom systems [7,8], particularly as a function of time, naturally leads to interest in the out-of-equilibrium dynamics of the BHM especially in the vicinity of a quantum critical point [6].	e
CCT175	"where , are the initial and final values of the lattice potential and is the ramp time. By comparing a homogeneous system with 1 atom per site with different initial configurations of bosons in a trap as in experiments in [146,186,#CITATION_TAG], Natu et al. argued that local equilibration will be fast, but the speed of global relaxation is strongly affected by whether there needs to be mass transport from one region of the trap to another, particularly if there is a Mott insulating phase, which can act as a barrier to particle diffusion (this is the ""Mott barrier"" idea discussed by Bernier et al. [99]). Evidence of slow relaxation and local, but not global equilibration is illustrated in Figure 19 for an initially superfluid configuration. The figure shows the initial and final density distribution, ( ( )) + trap , and the coherences ( ). In equilibrium, ( ( )) + trap = , but this is not the case in Figure 19, where it can be seen to have local plateaux, but is not globally flat. The plot of coherences = ‚àí‚ü® ‚ü© ‚àë ‚ü® * ‚ü© illustrates that for parameters appropriate to 87 Rb, relaxation timescales can be on the order of 200 ms, much longer than ‚Ñé/ ‚àº 3.3 ms, as seen by Hung et al."	0	"where , are the initial and final values of the lattice potential and is the ramp time. By comparing a homogeneous system with 1 atom per site with different initial configurations of bosons in a trap as in experiments in [146,186,#CITATION_TAG], Natu et al. argued that local equilibration will be fast, but the speed of global relaxation is strongly affected by whether there needs to be mass transport from one region of the trap to another, particularly if there is a Mott insulating phase, which can act as a barrier to particle diffusion (this is the ""Mott barrier"" idea discussed by Bernier et al. [99]). Evidence of slow relaxation and local, but not global equilibration is illustrated in Figure 19 for an initially superfluid configuration. The figure shows the initial and final density distribution, ( ( )) + trap , and the coherences ( ). In equilibrium, ( ( )) + trap = , but this is not the case in Figure 19, where it can be seen to have local plateaux, but is not globally flat."	y
CCT176	A similar role as a dissecting spatial feature can also be ascribed to the Rh√¥ne-Sa√¥ne river system during the onset of the Last Glacial Maximum (Fig. 6b). The large fluviophysiographic feature separates the Solutrean from the Early Epigravettien (Floss 2000a(Floss , 2005Banks et al. 2008;Hussain and Floss 2014). Banks et al. (2008) have suggested that this spatial pattern is largely a function of crucially different ecological conditions east and west of the Rh√¥ne River, leading to completely different technocultural adaptations. Nevertheless, it is still reasonable to argue that periglacial permafrost conditions in the Rh√¥ne Valley, with successive freezing and flooding events (Banks et al. 2008), hampered communication between human groups east and west of its banks. Along with the impact of nearby mountain ranges, glaciers, and associated glacial lakes, this would have resulted in a spatial configuration limiting human movement and communication across the river system. This setting, therefore, would have created strong affordances for avoiding the area and favors sociocultural frontier notions. The succeeding Badegoulian technocultural entity conserves this eastern margin, coinciding with the course of the Rh√¥ne-Sa√¥ne river regime (Floss 2000a;#CITATION_TAG et al. 2011). Moreover, its source area is well defined by major river systems and coastlines in the west and south (Fig. 6c).	2	Nevertheless, it is still reasonable to argue that periglacial permafrost conditions in the Rh√¥ne Valley, with successive freezing and flooding events (Banks et al. 2008), hampered communication between human groups east and west of its banks. Along with the impact of nearby mountain ranges, glaciers, and associated glacial lakes, this would have resulted in a spatial configuration limiting human movement and communication across the river system. This setting, therefore, would have created strong affordances for avoiding the area and favors sociocultural frontier notions. The succeeding Badegoulian technocultural entity conserves this eastern margin, coinciding with the course of the Rh√¥ne-Sa√¥ne river regime (Floss 2000a;#CITATION_TAG et al. 2011). Moreover, its source area is well defined by major river systems and coastlines in the west and south (Fig. 6c).	c
CCT177	"The Ebro River system in northeastern Spain is the second largest river on the Iberian Peninsula and has long been of special importance for archaeologists and paleoanthropologists interested in the spatiotemporal dynamics of late Neanderthal demise and the emergence of AMH groups in this region (d""Errico et al. 1998;Delson and Havarti 2006;Zilh√£o 2009). In a seminal paper, d""Errico et al. (1998) have argued for the existence of an BEbro frontier^separating late Neanderthal populations in southern Spain from the first AMH arrivals in southwestern France and northernmost Iberia (compare Zilh√£o 2000Zilh√£o , 2009Zilh√£o et al. 2010). Much attention has been paid to the apparently young C dates of Gorham""s Cave level IV in Gibraltar which seem to support this scenario (Finlayson et al. 2006(Finlayson et al. , 2008compare also Rodr√≠guez-Vidal et al. 2014). Furthermore, a range of biogeographical arguments have been brought forward to demonstrate a refuge-like role of southern Iberia and Gibraltar, respectively (Finlayson and Carri√≥n 2007;Jennings et al. 2011). In the face of considerable dating problems, however, it is unclear how much credibility these dates still bear (J√∂ris and Adler 2008;J√∂ris and Street 2008;Blockley et al. 2008;Pettitt 2008;J√∂ris et al. 2011;Maroto et al. 2012). Other issues touch upon the postulated favorable condition quality of the area south of the Ebro basin, which has recently been challenged by new climatic and biogeographic data indicating that southern Iberia was at times far from a refugiale zone (but see #CITATION_TAG et al. 2013). On the contrary, the critical time frame around Heinrich IV is characterized by a displacement of the 100-mm precipitation boundary to the north, resulting in an aridization of most of the area (Sepulchre et al. 2007;Jim√©nez-Espejo et al. 2007;Bradtm√∂ller et al. 2012;Schmidt et al. 2012)."	0	"Much attention has been paid to the apparently young C dates of Gorham""s Cave level IV in Gibraltar which seem to support this scenario (Finlayson et al. 2006(Finlayson et al. , 2008compare also Rodr√≠guez-Vidal et al. 2014). Furthermore, a range of biogeographical arguments have been brought forward to demonstrate a refuge-like role of southern Iberia and Gibraltar, respectively (Finlayson and Carri√≥n 2007;Jennings et al. 2011). In the face of considerable dating problems, however, it is unclear how much credibility these dates still bear (J√∂ris and Adler 2008;J√∂ris and Street 2008;Blockley et al. 2008;Pettitt 2008;J√∂ris et al. 2011;Maroto et al. 2012). Other issues touch upon the postulated favorable condition quality of the area south of the Ebro basin, which has recently been challenged by new climatic and biogeographic data indicating that southern Iberia was at times far from a refugiale zone (but see #CITATION_TAG et al. 2013). On the contrary, the critical time frame around Heinrich IV is characterized by a displacement of the 100-mm precipitation boundary to the north, resulting in an aridization of most of the area (Sepulchre et al. 2007;Jim√©nez-Espejo et al. 2007;Bradtm√∂ller et al. 2012;Schmidt et al. 2012)."	 
CCT178	Periodic shifts in flow qualities and thawing are a good example in this respect. These microscale river transformations are ethnographically, in many cases, associated with huge feasting activities and Brites of passage^: the Native Americans of the Northwest Coast, for example, coordinate gift-giving ceremonies with riverine fluctuations (e.g., Pritzker 1998;Waldman 2006;Johansen andPritzker 2008, 1048ff.; see also Strang 2004Strang , 2008. Issues of identity are similarly negotiated in relation to fluvial regimes (#CITATION_TAG et al. 1968;Smith 1990;Strang 1997;Lee and Daly 1999). The Akulmiut of western Alaska, for example, consider themselves as Bpeople between Yukon and Kuskokwim^ (Andrews 1994), while the Khwe of southern Africa determine their location by referring to Bthis^or Bthe other side^of the Kavango River (Brenzinger 2008). In the case of the Cholanaickan of southern India, rivers even serve as boundaries that separate different regional groups and thus spatially construct and enforce social identities (Bhanu 1992).	0	Periodic shifts in flow qualities and thawing are a good example in this respect. These microscale river transformations are ethnographically, in many cases, associated with huge feasting activities and Brites of passage^: the Native Americans of the Northwest Coast, for example, coordinate gift-giving ceremonies with riverine fluctuations (e.g., Pritzker 1998;Waldman 2006;Johansen andPritzker 2008, 1048ff. ; see also Strang 2004Strang , 2008. Issues of identity are similarly negotiated in relation to fluvial regimes (#CITATION_TAG et al. 1968;Smith 1990;Strang 1997;Lee and Daly 1999). The Akulmiut of western Alaska, for example, consider themselves as Bpeople between Yukon and Kuskokwim^ (Andrews 1994), while the Khwe of southern Africa determine their location by referring to Bthis^or Bthe other side^of the Kavango River (Brenzinger 2008). In the case of the Cholanaickan of southern India, rivers even serve as boundaries that separate different regional groups and thus spatially construct and enforce social identities (Bhanu 1992).	u
CCT179	"The Danube River in particular holds a key position in structuring population movement and sociocultural exchange in an east-west direction (Conard 2000, p. 351;Bolus 2003, 2008;Floss 2003aFloss , 2009aBolus 2009). Recent radiocarbon dates from the key Swabian Jura sites of Hohle Fels and Gei√üenkl√∂sterle in the Ach valley, a small tributary of the Upper Danube, support this view and place the earliest occupation in the region even before Heinrich event IV (Conard 2009a;#CITATION_TAG et al. 2012Higham et al. , 2014. Dates between 40 and 42 ka cal. BP for a wellestablished Early Aurignacian presence in the Upper Danube suggest that AMH groups very rapidly entered the gates of Europe via this large river valley (Conard and Bolus 2003;Bolus 2009). The age determinations are supported by several other Early Aurignacian sites from the region that yielded calibrated 14 C dates between 38 and 40 ka BP (Conard 2003(Conard , 2006Nigst 2006;J√∂ris et al. 2010;Kind et al. 2015). Moreover, these sites share a regionally distinct Bcultural heritage^represented by a unique tradition of both ivory figurines and personal ornaments (Hahn 1993;Floss 2000, 2010;Vanhaeren and d""Errico 2006;Floss 2007Floss , 2009bConard 2007Conard , 2009aPorr 2010;Wolf 2015;Conard et al. 2015). We would argue that the emergence of a regionally distinct tradition of figurine and ornament making already signals the end of a true Bpioneer phase√Æ n the initial incursion into the European mainland. From this perspective, the very early and therefore pioneer Aurignacian assemblages reflecting an initial advance into largely unknown landscapes are expected to be even more rudimentary and ephemeral in this respect (cf. Davies 2001Davies , 2007. Recent evidence from Willendorf II in Lower Austria is in strong agreement with this model and demonstrates the presence of Aurignacian technologies without personal ornaments and figurines along the Danube already before ka cal. BP (Nigst et al. 2014)."	0	The Danube River in particular holds a key position in structuring population movement and sociocultural exchange in an east-west direction (Conard 2000, p. 351;Bolus 2003, 2008;Floss 2003aFloss , 2009aBolus 2009). Recent radiocarbon dates from the key Swabian Jura sites of Hohle Fels and Gei√üenkl√∂sterle in the Ach valley, a small tributary of the Upper Danube, support this view and place the earliest occupation in the region even before Heinrich event IV (Conard 2009a;#CITATION_TAG et al. 2012Higham et al. , 2014. Dates between 40 and 42 ka cal. BP for a wellestablished Early Aurignacian presence in the Upper Danube suggest that AMH groups very rapidly entered the gates of Europe via this large river valley (Conard and Bolus 2003;Bolus 2009). The age determinations are supported by several other Early Aurignacian sites from the region that yielded calibrated 14 C dates between 38 and 40 ka BP (Conard 2003(Conard , 2006Nigst 2006;J√∂ris et al. 2010;Kind et al. 2015).	e
CCT180	"A similar role as an Early Aurignacian expansion route is hypothesized for the Don River system near the Black Sea (Anikovich et al. 2007; Fig. 5). Bataille (2013, 76ff.) has recently reinforced this model and extended it to the whole region, arguing for the important role of the Dniester, the Dnepr, and the Don in accessing new land in Eastern Europe during this period. In a systematic survey of Late Aurignacian occurrences on the British Isles, Dinnis (2008Dinnis ( , 2009Dinnis ( , 2012a has proposed an analogous perspective for the now submerged Channel River system in explaining human dispersal into Northern Europe (cf. Fig. 5). The argument is mainly based on the striking western distribution of Late Aurignacian sites in Britain, which cannot be explained by differential find preservation or lack of research alone (Jacobi 2007;Pettitt 2008;Flas 2009;Dinnis 2012a, b). In the past, scholars have proposed that these Aurignacian groups came from northwestern France because of its close spatial proximity and a presumed environmental similarity between the two regions (Jacobi 1999;Pettitt 2008). The distinct spatial patterning of Paviland burin technologies, however, now clearly favors an eastern source area comprised of today""s Belgium and parts of northeastern France (Flas et al. 2006;Dinnis 2008Dinnis , 2012a. It is thus very likely that the Pleistocene Channel River network directed AMH movement to the British mainland (Pettitt 2008;Dinnis 2008Dinnis , 2009Dinnis , 2012a. This model is particularly appealing because the Late Pleistocene Channel River was directly linked to the Seine and the Rhine river system at this time (Antoine et al. 2003;Lericolais et al. 2003;Toucanne et al. 2010), offering a high degree of landscape interconnectivity that could easily be exploited by mobile foraging groups coming from the heart of Europe (cf. Fig. 5). Moreover, the river occupied an extensive area in the landscape with multiple migratory channels, minor tributaries, and a massive floodplain, including swamp and marsh environments (e.g., #CITATION_TAG et al. 2012). Apart from being extremely attractive for animals in general, and migratory fauna in particular (Dinnis 2009(Dinnis , 2012a, this spatial configuration brings forth an accessible and affording fluvial feature, testified in a high degree of connectivity in the archaeological patterning."	2	"The distinct spatial patterning of Paviland burin technologies, however, now clearly favors an eastern source area comprised of today""s Belgium and parts of northeastern France (Flas et al. 2006;Dinnis 2008Dinnis , 2012a. It is thus very likely that the Pleistocene Channel River network directed AMH movement to the British mainland (Pettitt 2008;Dinnis 2008Dinnis , 2009Dinnis , 2012a. This model is particularly appealing because the Late Pleistocene Channel River was directly linked to the Seine and the Rhine river system at this time (Antoine et al. 2003;Lericolais et al. 2003;Toucanne et al. 2010), offering a high degree of landscape interconnectivity that could easily be exploited by mobile foraging groups coming from the heart of Europe (cf. Fig. 5). Moreover, the river occupied an extensive area in the landscape with multiple migratory channels, minor tributaries, and a massive floodplain, including swamp and marsh environments (e.g., #CITATION_TAG et al. 2012). Apart from being extremely attractive for animals in general, and migratory fauna in particular (Dinnis 2009(Dinnis , 2012a, this spatial configuration brings forth an accessible and affording fluvial feature, testified in a high degree of connectivity in the archaeological patterning."	 
CCT181	This idea largely dates back to the Continental European tradition of philosophical inquiry, broadly characterized as phenomenological, and most prominently advocated by Martin Heidegger and Maurice Merleau-Ponty (cf. Cataldi and Hamrick 2007). Both argue that humans are before anything else Bbeings-in-the-world^ (Heidegger 1927a, b;Merleau-Ponty 1945, 1964. They are thrown into predefined spatial settings, enriched by the respective cultural traditions and underpinned by the physiographic properties of the surrounding landscapes. Perception, experience, and behavior thus emerge from the complex interplay of natural environments and cultural systems. Consequently, it is the phenomenology of a particular setting that becomes central to human spatial dwelling and the resulting archaeological patterning. Accordingly, Bspatial turn^advocates (cf. D√ºnne and G√ºnzel 2006;D√∂ring and Thielmann 2008;G√ºnzel 2009;Warf and Arias 2009;Bachman-Medick 2010) have convincingly argued for the Bsocially constructed^and Bculturally built^dimension of space emphasizing the human factor therein (e.g., Ashmore and Knapp 1999;Muir 2000;Lang 2009). Each spatial feature has therefore to be understood as an entanglement of natural properties and sociocultural dimensions (e.g., Gamble 1993;Tilley 1994;Rockman 2003;Meskell and Preucel 2004;Edgeworth 2011;#CITATION_TAG 2012). As a result, the specific and potentially changing place of individual spatial entities within larger Becocultural systems^(sensu Rapport and Maffi 2010, p. 104; see also Pretty and Pilgrim 2010 and references therein) can be extremely informative.	4	Perception, experience, and behavior thus emerge from the complex interplay of natural environments and cultural systems. Consequently, it is the phenomenology of a particular setting that becomes central to human spatial dwelling and the resulting archaeological patterning. Accordingly, Bspatial turn^advocates (cf. D√ºnne and G√ºnzel 2006;D√∂ring and Thielmann 2008;G√ºnzel 2009;Warf and Arias 2009;Bachman-Medick 2010) have convincingly argued for the Bsocially constructed^and Bculturally built^dimension of space emphasizing the human factor therein (e.g., Ashmore and Knapp 1999;Muir 2000;Lang 2009). Each spatial feature has therefore to be understood as an entanglement of natural properties and sociocultural dimensions (e.g., Gamble 1993;Tilley 1994;Rockman 2003;Meskell and Preucel 2004;Edgeworth 2011;#CITATION_TAG 2012). As a result, the specific and potentially changing place of individual spatial entities within larger Becocultural systems^(sensu Rapport and Maffi 2010, p. 104; see also Pretty and Pilgrim 2010 and references therein) can be extremely informative.	p
CCT182	"Evidence for the movement of lithic raw materials along the great Danube River during the Magdalenian is most notably constituted by BPlattenhornstein,^a special tabular chert variety that originates in the Franconian Jura (Floss 1994). Pieces of this particular raw material group appear in several Magdalenian sites of the Swabian Jura, bridging distances up to 160 km up-river and connecting both regions (Floss 1994(Floss , 2000aBurkert and Floss 2005;Maier 2012a; compare Table 1). It is important to note that these raw materials are by no means the only physical indication for an east-west interconnectivity of the Central European Magdalenian parallel to the Danube. The Upper Danube area shares some striking sociocultural peculiarities, from which regularly red-dotted stones, often plaquettes, are particularly worth mentioning (Conard and Floss 1999;Conard and Uerpmann 2000;Conard 2001, 2009;Conard and Malina 2010). They have been found in Magdalenian layers of Hohle Fels and Kleine Scheuer in the Swabian Jura and, among others, in Obere Klause in the Altm√ºhl Valley (#CITATION_TAG and Floss 2014;Conard et al. 2015, p. 109), thus clearly revealing an area of Bcommon cultural heritage^and an enclosed communication space at the least (Floss 2014;Hussain and Floss 2014). These findings are consistent with Erikson""s (2002) suggestion that the emphasis on lithic raw material transfer (interpreted as expression of direct or embedded procurement) on this spatial axis would favor scenarios of actual group movement along the Danube. From this perspective, the material evidence clearly points to a mediating role of the Danube River system in the Magdalenian, channeling and regulating both the flow of people and materials."	2	"Pieces of this particular raw material group appear in several Magdalenian sites of the Swabian Jura, bridging distances up to 160 km up-river and connecting both regions (Floss 1994(Floss , 2000aBurkert and Floss 2005;Maier 2012a; compare Table 1). It is important to note that these raw materials are by no means the only physical indication for an east-west interconnectivity of the Central European Magdalenian parallel to the Danube. The Upper Danube area shares some striking sociocultural peculiarities, from which regularly red-dotted stones, often plaquettes, are particularly worth mentioning (Conard and Floss 1999;Conard and Uerpmann 2000;Conard 2001, 2009;Conard and Malina 2010). They have been found in Magdalenian layers of Hohle Fels and Kleine Scheuer in the Swabian Jura and, among others, in Obere Klause in the Altm√ºhl Valley (#CITATION_TAG and Floss 2014;Conard et al. 2015, p. 109), thus clearly revealing an area of Bcommon cultural heritage^and an enclosed communication space at the least (Floss 2014;Hussain and Floss 2014). These findings are consistent with Erikson""s (2002) suggestion that the emphasis on lithic raw material transfer (interpreted as expression of direct or embedded procurement) on this spatial axis would favor scenarios of actual group movement along the Danube. From this perspective, the material evidence clearly points to a mediating role of the Danube River system in the Magdalenian, channeling and regulating both the flow of people and materials."	 
CCT183	While many scholars dealing with post-Pleistocene societies tend to emphasize the conceptualized and Bbuilt^nature of each Banthropospace^(e.g., Tilley 1994;Ashmore and Knapp 1999;Muir 2000;Meskell and Preucel 2004;Lang 2009;#CITATION_TAG and Linduff 2009), Paleolithic archaeologists usually focus on the Bnatural^dimension of spatiality, on the environment sensu stricto, tacitly assuming that spatial presence in general is before anything else driven and crucially constrained by bioecological regimes (e.g., Verpoorte 2009;M√ºller et al. 2011;Richter et al. 2012;Hertler et al. 2013;Harcourt 2012, p. 77;Arrizabalaga et al. 2013). It is not our aim here to contest the undeniable contribution of ecology and physiography. We rather believe, however, that it is time now for Paleolithic archaeology to move beyond that one-sided paradigm. After all, there is good reason to believe that spatial behavior is in fact a product of the dynamic interplay of both naturally given and lived and experienced properties of the landscape.	0	While many scholars dealing with post-Pleistocene societies tend to emphasize the conceptualized and Bbuilt^nature of each Banthropospace^(e.g., Tilley 1994;Ashmore and Knapp 1999;Muir 2000;Meskell and Preucel 2004;Lang 2009;#CITATION_TAG and Linduff 2009), Paleolithic archaeologists usually focus on the Bnatural^dimension of spatiality, on the environment sensu stricto, tacitly assuming that spatial presence in general is before anything else driven and crucially constrained by bioecological regimes (e.g., Verpoorte 2009;M√ºller et al. 2011;Richter et al. 2012;Hertler et al. 2013;Harcourt 2012, p. 77;Arrizabalaga et al. 2013). It is not our aim here to contest the undeniable contribution of ecology and physiography. We rather believe, however, that it is time now for Paleolithic archaeology to move beyond that one-sided paradigm. After all, there is good reason to believe that spatial behavior is in fact a product of the dynamic interplay of both naturally given and lived and experienced properties of the landscape.	W
CCT184	"The Danube River in particular holds a key position in structuring population movement and sociocultural exchange in an east-west direction (Conard 2000, p. 351;Bolus 2003, 2008;Floss 2003aFloss , 2009aBolus 2009). Recent radiocarbon dates from the key Swabian Jura sites of Hohle Fels and Gei√üenkl√∂sterle in the Ach valley, a small tributary of the Upper Danube, support this view and place the earliest occupation in the region even before Heinrich event IV (Conard 2009a;Higham et al. 2012Higham et al. , 2014. Dates between 40 and 42 ka cal. BP for a wellestablished Early Aurignacian presence in the Upper Danube suggest that AMH groups very rapidly entered the gates of Europe via this large river valley (Conard and Bolus 2003;Bolus 2009). The age determinations are supported by several other Early Aurignacian sites from the region that yielded calibrated 14 C dates between 38 and 40 ka BP (Conard 2003(Conard , 2006Nigst 2006;J√∂ris et al. 2010;Kind et al. 2015). Moreover, these sites share a regionally distinct Bcultural heritage^represented by a unique tradition of both ivory figurines and personal ornaments (#CITATION_TAG 1993;Floss 2000, 2010;Vanhaeren and d""Errico 2006;Floss 2007Floss , 2009bConard 2007Conard , 2009aPorr 2010;Wolf 2015;Conard et al. 2015). We would argue that the emergence of a regionally distinct tradition of figurine and ornament making already signals the end of a true Bpioneer phase√Æ n the initial incursion into the European mainland. From this perspective, the very early and therefore pioneer Aurignacian assemblages reflecting an initial advance into largely unknown landscapes are expected to be even more rudimentary and ephemeral in this respect (cf. Davies 2001Davies , 2007. Recent evidence from Willendorf II in Lower Austria is in strong agreement with this model and demonstrates the presence of Aurignacian technologies without personal ornaments and figurines along the Danube already before ka cal. BP (Nigst et al. 2014)."	0	"Dates between 40 and 42 ka cal. BP for a wellestablished Early Aurignacian presence in the Upper Danube suggest that AMH groups very rapidly entered the gates of Europe via this large river valley (Conard and Bolus 2003;Bolus 2009). The age determinations are supported by several other Early Aurignacian sites from the region that yielded calibrated 14 C dates between 38 and 40 ka BP (Conard 2003(Conard , 2006Nigst 2006;J√∂ris et al. 2010;Kind et al. 2015). Moreover, these sites share a regionally distinct Bcultural heritage^represented by a unique tradition of both ivory figurines and personal ornaments (#CITATION_TAG 1993;Floss 2000, 2010;Vanhaeren and d""Errico 2006;Floss 2007Floss , 2009bConard 2007Conard , 2009aPorr 2010;Wolf 2015;Conard et al. 2015). We would argue that the emergence of a regionally distinct tradition of figurine and ornament making already signals the end of a true Bpioneer phase√Æ n the initial incursion into the European mainland. From this perspective, the very early and therefore pioneer Aurignacian assemblages reflecting an initial advance into largely unknown landscapes are expected to be even more rudimentary and ephemeral in this respect (cf. Davies 2001Davies , 2007. Recent evidence from Willendorf II in Lower Austria is in strong agreement with this model and demonstrates the presence of Aurignacian technologies without personal ornaments and figurines along the Danube already before ka cal."	v
CCT185	"To conclude, it appears that Aurignacian site occurrence at the European scale is strongly correlated with the presence of large river systems in the landscape (Otte 1979;Davies 2001;. Individual prominent, accessible, and strongly accommodating river systems considerably shape the sociocultural geography of the Aurignacian record. These rivers clearly serve as key features ensuring connectivity between various occupational areas. We would argue that the role of these river systems as communication corridors and mobility conduits is largely a result of both their ecophysiographic characteristics and the unique social context of dispersal and migration. To begin with, if we accept the two-phase dispersal model of Aurignacian technologies, with a pioneer and a consolidated phase reflected in different sociocultural signatures (Davies 2001(Davies , 2007, the conditions of landscape knowledge and learning deserve special attention (e.g., Golledge 2003;Kelly 2003). It is reasonable to assume that AMH groups entering Europe experienced largely unknown and unfamiliar landscapes and had very limited ecological knowledge on which spatial behavior, food acquisition, and sociocultural topology could be based. Large rivers are then very likely to play a key role because they are reliable spatial heuristics for orientation and the exploitation of the wider landscape. The visual prominence and physical accessibility of mostly braided river systems in the Early Aurignacian cold climatic phase further enhances their affordance structure. In the wider ecocultural system of Aurignacian times, these rivers can therefore be characterized as anchor points that organize spatial cognition and performance. #CITATION_TAG (1978) already pointed out that such anchoring features are designated to hierarchically structure the local environment around them and serve as a Bcheap^and effective means of landscape use and way-finding in particular (see also Couclelis et al. 1987). This emerging property would thus underscore the integral role of large rivers in the context of Bfast and frugal^decision-making during human expansion and colonization. G√§rling et al. (1984) have shown that the Benvironmental legibility^that contributes to a spatial feature""s experienced quality varies according to the conditions of landscape knowledge and can thus be discussed in relation to three main stages: exploratory, adaptive, and abstract. The exploratory stage, broadly equitable to dispersal and migration scenarios, is generally characterized by the dominance of visual experience in orientation. Human groups therefore use concrete spatial representations mainly related to focal physiographic features (Golledge 2003, p. 36). Moreover, there seems to be a positive relationship between Blandscape unfamiliarity^and the focality of spatial features that impact the mobility of social groups (Kelly 2003, p. 48). In the adaptive and abstract stages, on the other hand, sociocultural meaning becomes increasingly separated from physiographic properties. This general matrix of spatial performance might explain why large river systems play such an important role in the successive settlement of the European continent, both as directing and channeling spatial features, and offers a parsimonious blueprint for interpreting the spatiality of the Aurignacian record (compare Fig. 5)."	5	"Large rivers are then very likely to play a key role because they are reliable spatial heuristics for orientation and the exploitation of the wider landscape. The visual prominence and physical accessibility of mostly braided river systems in the Early Aurignacian cold climatic phase further enhances their affordance structure. In the wider ecocultural system of Aurignacian times, these rivers can therefore be characterized as anchor points that organize spatial cognition and performance. #CITATION_TAG (1978) already pointed out that such anchoring features are designated to hierarchically structure the local environment around them and serve as a Bcheap^and effective means of landscape use and way-finding in particular (see also Couclelis et al. 1987). This emerging property would thus underscore the integral role of large rivers in the context of Bfast and frugal^decision-making during human expansion and colonization. G√§rling et al. (1984) have shown that the Benvironmental legibility^that contributes to a spatial feature""s experienced quality varies according to the conditions of landscape knowledge and can thus be discussed in relation to three main stages: exploratory, adaptive, and abstract. The exploratory stage, broadly equitable to dispersal and migration scenarios, is generally characterized by the dominance of visual experience in orientation."	_
CCT186	"The idea, that large river systems coincide with social boundaries and thus structure the Paleolithic world on larger scales, has been extremely influential in the field""s history. Some of these ideas even had a deep impact on how scholars recognized the entire period. Most famously, Hallam L. Movius claimed in the middle of the last century the existence of a demarcation line dividing the Lower Paleolithic into two hemispheres, one with bifaces and the other lacking them (Movius 1949). He identified the BMovius line^as a robust spatiotemporal feature in Central Europe thought to be largely identical with the course of the River Rhine. For a long time, scholars therefore considered the famous biface of Hochdahl as the only handaxe occurrence east of the river and beyond the Movius line (Andree 1939, 569ff.;Bosinski 2008, p. 113). Another famous historical example is the case of the Nile Valley seemingly forming the eastern margin of the Aterian world within the greater North African Middle Stone Age complex (#CITATION_TAG 1946;Marks 1975, p. 440;Deb√©nath 1986, p. 25;Kleindienst 2000Kleindienst , 2001Hublin and McPherron 2012;Scerri 2013)."	0	He identified the BMovius line^as a robust spatiotemporal feature in Central Europe thought to be largely identical with the course of the River Rhine. For a long time, scholars therefore considered the famous biface of Hochdahl as the only handaxe occurrence east of the river and beyond the Movius line (Andree 1939, 569ff. ;Bosinski 2008, p. 113). Another famous historical example is the case of the Nile Valley seemingly forming the eastern margin of the Aterian world within the greater North African Middle Stone Age complex (#CITATION_TAG 1946;Marks 1975, p. 440;Deb√©nath 1986, p. 25;Kleindienst 2000Kleindienst , 2001Hublin and McPherron 2012;Scerri 2013).	r
CCT187	In this way, rivers constitute an important cornerstone of a Bbounded^or Becological^perspective on decision-making and judgment in space (Simon 1989;#CITATION_TAG and Goldstein 1996;Gigerenzer and Selten 2002;Kahneman 2003;Gr√ºne-Yanoff 2007;Todd et al. 2012). Viewed in this light, heuristics can even be seen as integral components of the human Badaptive toolbox^ (Gigerenzer et al. 1999;Boudry et al. 2015;Polonioli 2015). They provide behavioral guidelines by their own virtue, which is by no means Bmystical,^but grounded in the specific nature of each riverenvironment relationship.	4	In this way, rivers constitute an important cornerstone of a Bbounded^or Becological^perspective on decision-making and judgment in space (Simon 1989;#CITATION_TAG and Goldstein 1996;Gigerenzer and Selten 2002;Kahneman 2003;Gr√ºne-Yanoff 2007;Todd et al. 2012). Viewed in this light, heuristics can even be seen as integral components of the human Badaptive toolbox^ (Gigerenzer et al. 1999;Boudry et al. 2015;Polonioli 2015). They provide behavioral guidelines by their own virtue, which is by no means Bmystical,^but grounded in the specific nature of each riverenvironment relationship.	I
CCT188	In this way, rivers constitute an important cornerstone of a Bbounded^or Becological^perspective on decision-making and judgment in space (Simon 1989;Gigerenzer and Goldstein 1996;Gigerenzer and Selten 2002;Kahneman 2003;Gr√ºne-Yanoff 2007;Todd et al. 2012). Viewed in this light, heuristics can even be seen as integral components of the human Badaptive toolbox^ (#CITATION_TAG et al. 1999;Boudry et al. 2015;Polonioli 2015). They provide behavioral guidelines by their own virtue, which is by no means Bmystical,^but grounded in the specific nature of each riverenvironment relationship.	4	In this way, rivers constitute an important cornerstone of a Bbounded^or Becological^perspective on decision-making and judgment in space (Simon 1989;Gigerenzer and Goldstein 1996;Gigerenzer and Selten 2002;Kahneman 2003;Gr√ºne-Yanoff 2007;Todd et al. 2012). Viewed in this light, heuristics can even be seen as integral components of the human Badaptive toolbox^ (#CITATION_TAG et al. 1999;Boudry et al. 2015;Polonioli 2015). They provide behavioral guidelines by their own virtue, which is by no means Bmystical,^but grounded in the specific nature of each riverenvironment relationship.	i
CCT189	Humans are spatial beings and the nature of our spatial presence is in many ways crucial for what we are. How we define our relationship to the world and how we understand and access what surrounds us is an important cornerstone of our different lifestyles. Space utilization (Raumnutzung), therefore, is a central research area for all the human sciences (e.g., D√ºnne and G√ºnzel 2006;Warf and Arias 2009;Bachman-Medick 2010). Archaeologists, consequently, have ever since attempted to tackle the Bspatiality^of past human social units from a whole range of different angles (e.g., Shott 1986;Kelly 1992;Close 2000;Brantingham 2006;#CITATION_TAG and Wendrich 2008;Grove 2009Grove , 2010Turq et al. 2013;Cameron 2013;Van Dommelen 2014). Yet, how anchoring key notions such as Bspace^need to be approached is highly disputed and remains a very sensitive matter.	0	Humans are spatial beings and the nature of our spatial presence is in many ways crucial for what we are. How we define our relationship to the world and how we understand and access what surrounds us is an important cornerstone of our different lifestyles. Space utilization (Raumnutzung), therefore, is a central research area for all the human sciences (e.g., D√ºnne and G√ºnzel 2006;Warf and Arias 2009;Bachman-Medick 2010). Archaeologists, consequently, have ever since attempted to tackle the Bspatiality^of past human social units from a whole range of different angles (e.g., Shott 1986;Kelly 1992;Close 2000;Brantingham 2006;#CITATION_TAG and Wendrich 2008;Grove 2009Grove , 2010Turq et al. 2013;Cameron 2013;Van Dommelen 2014). Yet, how anchoring key notions such as Bspace^need to be approached is highly disputed and remains a very sensitive matter.	h
CCT190	"To conclude, it appears that Aurignacian site occurrence at the European scale is strongly correlated with the presence of large river systems in the landscape (Otte 1979;Davies 2001;. Individual prominent, accessible, and strongly accommodating river systems considerably shape the sociocultural geography of the Aurignacian record. These rivers clearly serve as key features ensuring connectivity between various occupational areas. We would argue that the role of these river systems as communication corridors and mobility conduits is largely a result of both their ecophysiographic characteristics and the unique social context of dispersal and migration. To begin with, if we accept the two-phase dispersal model of Aurignacian technologies, with a pioneer and a consolidated phase reflected in different sociocultural signatures (Davies 2001(Davies , 2007, the conditions of landscape knowledge and learning deserve special attention (e.g., #CITATION_TAG 2003;Kelly 2003). It is reasonable to assume that AMH groups entering Europe experienced largely unknown and unfamiliar landscapes and had very limited ecological knowledge on which spatial behavior, food acquisition, and sociocultural topology could be based. Large rivers are then very likely to play a key role because they are reliable spatial heuristics for orientation and the exploitation of the wider landscape. The visual prominence and physical accessibility of mostly braided river systems in the Early Aurignacian cold climatic phase further enhances their affordance structure. In the wider ecocultural system of Aurignacian times, these rivers can therefore be characterized as anchor points that organize spatial cognition and performance. Golledge (1978) already pointed out that such anchoring features are designated to hierarchically structure the local environment around them and serve as a Bcheap^and effective means of landscape use and way-finding in particular (see also Couclelis et al. 1987). This emerging property would thus underscore the integral role of large rivers in the context of Bfast and frugal^decision-making during human expansion and colonization. G√§rling et al. (1984) have shown that the Benvironmental legibility^that contributes to a spatial feature""s experienced quality varies according to the conditions of landscape knowledge and can thus be discussed in relation to three main stages: exploratory, adaptive, and abstract. The exploratory stage, broadly equitable to dispersal and migration scenarios, is generally characterized by the dominance of visual experience in orientation. Human groups therefore use concrete spatial representations mainly related to focal physiographic features (Golledge 2003, p. 36). Moreover, there seems to be a positive relationship between Blandscape unfamiliarity^and the focality of spatial features that impact the mobility of social groups (Kelly 2003, p. 48). In the adaptive and abstract stages, on the other hand, sociocultural meaning becomes increasingly separated from physiographic properties. This general matrix of spatial performance might explain why large river systems play such an important role in the successive settlement of the European continent, both as directing and channeling spatial features, and offers a parsimonious blueprint for interpreting the spatiality of the Aurignacian record (compare Fig. 5)."	4	Individual prominent, accessible, and strongly accommodating river systems considerably shape the sociocultural geography of the Aurignacian record. These rivers clearly serve as key features ensuring connectivity between various occupational areas. We would argue that the role of these river systems as communication corridors and mobility conduits is largely a result of both their ecophysiographic characteristics and the unique social context of dispersal and migration. To begin with, if we accept the two-phase dispersal model of Aurignacian technologies, with a pioneer and a consolidated phase reflected in different sociocultural signatures (Davies 2001(Davies , 2007, the conditions of landscape knowledge and learning deserve special attention (e.g., #CITATION_TAG 2003;Kelly 2003). It is reasonable to assume that AMH groups entering Europe experienced largely unknown and unfamiliar landscapes and had very limited ecological knowledge on which spatial behavior, food acquisition, and sociocultural topology could be based. Large rivers are then very likely to play a key role because they are reliable spatial heuristics for orientation and the exploitation of the wider landscape. The visual prominence and physical accessibility of mostly braided river systems in the Early Aurignacian cold climatic phase further enhances their affordance structure.	e
CCT191	Humans are spatial beings and the nature of our spatial presence is in many ways crucial for what we are. How we define our relationship to the world and how we understand and access what surrounds us is an important cornerstone of our different lifestyles. Space utilization (Raumnutzung), therefore, is a central research area for all the human sciences (e.g., D√ºnne and G√ºnzel 2006;Warf and Arias 2009;Bachman-Medick 2010). Archaeologists, consequently, have ever since attempted to tackle the Bspatiality^of past human social units from a whole range of different angles (e.g., Shott 1986;Kelly 1992;#CITATION_TAG 2000;Brantingham 2006;Bernard and Wendrich 2008;Grove 2009Grove , 2010Turq et al. 2013;Cameron 2013;Van Dommelen 2014). Yet, how anchoring key notions such as Bspace^need to be approached is highly disputed and remains a very sensitive matter.	0	Humans are spatial beings and the nature of our spatial presence is in many ways crucial for what we are. How we define our relationship to the world and how we understand and access what surrounds us is an important cornerstone of our different lifestyles. Space utilization (Raumnutzung), therefore, is a central research area for all the human sciences (e.g., D√ºnne and G√ºnzel 2006;Warf and Arias 2009;Bachman-Medick 2010). Archaeologists, consequently, have ever since attempted to tackle the Bspatiality^of past human social units from a whole range of different angles (e.g., Shott 1986;Kelly 1992;#CITATION_TAG 2000;Brantingham 2006;Bernard and Wendrich 2008;Grove 2009Grove , 2010Turq et al. 2013;Cameron 2013;Van Dommelen 2014). Yet, how anchoring key notions such as Bspace^need to be approached is highly disputed and remains a very sensitive matter.	h
CCT192	Humans are spatial beings and the nature of our spatial presence is in many ways crucial for what we are. How we define our relationship to the world and how we understand and access what surrounds us is an important cornerstone of our different lifestyles. Space utilization (Raumnutzung), therefore, is a central research area for all the human sciences (e.g., D√ºnne and G√ºnzel 2006;Warf and Arias 2009;Bachman-Medick 2010). Archaeologists, consequently, have ever since attempted to tackle the Bspatiality^of past human social units from a whole range of different angles (e.g., Shott 1986;Kelly 1992;Close 2000;Brantingham 2006;Bernard and Wendrich 2008;#CITATION_TAG 2009Grove , 2010Turq et al. 2013;Cameron 2013;Van Dommelen 2014). Yet, how anchoring key notions such as Bspace^need to be approached is highly disputed and remains a very sensitive matter.	0	Humans are spatial beings and the nature of our spatial presence is in many ways crucial for what we are. How we define our relationship to the world and how we understand and access what surrounds us is an important cornerstone of our different lifestyles. Space utilization (Raumnutzung), therefore, is a central research area for all the human sciences (e.g., D√ºnne and G√ºnzel 2006;Warf and Arias 2009;Bachman-Medick 2010). Archaeologists, consequently, have ever since attempted to tackle the Bspatiality^of past human social units from a whole range of different angles (e.g., Shott 1986;Kelly 1992;Close 2000;Brantingham 2006;Bernard and Wendrich 2008;#CITATION_TAG 2009Grove , 2010Turq et al. 2013;Cameron 2013;Van Dommelen 2014). Yet, how anchoring key notions such as Bspace^need to be approached is highly disputed and remains a very sensitive matter.	h
CCT193	"Although belief in the biological determination of sexual orientation is correlated with tolerance towards lesbians and gay men, beliefs in biological determination are also correlated with prejudice and stereotyping of other minority groups (c.f., Bastian & Haslam, 2006;Keller, 2005;Martin & Parker, 1995;#CITATION_TAG, Postmes, Haslam, & Hornsey, 2009;Prentice & Miller, 2007;Williams & Eberhardt, 2008;Yzerbyt, Rocher, & Schadron, 1997). This pattern of results has led researchers to wonder if sexual prejudice is a ""special case"" in this literature (e.g., D.J. Bem, 1998;Haslam et al., 2002;Jayaratne et al., 2006). However, as Prentice and Miller (2007) note, studies of essentialism and sexual prejudice in the domain of sexual orientation typically examine the belief in the idea that sexual orientation is itself an ""essential"" reality, whereas discussions of essentialism and ethnic prejudice typically refer to belief in the reality of stereotypes linking category membership with other traits. Heterosexual people who consider sexual orientation to be genetic are often less prejudiced. However, heterosexual people who consider that there is a gene that ties homosexuality to disease might not be. Ironically, genetic research on sexual orientation that has been widely announced as pro-gay research also aimed to determine a genetic link between homosexuality and alcoholism (c.f., Hamer & Copeland, 1994). Because of these implications of biological determinism, it is important to consider whether attribution theory""s claim that attributions affect attitudes has empirical support."	4	"Although belief in the biological determination of sexual orientation is correlated with tolerance towards lesbians and gay men, beliefs in biological determination are also correlated with prejudice and stereotyping of other minority groups (c.f., Bastian & Haslam, 2006;Keller, 2005;Martin & Parker, 1995;#CITATION_TAG, Postmes, Haslam, & Hornsey, 2009;Prentice & Miller, 2007;Williams & Eberhardt, 2008;Yzerbyt, Rocher, & Schadron, 1997). This pattern of results has led researchers to wonder if sexual prejudice is a ""special case"" in this literature (e.g., D.J. Bem, 1998;Haslam et al., 2002;Jayaratne et al., 2006). However, as Prentice and Miller (2007) note, studies of essentialism and sexual prejudice in the domain of sexual orientation typically examine the belief in the idea that sexual orientation is itself an ""essential"" reality, whereas discussions of essentialism and ethnic prejudice typically refer to belief in the reality of stereotypes linking category membership with other traits. Heterosexual people who consider sexual orientation to be genetic are often less prejudiced."	A
CCT194	"A third body of evidence that challenges attribution theory is most relevant to the current educational study. If sexual prejudice reduces in human sexuality classrooms because of the effects of biological theories, then one might expect students to become more interested in such theories as their prejudice decreases. #CITATION_TAG et al. (2001) assessed students"" prejudice and their interest in 26 topics at the beginning and end of a course titled ""The Psychology of Homosexuality"". Prejudice reduced among these largely heterosexual students. At the start of the semester, students were most interested in two topics: ""theories of why people are gay"" and ""biological differences between homosexuals and heterosexuals"". At the end of the course these interests were ranked only 2nd and 10th respectively among their interests. By the end of the course, students were also less interested in ways of detecting a person""s sexual orientation, and had become most interested in ""supporting someone coming out"". By showing that prejudice reduction can co-occur with a reduction in interest in biological determinist questions, this study casts further doubt on the possibility that biological determinist thinking supports prejudice reduction directly."	4	"A third body of evidence that challenges attribution theory is most relevant to the current educational study. If sexual prejudice reduces in human sexuality classrooms because of the effects of biological theories, then one might expect students to become more interested in such theories as their prejudice decreases. #CITATION_TAG et al. (2001) assessed students"" prejudice and their interest in 26 topics at the beginning and end of a course titled ""The Psychology of Homosexuality"". Prejudice reduced among these largely heterosexual students. At the start of the semester, students were most interested in two topics: ""theories of why people are gay"" and ""biological differences between homosexuals and heterosexuals"". At the end of the course these interests were ranked only 2nd and 10th respectively among their interests."	I
CCT195	"With few exceptions (e.g., Hegarty, 2002;Hegarty & Pratto, 2001;Herek & Capitanio, 1995), social psychologists who have studied structural relationships between biological beliefs and attitudes to lesbians and gay men have tended to interpret those findings as evidence of causal effects of beliefs on attitudes. However, only rarely have authors conducted mediation analyses or verified structural equation models that support those interpretations (see #CITATION_TAG & Levy, 2006;Horvath & Ryan, 2003 for notable exceptions). More often, Weiner""s attributional theory of stigma (Weiner, 1993(Weiner, , 1995(Weiner, , 1996Weiner, Perry, & Magnusson, 1988) has been invoked to interpret the causal relationships between attitudes and beliefs that could have led to such correlations. Attribution theory predicts that when a non-stigmatised person encounters a stigmatised individual or group that the nonstigmatised judge considers possible attributions for the existence of the stigma. When the stigma is attributed to factors beyond personal control, positive emotions, such as pity, result. However, when the stigma is attributed to factors under the control of the stigmatised target, negative emotions, such as anger, are elicited."	4	"With few exceptions (e.g., Hegarty, 2002;Hegarty & Pratto, 2001;Herek & Capitanio, 1995), social psychologists who have studied structural relationships between biological beliefs and attitudes to lesbians and gay men have tended to interpret those findings as evidence of causal effects of beliefs on attitudes. However, only rarely have authors conducted mediation analyses or verified structural equation models that support those interpretations (see #CITATION_TAG & Levy, 2006;Horvath & Ryan, 2003 for notable exceptions). More often, Weiner""s attributional theory of stigma (Weiner, 1993(Weiner, , 1995(Weiner, , 1996Weiner, Perry, & Magnusson, 1988) has been invoked to interpret the causal relationships between attitudes and beliefs that could have led to such correlations. Attribution theory predicts that when a non-stigmatised person encounters a stigmatised individual or group that the nonstigmatised judge considers possible attributions for the existence of the stigma. When the stigma is attributed to factors beyond personal control, positive emotions, such as pity, result."	o
CCT196	"Although belief in the biological determination of sexual orientation is correlated with tolerance towards lesbians and gay men, beliefs in biological determination are also correlated with prejudice and stereotyping of other minority groups (c.f., Bastian & Haslam, 2006;Keller, 2005;Martin & Parker, 1995;Morton, Postmes, Haslam, & Hornsey, 2009;#CITATION_TAG & Miller, 2007;Williams & Eberhardt, 2008;Yzerbyt, Rocher, & Schadron, 1997). This pattern of results has led researchers to wonder if sexual prejudice is a ""special case"" in this literature (e.g., D.J. Bem, 1998;Haslam et al., 2002;Jayaratne et al., 2006). However, as Prentice and Miller (2007) note, studies of essentialism and sexual prejudice in the domain of sexual orientation typically examine the belief in the idea that sexual orientation is itself an ""essential"" reality, whereas discussions of essentialism and ethnic prejudice typically refer to belief in the reality of stereotypes linking category membership with other traits. Heterosexual people who consider sexual orientation to be genetic are often less prejudiced. However, heterosexual people who consider that there is a gene that ties homosexuality to disease might not be. Ironically, genetic research on sexual orientation that has been widely announced as pro-gay research also aimed to determine a genetic link between homosexuality and alcoholism (c.f., Hamer & Copeland, 1994). Because of these implications of biological determinism, it is important to consider whether attribution theory""s claim that attributions affect attitudes has empirical support."	4	"Although belief in the biological determination of sexual orientation is correlated with tolerance towards lesbians and gay men, beliefs in biological determination are also correlated with prejudice and stereotyping of other minority groups (c.f., Bastian & Haslam, 2006;Keller, 2005;Martin & Parker, 1995;Morton, Postmes, Haslam, & Hornsey, 2009;#CITATION_TAG & Miller, 2007;Williams & Eberhardt, 2008;Yzerbyt, Rocher, & Schadron, 1997). This pattern of results has led researchers to wonder if sexual prejudice is a ""special case"" in this literature (e.g., D.J. Bem, 1998;Haslam et al., 2002;Jayaratne et al., 2006). However, as Prentice and Miller (2007) note, studies of essentialism and sexual prejudice in the domain of sexual orientation typically examine the belief in the idea that sexual orientation is itself an ""essential"" reality, whereas discussions of essentialism and ethnic prejudice typically refer to belief in the reality of stereotypes linking category membership with other traits. Heterosexual people who consider sexual orientation to be genetic are often less prejudiced."	A
CCT197	"With few exceptions (e.g., #CITATION_TAG, 2002;Hegarty & Pratto, 2001;Herek & Capitanio, 1995), social psychologists who have studied structural relationships between biological beliefs and attitudes to lesbians and gay men have tended to interpret those findings as evidence of causal effects of beliefs on attitudes. However, only rarely have authors conducted mediation analyses or verified structural equation models that support those interpretations (see Haslam & Levy, 2006;Horvath & Ryan, 2003 for notable exceptions). More often, Weiner""s attributional theory of stigma (Weiner, 1993(Weiner, , 1995(Weiner, , 1996Weiner, Perry, & Magnusson, 1988) has been invoked to interpret the causal relationships between attitudes and beliefs that could have led to such correlations. Attribution theory predicts that when a non-stigmatised person encounters a stigmatised individual or group that the nonstigmatised judge considers possible attributions for the existence of the stigma. When the stigma is attributed to factors beyond personal control, positive emotions, such as pity, result. However, when the stigma is attributed to factors under the control of the stigmatised target, negative emotions, such as anger, are elicited."	4	"With few exceptions (e.g., #CITATION_TAG, 2002;Hegarty & Pratto, 2001;Herek & Capitanio, 1995), social psychologists who have studied structural relationships between biological beliefs and attitudes to lesbians and gay men have tended to interpret those findings as evidence of causal effects of beliefs on attitudes. However, only rarely have authors conducted mediation analyses or verified structural equation models that support those interpretations (see Haslam & Levy, 2006;Horvath & Ryan, 2003 for notable exceptions). More often, Weiner""s attributional theory of stigma (Weiner, 1993(Weiner, , 1995(Weiner, , 1996Weiner, Perry, & Magnusson, 1988) has been invoked to interpret the causal relationships between attitudes and beliefs that could have led to such correlations. Attribution theory predicts that when a non-stigmatised person encounters a stigmatised individual or group that the nonstigmatised judge considers possible attributions for the existence of the stigma."	W
CCT198	). We have indicated here that flavour effects [19][20][21][22][23]#CITATION_TAG might play a role, i.e., Œµ Œ± i describes the decay of the heavy neutrino of mass M i into leptons of flavour Œ± = e, Œº, œÑ . In the case when the lowest-mass heavy neutrino is much lighter than the other two, i.e., M 1 M 2,3 , the lepton asymmetry is dominated by the decay of this lightest neutrino and f (M 2 j /M 2 1 ) ‚àí3M 1 /M j . We have omitted additional terms in Œµ Œ± i which vanish when summed over flavours and which are suppressed by an additional power of M 1 /M j when neutrinos are hierarchical. The sum over flavours reads	0	). We have indicated here that flavour effects [19][20][21][22][23]#CITATION_TAG might play a role, i.e., Œµ Œ± i describes the decay of the heavy neutrino of mass M i into leptons of flavour Œ± = e, Œº, œÑ . In the case when the lowest-mass heavy neutrino is much lighter than the other two, i.e., M 1 M 2,3 , the lepton asymmetry is dominated by the decay of this lightest neutrino and f (M 2 j /M 2 1 ) ‚àí3M 1 /M j We have omitted additional terms in Œµ Œ± i which vanish when summed over flavours and which are suppressed by an additional power of M 1 /M j when neutrinos are hierarchical. The sum over flavours reads	e
CCT199	"reduced knee joint range of motion (ROM) together with catching/locking of the knee. Non-traumatic tears (NTT) are typically observed in the middle-aged (35-55 years) and older population. These tears are associated with meniscal calcification 18 and risk factors for these tears include, presence of Heberdens""s and Bouchard nodes, knee malalignment and occupational kneeling ; however, the aetiology is largely unclear. 2][23] Evidence from four well-designed trials demonstrated that arthroscopic interventions 10 24 and meniscectomy [25][26]#CITATION_TAG were no better or provided no additional effect, than the comparator (ie, sham surgery, physical therapy or a combination of physical and medical therapy) to relieve pain and improve function in the middle-aged patients with knee OA or early signs of knee OA. No corresponding randomised trials exist specifically for TT but an observational study showed that patients with degenerative meniscus lesions (ie, NTT) self-report worse function and QOL compared to individuals with TT at follow-up 14 years after meniscectomy. 28 Thus, it is conceivable, but currently unproven, that arthroscopic meniscus surgery is more effective in resolving symptoms of a meniscus tear of traumatic aetiology compared with non-NTT in the middle-aged population."	0	"reduced knee joint range of motion (ROM) together with catching/locking of the knee. Non-traumatic tears (NTT) are typically observed in the middle-aged (35-55 years) and older population. These tears are associated with meniscal calcification 18 and risk factors for these tears include, presence of Heberdens""s and Bouchard nodes, knee malalignment and occupational kneeling ; however, the aetiology is largely unclear. 2][23] Evidence from four well-designed trials demonstrated that arthroscopic interventions 10 24 and meniscectomy [25][26]#CITATION_TAG were no better or provided no additional effect, than the comparator (ie, sham surgery, physical therapy or a combination of physical and medical therapy) to relieve pain and improve function in the middle-aged patients with knee OA or early signs of knee OA. No corresponding randomised trials exist specifically for TT but an observational study showed that patients with degenerative meniscus lesions (ie, NTT) self-report worse function and QOL compared to individuals with TT at follow-up 14 years after meniscectomy. 28 Thus, it is conceivable, but currently unproven, that arthroscopic meniscus surgery is more effective in resolving symptoms of a meniscus tear of traumatic aetiology compared with non-NTT in the middle-aged population."	2
CCT200	"Meniscus surgery is a high-volume surgery carried out on 1 million patients annually in the USA. 1 The procedure is conducted on an outpatient basis and patients leave the hospital few hours after surgery. Nevertheless, little is known about the natural time course of patient perceived pain, function and quality of life (QOL) after meniscus surgery and which factors affect these outcomes. #CITATION_TAG 7][8] One explanation for the poor selfreported outcomes may be that the loss of meniscal function triggers other events that may cause knee pain. Complicating the assessment of surgery effectiveness further, surgical procedures have shown to be associated with considerable ""placebo effect"". 10 11 critical limitation of previous studies [12][13][14][15] is their failure to account for the type of symptom onset (ie, injury mechanism). Meniscus tears can be categorised as either traumatic or non-traumatic. Traumatic tears (TT) are usually observed in younger, active individuals in an otherwise ""healthy"" meniscus and joint, and can be attributed to a specific incident (eg, sports-related trauma). TT""s are often associated with joint effusion,"	0	"Meniscus surgery is a high-volume surgery carried out on 1 million patients annually in the USA. 1 The procedure is conducted on an outpatient basis and patients leave the hospital few hours after surgery. Nevertheless, little is known about the natural time course of patient perceived pain, function and quality of life (QOL) after meniscus surgery and which factors affect these outcomes. #CITATION_TAG 7][8] One explanation for the poor selfreported outcomes may be that the loss of meniscal function triggers other events that may cause knee pain. Complicating the assessment of surgery effectiveness further, surgical procedures have shown to be associated with considerable ""placebo effect"". 10 11 critical limitation of previous studies [12][13][14][15] is their failure to account for the type of symptom onset (ie, injury mechanism). Meniscus tears can be categorised as either traumatic or non-traumatic."	T
CCT201	"reduced knee joint range of motion (ROM) together with catching/locking of the knee. Non-traumatic tears (NTT) are typically observed in the middle-aged (35-55 years) and older population. These tears are associated with meniscal calcification 18 and risk factors for these tears include, presence of Heberdens""s and Bouchard nodes, knee malalignment and occupational kneeling ; however, the aetiology is largely unclear. 2][23] Evidence from four well-designed trials demonstrated that arthroscopic interventions 10 24 and meniscectomy #CITATION_TAG[26][27] were no better or provided no additional effect, than the comparator (ie, sham surgery, physical therapy or a combination of physical and medical therapy) to relieve pain and improve function in the middle-aged patients with knee OA or early signs of knee OA. No corresponding randomised trials exist specifically for TT but an observational study showed that patients with degenerative meniscus lesions (ie, NTT) self-report worse function and QOL compared to individuals with TT at follow-up 14 years after meniscectomy. 28 Thus, it is conceivable, but currently unproven, that arthroscopic meniscus surgery is more effective in resolving symptoms of a meniscus tear of traumatic aetiology compared with non-NTT in the middle-aged population."	0	"reduced knee joint range of motion (ROM) together with catching/locking of the knee. Non-traumatic tears (NTT) are typically observed in the middle-aged (35-55 years) and older population. These tears are associated with meniscal calcification 18 and risk factors for these tears include, presence of Heberdens""s and Bouchard nodes, knee malalignment and occupational kneeling ; however, the aetiology is largely unclear. 2][23] Evidence from four well-designed trials demonstrated that arthroscopic interventions 10 24 and meniscectomy #CITATION_TAG[26][27] were no better or provided no additional effect, than the comparator (ie, sham surgery, physical therapy or a combination of physical and medical therapy) to relieve pain and improve function in the middle-aged patients with knee OA or early signs of knee OA. No corresponding randomised trials exist specifically for TT but an observational study showed that patients with degenerative meniscus lesions (ie, NTT) self-report worse function and QOL compared to individuals with TT at follow-up 14 years after meniscectomy. 28 Thus, it is conceivable, but currently unproven, that arthroscopic meniscus surgery is more effective in resolving symptoms of a meniscus tear of traumatic aetiology compared with non-NTT in the middle-aged population."	2
CCT202	"reduced knee joint range of motion (ROM) together with catching/locking of the knee. Non-traumatic tears (NTT) are typically observed in the middle-aged (35-55 years) and older population. These tears are associated with meniscal calcification 18 and risk factors for these tears include, presence of Heberdens""s and Bouchard nodes, knee malalignment and occupational kneeling ; however, the aetiology is largely unclear. 2][23] Evidence from four well-designed trials demonstrated that arthroscopic interventions 10 24 and meniscectomy [25]#CITATION_TAG[27] were no better or provided no additional effect, than the comparator (ie, sham surgery, physical therapy or a combination of physical and medical therapy) to relieve pain and improve function in the middle-aged patients with knee OA or early signs of knee OA. No corresponding randomised trials exist specifically for TT but an observational study showed that patients with degenerative meniscus lesions (ie, NTT) self-report worse function and QOL compared to individuals with TT at follow-up 14 years after meniscectomy. 28 Thus, it is conceivable, but currently unproven, that arthroscopic meniscus surgery is more effective in resolving symptoms of a meniscus tear of traumatic aetiology compared with non-NTT in the middle-aged population."	0	"reduced knee joint range of motion (ROM) together with catching/locking of the knee. Non-traumatic tears (NTT) are typically observed in the middle-aged (35-55 years) and older population. These tears are associated with meniscal calcification 18 and risk factors for these tears include, presence of Heberdens""s and Bouchard nodes, knee malalignment and occupational kneeling ; however, the aetiology is largely unclear. 2][23] Evidence from four well-designed trials demonstrated that arthroscopic interventions 10 24 and meniscectomy [25]#CITATION_TAG[27] were no better or provided no additional effect, than the comparator (ie, sham surgery, physical therapy or a combination of physical and medical therapy) to relieve pain and improve function in the middle-aged patients with knee OA or early signs of knee OA. No corresponding randomised trials exist specifically for TT but an observational study showed that patients with degenerative meniscus lesions (ie, NTT) self-report worse function and QOL compared to individuals with TT at follow-up 14 years after meniscectomy. 28 Thus, it is conceivable, but currently unproven, that arthroscopic meniscus surgery is more effective in resolving symptoms of a meniscus tear of traumatic aetiology compared with non-NTT in the middle-aged population."	2
CCT203	"Meniscus surgery is a high-volume surgery carried out on 1 million patients annually in the USA. 1 The procedure is conducted on an outpatient basis and patients leave the hospital few hours after surgery. Nevertheless, little is known about the natural time course of patient perceived pain, function and quality of life (QOL) after meniscus surgery and which factors affect these outcomes. 2 7][8] One explanation for the poor selfreported outcomes may be that the loss of meniscal function triggers other events that may cause knee pain. Complicating the assessment of surgery effectiveness further, surgical procedures have shown to be associated with considerable ""placebo effect"". 10 11 critical limitation of previous studies [12][13][14]#CITATION_TAG is their failure to account for the type of symptom onset (ie, injury mechanism). Meniscus tears can be categorised as either traumatic or non-traumatic. Traumatic tears (TT) are usually observed in younger, active individuals in an otherwise ""healthy"" meniscus and joint, and can be attributed to a specific incident (eg, sports-related trauma). TT""s are often associated with joint effusion,"	1	"Nevertheless, little is known about the natural time course of patient perceived pain, function and quality of life (QOL) after meniscus surgery and which factors affect these outcomes. 2 7][8] One explanation for the poor selfreported outcomes may be that the loss of meniscal function triggers other events that may cause knee pain. Complicating the assessment of surgery effectiveness further, surgical procedures have shown to be associated with considerable ""placebo effect"". 10 11 critical limitation of previous studies [12][13][14]#CITATION_TAG is their failure to account for the type of symptom onset (ie, injury mechanism). Meniscus tears can be categorised as either traumatic or non-traumatic. Traumatic tears (TT) are usually observed in younger, active individuals in an otherwise ""healthy"" meniscus and joint, and can be attributed to a specific incident (eg, sports-related trauma). TT""s are often associated with joint effusion,"	 
CCT204	#CITATION_TAG[4][5] More importantly, however, recent studies have shown substantial patient-reported disability and pain in patients up to 4 years after surgery	0	#CITATION_TAG[4][5] More importantly, however, recent studies have shown substantial patient-reported disability and pain in patients up to 4 years after surgery	#
CCT205	[3]#CITATION_TAG[5] More importantly, however, recent studies have shown substantial patient-reported disability and pain in patients up to 4 years after surgery	0	[3]#CITATION_TAG[5] More importantly, however, recent studies have shown substantial patient-reported disability and pain in patients up to 4 years after surgery	[
CCT206	[3][4]#CITATION_TAG More importantly, however, recent studies have shown substantial patient-reported disability and pain in patients up to 4 years after surgery	0	[3][4]#CITATION_TAG More importantly, however, recent studies have shown substantial patient-reported disability and pain in patients up to 4 years after surgery	[
CCT207	[6]#CITATION_TAG[8] One explanation for the poor selfreported outcomes may be that the loss of meniscal function triggers other events that may cause knee pain	0	[6]#CITATION_TAG[8] One explanation for the poor selfreported outcomes may be that the loss of meniscal function triggers other events that may cause knee pain	[
CCT208	"Meniscus surgery is a high-volume surgery carried out on 1 million patients annually in the USA. 1 The procedure is conducted on an outpatient basis and patients leave the hospital few hours after surgery. Nevertheless, little is known about the natural time course of patient perceived pain, function and quality of life (QOL) after meniscus surgery and which factors affect these outcomes. 2 7]#CITATION_TAG One explanation for the poor selfreported outcomes may be that the loss of meniscal function triggers other events that may cause knee pain. Complicating the assessment of surgery effectiveness further, surgical procedures have shown to be associated with considerable ""placebo effect"". 10 11 critical limitation of previous studies [12][13][14][15] is their failure to account for the type of symptom onset (ie, injury mechanism). Meniscus tears can be categorised as either traumatic or non-traumatic. Traumatic tears (TT) are usually observed in younger, active individuals in an otherwise ""healthy"" meniscus and joint, and can be attributed to a specific incident (eg, sports-related trauma). TT""s are often associated with joint effusion,"	0	"Meniscus surgery is a high-volume surgery carried out on 1 million patients annually in the USA. 1 The procedure is conducted on an outpatient basis and patients leave the hospital few hours after surgery. Nevertheless, little is known about the natural time course of patient perceived pain, function and quality of life (QOL) after meniscus surgery and which factors affect these outcomes. 2 7]#CITATION_TAG One explanation for the poor selfreported outcomes may be that the loss of meniscal function triggers other events that may cause knee pain. Complicating the assessment of surgery effectiveness further, surgical procedures have shown to be associated with considerable ""placebo effect"". 10 11 critical limitation of previous studies [12][13][14][15] is their failure to account for the type of symptom onset (ie, injury mechanism). Meniscus tears can be categorised as either traumatic or non-traumatic."	]
CCT209	#CITATION_TAG[7][8] One explanation for the poor selfreported outcomes may be that the loss of meniscal function triggers other events that may cause knee pain	0	#CITATION_TAG[7][8] One explanation for the poor selfreported outcomes may be that the loss of meniscal function triggers other events that may cause knee pain	#
CCT210	Arthroscopic meniscus surgery is a high-volume surgery. 1 Little is known about the natural time course of PROs after meniscus surgery and which factors affect these outcomes. This prospective cohort will collect data from a large number of patients on the natural time course of PROs prior and following arthroscopic meniscus surgery. Our results will enable analysis of the dependence of postsurgery outcome on the type of meniscus tear (ie, TT vs NTT in middle-aged patients). Further, it will be possible to investigate the dependence of postsurgery outcome on the type of surgery in the subgroup of patients with TT (ie, TT RES vs TT REP ). In contrast, other on-going randomised placebo controlled trials are investigating the effect of meniscus surgery for patients with degenerative tears. 45 46 this study a pragmatic clinical approach was chosen to categorise meniscus tears as either TT or NTT (ie, degenerative). The advantages of this approach are that it is simple, cheap, can be determined prior to surgery (in contrast to histology or arthroscopic observation) and feasible in a routine clinical setting. Thus, this information can be used to form an algorithm based on information available prior to surgery to select those patients who benefit most from surgery, which can be implemented in clinical practice. The definition of TT and NTT are similar but not identical to what has previously been used in other studies. Camanho et al 12 divided the patients into three groups; traumatic, degenerative and fatigue. In the present study the NTT group will include degenerative as well as fatigue as defined by Camanho et al as the focus of this study is on the traumatic versus non-traumatic initiation of the meniscal tear. Others have based their definition on sports participation. #CITATION_TAG limitation to this study is that patients are included based on the main reason for surgery (ie, suspicion of a meniscus tear). However, meniscus surgery may also be performed in relation to surgery for other knee pathologies. Those patients will not be included in the KACS. This should be taken into account when interpreting the cohort data. On the other hand, this makes it more likely that patient symptoms in the KACS cohort are primarily caused by the meniscus injury. Furthermore, we expect the age to be different in the TT compared with the NTT groups (ie, NTT group being older), thus all statistical analysis will be adjusted for age. Nevertheless, this should still be taken into consideration when interpreting the results.	1	Camanho et al 12 divided the patients into three groups; traumatic, degenerative and fatigue. In the present study the NTT group will include degenerative as well as fatigue as defined by Camanho et al as the focus of this study is on the traumatic versus non-traumatic initiation of the meniscal tear. Others have based their definition on sports participation. #CITATION_TAG limitation to this study is that patients are included based on the main reason for surgery (ie, suspicion of a meniscus tear). However, meniscus surgery may also be performed in relation to surgery for other knee pathologies. Those patients will not be included in the KACS. This should be taken into account when interpreting the cohort data.	 
CCT211	"Meniscus surgery is a high-volume surgery carried out on 1 million patients annually in the USA. 1 The procedure is conducted on an outpatient basis and patients leave the hospital few hours after surgery. Nevertheless, little is known about the natural time course of patient perceived pain, function and quality of life (QOL) after meniscus surgery and which factors affect these outcomes. 2 7][8] One explanation for the poor selfreported outcomes may be that the loss of meniscal function triggers other events that may cause knee pain. Complicating the assessment of surgery effectiveness further, surgical procedures have shown to be associated with considerable ""placebo effect"". 10 11 critical limitation of previous studies [12][13]#CITATION_TAG[15] is their failure to account for the type of symptom onset (ie, injury mechanism). Meniscus tears can be categorised as either traumatic or non-traumatic. Traumatic tears (TT) are usually observed in younger, active individuals in an otherwise ""healthy"" meniscus and joint, and can be attributed to a specific incident (eg, sports-related trauma). TT""s are often associated with joint effusion,"	1	"Nevertheless, little is known about the natural time course of patient perceived pain, function and quality of life (QOL) after meniscus surgery and which factors affect these outcomes. 2 7][8] One explanation for the poor selfreported outcomes may be that the loss of meniscal function triggers other events that may cause knee pain. Complicating the assessment of surgery effectiveness further, surgical procedures have shown to be associated with considerable ""placebo effect"". 10 11 critical limitation of previous studies [12][13]#CITATION_TAG[15] is their failure to account for the type of symptom onset (ie, injury mechanism). Meniscus tears can be categorised as either traumatic or non-traumatic. Traumatic tears (TT) are usually observed in younger, active individuals in an otherwise ""healthy"" meniscus and joint, and can be attributed to a specific incident (eg, sports-related trauma). TT""s are often associated with joint effusion,"	 
CCT212	"Meniscus surgery is a high-volume surgery carried out on 1 million patients annually in the USA. 1 The procedure is conducted on an outpatient basis and patients leave the hospital few hours after surgery. Nevertheless, little is known about the natural time course of patient perceived pain, function and quality of life (QOL) after meniscus surgery and which factors affect these outcomes. 2 7][8] One explanation for the poor selfreported outcomes may be that the loss of meniscal function triggers other events that may cause knee pain. Complicating the assessment of surgery effectiveness further, surgical procedures have shown to be associated with considerable ""placebo effect"". 10 11 critical limitation of previous studies #CITATION_TAG[13][14][15] is their failure to account for the type of symptom onset (ie, injury mechanism). Meniscus tears can be categorised as either traumatic or non-traumatic. Traumatic tears (TT) are usually observed in younger, active individuals in an otherwise ""healthy"" meniscus and joint, and can be attributed to a specific incident (eg, sports-related trauma). TT""s are often associated with joint effusion,"	1	"Nevertheless, little is known about the natural time course of patient perceived pain, function and quality of life (QOL) after meniscus surgery and which factors affect these outcomes. 2 7][8] One explanation for the poor selfreported outcomes may be that the loss of meniscal function triggers other events that may cause knee pain. Complicating the assessment of surgery effectiveness further, surgical procedures have shown to be associated with considerable ""placebo effect"". 10 11 critical limitation of previous studies #CITATION_TAG[13][14][15] is their failure to account for the type of symptom onset (ie, injury mechanism). Meniscus tears can be categorised as either traumatic or non-traumatic. Traumatic tears (TT) are usually observed in younger, active individuals in an otherwise ""healthy"" meniscus and joint, and can be attributed to a specific incident (eg, sports-related trauma). TT""s are often associated with joint effusion,"	 
CCT213	"Meniscus surgery is a high-volume surgery carried out on 1 million patients annually in the USA. 1 The procedure is conducted on an outpatient basis and patients leave the hospital few hours after surgery. Nevertheless, little is known about the natural time course of patient perceived pain, function and quality of life (QOL) after meniscus surgery and which factors affect these outcomes. 2 7][8] One explanation for the poor selfreported outcomes may be that the loss of meniscal function triggers other events that may cause knee pain. Complicating the assessment of surgery effectiveness further, surgical procedures have shown to be associated with considerable ""placebo effect"". 10 11 critical limitation of previous studies [12]#CITATION_TAG[14][15] is their failure to account for the type of symptom onset (ie, injury mechanism). Meniscus tears can be categorised as either traumatic or non-traumatic. Traumatic tears (TT) are usually observed in younger, active individuals in an otherwise ""healthy"" meniscus and joint, and can be attributed to a specific incident (eg, sports-related trauma). TT""s are often associated with joint effusion,"	1	"Nevertheless, little is known about the natural time course of patient perceived pain, function and quality of life (QOL) after meniscus surgery and which factors affect these outcomes. 2 7][8] One explanation for the poor selfreported outcomes may be that the loss of meniscal function triggers other events that may cause knee pain. Complicating the assessment of surgery effectiveness further, surgical procedures have shown to be associated with considerable ""placebo effect"". 10 11 critical limitation of previous studies [12]#CITATION_TAG[14][15] is their failure to account for the type of symptom onset (ie, injury mechanism). Meniscus tears can be categorised as either traumatic or non-traumatic. Traumatic tears (TT) are usually observed in younger, active individuals in an otherwise ""healthy"" meniscus and joint, and can be attributed to a specific incident (eg, sports-related trauma). TT""s are often associated with joint effusion,"	 
CCT214	Approximately 100 fish species are in the West-central Mexico, 70% of which are endemic and one of the most representative endemic fish groups of this region is the subfamily Goodeinae [5]. The group presents high species richness in a small area (c. 41 species) and unique characteristics associated with breeding strategies and embryo development, such as internal fertilization, matrotrophy, and sexual selection #CITATION_TAG[10][11][12][13]. The family presents a high diversification apparently influenced by viviparity, with vicariance and adaptive radiation being the most important factors. The speciation rate of goodeids has not been constant and has been impacted by multiple extinctions, estimating that at least 25 000 years is required to establish an evolutionary lineage [14].	0	Approximately 100 fish species are in the West-central Mexico, 70% of which are endemic and one of the most representative endemic fish groups of this region is the subfamily Goodeinae [5]. The group presents high species richness in a small area (c. 41 species) and unique characteristics associated with breeding strategies and embryo development, such as internal fertilization, matrotrophy, and sexual selection #CITATION_TAG[10][11][12][13]. The family presents a high diversification apparently influenced by viviparity, with vicariance and adaptive radiation being the most important factors. The speciation rate of goodeids has not been constant and has been impacted by multiple extinctions, estimating that at least 25 000 years is required to establish an evolutionary lineage [14].	 
CCT215	"The region in West-central Mexico, particularly between the Lerma-Santiago and Balsas rivers, is characterized by varied and rugged physiography, a product of intense tectonic and volcanic activity in the area since the Miocene #CITATION_TAG. Also, this region is an area with a long cultural history, with the P""urh√©pecha settlement developing one of the most stable empires at least years ago [6], particularly due to the richness and abundance of lacustrine resources. The main resources currently exploited by settlements around the lakes are fish, as well as turtles, salamanders, clams, and wetland plants [7,8]. Even the area was formerly known by the N√°huatl culture as Mechuacan, ""a place of fishermen,"" and is currently called Michoac√°n."	0	"The region in West-central Mexico, particularly between the Lerma-Santiago and Balsas rivers, is characterized by varied and rugged physiography, a product of intense tectonic and volcanic activity in the area since the Miocene #CITATION_TAG. Also, this region is an area with a long cultural history, with the P""urh√©pecha settlement developing one of the most stable empires at least years ago [6], particularly due to the richness and abundance of lacustrine resources. The main resources currently exploited by settlements around the lakes are fish, as well as turtles, salamanders, clams, and wetland plants [7,8]. Even the area was formerly known by the N√°huatl culture as Mechuacan, ""a place of fishermen,"" and is currently called Michoac√°n."	T
CCT216	The genus Allotoca is the most diverse within the Goodeinae, and is the subject of taxonomic controversy, with the need for taxonomic revision to validate species [9,10,#CITATION_TAG[16][17]. The A. diazi complex comprises three recognized species [5]: Allotoca diazi [18], endemic to P√°tzcuaro basin, A. meeki [16], endemic in the Zirahu√©n basin, and Allotoca catarinae [15], restricted to the Cupatitzio River, an upper tributary of the Balsas River basin (Fig 1). Allotoca diazi was extirpated from P√°tzcuaro Lake and is currently restricted to the Chapultepec Spring, a tributary of P√°tzcuaro Lake, while A. meeki was extirpated from Zirahu√©n Lake and currently restricted to Opopeo Spring, a tributary of the Zirahu√©n Lake [5]. The lakes are located in the Michoac√°n-Guanajuato Corridor, an area of over 1000 volcanic cones active from the Pliocene to the present. To explain the evolution of these three sister species and other co-distributed taxa, two biogeographic hypotheses have been proposed. The first argues the existence of a tributary connecting the Lerma River with Cuitzeo, P√°tzcuaro, and Zirahu√©n lakes [19] around 700 000 years ago [20]. The second hypothesis indicates the existence of a tributary connecting the Cupatitzio River with Zirahu√©n and P√°tzcuaro lakes, reaching Zacapu [21].	0	The genus Allotoca is the most diverse within the Goodeinae, and is the subject of taxonomic controversy, with the need for taxonomic revision to validate species [9,10,#CITATION_TAG[16][17]. The A. diazi complex comprises three recognized species [5]: Allotoca diazi [18], endemic to P√°tzcuaro basin, A. meeki [16], endemic in the Zirahu√©n basin, and Allotoca catarinae [15], restricted to the Cupatitzio River, an upper tributary of the Balsas River basin (Fig 1). Allotoca diazi was extirpated from P√°tzcuaro Lake and is currently restricted to the Chapultepec Spring, a tributary of P√°tzcuaro Lake, while A. meeki was extirpated from Zirahu√©n Lake and currently restricted to Opopeo Spring, a tributary of the Zirahu√©n Lake [5]. The lakes are located in the Michoac√°n-Guanajuato Corridor, an area of over 1000 volcanic cones active from the Pliocene to the present.	T
CCT217	In order to elucidate and analyze the two biogeographic hypotheses about the connections or disconnections between the Zirahu√©n, P√°tzcuaro and Cupatitzio basins, and the possibility of a species translocation, we examined the evolutionary history of Allotoca diazi complex using two different molecular markers described for the Goodeinae Subfamily [9,#CITATION_TAG,26]: a conserved molecular marker of mitochondrial DNA (Cytochrome b, Cytb gene) and a less conserved microsatellite nuclear markers. We obtained these molecular markers to explore the genetic differentiation at intraspecific and interspecific level applying phylogeographic and phylogenetic approaches. The results of the genetic study were analyzed based on geological, paleoclimatic and anthropogenic records from central Mexico to access how natural and artificial historical processes are involved in the evolutionary history of A. diazi complex. In addition, we used all the genetic information and ecological niche predictions for identify operational conservation units.	5	In order to elucidate and analyze the two biogeographic hypotheses about the connections or disconnections between the Zirahu√©n, P√°tzcuaro and Cupatitzio basins, and the possibility of a species translocation, we examined the evolutionary history of Allotoca diazi complex using two different molecular markers described for the Goodeinae Subfamily [9,#CITATION_TAG,26]: a conserved molecular marker of mitochondrial DNA (Cytochrome b, Cytb gene) and a less conserved microsatellite nuclear markers. We obtained these molecular markers to explore the genetic differentiation at intraspecific and interspecific level applying phylogeographic and phylogenetic approaches. The results of the genetic study were analyzed based on geological, paleoclimatic and anthropogenic records from central Mexico to access how natural and artificial historical processes are involved in the evolutionary history of A. diazi complex. In addition, we used all the genetic information and ecological niche predictions for identify operational conservation units.	I
CCT218	"We estimated that the isolation of A. diazi from A. meeki occurred in the past 400-7000 years, which is consistent with geological, climatic, and anthropogenic events involving P√°tzcuaro and Zirahu√©n lakes. Tecto-volcanic events giving rise to the separation of P√°tzcuaro and Zirahu√©n lakes began 8000 years ago with the formation and activity of the La Tasa volcano southwest of Lake P√°tzcuaro and climate fluctuations causing decline in water level and drying of streams [21,[90][91][92][93]. Fluctuations in the level of Lake P√°tzcuaro during the Holocene associated with climate change, human activity [90,91,[#CITATION_TAG][95][96][97][98][99], and occurrence of tsunamis [100] could be involved to the isolation and demographics changes of A. diazi and A. meeki. These demographic changes were reflected in genetic diversity including the positive D T value, which was found to be low in A. diazi, and associated with recent bottlenecks that promoted inbreeding (F IS = 0.141), reduced heterozygosity, and the loss of allelic richness. In contrast, a bottleneck identified in A. meeki is attributed to the rapid loss of allelic diversity; however, the R ST value and the BSP analysis (in the HPD range) indicates that the bottleneck detected by IAM were overestimated. The population dynamics of A. meeki can be explained by the variations in nucleotide diversity and proportion of segregating sites (œÄ < Œòs), which is interpreted as a recent population reduction followed by expansion, as demonstrated by the estimated value of D T = -0.86 and non-significant positive values of Fu""s FS estimates [101][102][103]."	1	"We estimated that the isolation of A. diazi from A. meeki occurred in the past 400-7000 years, which is consistent with geological, climatic, and anthropogenic events involving P√°tzcuaro and Zirahu√©n lakes. Tecto-volcanic events giving rise to the separation of P√°tzcuaro and Zirahu√©n lakes began 8000 years ago with the formation and activity of the La Tasa volcano southwest of Lake P√°tzcuaro and climate fluctuations causing decline in water level and drying of streams [21,[90][91][92][93]. Fluctuations in the level of Lake P√°tzcuaro during the Holocene associated with climate change, human activity [90,91,[#CITATION_TAG][95][96][97][98][99], and occurrence of tsunamis [100] could be involved to the isolation and demographics changes of A. diazi and A. meeki. These demographic changes were reflected in genetic diversity including the positive D T value, which was found to be low in A. diazi, and associated with recent bottlenecks that promoted inbreeding (F IS = 0.141), reduced heterozygosity, and the loss of allelic richness. In contrast, a bottleneck identified in A. meeki is attributed to the rapid loss of allelic diversity; however, the R ST value and the BSP analysis (in the HPD range) indicates that the bottleneck detected by IAM were overestimated. The population dynamics of A. meeki can be explained by the variations in nucleotide diversity and proportion of segregating sites (œÄ < Œòs), which is interpreted as a recent population reduction followed by expansion, as demonstrated by the estimated value of D T = -0.86 and non-significant positive values of Fu""s FS estimates [101][102][103]."	u
CCT219	The genus Allotoca is the most diverse within the Goodeinae, and is the subject of taxonomic controversy, with the need for taxonomic revision to validate species [9,10,[15][16][17]. The A. diazi complex comprises three recognized species [5]: Allotoca diazi [18], endemic to P√°tzcuaro basin, A. meeki [16], endemic in the Zirahu√©n basin, and Allotoca catarinae [15], restricted to the Cupatitzio River, an upper tributary of the Balsas River basin (Fig 1). Allotoca diazi was extirpated from P√°tzcuaro Lake and is currently restricted to the Chapultepec Spring, a tributary of P√°tzcuaro Lake, while A. meeki was extirpated from Zirahu√©n Lake and currently restricted to Opopeo Spring, a tributary of the Zirahu√©n Lake [5]. The lakes are located in the Michoac√°n-Guanajuato Corridor, an area of over 1000 volcanic cones active from the Pliocene to the present. To explain the evolution of these three sister species and other co-distributed taxa, two biogeographic hypotheses have been proposed. The first argues the existence of a tributary connecting the Lerma River with Cuitzeo, P√°tzcuaro, and Zirahu√©n lakes #CITATION_TAG around 700 000 years ago [20]. The second hypothesis indicates the existence of a tributary connecting the Cupatitzio River with Zirahu√©n and P√°tzcuaro lakes, reaching Zacapu [21].	0	Allotoca diazi was extirpated from P√°tzcuaro Lake and is currently restricted to the Chapultepec Spring, a tributary of P√°tzcuaro Lake, while A. meeki was extirpated from Zirahu√©n Lake and currently restricted to Opopeo Spring, a tributary of the Zirahu√©n Lake [5]. The lakes are located in the Michoac√°n-Guanajuato Corridor, an area of over 1000 volcanic cones active from the Pliocene to the present. To explain the evolution of these three sister species and other co-distributed taxa, two biogeographic hypotheses have been proposed. The first argues the existence of a tributary connecting the Lerma River with Cuitzeo, P√°tzcuaro, and Zirahu√©n lakes #CITATION_TAG around 700 000 years ago [20]. The second hypothesis indicates the existence of a tributary connecting the Cupatitzio River with Zirahu√©n and P√°tzcuaro lakes, reaching Zacapu [21].	i
CCT220	In order to elucidate and analyze the two biogeographic hypotheses about the connections or disconnections between the Zirahu√©n, P√°tzcuaro and Cupatitzio basins, and the possibility of a species translocation, we examined the evolutionary history of Allotoca diazi complex using two different molecular markers described for the Goodeinae Subfamily [9,25,#CITATION_TAG]: a conserved molecular marker of mitochondrial DNA (Cytochrome b, Cytb gene) and a less conserved microsatellite nuclear markers. We obtained these molecular markers to explore the genetic differentiation at intraspecific and interspecific level applying phylogeographic and phylogenetic approaches. The results of the genetic study were analyzed based on geological, paleoclimatic and anthropogenic records from central Mexico to access how natural and artificial historical processes are involved in the evolutionary history of A. diazi complex. In addition, we used all the genetic information and ecological niche predictions for identify operational conservation units.	5	In order to elucidate and analyze the two biogeographic hypotheses about the connections or disconnections between the Zirahu√©n, P√°tzcuaro and Cupatitzio basins, and the possibility of a species translocation, we examined the evolutionary history of Allotoca diazi complex using two different molecular markers described for the Goodeinae Subfamily [9,25,#CITATION_TAG]: a conserved molecular marker of mitochondrial DNA (Cytochrome b, Cytb gene) and a less conserved microsatellite nuclear markers. We obtained these molecular markers to explore the genetic differentiation at intraspecific and interspecific level applying phylogeographic and phylogenetic approaches. The results of the genetic study were analyzed based on geological, paleoclimatic and anthropogenic records from central Mexico to access how natural and artificial historical processes are involved in the evolutionary history of A. diazi complex. In addition, we used all the genetic information and ecological niche predictions for identify operational conservation units.	I
CCT221	"We estimated that the isolation of A. diazi from A. meeki occurred in the past 400-7000 years, which is consistent with geological, climatic, and anthropogenic events involving P√°tzcuaro and Zirahu√©n lakes. Tecto-volcanic events giving rise to the separation of P√°tzcuaro and Zirahu√©n lakes began 8000 years ago with the formation and activity of the La Tasa volcano southwest of Lake P√°tzcuaro and climate fluctuations causing decline in water level and drying of streams [21,[90][91][92][93]. Fluctuations in the level of Lake P√°tzcuaro during the Holocene associated with climate change, human activity [90,91,[94]#CITATION_TAG[96][97][98][99], and occurrence of tsunamis [100] could be involved to the isolation and demographics changes of A. diazi and A. meeki. These demographic changes were reflected in genetic diversity including the positive D T value, which was found to be low in A. diazi, and associated with recent bottlenecks that promoted inbreeding (F IS = 0.141), reduced heterozygosity, and the loss of allelic richness. In contrast, a bottleneck identified in A. meeki is attributed to the rapid loss of allelic diversity; however, the R ST value and the BSP analysis (in the HPD range) indicates that the bottleneck detected by IAM were overestimated. The population dynamics of A. meeki can be explained by the variations in nucleotide diversity and proportion of segregating sites (œÄ < Œòs), which is interpreted as a recent population reduction followed by expansion, as demonstrated by the estimated value of D T = -0.86 and non-significant positive values of Fu""s FS estimates [101][102][103]."	0	"We estimated that the isolation of A. diazi from A. meeki occurred in the past 400-7000 years, which is consistent with geological, climatic, and anthropogenic events involving P√°tzcuaro and Zirahu√©n lakes. Tecto-volcanic events giving rise to the separation of P√°tzcuaro and Zirahu√©n lakes began 8000 years ago with the formation and activity of the La Tasa volcano southwest of Lake P√°tzcuaro and climate fluctuations causing decline in water level and drying of streams [21,[90][91][92][93]. Fluctuations in the level of Lake P√°tzcuaro during the Holocene associated with climate change, human activity [90,91,[94]#CITATION_TAG[96][97][98][99], and occurrence of tsunamis [100] could be involved to the isolation and demographics changes of A. diazi and A. meeki. These demographic changes were reflected in genetic diversity including the positive D T value, which was found to be low in A. diazi, and associated with recent bottlenecks that promoted inbreeding (F IS = 0.141), reduced heterozygosity, and the loss of allelic richness. In contrast, a bottleneck identified in A. meeki is attributed to the rapid loss of allelic diversity; however, the R ST value and the BSP analysis (in the HPD range) indicates that the bottleneck detected by IAM were overestimated. The population dynamics of A. meeki can be explained by the variations in nucleotide diversity and proportion of segregating sites (œÄ < Œòs), which is interpreted as a recent population reduction followed by expansion, as demonstrated by the estimated value of D T = -0.86 and non-significant positive values of Fu""s FS estimates [101][102][103]."	u
CCT222	"We estimated that the isolation of A. diazi from A. meeki occurred in the past 400-7000 years, which is consistent with geological, climatic, and anthropogenic events involving P√°tzcuaro and Zirahu√©n lakes. Tecto-volcanic events giving rise to the separation of P√°tzcuaro and Zirahu√©n lakes began 8000 years ago with the formation and activity of the La Tasa volcano southwest of Lake P√°tzcuaro and climate fluctuations causing decline in water level and drying of streams [21,[90][91][92][93]. Fluctuations in the level of Lake P√°tzcuaro during the Holocene associated with climate change, human activity [90,91,[94][95]#CITATION_TAG[97][98][99], and occurrence of tsunamis [100] could be involved to the isolation and demographics changes of A. diazi and A. meeki. These demographic changes were reflected in genetic diversity including the positive D T value, which was found to be low in A. diazi, and associated with recent bottlenecks that promoted inbreeding (F IS = 0.141), reduced heterozygosity, and the loss of allelic richness. In contrast, a bottleneck identified in A. meeki is attributed to the rapid loss of allelic diversity; however, the R ST value and the BSP analysis (in the HPD range) indicates that the bottleneck detected by IAM were overestimated. The population dynamics of A. meeki can be explained by the variations in nucleotide diversity and proportion of segregating sites (œÄ < Œòs), which is interpreted as a recent population reduction followed by expansion, as demonstrated by the estimated value of D T = -0.86 and non-significant positive values of Fu""s FS estimates [101][102][103]."	0	"We estimated that the isolation of A. diazi from A. meeki occurred in the past 400-7000 years, which is consistent with geological, climatic, and anthropogenic events involving P√°tzcuaro and Zirahu√©n lakes. Tecto-volcanic events giving rise to the separation of P√°tzcuaro and Zirahu√©n lakes began 8000 years ago with the formation and activity of the La Tasa volcano southwest of Lake P√°tzcuaro and climate fluctuations causing decline in water level and drying of streams [21,[90][91][92][93]. Fluctuations in the level of Lake P√°tzcuaro during the Holocene associated with climate change, human activity [90,91,[94][95]#CITATION_TAG[97][98][99], and occurrence of tsunamis [100] could be involved to the isolation and demographics changes of A. diazi and A. meeki. These demographic changes were reflected in genetic diversity including the positive D T value, which was found to be low in A. diazi, and associated with recent bottlenecks that promoted inbreeding (F IS = 0.141), reduced heterozygosity, and the loss of allelic richness. In contrast, a bottleneck identified in A. meeki is attributed to the rapid loss of allelic diversity; however, the R ST value and the BSP analysis (in the HPD range) indicates that the bottleneck detected by IAM were overestimated. The population dynamics of A. meeki can be explained by the variations in nucleotide diversity and proportion of segregating sites (œÄ < Œòs), which is interpreted as a recent population reduction followed by expansion, as demonstrated by the estimated value of D T = -0.86 and non-significant positive values of Fu""s FS estimates [101][102][103]."	u
CCT223	"We estimated that the isolation of A. diazi from A. meeki occurred in the past 400-7000 years, which is consistent with geological, climatic, and anthropogenic events involving P√°tzcuaro and Zirahu√©n lakes. Tecto-volcanic events giving rise to the separation of P√°tzcuaro and Zirahu√©n lakes began 8000 years ago with the formation and activity of the La Tasa volcano southwest of Lake P√°tzcuaro and climate fluctuations causing decline in water level and drying of streams [21,[90][91][92][93]. Fluctuations in the level of Lake P√°tzcuaro during the Holocene associated with climate change, human activity [90,91,[94][95][96]#CITATION_TAG[98][99], and occurrence of tsunamis [100] could be involved to the isolation and demographics changes of A. diazi and A. meeki. These demographic changes were reflected in genetic diversity including the positive D T value, which was found to be low in A. diazi, and associated with recent bottlenecks that promoted inbreeding (F IS = 0.141), reduced heterozygosity, and the loss of allelic richness. In contrast, a bottleneck identified in A. meeki is attributed to the rapid loss of allelic diversity; however, the R ST value and the BSP analysis (in the HPD range) indicates that the bottleneck detected by IAM were overestimated. The population dynamics of A. meeki can be explained by the variations in nucleotide diversity and proportion of segregating sites (œÄ < Œòs), which is interpreted as a recent population reduction followed by expansion, as demonstrated by the estimated value of D T = -0.86 and non-significant positive values of Fu""s FS estimates [101][102][103]."	0	"We estimated that the isolation of A. diazi from A. meeki occurred in the past 400-7000 years, which is consistent with geological, climatic, and anthropogenic events involving P√°tzcuaro and Zirahu√©n lakes. Tecto-volcanic events giving rise to the separation of P√°tzcuaro and Zirahu√©n lakes began 8000 years ago with the formation and activity of the La Tasa volcano southwest of Lake P√°tzcuaro and climate fluctuations causing decline in water level and drying of streams [21,[90][91][92][93]. Fluctuations in the level of Lake P√°tzcuaro during the Holocene associated with climate change, human activity [90,91,[94][95][96]#CITATION_TAG[98][99], and occurrence of tsunamis [100] could be involved to the isolation and demographics changes of A. diazi and A. meeki. These demographic changes were reflected in genetic diversity including the positive D T value, which was found to be low in A. diazi, and associated with recent bottlenecks that promoted inbreeding (F IS = 0.141), reduced heterozygosity, and the loss of allelic richness. In contrast, a bottleneck identified in A. meeki is attributed to the rapid loss of allelic diversity; however, the R ST value and the BSP analysis (in the HPD range) indicates that the bottleneck detected by IAM were overestimated. The population dynamics of A. meeki can be explained by the variations in nucleotide diversity and proportion of segregating sites (œÄ < Œòs), which is interpreted as a recent population reduction followed by expansion, as demonstrated by the estimated value of D T = -0.86 and non-significant positive values of Fu""s FS estimates [101][102][103]."	u
CCT224	"We estimated that the isolation of A. diazi from A. meeki occurred in the past 400-7000 years, which is consistent with geological, climatic, and anthropogenic events involving P√°tzcuaro and Zirahu√©n lakes. Tecto-volcanic events giving rise to the separation of P√°tzcuaro and Zirahu√©n lakes began 8000 years ago with the formation and activity of the La Tasa volcano southwest of Lake P√°tzcuaro and climate fluctuations causing decline in water level and drying of streams [21,[90][91][92][93]. Fluctuations in the level of Lake P√°tzcuaro during the Holocene associated with climate change, human activity [90,91,[94][95][96][97]#CITATION_TAG[99], and occurrence of tsunamis [100] could be involved to the isolation and demographics changes of A. diazi and A. meeki. These demographic changes were reflected in genetic diversity including the positive D T value, which was found to be low in A. diazi, and associated with recent bottlenecks that promoted inbreeding (F IS = 0.141), reduced heterozygosity, and the loss of allelic richness. In contrast, a bottleneck identified in A. meeki is attributed to the rapid loss of allelic diversity; however, the R ST value and the BSP analysis (in the HPD range) indicates that the bottleneck detected by IAM were overestimated. The population dynamics of A. meeki can be explained by the variations in nucleotide diversity and proportion of segregating sites (œÄ < Œòs), which is interpreted as a recent population reduction followed by expansion, as demonstrated by the estimated value of D T = -0.86 and non-significant positive values of Fu""s FS estimates [101][102][103]."	0	"We estimated that the isolation of A. diazi from A. meeki occurred in the past 400-7000 years, which is consistent with geological, climatic, and anthropogenic events involving P√°tzcuaro and Zirahu√©n lakes. Tecto-volcanic events giving rise to the separation of P√°tzcuaro and Zirahu√©n lakes began 8000 years ago with the formation and activity of the La Tasa volcano southwest of Lake P√°tzcuaro and climate fluctuations causing decline in water level and drying of streams [21,[90][91][92][93]. Fluctuations in the level of Lake P√°tzcuaro during the Holocene associated with climate change, human activity [90,91,[94][95][96][97]#CITATION_TAG[99], and occurrence of tsunamis [100] could be involved to the isolation and demographics changes of A. diazi and A. meeki. These demographic changes were reflected in genetic diversity including the positive D T value, which was found to be low in A. diazi, and associated with recent bottlenecks that promoted inbreeding (F IS = 0.141), reduced heterozygosity, and the loss of allelic richness. In contrast, a bottleneck identified in A. meeki is attributed to the rapid loss of allelic diversity; however, the R ST value and the BSP analysis (in the HPD range) indicates that the bottleneck detected by IAM were overestimated. The population dynamics of A. meeki can be explained by the variations in nucleotide diversity and proportion of segregating sites (œÄ < Œòs), which is interpreted as a recent population reduction followed by expansion, as demonstrated by the estimated value of D T = -0.86 and non-significant positive values of Fu""s FS estimates [101][102][103]."	u
CCT225	"We estimated that the isolation of A. diazi from A. meeki occurred in the past 400-7000 years, which is consistent with geological, climatic, and anthropogenic events involving P√°tzcuaro and Zirahu√©n lakes. Tecto-volcanic events giving rise to the separation of P√°tzcuaro and Zirahu√©n lakes began 8000 years ago with the formation and activity of the La Tasa volcano southwest of Lake P√°tzcuaro and climate fluctuations causing decline in water level and drying of streams [21,[90][91]#CITATION_TAG[93]. Fluctuations in the level of Lake P√°tzcuaro during the Holocene associated with climate change, human activity [90,91,[94][95][96][97][98][99], and occurrence of tsunamis [100] could be involved to the isolation and demographics changes of A. diazi and A. meeki. These demographic changes were reflected in genetic diversity including the positive D T value, which was found to be low in A. diazi, and associated with recent bottlenecks that promoted inbreeding (F IS = 0.141), reduced heterozygosity, and the loss of allelic richness. In contrast, a bottleneck identified in A. meeki is attributed to the rapid loss of allelic diversity; however, the R ST value and the BSP analysis (in the HPD range) indicates that the bottleneck detected by IAM were overestimated. The population dynamics of A. meeki can be explained by the variations in nucleotide diversity and proportion of segregating sites (œÄ < Œòs), which is interpreted as a recent population reduction followed by expansion, as demonstrated by the estimated value of D T = -0.86 and non-significant positive values of Fu""s FS estimates [101][102][103]."	1	We estimated that the isolation of A. diazi from A. meeki occurred in the past 400-7000 years, which is consistent with geological, climatic, and anthropogenic events involving P√°tzcuaro and Zirahu√©n lakes. Tecto-volcanic events giving rise to the separation of P√°tzcuaro and Zirahu√©n lakes began 8000 years ago with the formation and activity of the La Tasa volcano southwest of Lake P√°tzcuaro and climate fluctuations causing decline in water level and drying of streams [21,[90][91]#CITATION_TAG[93]. Fluctuations in the level of Lake P√°tzcuaro during the Holocene associated with climate change, human activity [90,91,[94][95][96][97][98][99], and occurrence of tsunamis [100] could be involved to the isolation and demographics changes of A. diazi and A. meeki. These demographic changes were reflected in genetic diversity including the positive D T value, which was found to be low in A. diazi, and associated with recent bottlenecks that promoted inbreeding (F IS = 0.141), reduced heterozygosity, and the loss of allelic richness. In contrast, a bottleneck identified in A. meeki is attributed to the rapid loss of allelic diversity; however, the R ST value and the BSP analysis (in the HPD range) indicates that the bottleneck detected by IAM were overestimated.	e
CCT226	"The ""islander Chichimeca"" and the ""Coringuaro considered as first human groups to settle in the region of Uruapan and south of Michoac√°n, probably had influence on the management of aquatic resources and translocation of species may have occurred [#CITATION_TAG,110]. However, the information about their biological impact is less well documented. The rise of the P""urh√©pecha culture occurred around 1350, during the formation of the empire, with establishment of new villages, and species translocations possibly took place [109][110][111][112]. The expansion of the P""urh√©pecha Empire occurred during the second period with establishment around 1400 (second period) and 1450-1530 (third period) (S3 Fig) . During these periods, settlements ranged from the region of the La Palma River, to the Marqu√©s River region, in the Balsas Depression. Evidence from the P""urh√©pechas settlements in the Cupatitzio River subbasin and the Tepalcatepec-Balsas River suggests that, in this period, A.diazi translocation may have occurred. We conclude that the biogeographic history of A. catarinae was possibly determined by a founder effect mediated by pre-Hispanics in the past 3000 years, and taking into account this inference we cannot rule out species translocations in P√°tzcuaro and Zirahu√©n lakes."	0	"The ""islander Chichimeca"" and the ""Coringuaro considered as first human groups to settle in the region of Uruapan and south of Michoac√°n, probably had influence on the management of aquatic resources and translocation of species may have occurred [#CITATION_TAG,110]. However, the information about their biological impact is less well documented. The rise of the P""urh√©pecha culture occurred around 1350, during the formation of the empire, with establishment of new villages, and species translocations possibly took place [109][110][111][112]. The expansion of the P""urh√©pecha Empire occurred during the second period with establishment around 1400 (second period) and 1450-1530 (third period) (S3 Fig) . During these periods, settlements ranged from the region of the La Palma River, to the Marqu√©s River region, in the Balsas Depression."	T
CCT227	The genus Allotoca is the most diverse within the Goodeinae, and is the subject of taxonomic controversy, with the need for taxonomic revision to validate species [9,10,[15][16]#CITATION_TAG. The A. diazi complex comprises three recognized species [5]: Allotoca diazi [18], endemic to P√°tzcuaro basin, A. meeki [16], endemic in the Zirahu√©n basin, and Allotoca catarinae [15], restricted to the Cupatitzio River, an upper tributary of the Balsas River basin (Fig 1). Allotoca diazi was extirpated from P√°tzcuaro Lake and is currently restricted to the Chapultepec Spring, a tributary of P√°tzcuaro Lake, while A. meeki was extirpated from Zirahu√©n Lake and currently restricted to Opopeo Spring, a tributary of the Zirahu√©n Lake [5]. The lakes are located in the Michoac√°n-Guanajuato Corridor, an area of over 1000 volcanic cones active from the Pliocene to the present. To explain the evolution of these three sister species and other co-distributed taxa, two biogeographic hypotheses have been proposed. The first argues the existence of a tributary connecting the Lerma River with Cuitzeo, P√°tzcuaro, and Zirahu√©n lakes [19] around 700 000 years ago [20]. The second hypothesis indicates the existence of a tributary connecting the Cupatitzio River with Zirahu√©n and P√°tzcuaro lakes, reaching Zacapu [21].	0	The genus Allotoca is the most diverse within the Goodeinae, and is the subject of taxonomic controversy, with the need for taxonomic revision to validate species [9,10,[15][16]#CITATION_TAG. The A. diazi complex comprises three recognized species [5]: Allotoca diazi [18], endemic to P√°tzcuaro basin, A. meeki [16], endemic in the Zirahu√©n basin, and Allotoca catarinae [15], restricted to the Cupatitzio River, an upper tributary of the Balsas River basin (Fig 1). Allotoca diazi was extirpated from P√°tzcuaro Lake and is currently restricted to the Chapultepec Spring, a tributary of P√°tzcuaro Lake, while A. meeki was extirpated from Zirahu√©n Lake and currently restricted to Opopeo Spring, a tributary of the Zirahu√©n Lake [5]. The lakes are located in the Michoac√°n-Guanajuato Corridor, an area of over 1000 volcanic cones active from the Pliocene to the present.	T
CCT228	Approximately 100 fish species are in the West-central Mexico, 70% of which are endemic and one of the most representative endemic fish groups of this region is the subfamily Goodeinae [5]. The group presents high species richness in a small area (c. 41 species) and unique characteristics associated with breeding strategies and embryo development, such as internal fertilization, matrotrophy, and sexual selection [9][10][11][12]#CITATION_TAG. The family presents a high diversification apparently influenced by viviparity, with vicariance and adaptive radiation being the most important factors. The speciation rate of goodeids has not been constant and has been impacted by multiple extinctions, estimating that at least 25 000 years is required to establish an evolutionary lineage [14].	0	Approximately 100 fish species are in the West-central Mexico, 70% of which are endemic and one of the most representative endemic fish groups of this region is the subfamily Goodeinae [5]. The group presents high species richness in a small area (c. 41 species) and unique characteristics associated with breeding strategies and embryo development, such as internal fertilization, matrotrophy, and sexual selection [9][10][11][12]#CITATION_TAG. The family presents a high diversification apparently influenced by viviparity, with vicariance and adaptive radiation being the most important factors. The speciation rate of goodeids has not been constant and has been impacted by multiple extinctions, estimating that at least 25 000 years is required to establish an evolutionary lineage [14].	 
CCT229	Approximately 100 fish species are in the West-central Mexico, 70% of which are endemic and one of the most representative endemic fish groups of this region is the subfamily Goodeinae [5]. The group presents high species richness in a small area (c. 41 species) and unique characteristics associated with breeding strategies and embryo development, such as internal fertilization, matrotrophy, and sexual selection [9]#CITATION_TAG[11][12][13]. The family presents a high diversification apparently influenced by viviparity, with vicariance and adaptive radiation being the most important factors. The speciation rate of goodeids has not been constant and has been impacted by multiple extinctions, estimating that at least 25 000 years is required to establish an evolutionary lineage [14].	0	Approximately 100 fish species are in the West-central Mexico, 70% of which are endemic and one of the most representative endemic fish groups of this region is the subfamily Goodeinae [5]. The group presents high species richness in a small area (c. 41 species) and unique characteristics associated with breeding strategies and embryo development, such as internal fertilization, matrotrophy, and sexual selection [9]#CITATION_TAG[11][12][13]. The family presents a high diversification apparently influenced by viviparity, with vicariance and adaptive radiation being the most important factors. The speciation rate of goodeids has not been constant and has been impacted by multiple extinctions, estimating that at least 25 000 years is required to establish an evolutionary lineage [14].	 
CCT230	"The region in West-central Mexico, particularly between the Lerma-Santiago and Balsas rivers, is characterized by varied and rugged physiography, a product of intense tectonic and volcanic activity in the area since the Miocene [5]. Also, this region is an area with a long cultural history, with the P""urh√©pecha settlement developing one of the most stable empires at least years ago [6], particularly due to the richness and abundance of lacustrine resources. The main resources currently exploited by settlements around the lakes are fish, as well as turtles, salamanders, clams, and wetland plants [#CITATION_TAG,8]. Even the area was formerly known by the N√°huatl culture as Mechuacan, ""a place of fishermen,"" and is currently called Michoac√°n."	0	"The region in West-central Mexico, particularly between the Lerma-Santiago and Balsas rivers, is characterized by varied and rugged physiography, a product of intense tectonic and volcanic activity in the area since the Miocene [5]. Also, this region is an area with a long cultural history, with the P""urh√©pecha settlement developing one of the most stable empires at least years ago [6], particularly due to the richness and abundance of lacustrine resources. The main resources currently exploited by settlements around the lakes are fish, as well as turtles, salamanders, clams, and wetland plants [#CITATION_TAG,8]. Even the area was formerly known by the N√°huatl culture as Mechuacan, ""a place of fishermen,"" and is currently called Michoac√°n."	e
CCT231	"We estimated that the isolation of A. diazi from A. meeki occurred in the past 400-7000 years, which is consistent with geological, climatic, and anthropogenic events involving P√°tzcuaro and Zirahu√©n lakes. Tecto-volcanic events giving rise to the separation of P√°tzcuaro and Zirahu√©n lakes began 8000 years ago with the formation and activity of the La Tasa volcano southwest of Lake P√°tzcuaro and climate fluctuations causing decline in water level and drying of streams [21,[90][91][92][93]. Fluctuations in the level of Lake P√°tzcuaro during the Holocene associated with climate change, human activity [90,91,[94][95][96][97][98]#CITATION_TAG, and occurrence of tsunamis [100] could be involved to the isolation and demographics changes of A. diazi and A. meeki. These demographic changes were reflected in genetic diversity including the positive D T value, which was found to be low in A. diazi, and associated with recent bottlenecks that promoted inbreeding (F IS = 0.141), reduced heterozygosity, and the loss of allelic richness. In contrast, a bottleneck identified in A. meeki is attributed to the rapid loss of allelic diversity; however, the R ST value and the BSP analysis (in the HPD range) indicates that the bottleneck detected by IAM were overestimated. The population dynamics of A. meeki can be explained by the variations in nucleotide diversity and proportion of segregating sites (œÄ < Œòs), which is interpreted as a recent population reduction followed by expansion, as demonstrated by the estimated value of D T = -0.86 and non-significant positive values of Fu""s FS estimates [101][102][103]."	0	"We estimated that the isolation of A. diazi from A. meeki occurred in the past 400-7000 years, which is consistent with geological, climatic, and anthropogenic events involving P√°tzcuaro and Zirahu√©n lakes. Tecto-volcanic events giving rise to the separation of P√°tzcuaro and Zirahu√©n lakes began 8000 years ago with the formation and activity of the La Tasa volcano southwest of Lake P√°tzcuaro and climate fluctuations causing decline in water level and drying of streams [21,[90][91][92][93]. Fluctuations in the level of Lake P√°tzcuaro during the Holocene associated with climate change, human activity [90,91,[94][95][96][97][98]#CITATION_TAG, and occurrence of tsunamis [100] could be involved to the isolation and demographics changes of A. diazi and A. meeki. These demographic changes were reflected in genetic diversity including the positive D T value, which was found to be low in A. diazi, and associated with recent bottlenecks that promoted inbreeding (F IS = 0.141), reduced heterozygosity, and the loss of allelic richness. In contrast, a bottleneck identified in A. meeki is attributed to the rapid loss of allelic diversity; however, the R ST value and the BSP analysis (in the HPD range) indicates that the bottleneck detected by IAM were overestimated. The population dynamics of A. meeki can be explained by the variations in nucleotide diversity and proportion of segregating sites (œÄ < Œòs), which is interpreted as a recent population reduction followed by expansion, as demonstrated by the estimated value of D T = -0.86 and non-significant positive values of Fu""s FS estimates [101][102][103]."	u
CCT232	The Allotoca diazi complex consists of a genetic group with low genetic structure and its isolation within the members was more recent, during the Holocene. The isolation of A. diazi, A. meeki, and A. catarinae is reflected in the low genetic differences, non-monophyletic patterns, shared haplotypes, and genetic groups assignment, and we considered that the species complex consist in an incomplete lineage sorting pattern [72][73][74][75]. The genetic distances among the three species in Cytb are smaller than reported to sister Goodeinae species (1.7-11%) [9] and sister species, congeneric species, and cofamilial genera within and across the major vertebrate taxonomic classes (~2%) [76][77][78][79]. The genetic variation estimated in the species complex based on the Cytb gene is attributed to genetic drift and mutation (D T and FS values did not show significant deviation from neutrality). Low genetic variation was detected as a genetic pool arrangement through AMOVA analysis. However, BI detected this minimum mark of genetic  structure as two genetic groups. The results obtained are supported by the minimal morphological differences previously reported [15,17,[80][81][82]#CITATION_TAG[84].	1	The genetic variation estimated in the species complex based on the Cytb gene is attributed to genetic drift and mutation (D T and FS values did not show significant deviation from neutrality). Low genetic variation was detected as a genetic pool arrangement through AMOVA analysis. However, BI detected this minimum mark of genetic  structure as two genetic groups. The results obtained are supported by the minimal morphological differences previously reported [15,17,[80][81][82]#CITATION_TAG[84].	s
CCT233	The Allotoca diazi complex consists of a genetic group with low genetic structure and its isolation within the members was more recent, during the Holocene. The isolation of A. diazi, A. meeki, and A. catarinae is reflected in the low genetic differences, non-monophyletic patterns, shared haplotypes, and genetic groups assignment, and we considered that the species complex consist in an incomplete lineage sorting pattern [72][73][74][75]. The genetic distances among the three species in Cytb are smaller than reported to sister Goodeinae species (1.7-11%) [9] and sister species, congeneric species, and cofamilial genera within and across the major vertebrate taxonomic classes (~2%) [76][77][78][79]. The genetic variation estimated in the species complex based on the Cytb gene is attributed to genetic drift and mutation (D T and FS values did not show significant deviation from neutrality). Low genetic variation was detected as a genetic pool arrangement through AMOVA analysis. However, BI detected this minimum mark of genetic  structure as two genetic groups. The results obtained are supported by the minimal morphological differences previously reported [15,17,[80][81][82][83]#CITATION_TAG.	1	The genetic variation estimated in the species complex based on the Cytb gene is attributed to genetic drift and mutation (D T and FS values did not show significant deviation from neutrality). Low genetic variation was detected as a genetic pool arrangement through AMOVA analysis. However, BI detected this minimum mark of genetic  structure as two genetic groups. The results obtained are supported by the minimal morphological differences previously reported [15,17,[80][81][82][83]#CITATION_TAG.	s
CCT234	The diversity and distribution of freshwater ichthyofauna has been strongly linked to natural events, mainly geological process and historical climatic fluctuations. It is therefore that, taking into account the biogeographic history of each region in the world; the freshwater fish have been used as a model for the study of biogeography, speciation, paleohydrology and evolution. However, translocation and introduction of fish species is well documented in many ancient cultures having an important role in their current distribution, misunderstanding the evolutionary history of the species, In America, particularly in Mexico, the impact of pre-Hispanic cultures in the current distribution of the biota, is little known and mostly documented for birds #CITATION_TAG[2][3]. In fact, the scientific community has long assumed that translocations and introduction of species in America occurred only after European colonization [4].	1	The diversity and distribution of freshwater ichthyofauna has been strongly linked to natural events, mainly geological process and historical climatic fluctuations. It is therefore that, taking into account the biogeographic history of each region in the world; the freshwater fish have been used as a model for the study of biogeography, speciation, paleohydrology and evolution. However, translocation and introduction of fish species is well documented in many ancient cultures having an important role in their current distribution, misunderstanding the evolutionary history of the species, In America, particularly in Mexico, the impact of pre-Hispanic cultures in the current distribution of the biota, is little known and mostly documented for birds #CITATION_TAG[2][3]. In fact, the scientific community has long assumed that translocations and introduction of species in America occurred only after European colonization [4].	w
CCT235	The Allotoca diazi complex consists of a genetic group with low genetic structure and its isolation within the members was more recent, during the Holocene. The isolation of A. diazi, A. meeki, and A. catarinae is reflected in the low genetic differences, non-monophyletic patterns, shared haplotypes, and genetic groups assignment, and we considered that the species complex consist in an incomplete lineage sorting pattern [72][73][74][75]. The genetic distances among the three species in Cytb are smaller than reported to sister Goodeinae species (1.7-11%) [9] and sister species, congeneric species, and cofamilial genera within and across the major vertebrate taxonomic classes (~2%) [76][77][78][79]. The genetic variation estimated in the species complex based on the Cytb gene is attributed to genetic drift and mutation (D T and FS values did not show significant deviation from neutrality). Low genetic variation was detected as a genetic pool arrangement through AMOVA analysis. However, BI detected this minimum mark of genetic  structure as two genetic groups. The results obtained are supported by the minimal morphological differences previously reported [15,17,[80][81]#CITATION_TAG[83][84].	1	The genetic variation estimated in the species complex based on the Cytb gene is attributed to genetic drift and mutation (D T and FS values did not show significant deviation from neutrality). Low genetic variation was detected as a genetic pool arrangement through AMOVA analysis. However, BI detected this minimum mark of genetic  structure as two genetic groups. The results obtained are supported by the minimal morphological differences previously reported [15,17,[80][81]#CITATION_TAG[83][84].	s
CCT236	The Allotoca diazi complex consists of a genetic group with low genetic structure and its isolation within the members was more recent, during the Holocene. The isolation of A. diazi, A. meeki, and A. catarinae is reflected in the low genetic differences, non-monophyletic patterns, shared haplotypes, and genetic groups assignment, and we considered that the species complex consist in an incomplete lineage sorting pattern [72][73][74][75]. The genetic distances among the three species in Cytb are smaller than reported to sister Goodeinae species (1.7-11%) [9] and sister species, congeneric species, and cofamilial genera within and across the major vertebrate taxonomic classes (~2%) [76][77][78][79]. The genetic variation estimated in the species complex based on the Cytb gene is attributed to genetic drift and mutation (D T and FS values did not show significant deviation from neutrality). Low genetic variation was detected as a genetic pool arrangement through AMOVA analysis. However, BI detected this minimum mark of genetic  structure as two genetic groups. The results obtained are supported by the minimal morphological differences previously reported [15,17,[80]#CITATION_TAG[82][83][84].	1	The genetic variation estimated in the species complex based on the Cytb gene is attributed to genetic drift and mutation (D T and FS values did not show significant deviation from neutrality). Low genetic variation was detected as a genetic pool arrangement through AMOVA analysis. However, BI detected this minimum mark of genetic  structure as two genetic groups. The results obtained are supported by the minimal morphological differences previously reported [15,17,[80]#CITATION_TAG[82][83][84].	s
CCT237	The Allotoca diazi complex consists of a genetic group with low genetic structure and its isolation within the members was more recent, during the Holocene. The isolation of A. diazi, A. meeki, and A. catarinae is reflected in the low genetic differences, non-monophyletic patterns, shared haplotypes, and genetic groups assignment, and we considered that the species complex consist in an incomplete lineage sorting pattern [72][73][74][75]. The genetic distances among the three species in Cytb are smaller than reported to sister Goodeinae species (1.7-11%) [9] and sister species, congeneric species, and cofamilial genera within and across the major vertebrate taxonomic classes (~2%) [76][77][78]#CITATION_TAG. The genetic variation estimated in the species complex based on the Cytb gene is attributed to genetic drift and mutation (D T and FS values did not show significant deviation from neutrality). Low genetic variation was detected as a genetic pool arrangement through AMOVA analysis. However, BI detected this minimum mark of genetic  structure as two genetic groups. The results obtained are supported by the minimal morphological differences previously reported [15,17,[80][81][82][83][84].	1	The Allotoca diazi complex consists of a genetic group with low genetic structure and its isolation within the members was more recent, during the Holocene. The isolation of A. diazi, A. meeki, and A. catarinae is reflected in the low genetic differences, non-monophyletic patterns, shared haplotypes, and genetic groups assignment, and we considered that the species complex consist in an incomplete lineage sorting pattern [72][73][74][75]. The genetic distances among the three species in Cytb are smaller than reported to sister Goodeinae species (1.7-11%) [9] and sister species, congeneric species, and cofamilial genera within and across the major vertebrate taxonomic classes (~2%) [76][77][78]#CITATION_TAG. The genetic variation estimated in the species complex based on the Cytb gene is attributed to genetic drift and mutation (D T and FS values did not show significant deviation from neutrality). Low genetic variation was detected as a genetic pool arrangement through AMOVA analysis. However, BI detected this minimum mark of genetic  structure as two genetic groups.	e
CCT238	The Allotoca diazi complex consists of a genetic group with low genetic structure and its isolation within the members was more recent, during the Holocene. The isolation of A. diazi, A. meeki, and A. catarinae is reflected in the low genetic differences, non-monophyletic patterns, shared haplotypes, and genetic groups assignment, and we considered that the species complex consist in an incomplete lineage sorting pattern [72][73][74][75]. The genetic distances among the three species in Cytb are smaller than reported to sister Goodeinae species (1.7-11%) [9] and sister species, congeneric species, and cofamilial genera within and across the major vertebrate taxonomic classes (~2%) [76][77]#CITATION_TAG[79]. The genetic variation estimated in the species complex based on the Cytb gene is attributed to genetic drift and mutation (D T and FS values did not show significant deviation from neutrality). Low genetic variation was detected as a genetic pool arrangement through AMOVA analysis. However, BI detected this minimum mark of genetic  structure as two genetic groups. The results obtained are supported by the minimal morphological differences previously reported [15,17,[80][81][82][83][84].	1	The Allotoca diazi complex consists of a genetic group with low genetic structure and its isolation within the members was more recent, during the Holocene. The isolation of A. diazi, A. meeki, and A. catarinae is reflected in the low genetic differences, non-monophyletic patterns, shared haplotypes, and genetic groups assignment, and we considered that the species complex consist in an incomplete lineage sorting pattern [72][73][74][75]. The genetic distances among the three species in Cytb are smaller than reported to sister Goodeinae species (1.7-11%) [9] and sister species, congeneric species, and cofamilial genera within and across the major vertebrate taxonomic classes (~2%) [76][77]#CITATION_TAG[79]. The genetic variation estimated in the species complex based on the Cytb gene is attributed to genetic drift and mutation (D T and FS values did not show significant deviation from neutrality). Low genetic variation was detected as a genetic pool arrangement through AMOVA analysis. However, BI detected this minimum mark of genetic  structure as two genetic groups.	e
CCT239	The Allotoca diazi complex consists of a genetic group with low genetic structure and its isolation within the members was more recent, during the Holocene. The isolation of A. diazi, A. meeki, and A. catarinae is reflected in the low genetic differences, non-monophyletic patterns, shared haplotypes, and genetic groups assignment, and we considered that the species complex consist in an incomplete lineage sorting pattern [72][73][74][75]. The genetic distances among the three species in Cytb are smaller than reported to sister Goodeinae species (1.7-11%) [9] and sister species, congeneric species, and cofamilial genera within and across the major vertebrate taxonomic classes (~2%) [76]#CITATION_TAG[78][79]. The genetic variation estimated in the species complex based on the Cytb gene is attributed to genetic drift and mutation (D T and FS values did not show significant deviation from neutrality). Low genetic variation was detected as a genetic pool arrangement through AMOVA analysis. However, BI detected this minimum mark of genetic  structure as two genetic groups. The results obtained are supported by the minimal morphological differences previously reported [15,17,[80][81][82][83][84].	1	The Allotoca diazi complex consists of a genetic group with low genetic structure and its isolation within the members was more recent, during the Holocene. The isolation of A. diazi, A. meeki, and A. catarinae is reflected in the low genetic differences, non-monophyletic patterns, shared haplotypes, and genetic groups assignment, and we considered that the species complex consist in an incomplete lineage sorting pattern [72][73][74][75]. The genetic distances among the three species in Cytb are smaller than reported to sister Goodeinae species (1.7-11%) [9] and sister species, congeneric species, and cofamilial genera within and across the major vertebrate taxonomic classes (~2%) [76]#CITATION_TAG[78][79]. The genetic variation estimated in the species complex based on the Cytb gene is attributed to genetic drift and mutation (D T and FS values did not show significant deviation from neutrality). Low genetic variation was detected as a genetic pool arrangement through AMOVA analysis. However, BI detected this minimum mark of genetic  structure as two genetic groups.	e
CCT240	The hypothesis of connection and disconnection of P√°tzcuaro and Zirahu√©n lakes during the last 700 000 years [19] is supported by stratigraphic [85]; limnologic data [#CITATION_TAG,87]; shared native icthyofauna such as Chirostoma estor, Chirostoma p√°tzcuaro (Atherinopsidae), Algansea lacustris (Cypronidae), Alloophorus robustus, Skiffia lermae, Allotoca dugesii, and Goodea atripinnis (Goodeidae) [88]; and genetic data [12,89]. Shared haplotypes of A. diazi and A. meeki and the high proportion of individuals assigned to other species (0.5 to 0.7) by microsatellite data, suggest recent gene flow. Microsatellite information showed low level of genetic differentiation (F ST = 0.084). Low genetic diversity was estimated for A. diazi in the Cytb gene (h = 0.78, œÄ = 0.0030) and even lower for A. meeki (h = 0.52, œÄ = 0.0007). The migration rate between the two species is not significant any time.	0	The hypothesis of connection and disconnection of P√°tzcuaro and Zirahu√©n lakes during the last 700 000 years [19] is supported by stratigraphic [85]; limnologic data [#CITATION_TAG,87]; shared native icthyofauna such as Chirostoma estor, Chirostoma p√°tzcuaro (Atherinopsidae), Algansea lacustris (Cypronidae), Alloophorus robustus, Skiffia lermae, Allotoca dugesii, and Goodea atripinnis (Goodeidae) [88]; and genetic data [12,89]. Shared haplotypes of A. diazi and A. meeki and the high proportion of individuals assigned to other species (0.5 to 0.7) by microsatellite data, suggest recent gene flow. Microsatellite information showed low level of genetic differentiation (F ST = 0.084). Low genetic diversity was estimated for A. diazi in the Cytb gene (h = 0.78, œÄ = 0.0030) and even lower for A. meeki (h = 0.52, œÄ = 0.0007).	T
CCT241	The Allotoca diazi complex consists of a genetic group with low genetic structure and its isolation within the members was more recent, during the Holocene. The isolation of A. diazi, A. meeki, and A. catarinae is reflected in the low genetic differences, non-monophyletic patterns, shared haplotypes, and genetic groups assignment, and we considered that the species complex consist in an incomplete lineage sorting pattern [72][73][74][75]. The genetic distances among the three species in Cytb are smaller than reported to sister Goodeinae species (1.7-11%) [9] and sister species, congeneric species, and cofamilial genera within and across the major vertebrate taxonomic classes (~2%) #CITATION_TAG[77][78][79]. The genetic variation estimated in the species complex based on the Cytb gene is attributed to genetic drift and mutation (D T and FS values did not show significant deviation from neutrality). Low genetic variation was detected as a genetic pool arrangement through AMOVA analysis. However, BI detected this minimum mark of genetic  structure as two genetic groups. The results obtained are supported by the minimal morphological differences previously reported [15,17,[80][81][82][83][84].	1	The Allotoca diazi complex consists of a genetic group with low genetic structure and its isolation within the members was more recent, during the Holocene. The isolation of A. diazi, A. meeki, and A. catarinae is reflected in the low genetic differences, non-monophyletic patterns, shared haplotypes, and genetic groups assignment, and we considered that the species complex consist in an incomplete lineage sorting pattern [72][73][74][75]. The genetic distances among the three species in Cytb are smaller than reported to sister Goodeinae species (1.7-11%) [9] and sister species, congeneric species, and cofamilial genera within and across the major vertebrate taxonomic classes (~2%) #CITATION_TAG[77][78][79]. The genetic variation estimated in the species complex based on the Cytb gene is attributed to genetic drift and mutation (D T and FS values did not show significant deviation from neutrality). Low genetic variation was detected as a genetic pool arrangement through AMOVA analysis. However, BI detected this minimum mark of genetic  structure as two genetic groups.	e
CCT242	The Allotoca diazi complex consists of a genetic group with low genetic structure and its isolation within the members was more recent, during the Holocene. The isolation of A. diazi, A. meeki, and A. catarinae is reflected in the low genetic differences, non-monophyletic patterns, shared haplotypes, and genetic groups assignment, and we considered that the species complex consist in an incomplete lineage sorting pattern [72][73][74]#CITATION_TAG. The genetic distances among the three species in Cytb are smaller than reported to sister Goodeinae species (1.7-11%) [9] and sister species, congeneric species, and cofamilial genera within and across the major vertebrate taxonomic classes (~2%) [76][77][78][79]. The genetic variation estimated in the species complex based on the Cytb gene is attributed to genetic drift and mutation (D T and FS values did not show significant deviation from neutrality). Low genetic variation was detected as a genetic pool arrangement through AMOVA analysis. However, BI detected this minimum mark of genetic  structure as two genetic groups. The results obtained are supported by the minimal morphological differences previously reported [15,17,[80][81][82][83][84].	1	The Allotoca diazi complex consists of a genetic group with low genetic structure and its isolation within the members was more recent, during the Holocene. The isolation of A. diazi, A. meeki, and A. catarinae is reflected in the low genetic differences, non-monophyletic patterns, shared haplotypes, and genetic groups assignment, and we considered that the species complex consist in an incomplete lineage sorting pattern [72][73][74]#CITATION_TAG. The genetic distances among the three species in Cytb are smaller than reported to sister Goodeinae species (1.7-11%) [9] and sister species, congeneric species, and cofamilial genera within and across the major vertebrate taxonomic classes (~2%) [76][77][78][79]. The genetic variation estimated in the species complex based on the Cytb gene is attributed to genetic drift and mutation (D T and FS values did not show significant deviation from neutrality). Low genetic variation was detected as a genetic pool arrangement through AMOVA analysis.	h
CCT243	The Allotoca diazi complex consists of a genetic group with low genetic structure and its isolation within the members was more recent, during the Holocene. The isolation of A. diazi, A. meeki, and A. catarinae is reflected in the low genetic differences, non-monophyletic patterns, shared haplotypes, and genetic groups assignment, and we considered that the species complex consist in an incomplete lineage sorting pattern [72][73]#CITATION_TAG[75]. The genetic distances among the three species in Cytb are smaller than reported to sister Goodeinae species (1.7-11%) [9] and sister species, congeneric species, and cofamilial genera within and across the major vertebrate taxonomic classes (~2%) [76][77][78][79]. The genetic variation estimated in the species complex based on the Cytb gene is attributed to genetic drift and mutation (D T and FS values did not show significant deviation from neutrality). Low genetic variation was detected as a genetic pool arrangement through AMOVA analysis. However, BI detected this minimum mark of genetic  structure as two genetic groups. The results obtained are supported by the minimal morphological differences previously reported [15,17,[80][81][82][83][84].	1	The Allotoca diazi complex consists of a genetic group with low genetic structure and its isolation within the members was more recent, during the Holocene. The isolation of A. diazi, A. meeki, and A. catarinae is reflected in the low genetic differences, non-monophyletic patterns, shared haplotypes, and genetic groups assignment, and we considered that the species complex consist in an incomplete lineage sorting pattern [72][73]#CITATION_TAG[75]. The genetic distances among the three species in Cytb are smaller than reported to sister Goodeinae species (1.7-11%) [9] and sister species, congeneric species, and cofamilial genera within and across the major vertebrate taxonomic classes (~2%) [76][77][78][79]. The genetic variation estimated in the species complex based on the Cytb gene is attributed to genetic drift and mutation (D T and FS values did not show significant deviation from neutrality). Low genetic variation was detected as a genetic pool arrangement through AMOVA analysis.	h
CCT244	The Allotoca diazi complex consists of a genetic group with low genetic structure and its isolation within the members was more recent, during the Holocene. The isolation of A. diazi, A. meeki, and A. catarinae is reflected in the low genetic differences, non-monophyletic patterns, shared haplotypes, and genetic groups assignment, and we considered that the species complex consist in an incomplete lineage sorting pattern [72]#CITATION_TAG[74][75]. The genetic distances among the three species in Cytb are smaller than reported to sister Goodeinae species (1.7-11%) [9] and sister species, congeneric species, and cofamilial genera within and across the major vertebrate taxonomic classes (~2%) [76][77][78][79]. The genetic variation estimated in the species complex based on the Cytb gene is attributed to genetic drift and mutation (D T and FS values did not show significant deviation from neutrality). Low genetic variation was detected as a genetic pool arrangement through AMOVA analysis. However, BI detected this minimum mark of genetic  structure as two genetic groups. The results obtained are supported by the minimal morphological differences previously reported [15,17,[80][81][82][83][84].	1	The Allotoca diazi complex consists of a genetic group with low genetic structure and its isolation within the members was more recent, during the Holocene. The isolation of A. diazi, A. meeki, and A. catarinae is reflected in the low genetic differences, non-monophyletic patterns, shared haplotypes, and genetic groups assignment, and we considered that the species complex consist in an incomplete lineage sorting pattern [72]#CITATION_TAG[74][75]. The genetic distances among the three species in Cytb are smaller than reported to sister Goodeinae species (1.7-11%) [9] and sister species, congeneric species, and cofamilial genera within and across the major vertebrate taxonomic classes (~2%) [76][77][78][79]. The genetic variation estimated in the species complex based on the Cytb gene is attributed to genetic drift and mutation (D T and FS values did not show significant deviation from neutrality). Low genetic variation was detected as a genetic pool arrangement through AMOVA analysis.	h
CCT245	The isolation of the Allotoca diazi complex from its common ancestor A. zacapuensis, does not contradict the hypothesis of √Ålvarez (1972) [21] with respect to the connection between the Zacapu and P√°tzcuaro basins during the Pleistocene, resulted from the formation of the El Zirate mountain and the northern P√°tzcuaro Lake shoreline during the Late Pleistocene #CITATION_TAG.	0	The isolation of the Allotoca diazi complex from its common ancestor A. zacapuensis, does not contradict the hypothesis of √Ålvarez (1972) [21] with respect to the connection between the Zacapu and P√°tzcuaro basins during the Pleistocene, resulted from the formation of the El Zirate mountain and the northern P√°tzcuaro Lake shoreline during the Late Pleistocene #CITATION_TAG.	T
CCT246	"We estimated that the isolation of A. diazi from A. meeki occurred in the past 400-7000 years, which is consistent with geological, climatic, and anthropogenic events involving P√°tzcuaro and Zirahu√©n lakes. Tecto-volcanic events giving rise to the separation of P√°tzcuaro and Zirahu√©n lakes began 8000 years ago with the formation and activity of the La Tasa volcano southwest of Lake P√°tzcuaro and climate fluctuations causing decline in water level and drying of streams [21,[90][91][92][93]. Fluctuations in the level of Lake P√°tzcuaro during the Holocene associated with climate change, human activity [90,91,[94][95][96][97][98][99], and occurrence of tsunamis [100] could be involved to the isolation and demographics changes of A. diazi and A. meeki. These demographic changes were reflected in genetic diversity including the positive D T value, which was found to be low in A. diazi, and associated with recent bottlenecks that promoted inbreeding (F IS = 0.141), reduced heterozygosity, and the loss of allelic richness. In contrast, a bottleneck identified in A. meeki is attributed to the rapid loss of allelic diversity; however, the R ST value and the BSP analysis (in the HPD range) indicates that the bottleneck detected by IAM were overestimated. The population dynamics of A. meeki can be explained by the variations in nucleotide diversity and proportion of segregating sites (œÄ < Œòs), which is interpreted as a recent population reduction followed by expansion, as demonstrated by the estimated value of D T = -0.86 and non-significant positive values of Fu""s FS estimates #CITATION_TAG[102][103]."	0	"Fluctuations in the level of Lake P√°tzcuaro during the Holocene associated with climate change, human activity [90,91,[94][95][96][97][98][99], and occurrence of tsunamis [100] could be involved to the isolation and demographics changes of A. diazi and A. meeki. These demographic changes were reflected in genetic diversity including the positive D T value, which was found to be low in A. diazi, and associated with recent bottlenecks that promoted inbreeding (F IS = 0.141), reduced heterozygosity, and the loss of allelic richness. In contrast, a bottleneck identified in A. meeki is attributed to the rapid loss of allelic diversity; however, the R ST value and the BSP analysis (in the HPD range) indicates that the bottleneck detected by IAM were overestimated. The population dynamics of A. meeki can be explained by the variations in nucleotide diversity and proportion of segregating sites (œÄ < Œòs), which is interpreted as a recent population reduction followed by expansion, as demonstrated by the estimated value of D T = -0.86 and non-significant positive values of Fu""s FS estimates #CITATION_TAG[102][103]."	o
CCT247	The hypothesis of connection and disconnection of P√°tzcuaro and Zirahu√©n lakes during the last 700 000 years [19] is supported by stratigraphic [85]; limnologic data [86,87]; shared native icthyofauna such as Chirostoma estor, Chirostoma p√°tzcuaro (Atherinopsidae), Algansea lacustris (Cypronidae), Alloophorus robustus, Skiffia lermae, Allotoca dugesii, and Goodea atripinnis (Goodeidae) [88]; and genetic data [12,#CITATION_TAG]. Shared haplotypes of A. diazi and A. meeki and the high proportion of individuals assigned to other species (0.5 to 0.7) by microsatellite data, suggest recent gene flow. Microsatellite information showed low level of genetic differentiation (F ST = 0.084). Low genetic diversity was estimated for A. diazi in the Cytb gene (h = 0.78, œÄ = 0.0030) and even lower for A. meeki (h = 0.52, œÄ = 0.0007). The migration rate between the two species is not significant any time.	0	The hypothesis of connection and disconnection of P√°tzcuaro and Zirahu√©n lakes during the last 700 000 years [19] is supported by stratigraphic [85]; limnologic data [86,87]; shared native icthyofauna such as Chirostoma estor, Chirostoma p√°tzcuaro (Atherinopsidae), Algansea lacustris (Cypronidae), Alloophorus robustus, Skiffia lermae, Allotoca dugesii, and Goodea atripinnis (Goodeidae) [88]; and genetic data [12,#CITATION_TAG]. Shared haplotypes of A. diazi and A. meeki and the high proportion of individuals assigned to other species (0.5 to 0.7) by microsatellite data, suggest recent gene flow. Microsatellite information showed low level of genetic differentiation (F ST = 0.084). Low genetic diversity was estimated for A. diazi in the Cytb gene (h = 0.78, œÄ = 0.0030) and even lower for A. meeki (h = 0.52, œÄ = 0.0007).	T
CCT248	The genetic, biological, and ecological information obtained in this investigation, along with relevant published information [64,#CITATION_TAG], was used for identification of conservation units. In order to predict a future scenario for range of distribution of the natural members of the species complex, a discriminant analysis of presence-only data through maximum entropy using the program Maxent v3.3.3 [66][67] was conducted for the present and for two periods in the future, years 2041 to 2060 and 2061 to 2080. The 6.0 Representative Concentration Pathways (RCP6.0) [68] was selected from downscaling Intergovernmental Panel on Climate Change 5 scenario (IPPC5) (Coupled Model Intercomparison Project 5) [69] implementing the Community Climate System Model 4 (CCSM4) [70]. We implemented independent runs of 5000 iterations with 19 climatic variables (http://www.worldclim.org/bioclim), bootstrapping of 100 replicates to obtain 95% confidence intervals, regularization multiplier (RM) values from 0.01 to 10, evaluating area under the ROC curve (AUC) values and using the omission rates to discard identical AUC of different RM values. Collinear climatic variables were discarded (S4 Table ).	0	The genetic, biological, and ecological information obtained in this investigation, along with relevant published information [64,#CITATION_TAG], was used for identification of conservation units. In order to predict a future scenario for range of distribution of the natural members of the species complex, a discriminant analysis of presence-only data through maximum entropy using the program Maxent v3.3. 3 [66][67] was conducted for the present and for two periods in the future, years 2041 to 2060 and 2061 to 2080. The 6.0 Representative Concentration Pathways (RCP6.0) [68] was selected from downscaling Intergovernmental Panel on Climate Change 5 scenario (IPPC5) (Coupled Model Intercomparison Project 5) [69] implementing the Community Climate System Model 4 (CCSM4) [70].	T
CCT249	Brown adipose tissue assists in adaptation to cold challenges through futile substrate-energy cycles. One such cycle is the futile cycle, burning up ATP molecules between fructose-1,6diphosphatase and phosphofructokinase activities, that generates a metabolic signal having a circadian rhythm (Zhang et al., 2006). In addition, peroxiredoxins being abundant in brown adipose tissue contribute to the seasonal behavior under conditions in which the coordination by the suprachiasmatic nuclei is weak (Epperson et al., 2004), being reminiscent of those in which the time-keeping mechanisms are challenged (#CITATION_TAG et al., 2008) and circadian desynchrony is likely to emerge (van Oort et al., 2007).	4	Brown adipose tissue assists in adaptation to cold challenges through futile substrate-energy cycles. One such cycle is the futile cycle, burning up ATP molecules between fructose-1,6diphosphatase and phosphofructokinase activities, that generates a metabolic signal having a circadian rhythm (Zhang et al., 2006). In addition, peroxiredoxins being abundant in brown adipose tissue contribute to the seasonal behavior under conditions in which the coordination by the suprachiasmatic nuclei is weak (Epperson et al., 2004), being reminiscent of those in which the time-keeping mechanisms are challenged (#CITATION_TAG et al., 2008) and circadian desynchrony is likely to emerge (van Oort et al., 2007).	 
CCT250	These findings suggest that brown adipocytes and circadian clocks, of whose components the cryptochromes do react to ultraviolet radiation (#CITATION_TAG et al., 2011), are not only relevant to survival and adaptation, but also targeted by natural selection. Herein, I hypothesize that circadian clocks in brown adipocytes are relevant to mammalian adaptation. Further, the cryptochromes are of key importance here, because of their evolutionary roots and current position in the hierarchy of the components of circadian clocks. They favor the odds for survival from hazards caused by circadian desynchrony and the over-activated brown adipose tissue.	0	These findings suggest that brown adipocytes and circadian clocks, of whose components the cryptochromes do react to ultraviolet radiation (#CITATION_TAG et al., 2011), are not only relevant to survival and adaptation, but also targeted by natural selection. Herein, I hypothesize that circadian clocks in brown adipocytes are relevant to mammalian adaptation. Further, the cryptochromes are of key importance here, because of their evolutionary roots and current position in the hierarchy of the components of circadian clocks. They favor the odds for survival from hazards caused by circadian desynchrony and the over-activated brown adipose tissue.	T
CCT251	"I see that there is currently some evidence to suggest that ""the vigorous, the healthy, and the happy"" also have brown adipose tissue which is not easily over-activated. The proteins encoded by the cryptochrome genes (Hsu et al., 1996) are likely to be of key importance here, because of their unique role in the core of circadian transcriptional feedback loops (#CITATION_TAG et al., 2012;Padmanabhan et al., 2012), via their interaction with 5 -AMP-activated protein kinase (Um et al., 2011; for review, see Jordan and Lamia, 2012) whose activity in turn controls the activity of brown adipocytes (L√≥pez et al., 2010). In addition, there is a crossroad of actions at glucocorticoid receptors that provides a link between brown adipocytes and cryptochromes. On the one hand, a nuclear isoform of TRIP6 increases glucocorticoid-receptor-mediated transcription, and it is required for the transrepression of glucocorticoid receptor by NF-Œ∫B (Diefenbacher et al., 2010). On the other hand, cryptochromes directly take part in glucocorticoid-receptor-mediated repression of glucocorticoid synthesis (Lamia et al., 2011), and in blockade of the NF-Œ∫B signaling pathway (Narasimamurthy et al., 2012)."	0	"I see that there is currently some evidence to suggest that ""the vigorous, the healthy, and the happy"" also have brown adipose tissue which is not easily over-activated. The proteins encoded by the cryptochrome genes (Hsu et al., 1996) are likely to be of key importance here, because of their unique role in the core of circadian transcriptional feedback loops (#CITATION_TAG et al., 2012;Padmanabhan et al., 2012), via their interaction with 5 -AMP-activated protein kinase (Um et al., 2011; for review, see Jordan and Lamia, 2012) whose activity in turn controls the activity of brown adipocytes (L√≥pez et al., 2010). In addition, there is a crossroad of actions at glucocorticoid receptors that provides a link between brown adipocytes and cryptochromes. On the one hand, a nuclear isoform of TRIP6 increases glucocorticoid-receptor-mediated transcription, and it is required for the transrepression of glucocorticoid receptor by NF-Œ∫B (Diefenbacher et al., 2010). On the other hand, cryptochromes directly take part in glucocorticoid-receptor-mediated repression of glucocorticoid synthesis (Lamia et al., 2011), and in blockade of the NF-Œ∫B signaling pathway (Narasimamurthy et al., 2012)."	h
CCT252	The circulating blood is a carrier of heat which follows not only the circadian rhythm of core body temperature guided by the suprachiasmatic nuclei (Buhr et al., 2010), but also the ultradian fluctuation in non-shivering thermogenesis generated by brown adipose tissue (#CITATION_TAG et al., 2009). Furthermore, there is an ultradian rhythm of e.g., free corticosterone in the blood (Qian et al., 2012;Waite et al., 2012) that translates into synchronized rhythms of free glucocorticoid hormone in peripheral (the subcutaneous tissue) and central (the hippocampus) tissues (Qian et al., 2012). Ultradian rhythms are superimposed on the circadian rhythms, and under conditions where the circadian rhythms damp out, the ultradian rhythms remain (Eastman and Rechtschaffen, 1983).	4	The circulating blood is a carrier of heat which follows not only the circadian rhythm of core body temperature guided by the suprachiasmatic nuclei (Buhr et al., 2010), but also the ultradian fluctuation in non-shivering thermogenesis generated by brown adipose tissue (#CITATION_TAG et al., 2009). Furthermore, there is an ultradian rhythm of e.g., free corticosterone in the blood (Qian et al., 2012;Waite et al., 2012) that translates into synchronized rhythms of free glucocorticoid hormone in peripheral (the subcutaneous tissue) and central (the hippocampus) tissues (Qian et al., 2012). Ultradian rhythms are superimposed on the circadian rhythms, and under conditions where the circadian rhythms damp out, the ultradian rhythms remain (Eastman and Rechtschaffen, 1983).	T
CCT253	A view that solar radiation and ambient temperature have acted as selective forces among human populations and thereby guided species distributions has gained population genetic support. The genetic basis for adaptation to the climate-mediated selection was elucidated in a recent scan of the human genome using 61 worldwide populations (#CITATION_TAG et al., 2011). Its analysis of the biological pathways that have been targeted by natural selection indicated two sets of genes: genes that are keys to the differentiation of brown adipocytes, and those whose regulation makes a difference in response to ultraviolet radiation.	0	A view that solar radiation and ambient temperature have acted as selective forces among human populations and thereby guided species distributions has gained population genetic support. The genetic basis for adaptation to the climate-mediated selection was elucidated in a recent scan of the human genome using 61 worldwide populations (#CITATION_TAG et al., 2011). Its analysis of the biological pathways that have been targeted by natural selection indicated two sets of genes: genes that are keys to the differentiation of brown adipocytes, and those whose regulation makes a difference in response to ultraviolet radiation.	h
CCT254	"I hypothesize that the CRY1 and CRY2 proteins play this key role in brown adipose tissue, similar to their role in other tissues analyzed so far, where CRY1 (and possibly CRY2 as well) after the encoding gene being induced by melatonin (#CITATION_TAG et al., 2004) might mediate the inhibitory effect of melatonin on cyclic adenosine monophosphate reactions in brown adipocytes. This effect can be achieved directly through interaction of the CRY1 and CRY2 proteins with the G s Œ± subunit of heterotrimeric G protein (Zhang et al., 2010) or that of CRY1 (and possibly CRY2 as well) with adenylyl cyclase (Narasimamurthy et al., 2012). It reduces accumulation of cyclic adenosine monophosphate in response to G protein-coupled receptor activation and leads to inhibition of downstream reactions (Zambon et al., 2005;O""Neill et al., 2008)."	4	"I hypothesize that the CRY1 and CRY2 proteins play this key role in brown adipose tissue, similar to their role in other tissues analyzed so far, where CRY1 (and possibly CRY2 as well) after the encoding gene being induced by melatonin (#CITATION_TAG et al., 2004) might mediate the inhibitory effect of melatonin on cyclic adenosine monophosphate reactions in brown adipocytes. This effect can be achieved directly through interaction of the CRY1 and CRY2 proteins with the G s Œ± subunit of heterotrimeric G protein (Zhang et al., 2010) or that of CRY1 (and possibly CRY2 as well) with adenylyl cyclase (Narasimamurthy et al., 2012). It reduces accumulation of cyclic adenosine monophosphate in response to G protein-coupled receptor activation and leads to inhibition of downstream reactions (Zambon et al., 2005;O""Neill et al., 2008)."	I
CCT255	"I see that there is currently some evidence to suggest that ""the vigorous, the healthy, and the happy"" also have brown adipose tissue which is not easily over-activated. The proteins encoded by the cryptochrome genes (Hsu et al., 1996) are likely to be of key importance here, because of their unique role in the core of circadian transcriptional feedback loops (Hirota et al., 2012;#CITATION_TAG et al., 2012), via their interaction with 5 -AMP-activated protein kinase (Um et al., 2011; for review, see Jordan and Lamia, 2012) whose activity in turn controls the activity of brown adipocytes (L√≥pez et al., 2010). In addition, there is a crossroad of actions at glucocorticoid receptors that provides a link between brown adipocytes and cryptochromes. On the one hand, a nuclear isoform of TRIP6 increases glucocorticoid-receptor-mediated transcription, and it is required for the transrepression of glucocorticoid receptor by NF-Œ∫B (Diefenbacher et al., 2010). On the other hand, cryptochromes directly take part in glucocorticoid-receptor-mediated repression of glucocorticoid synthesis (Lamia et al., 2011), and in blockade of the NF-Œ∫B signaling pathway (Narasimamurthy et al., 2012)."	0	"I see that there is currently some evidence to suggest that ""the vigorous, the healthy, and the happy"" also have brown adipose tissue which is not easily over-activated. The proteins encoded by the cryptochrome genes (Hsu et al., 1996) are likely to be of key importance here, because of their unique role in the core of circadian transcriptional feedback loops (Hirota et al., 2012;#CITATION_TAG et al., 2012), via their interaction with 5 -AMP-activated protein kinase (Um et al., 2011; for review, see Jordan and Lamia, 2012) whose activity in turn controls the activity of brown adipocytes (L√≥pez et al., 2010). In addition, there is a crossroad of actions at glucocorticoid receptors that provides a link between brown adipocytes and cryptochromes. On the one hand, a nuclear isoform of TRIP6 increases glucocorticoid-receptor-mediated transcription, and it is required for the transrepression of glucocorticoid receptor by NF-Œ∫B (Diefenbacher et al., 2010). On the other hand, cryptochromes directly take part in glucocorticoid-receptor-mediated repression of glucocorticoid synthesis (Lamia et al., 2011), and in blockade of the NF-Œ∫B signaling pathway (Narasimamurthy et al., 2012)."	h
CCT256	The resistance of ultradian rhythms to interventions which lengthen the period of free-running circadian rhythms, especially that of nocturnal ultradian rhythms , contrasts with the slowing of other biological timing processes, suggesting unique control mechanisms for generation of ultradian and circadian rhythms . There is evidence that brown adipose tissue may be a site of interaction between metabolic and circadian systems (van der Veen et al., 2012). It appears that a non-transcriptional pathway for the metabolic cycle engages the circadian clock, thereby enhancing clock performance (#CITATION_TAG and Millar, 2012). Changes in the cellular metabolic state could be the cause, not just the result, of neuronal activity (Wang et al., 2012), and if this holds true, then the ultradian rhythms in brown adipose tissue may lead neuronal activity. Importantly, in support to this view, changes in the activity of brown adipose tissue can guide the overall maintenance of the circadian rhythm of core body temperature (Yang et al., 2011).	0	The resistance of ultradian rhythms to interventions which lengthen the period of free-running circadian rhythms, especially that of nocturnal ultradian rhythms , contrasts with the slowing of other biological timing processes, suggesting unique control mechanisms for generation of ultradian and circadian rhythms . There is evidence that brown adipose tissue may be a site of interaction between metabolic and circadian systems (van der Veen et al., 2012). It appears that a non-transcriptional pathway for the metabolic cycle engages the circadian clock, thereby enhancing clock performance (#CITATION_TAG and Millar, 2012). Changes in the cellular metabolic state could be the cause, not just the result, of neuronal activity (Wang et al., 2012), and if this holds true, then the ultradian rhythms in brown adipose tissue may lead neuronal activity. Importantly, in support to this view, changes in the activity of brown adipose tissue can guide the overall maintenance of the circadian rhythm of core body temperature (Yang et al., 2011).	t
CCT257	Lack of this inhibition of downstream reactions in dopaminergic cells, at least in the striatum (Park et al., 2005) but potentially elsewhere as well such as in the ventral tegmental area (Gonzalez and Aston-Jones, 2008;Hampp et al., 2008; for review, see Borrelli et al., 2008), results in increased depression-like behaviors. Under the short photoperiod the melatonin signal is not sufficient to inhibit the cyclic adenosine monophosphate response during the second half of the night (#CITATION_TAG and , but adenosine elicits through the melatonin-sensitized adenosine A 2b receptor an increase in the transcription of cyclic adenosine monophosphate-inducible genes (von Gall et al., 2002), which characterizes the so-called sleep-sensitive circadian period of the individual. Being abnormally activated, or over-activated, this cascade provides a key to the antidepressant action of sleep deprivation protocols in the depressed (Wirz-Justice and Terman, 2012).	4	Lack of this inhibition of downstream reactions in dopaminergic cells, at least in the striatum (Park et al., 2005) but potentially elsewhere as well such as in the ventral tegmental area (Gonzalez and Aston-Jones, 2008;Hampp et al., 2008; for review, see Borrelli et al., 2008), results in increased depression-like behaviors. Under the short photoperiod the melatonin signal is not sufficient to inhibit the cyclic adenosine monophosphate response during the second half of the night (#CITATION_TAG and , but adenosine elicits through the melatonin-sensitized adenosine A 2b receptor an increase in the transcription of cyclic adenosine monophosphate-inducible genes (von Gall et al., 2002), which characterizes the so-called sleep-sensitive circadian period of the individual. Being abnormally activated, or over-activated, this cascade provides a key to the antidepressant action of sleep deprivation protocols in the depressed (Wirz-Justice and Terman, 2012).	n
CCT258	"I see that there is currently some evidence to suggest that ""the vigorous, the healthy, and the happy"" also have brown adipose tissue which is not easily over-activated. The proteins encoded by the cryptochrome genes (Hsu et al., 1996) are likely to be of key importance here, because of their unique role in the core of circadian transcriptional feedback loops (Hirota et al., 2012;Padmanabhan et al., 2012), via their interaction with 5 -AMP-activated protein kinase (Um et al., 2011; for review, see Jordan and Lamia, 2012) whose activity in turn controls the activity of brown adipocytes (L√≥pez et al., 2010). In addition, there is a crossroad of actions at glucocorticoid receptors that provides a link between brown adipocytes and cryptochromes. On the one hand, a nuclear isoform of TRIP6 increases glucocorticoid-receptor-mediated transcription, and it is required for the transrepression of glucocorticoid receptor by NF-Œ∫B (Diefenbacher et al., 2010). On the other hand, cryptochromes directly take part in glucocorticoid-receptor-mediated repression of glucocorticoid synthesis (Lamia et al., 2011), and in blockade of the NF-Œ∫B signaling pathway (#CITATION_TAG et al., 2012)."	0	The proteins encoded by the cryptochrome genes (Hsu et al., 1996) are likely to be of key importance here, because of their unique role in the core of circadian transcriptional feedback loops (Hirota et al., 2012;Padmanabhan et al., 2012), via their interaction with 5 -AMP-activated protein kinase (Um et al., 2011; for review, see Jordan and Lamia, 2012) whose activity in turn controls the activity of brown adipocytes (L√≥pez et al., 2010). In addition, there is a crossroad of actions at glucocorticoid receptors that provides a link between brown adipocytes and cryptochromes. On the one hand, a nuclear isoform of TRIP6 increases glucocorticoid-receptor-mediated transcription, and it is required for the transrepression of glucocorticoid receptor by NF-Œ∫B (Diefenbacher et al., 2010). On the other hand, cryptochromes directly take part in glucocorticoid-receptor-mediated repression of glucocorticoid synthesis (Lamia et al., 2011), and in blockade of the NF-Œ∫B signaling pathway (#CITATION_TAG et al., 2012).	h
CCT259	Brown adipose tissue may in fact be an active pacemaker tissue, having activity in a range of ultradian (Ootsuka et al., 2009) to infradian (#CITATION_TAG et al., 2010) oscillations. Here, I hypothesize that it is so, because (a) in brown adipose tissue, there is abundance of peroxisomes that are responsive to thermogenic stimuli (Bagattin et al., 2010), (b) when brown adipose tissue is activated by cold in humans, glucose uptake increases by 12-fold, accompanied by a twofold increase in perfusion, whereas in response to insulin there is high glucose uptake without increased perfusion (Orava et al., 2011), and (c) the increased glycolytic capacity of brown adipose tissue involves a twofold increase in the activity of phosphofructokinase (Cooney and Newsholme, 1982).	4	Brown adipose tissue may in fact be an active pacemaker tissue, having activity in a range of ultradian (Ootsuka et al., 2009) to infradian (#CITATION_TAG et al., 2010) oscillations. Here, I hypothesize that it is so, because (a) in brown adipose tissue, there is abundance of peroxisomes that are responsive to thermogenic stimuli (Bagattin et al., 2010), (b) when brown adipose tissue is activated by cold in humans, glucose uptake increases by 12-fold, accompanied by a twofold increase in perfusion, whereas in response to insulin there is high glucose uptake without increased perfusion (Orava et al., 2011), and (c) the increased glycolytic capacity of brown adipose tissue involves a twofold increase in the activity of phosphofructokinase (Cooney and Newsholme, 1982).	B
CCT260	"I hypothesize that the CRY1 and CRY2 proteins play this key role in brown adipose tissue, similar to their role in other tissues analyzed so far, where CRY1 (and possibly CRY2 as well) after the encoding gene being induced by melatonin (Hazlerigg et al., 2004) might mediate the inhibitory effect of melatonin on cyclic adenosine monophosphate reactions in brown adipocytes. This effect can be achieved directly through interaction of the CRY1 and CRY2 proteins with the G s Œ± subunit of heterotrimeric G protein (#CITATION_TAG et al., 2010) or that of CRY1 (and possibly CRY2 as well) with adenylyl cyclase (Narasimamurthy et al., 2012). It reduces accumulation of cyclic adenosine monophosphate in response to G protein-coupled receptor activation and leads to inhibition of downstream reactions (Zambon et al., 2005;O""Neill et al., 2008)."	4	"I hypothesize that the CRY1 and CRY2 proteins play this key role in brown adipose tissue, similar to their role in other tissues analyzed so far, where CRY1 (and possibly CRY2 as well) after the encoding gene being induced by melatonin (Hazlerigg et al., 2004) might mediate the inhibitory effect of melatonin on cyclic adenosine monophosphate reactions in brown adipocytes. This effect can be achieved directly through interaction of the CRY1 and CRY2 proteins with the G s Œ± subunit of heterotrimeric G protein (#CITATION_TAG et al., 2010) or that of CRY1 (and possibly CRY2 as well) with adenylyl cyclase (Narasimamurthy et al., 2012). It reduces accumulation of cyclic adenosine monophosphate in response to G protein-coupled receptor activation and leads to inhibition of downstream reactions (Zambon et al., 2005;O""Neill et al., 2008)."	h
CCT261	The resistance of ultradian rhythms to interventions which lengthen the period of free-running circadian rhythms, especially that of nocturnal ultradian rhythms , contrasts with the slowing of other biological timing processes, suggesting unique control mechanisms for generation of ultradian and circadian rhythms . There is evidence that brown adipose tissue may be a site of interaction between metabolic and circadian systems (van der Veen et al., 2012). It appears that a non-transcriptional pathway for the metabolic cycle engages the circadian clock, thereby enhancing clock performance (van Ooijen and Millar, 2012). Changes in the cellular metabolic state could be the cause, not just the result, of neuronal activity (#CITATION_TAG et al., 2012), and if this holds true, then the ultradian rhythms in brown adipose tissue may lead neuronal activity. Importantly, in support to this view, changes in the activity of brown adipose tissue can guide the overall maintenance of the circadian rhythm of core body temperature (Yang et al., 2011).	0	The resistance of ultradian rhythms to interventions which lengthen the period of free-running circadian rhythms, especially that of nocturnal ultradian rhythms , contrasts with the slowing of other biological timing processes, suggesting unique control mechanisms for generation of ultradian and circadian rhythms . There is evidence that brown adipose tissue may be a site of interaction between metabolic and circadian systems (van der Veen et al., 2012). It appears that a non-transcriptional pathway for the metabolic cycle engages the circadian clock, thereby enhancing clock performance (van Ooijen and Millar, 2012). Changes in the cellular metabolic state could be the cause, not just the result, of neuronal activity (#CITATION_TAG et al., 2012), and if this holds true, then the ultradian rhythms in brown adipose tissue may lead neuronal activity. Importantly, in support to this view, changes in the activity of brown adipose tissue can guide the overall maintenance of the circadian rhythm of core body temperature (Yang et al., 2011).	a
CCT262	"In mammals, brown fat has a key role in heat and cold tolerance, since in its activated state it generates heat, a phenomenon called as non-shivering thermogenesis. It is currently evident that brown adipose tissue is a highly active tissue, rather than only ""a form of embryonic adipose tissue"" (Sheldon, 1924) or the so-called hibernating gland, and it is highly prevalent in adult humans (#CITATION_TAG et al., 2011). It can be activated in nearly all but its activity is reduced in those who are overweight or obese (van Marken Lichtenbelt et al., 2009; for review, see Enerb√§ck, 2010)."	4	"In mammals, brown fat has a key role in heat and cold tolerance, since in its activated state it generates heat, a phenomenon called as non-shivering thermogenesis. It is currently evident that brown adipose tissue is a highly active tissue, rather than only ""a form of embryonic adipose tissue"" (Sheldon, 1924) or the so-called hibernating gland, and it is highly prevalent in adult humans (#CITATION_TAG et al., 2011). It can be activated in nearly all but its activity is reduced in those who are overweight or obese (van Marken Lichtenbelt et al., 2009; for review, see Enerb√§ck, 2010)."	t
CCT263	"Here, the CRY1 protein may however be second to the CRY2 protein (Dardente et al., 2007;Wongchitrat et al., 2009;Padmanabhan et al., 2012). This argument is supported by findings from knock-out mice which demonstrate that without the latter one the circadian period is lengthened similar to ""evening owls,"" whereas without the former one it is shortened similar to ""morning larks"" (van der Horst et al., 1999;Vitaterna et al., 1999). It is strengthened further by those which show that the CRY2 gene expression is abnormal when inbred-strain mice with the intrinsic level of high anxiety are deprived of sleep (#CITATION_TAG et al., 2008), and when humans with bipolar type 1 disorder do remain depressed after the antidepressant sleep deprivation (Lavebratt et al., 2010)."	4	"Here, the CRY1 protein may however be second to the CRY2 protein (Dardente et al., 2007;Wongchitrat et al., 2009;Padmanabhan et al., 2012). This argument is supported by findings from knock-out mice which demonstrate that without the latter one the circadian period is lengthened similar to ""evening owls,"" whereas without the former one it is shortened similar to ""morning larks"" (van der Horst et al., 1999;Vitaterna et al., 1999). It is strengthened further by those which show that the CRY2 gene expression is abnormal when inbred-strain mice with the intrinsic level of high anxiety are deprived of sleep (#CITATION_TAG et al., 2008), and when humans with bipolar type 1 disorder do remain depressed after the antidepressant sleep deprivation (Lavebratt et al., 2010)."	 
CCT264	"I see that there is currently some evidence to suggest that ""the vigorous, the healthy, and the happy"" also have brown adipose tissue which is not easily over-activated. The proteins encoded by the cryptochrome genes (Hsu et al., 1996) are likely to be of key importance here, because of their unique role in the core of circadian transcriptional feedback loops (Hirota et al., 2012;Padmanabhan et al., 2012), via their interaction with 5 -AMP-activated protein kinase (Um et al., 2011; for review, see Jordan and Lamia, 2012) whose activity in turn controls the activity of brown adipocytes (L√≥pez et al., 2010). In addition, there is a crossroad of actions at glucocorticoid receptors that provides a link between brown adipocytes and cryptochromes. On the one hand, a nuclear isoform of TRIP6 increases glucocorticoid-receptor-mediated transcription, and it is required for the transrepression of glucocorticoid receptor by NF-Œ∫B (Diefenbacher et al., 2010). On the other hand, cryptochromes directly take part in glucocorticoid-receptor-mediated repression of glucocorticoid synthesis (#CITATION_TAG et al., 2011), and in blockade of the NF-Œ∫B signaling pathway (Narasimamurthy et al., 2012)."	0	The proteins encoded by the cryptochrome genes (Hsu et al., 1996) are likely to be of key importance here, because of their unique role in the core of circadian transcriptional feedback loops (Hirota et al., 2012;Padmanabhan et al., 2012), via their interaction with 5 -AMP-activated protein kinase (Um et al., 2011; for review, see Jordan and Lamia, 2012) whose activity in turn controls the activity of brown adipocytes (L√≥pez et al., 2010). In addition, there is a crossroad of actions at glucocorticoid receptors that provides a link between brown adipocytes and cryptochromes. On the one hand, a nuclear isoform of TRIP6 increases glucocorticoid-receptor-mediated transcription, and it is required for the transrepression of glucocorticoid receptor by NF-Œ∫B (Diefenbacher et al., 2010). On the other hand, cryptochromes directly take part in glucocorticoid-receptor-mediated repression of glucocorticoid synthesis (#CITATION_TAG et al., 2011), and in blockade of the NF-Œ∫B signaling pathway (Narasimamurthy et al., 2012).	h
CCT265	"Currently, it is not known, whether the knock-out or the knockdown of the CRY2 gene in the whole organism or specific to a tissue FIGURE 1 | Scheme of the hypothesis integrating the circadian control, brown adipose tissue activity, and mood. Rapid changes in ambient temperature (cold nights, warm days) which are typical at temperate latitudes during the late-spring activate brown adipose tissue, once being activated it will not cool down easily and remains therefore prone to over-activation. Because of a genetic effect (CRY2 gene mutations or common variants which compromise the function of CRY2 proteins) or abnormalities in the post-translational control of CRY2, brown adipose tissue is over-activated easily. It is currently not known, whether this kind of over-activation of brown adipose tissue, hypothesized to lead to the increased cold tolerance but to cause defect in tolerance to heat, characterizes mood disorders and anxiety disorders, and whether it contributes to the seasonal peaks in their occurrence and mortality rates for deaths from suicide, but it needs to be tested against experiments and observations. produces any change in the activity of brown adipose tissue or in anxiety-like or depressive-like behaviors. Furthermore, it is not yet known how mutated CRY2 proteins (McCarthy et al., 2009) influence. It is of note here that the human CRY2 protein has two isoforms produced by alternative splicing, while the human CRY1 protein has none. This may be relevant if one takes a scenario where there is a link between the circadian clock to cold tolerance (or heat tolerance) and alternative splicing is used to fine-tune the individual""s responses to the environment, similar to that in fruit flies (#CITATION_TAG et al., 1999) or in plants (Seo et al., 2012). To the end I see that there are not yet enough data to conclude, but intuitively it seems essential, that ""the vigorous, the healthy, and the happy"" have fully functional cryptochromes."	0	"produces any change in the activity of brown adipose tissue or in anxiety-like or depressive-like behaviors. Furthermore, it is not yet known how mutated CRY2 proteins (McCarthy et al., 2009) influence. It is of note here that the human CRY2 protein has two isoforms produced by alternative splicing, while the human CRY1 protein has none. This may be relevant if one takes a scenario where there is a link between the circadian clock to cold tolerance (or heat tolerance) and alternative splicing is used to fine-tune the individual""s responses to the environment, similar to that in fruit flies (#CITATION_TAG et al., 1999) or in plants (Seo et al., 2012). To the end I see that there are not yet enough data to conclude, but intuitively it seems essential, that ""the vigorous, the healthy, and the happy"" have fully functional cryptochromes."	y
CCT266	"Currently, it is not known, whether the knock-out or the knockdown of the CRY2 gene in the whole organism or specific to a tissue FIGURE 1 | Scheme of the hypothesis integrating the circadian control, brown adipose tissue activity, and mood. Rapid changes in ambient temperature (cold nights, warm days) which are typical at temperate latitudes during the late-spring activate brown adipose tissue, once being activated it will not cool down easily and remains therefore prone to over-activation. Because of a genetic effect (CRY2 gene mutations or common variants which compromise the function of CRY2 proteins) or abnormalities in the post-translational control of CRY2, brown adipose tissue is over-activated easily. It is currently not known, whether this kind of over-activation of brown adipose tissue, hypothesized to lead to the increased cold tolerance but to cause defect in tolerance to heat, characterizes mood disorders and anxiety disorders, and whether it contributes to the seasonal peaks in their occurrence and mortality rates for deaths from suicide, but it needs to be tested against experiments and observations. produces any change in the activity of brown adipose tissue or in anxiety-like or depressive-like behaviors. Furthermore, it is not yet known how mutated CRY2 proteins (#CITATION_TAG et al., 2009) influence. It is of note here that the human CRY2 protein has two isoforms produced by alternative splicing, while the human CRY1 protein has none. This may be relevant if one takes a scenario where there is a link between the circadian clock to cold tolerance (or heat tolerance) and alternative splicing is used to fine-tune the individual""s responses to the environment, similar to that in fruit flies (Majercak et al., 1999) or in plants (Seo et al., 2012). To the end I see that there are not yet enough data to conclude, but intuitively it seems essential, that ""the vigorous, the healthy, and the happy"" have fully functional cryptochromes."	0	"Because of a genetic effect (CRY2 gene mutations or common variants which compromise the function of CRY2 proteins) or abnormalities in the post-translational control of CRY2, brown adipose tissue is over-activated easily. It is currently not known, whether this kind of over-activation of brown adipose tissue, hypothesized to lead to the increased cold tolerance but to cause defect in tolerance to heat, characterizes mood disorders and anxiety disorders, and whether it contributes to the seasonal peaks in their occurrence and mortality rates for deaths from suicide, but it needs to be tested against experiments and observations. produces any change in the activity of brown adipose tissue or in anxiety-like or depressive-like behaviors. Furthermore, it is not yet known how mutated CRY2 proteins (#CITATION_TAG et al., 2009) influence. It is of note here that the human CRY2 protein has two isoforms produced by alternative splicing, while the human CRY1 protein has none. This may be relevant if one takes a scenario where there is a link between the circadian clock to cold tolerance (or heat tolerance) and alternative splicing is used to fine-tune the individual""s responses to the environment, similar to that in fruit flies (Majercak et al., 1999) or in plants (Seo et al., 2012). To the end I see that there are not yet enough data to conclude, but intuitively it seems essential, that ""the vigorous, the healthy, and the happy"" have fully functional cryptochromes."	e
CCT267	If this holds true, then why there are more morning-types among the elderly? I see that this is due to the cross-sectional study design with which data have been collected. Currently, there are no longitudinal data on the same individuals assessed with the same method available, except from a cohort study in which 190 twins were followed-up for 5 years (#CITATION_TAG et al., 2007). These preliminary results yielded that in 63% of the individuals the chronotype remained the same and in 19% similar, but 7% changed from evening-types to morning-types and 11% from morning-types to evening-types. As such this finding disagrees with the common view according to which persons become more of morning-types with aging.	0	If this holds true, then why there are more morning-types among the elderly? I see that this is due to the cross-sectional study design with which data have been collected. Currently, there are no longitudinal data on the same individuals assessed with the same method available, except from a cohort study in which 190 twins were followed-up for 5 years (#CITATION_TAG et al., 2007). These preliminary results yielded that in 63% of the individuals the chronotype remained the same and in 19% similar, but 7% changed from evening-types to morning-types and 11% from morning-types to evening-types. As such this finding disagrees with the common view according to which persons become more of morning-types with aging.	r
CCT268	If both CRY1 and CRY2 feedback loops are intact, the nuclear ratio of CRY1 to CRY2 proteins controls the period of the circadian clock, more CRY1 causing longer periods and more CRY2 causing shorter periods (Hirota et al., 2012). Similarly, data on the core clock gene encoded proteins (for review, see Ko and Takahashi, 2006) suggest and I speculate here that the nuclear ratio of RORA to RORB may control the period of the circadian clock, more RORA causing longer periods and more RORB leading to shorter periods (for review, see Partonen, 2012). However, there are gaps of knowledge, as the impact of melatonin on transcription of CRY1 (Hazlerigg et al., 2004;MacGregor and Lincoln, 2008), the roles of PER2 and CRY1 as a systematically driven genes that bear a signal of time in a correct phase throughout the tissues (#CITATION_TAG et al., 2007;Hughes et al., 2012), and the cryptochrome-independent influence of the PER2 protein on transcription of the ARNTL (BMAL1) gene (Schmutz et al., 2010;Ye et al., 2011) are not yet understood in depth.	4	If both CRY1 and CRY2 feedback loops are intact, the nuclear ratio of CRY1 to CRY2 proteins controls the period of the circadian clock, more CRY1 causing longer periods and more CRY2 causing shorter periods (Hirota et al., 2012). Similarly, data on the core clock gene encoded proteins (for review, see Ko and Takahashi, 2006) suggest and I speculate here that the nuclear ratio of RORA to RORB may control the period of the circadian clock, more RORA causing longer periods and more RORB leading to shorter periods (for review, see Partonen, 2012). However, there are gaps of knowledge, as the impact of melatonin on transcription of CRY1 (Hazlerigg et al., 2004;MacGregor and Lincoln, 2008), the roles of PER2 and CRY1 as a systematically driven genes that bear a signal of time in a correct phase throughout the tissues (#CITATION_TAG et al., 2007;Hughes et al., 2012), and the cryptochrome-independent influence of the PER2 protein on transcription of the ARNTL (BMAL1) gene (Schmutz et al., 2010;Ye et al., 2011) are not yet understood in depth.	w
CCT269	"An explanation may be, and I call it here as the diurnal owl hypothesis, that evening-type of persons (""evening owls"") tend to die younger than morning-type of persons (""morning larks""), but whether this is because of a drive for delays in chronotype and subsequent circadian desynchrony, it is not known and needs verification. However, this view might not be far-fetched, since thus far all the health hazards assessed appear to cluster and be more frequent among the evening-types, including unhealthy dietary habits (Kanerva et al., 2012), smoking and nicotine dependence (Broms et al., 2012), and the increased odds for depressive, anxiety, and substance use disorders (Reid et al., 2012), insomnia (#CITATION_TAG et al., 2012a), hypertension, and type 2 diabetes (Merikanto et al., 2012b). Evening-types by definition do have greater deviations of their circadian period from the 24 h cycle on average than others (Duffy et al., 2001), but it is not currently known in detail how this property might link to a greater morbidity or mortality in humans."	0	"An explanation may be, and I call it here as the diurnal owl hypothesis, that evening-type of persons (""evening owls"") tend to die younger than morning-type of persons (""morning larks""), but whether this is because of a drive for delays in chronotype and subsequent circadian desynchrony, it is not known and needs verification. However, this view might not be far-fetched, since thus far all the health hazards assessed appear to cluster and be more frequent among the evening-types, including unhealthy dietary habits (Kanerva et al., 2012), smoking and nicotine dependence (Broms et al., 2012), and the increased odds for depressive, anxiety, and substance use disorders (Reid et al., 2012), insomnia (#CITATION_TAG et al., 2012a), hypertension, and type 2 diabetes (Merikanto et al., 2012b). Evening-types by definition do have greater deviations of their circadian period from the 24 h cycle on average than others (Duffy et al., 2001), but it is not currently known in detail how this property might link to a greater morbidity or mortality in humans."	o
CCT270	If both CRY1 and CRY2 feedback loops are intact, the nuclear ratio of CRY1 to CRY2 proteins controls the period of the circadian clock, more CRY1 causing longer periods and more CRY2 causing shorter periods (Hirota et al., 2012). Similarly, data on the core clock gene encoded proteins (for review, see #CITATION_TAG and Takahashi, 2006) suggest and I speculate here that the nuclear ratio of RORA to RORB may control the period of the circadian clock, more RORA causing longer periods and more RORB leading to shorter periods (for review, see Partonen, 2012). However, there are gaps of knowledge, as the impact of melatonin on transcription of CRY1 (Hazlerigg et al., 2004;MacGregor and Lincoln, 2008), the roles of PER2 and CRY1 as a systematically driven genes that bear a signal of time in a correct phase throughout the tissues (Kornmann et al., 2007;Hughes et al., 2012), and the cryptochrome-independent influence of the PER2 protein on transcription of the ARNTL (BMAL1) gene (Schmutz et al., 2010;Ye et al., 2011) are not yet understood in depth.	0	If both CRY1 and CRY2 feedback loops are intact, the nuclear ratio of CRY1 to CRY2 proteins controls the period of the circadian clock, more CRY1 causing longer periods and more CRY2 causing shorter periods (Hirota et al., 2012). Similarly, data on the core clock gene encoded proteins (for review, see #CITATION_TAG and Takahashi, 2006) suggest and I speculate here that the nuclear ratio of RORA to RORB may control the period of the circadian clock, more RORA causing longer periods and more RORB leading to shorter periods (for review, see Partonen, 2012). However, there are gaps of knowledge, as the impact of melatonin on transcription of CRY1 (Hazlerigg et al., 2004;MacGregor and Lincoln, 2008), the roles of PER2 and CRY1 as a systematically driven genes that bear a signal of time in a correct phase throughout the tissues (Kornmann et al., 2007;Hughes et al., 2012), and the cryptochrome-independent influence of the PER2 protein on transcription of the ARNTL (BMAL1) gene (Schmutz et al., 2010;Ye et al., 2011) are not yet understood in depth.	i
CCT271	"Normally, natural environmental light and ambient temperature of the external 24 h cycle act together to dictate the phase and to entrain circadian clocks (Boothroyd et al., 2007), but the change of seasons tends to challenge their functions, and therefore, for example, in plants the lengthened period serves to delay the onset of flowering until later in the season, and it could prove advantageous in avoiding the late-spring light but cold weather (#CITATION_TAG et al., 2003). Since most biochemical reactions respond robustly to temperature, the evolution of mechanisms to buffer the effects of day-to-day changes in ambient temperature is expected to favor adaptation (Fran√ßois et al., 2012). Pittendrigh and Takamura (1987) discovered that change in the level of response to all night-length measurements (durations of nighttime darkness, rather than those of day-length) is a fundamental property of the circadian clock, and that adjustment to temperature and latitude are not separate: at each new latitude invaded by fruit flies, natural selection retunes the temperature dependence of photoperiodic responses to assure that the individual""s reproductive activity will exploit the same temperature range to which the rest of its physiology has adapted at earlier latitudes (Pittendrigh, 1993). It is of note, concerning dayactive animals here, that transcription of the cryptochrome genes is induced in the evening (Lincoln et al., 2002), and that the heatinduced phase shifts of the circadian clock are severely reduced in the cryptochrome loss-of-function mutants (Kaushik et al., 2007)."	0	"Normally, natural environmental light and ambient temperature of the external 24 h cycle act together to dictate the phase and to entrain circadian clocks (Boothroyd et al., 2007), but the change of seasons tends to challenge their functions, and therefore, for example, in plants the lengthened period serves to delay the onset of flowering until later in the season, and it could prove advantageous in avoiding the late-spring light but cold weather (#CITATION_TAG et al., 2003). Since most biochemical reactions respond robustly to temperature, the evolution of mechanisms to buffer the effects of day-to-day changes in ambient temperature is expected to favor adaptation (Fran√ßois et al., 2012). Pittendrigh and Takamura (1987) discovered that change in the level of response to all night-length measurements (durations of nighttime darkness, rather than those of day-length) is a fundamental property of the circadian clock, and that adjustment to temperature and latitude are not separate: at each new latitude invaded by fruit flies, natural selection retunes the temperature dependence of photoperiodic responses to assure that the individual""s reproductive activity will exploit the same temperature range to which the rest of its physiology has adapted at earlier latitudes (Pittendrigh, 1993). It is of note, concerning dayactive animals here, that transcription of the cryptochrome genes is induced in the evening (Lincoln et al., 2002), and that the heatinduced phase shifts of the circadian clock are severely reduced in the cryptochrome loss-of-function mutants (Kaushik et al., 2007)."	N
CCT272	The circulating blood is a carrier of heat which follows not only the circadian rhythm of core body temperature guided by the suprachiasmatic nuclei (Buhr et al., 2010), but also the ultradian fluctuation in non-shivering thermogenesis generated by brown adipose tissue (Ootsuka et al., 2009). Furthermore, there is an ultradian rhythm of e.g., free corticosterone in the blood (Qian et al., 2012;#CITATION_TAG et al., 2012) that translates into synchronized rhythms of free glucocorticoid hormone in peripheral (the subcutaneous tissue) and central (the hippocampus) tissues (Qian et al., 2012). Ultradian rhythms are superimposed on the circadian rhythms, and under conditions where the circadian rhythms damp out, the ultradian rhythms remain (Eastman and Rechtschaffen, 1983).	0	The circulating blood is a carrier of heat which follows not only the circadian rhythm of core body temperature guided by the suprachiasmatic nuclei (Buhr et al., 2010), but also the ultradian fluctuation in non-shivering thermogenesis generated by brown adipose tissue (Ootsuka et al., 2009). Furthermore, there is an ultradian rhythm of e.g., free corticosterone in the blood (Qian et al., 2012;#CITATION_TAG et al., 2012) that translates into synchronized rhythms of free glucocorticoid hormone in peripheral (the subcutaneous tissue) and central (the hippocampus) tissues (Qian et al., 2012). Ultradian rhythms are superimposed on the circadian rhythms, and under conditions where the circadian rhythms damp out, the ultradian rhythms remain (Eastman and Rechtschaffen, 1983).	u
CCT273	"Evidence of increased mortality associated with mental illness has been derived from linked database studies, reviews of autopsy records and population-based cohort studies. Although suicide is an important cause of death linked to mental illness, increased mortality among people with mental illness mainly results from ""natural"" causes, such as cardiovascular disease, cancers and respiratory disease (De Hert et al 2009). Increased mortality is particularly associated with people who have substance misuse disorders and severe mental illness (psychosis) (#CITATION_TAG et al 2010). Studies of the life expectancy of people with mental health disorders have estimated 17 life years lost for substance misuse and 10-15 years for schizophrenia, compared with the general population (Chang et al 2011)."	0	"Evidence of increased mortality associated with mental illness has been derived from linked database studies, reviews of autopsy records and population-based cohort studies. Although suicide is an important cause of death linked to mental illness, increased mortality among people with mental illness mainly results from ""natural"" causes, such as cardiovascular disease, cancers and respiratory disease (De Hert et al 2009). Increased mortality is particularly associated with people who have substance misuse disorders and severe mental illness (psychosis) (#CITATION_TAG et al 2010). Studies of the life expectancy of people with mental health disorders have estimated 17 life years lost for substance misuse and 10-15 years for schizophrenia, compared with the general population (Chang et al 2011)."	c
CCT274	Mental health problems are widespread, however there are differences in the distribution of certain conditions among men and women, and their effects. The effects of health problems may be compounded by different approaches to seeking help between men and women, with men seeking help less frequently than women (Galdas et al 2005), particularly for psychological problems (#CITATION_TAG et al 2006). Women are nearly twice as likely to develop depression and some anxiety disorders as men, and around three times more likely to develop an eating disorder (WHO 2012a). The misuse of alcohol and drugs is three to four times more common in men, as is antisocial personality disorder (WHO 2012a).	0	Mental health problems are widespread, however there are differences in the distribution of certain conditions among men and women, and their effects. The effects of health problems may be compounded by different approaches to seeking help between men and women, with men seeking help less frequently than women (Galdas et al 2005), particularly for psychological problems (#CITATION_TAG et al 2006). Women are nearly twice as likely to develop depression and some anxiety disorders as men, and around three times more likely to develop an eating disorder (WHO 2012a). The misuse of alcohol and drugs is three to four times more common in men, as is antisocial personality disorder (WHO 2012a).	h
CCT275	Certain occupations are associated with increased risk of suicide. Men and women working as healthcare professionals have significantly higher mortality rates associated with suicide than the general population (Hawton and van Heeringen 2009). Nurses of both genders also have increased suicide mortality rates compared to the general population (Hawton and van Heeringen 2009). There is also increased risk of suicide among men working in construction and agricultural occupations (#CITATION_TAG et al 2008). This is likely to be related to the access that these individuals may have to means of committing suicide, such as drugs, firearms and dangerous equipment.	0	Certain occupations are associated with increased risk of suicide. Men and women working as healthcare professionals have significantly higher mortality rates associated with suicide than the general population (Hawton and van Heeringen 2009). Nurses of both genders also have increased suicide mortality rates compared to the general population (Hawton and van Heeringen 2009). There is also increased risk of suicide among men working in construction and agricultural occupations (#CITATION_TAG et al 2008). This is likely to be related to the access that these individuals may have to means of committing suicide, such as drugs, firearms and dangerous equipment.	r
CCT276	Ideas of suicide, acts of self-harm and completed suicide are associated with mental health problems, with approximately 90% of people who complete suicide having a diagnosable mental disorder, although only half of these individuals will have had a history of involvement with mental health services (Luoma et al 2002). Several health problems are associated with increased risk of suicide, and depression appears to be the most important mental disorder for suicidal ideation and behaviour among all age groups (#CITATION_TAG et al 2005). Other mental disorders that may be associated with suicide include bipolar affective disorder, schizophrenia, and alcohol dependence and addiction to other substances (Hawton and van Heeringen 2009).	4	Ideas of suicide, acts of self-harm and completed suicide are associated with mental health problems, with approximately 90% of people who complete suicide having a diagnosable mental disorder, although only half of these individuals will have had a history of involvement with mental health services (Luoma et al 2002). Several health problems are associated with increased risk of suicide, and depression appears to be the most important mental disorder for suicidal ideation and behaviour among all age groups (#CITATION_TAG et al 2005). Other mental disorders that may be associated with suicide include bipolar affective disorder, schizophrenia, and alcohol dependence and addiction to other substances (Hawton and van Heeringen 2009).	e
CCT277	"The most common mental disorder in childhood is conduct disorder, characterised by persistent defiant and antisocial behaviour. The disorder is twice as common in boys as girls, affecting 8% of boys and 4% of girls in Great Britain (#CITATION_TAG et al 2005). Hyperkinetic disorder and ADHD are more common in boys and men: in Great Britain, eight times as many boys as girls have hyperkinetic disorder (Green et al 2005). Findings from the most recent national adult household study of mental disorders in England for key conditions exhibiting marked gender differences in prevalence are shown in  There are particular groups in society at increased risk of mental ill health, such as ""looked-after children"" (children looked after by the state or in the care system), refugees, homeless rough sleepers and those in prison. Some of these groups, such as offenders in prison and homeless people, are mainly comprised of men. The US federal inmate population is 93.5% male (US Department of Justice 2012) and in England and Wales, males make up 95.2% of this population (Berman 2012). Nine out of ten rough sleepers in the UK are estimated to be male (Crisis 2012). These groups are particularly vulnerable to mental health problems, most commonly alcohol and substance misuse, and personality disorders. They are also vulnerable to mortality from accidents, violence and suicide."	0	"The most common mental disorder in childhood is conduct disorder, characterised by persistent defiant and antisocial behaviour. The disorder is twice as common in boys as girls, affecting 8% of boys and 4% of girls in Great Britain (#CITATION_TAG et al 2005). Hyperkinetic disorder and ADHD are more common in boys and men: in Great Britain, eight times as many boys as girls have hyperkinetic disorder (Green et al 2005). Findings from the most recent national adult household study of mental disorders in England for key conditions exhibiting marked gender differences in prevalence are shown in  There are particular groups in society at increased risk of mental ill health, such as ""looked-after children"" (children looked after by the state or in the care system), refugees, homeless rough sleepers and those in prison. Some of these groups, such as offenders in prison and homeless people, are mainly comprised of men."	h
CCT278	Mental health problems are widespread, however there are differences in the distribution of certain conditions among men and women, and their effects. The effects of health problems may be compounded by different approaches to seeking help between men and women, with men seeking help less frequently than women (#CITATION_TAG et al 2005), particularly for psychological problems (Smith et al 2006). Women are nearly twice as likely to develop depression and some anxiety disorders as men, and around three times more likely to develop an eating disorder (WHO 2012a). The misuse of alcohol and drugs is three to four times more common in men, as is antisocial personality disorder (WHO 2012a).	0	Mental health problems are widespread, however there are differences in the distribution of certain conditions among men and women, and their effects. The effects of health problems may be compounded by different approaches to seeking help between men and women, with men seeking help less frequently than women (#CITATION_TAG et al 2005), particularly for psychological problems (Smith et al 2006). Women are nearly twice as likely to develop depression and some anxiety disorders as men, and around three times more likely to develop an eating disorder (WHO 2012a). The misuse of alcohol and drugs is three to four times more common in men, as is antisocial personality disorder (WHO 2012a).	h
CCT279	"Initiatives focused on young men""s mental health in Northern Ireland have sought to educate clinicians and young men through a programme of seminars and associated projects about mental health, and provide guidance in engaging and supporting emotional health and self-esteem. Several evaluations of pilot projects designed specifically for men""s mental health and suicide risk have been conducted (#CITATION_TAG and Storey 2006). These involved delivering staff training in education settings, social and youth services, employment services, homeless organisations, and drug and alcohol agencies, as well as working directly with young men perceived to be at high risk of mental health problems. These projects provided interesting, but inconclusive findings, identifying challenges associated with engaging young men, and enabling mental health issues to be raised and shared (Oliver and Storey 2006)."	4	"Initiatives focused on young men""s mental health in Northern Ireland have sought to educate clinicians and young men through a programme of seminars and associated projects about mental health, and provide guidance in engaging and supporting emotional health and self-esteem. Several evaluations of pilot projects designed specifically for men""s mental health and suicide risk have been conducted (#CITATION_TAG and Storey 2006). These involved delivering staff training in education settings, social and youth services, employment services, homeless organisations, and drug and alcohol agencies, as well as working directly with young men perceived to be at high risk of mental health problems. These projects provided interesting, but inconclusive findings, identifying challenges associated with engaging young men, and enabling mental health issues to be raised and shared (Oliver and Storey 2006)."	e
CCT280	Ideas of suicide, acts of self-harm and completed suicide are associated with mental health problems, with approximately 90% of people who complete suicide having a diagnosable mental disorder, although only half of these individuals will have had a history of involvement with mental health services (#CITATION_TAG et al 2002). Several health problems are associated with increased risk of suicide, and depression appears to be the most important mental disorder for suicidal ideation and behaviour among all age groups (Mann et al 2005). Other mental disorders that may be associated with suicide include bipolar affective disorder, schizophrenia, and alcohol dependence and addiction to other substances (Hawton and van Heeringen 2009).	0	Ideas of suicide, acts of self-harm and completed suicide are associated with mental health problems, with approximately 90% of people who complete suicide having a diagnosable mental disorder, although only half of these individuals will have had a history of involvement with mental health services (#CITATION_TAG et al 2002). Several health problems are associated with increased risk of suicide, and depression appears to be the most important mental disorder for suicidal ideation and behaviour among all age groups (Mann et al 2005). Other mental disorders that may be associated with suicide include bipolar affective disorder, schizophrenia, and alcohol dependence and addiction to other substances (Hawton and van Heeringen 2009).	I
CCT281	In England in 2007, the direct costs of mental illness, incorporating NHS, social care and other agency costs, were ¬£22.5 billion. Indirect costs of lost employment were estimated to be an additional ¬£26.1 billion (#CITATION_TAG et al 2008). Including the wider costs to the economy in England, such as that related to informal care, has resulted in cost estimates of ¬£77 billion per year (Sainsbury Centre for Mental Health 2003). Evidence about the extent of social and economic costs of mental health problems has contributed to increased recognition of the need to promote positive mental health and wellbeing, and invest in approaches to prevent the onset of such problems (National Mental Health Development Unit 2010a, 2010b).	0	In England in 2007, the direct costs of mental illness, incorporating NHS, social care and other agency costs, were ¬£22.5 billion. Indirect costs of lost employment were estimated to be an additional ¬£26.1 billion (#CITATION_TAG et al 2008). Including the wider costs to the economy in England, such as that related to informal care, has resulted in cost estimates of ¬£77 billion per year (Sainsbury Centre for Mental Health 2003). Evidence about the extent of social and economic costs of mental health problems has contributed to increased recognition of the need to promote positive mental health and wellbeing, and invest in approaches to prevent the onset of such problems (National Mental Health Development Unit 2010a, 2010b).	n
CCT282	It appears that in response to stressors, there may be a tendency for women to internalise emotions, possibly leading to withdrawal, anxiety and depression, while men may be more likely to externalise emotions, leading to aggressive, impulsive or antisocial behaviour (Eaton et al 2012). Gender differences in the prevalence of these conditions appear to relate to a complex array of influences rather than simple biological factors, and these differences interact with social markers such as education, income, housing tenure, employment, marital status and ethnicity (WHO 2012a). For example, although lower socio-economic status is associated with increased prevalence of common mental disorders, its influence may be more pronounced among men: those with the lowest household income in England were found to be three times more likely to have depression or an anxiety condition as those in the highest income households (23.5% and 8.8% respectively), while for women, household income appeared to have less of an influence on mental health (#CITATION_TAG et al 2009). Job insecurity and high levels of job strain have been identified as risk factors for depression (Wang et al 2012). Links have also been made between the economic recession and its effects on work and traditional roles, particularly in terms of increased likelihood of depression among men (Dunlop and Mletzko 2011). Analysis of suicide rates in England reveals that regions with the greatest rise in unemployment related to the economic recession have had the greatest rise in suicide rates, particularly among men (Barr et al 2012).	4	It appears that in response to stressors, there may be a tendency for women to internalise emotions, possibly leading to withdrawal, anxiety and depression, while men may be more likely to externalise emotions, leading to aggressive, impulsive or antisocial behaviour (Eaton et al 2012). Gender differences in the prevalence of these conditions appear to relate to a complex array of influences rather than simple biological factors, and these differences interact with social markers such as education, income, housing tenure, employment, marital status and ethnicity (WHO 2012a). For example, although lower socio-economic status is associated with increased prevalence of common mental disorders, its influence may be more pronounced among men: those with the lowest household income in England were found to be three times more likely to have depression or an anxiety condition as those in the highest income households (23.5% and 8.8% respectively), while for women, household income appeared to have less of an influence on mental health (#CITATION_TAG et al 2009). Job insecurity and high levels of job strain have been identified as risk factors for depression (Wang et al 2012). Links have also been made between the economic recession and its effects on work and traditional roles, particularly in terms of increased likelihood of depression among men (Dunlop and Mletzko 2011). Analysis of suicide rates in England reveals that regions with the greatest rise in unemployment related to the economic recession have had the greatest rise in suicide rates, particularly among men (Barr et al 2012).	r
CCT283	Evidence from the WHO World Health Survey, involving nearly 250,000 participants from 60 countries in all world regions, indicated that having one or more long-term physical conditions was associated with a more than threefold increase in the prevalence of depression ( #CITATION_TAG et al 2007)	4	Evidence from the WHO World Health Survey, involving nearly 250,000 participants from 60 countries in all world regions, indicated that having one or more long-term physical conditions was associated with a more than threefold increase in the prevalence of depression ( #CITATION_TAG et al 2007)	E
CCT284	An increased risk of death from all causes is not restricted to the most severe mental illnesses, but is also associated with conditions such as depression and anxiety disorders (#CITATION_TAG 2001). Depression is associated with a near doubling of all-cause mortality rates (Saz andDewey 2001, Cuijpers andSmit 2002). This is important because the high prevalence of these common mental health problems means that there is a significant overall effect on mortality.	0	An increased risk of death from all causes is not restricted to the most severe mental illnesses, but is also associated with conditions such as depression and anxiety disorders (#CITATION_TAG 2001). Depression is associated with a near doubling of all-cause mortality rates (Saz andDewey 2001, Cuijpers andSmit 2002). This is important because the high prevalence of these common mental health problems means that there is a significant overall effect on mortality.	A
CCT285	The cost of mental health problems should be viewed in relation to the individual, society and the economy. Mental health problems often arise and cause disability at a time when the person affected would be at his or her most productive. For example, the teenage years are associated increasingly with incidence of mental health problems, with half of all lifetime cases of mental illness commencing by the age of 14 (#CITATION_TAG et al 2005), exacerbated by increased incidence of relapse and persistence.	0	The cost of mental health problems should be viewed in relation to the individual, society and the economy. Mental health problems often arise and cause disability at a time when the person affected would be at his or her most productive. For example, the teenage years are associated increasingly with incidence of mental health problems, with half of all lifetime cases of mental illness commencing by the age of 14 (#CITATION_TAG et al 2005), exacerbated by increased incidence of relapse and persistence.	r
CCT286	There is an increased risk of suicide and deliberate self-harm in men and women who are unemployed (Kposowa 2001), although findings suggest that risks may be increased for unemployed men (Ying and Chang 2009). Risks of self-harm and suicide are increased among particular groups who are marginalised within society. As previously noted, offenders in prison and homeless people are particularly vulnerable, with male prisoners five times more likely to die by suicide than men in the general population (#CITATION_TAG et al 2010), and a sevenfold increased risk of suicide in homeless men (Nielsen et al 2011).	4	There is an increased risk of suicide and deliberate self-harm in men and women who are unemployed (Kposowa 2001), although findings suggest that risks may be increased for unemployed men (Ying and Chang 2009). Risks of self-harm and suicide are increased among particular groups who are marginalised within society. As previously noted, offenders in prison and homeless people are particularly vulnerable, with male prisoners five times more likely to die by suicide than men in the general population (#CITATION_TAG et al 2010), and a sevenfold increased risk of suicide in homeless men (Nielsen et al 2011).	 
CCT287	Several prospective studies (Stansfeld et al 2002, #CITATION_TAG et al 2004, and a pooled analysis of population survey findings linked to death certification (Russ et al 2012), provided evidence that reduced life expectancy is not limited to specific diagnosed mental illnesses. It appears that there is a significant relationship between psychological distress and premature mortality. Findings based on nearly 70,000 adults from ten household population-based studies in England, showed that after controlling for confounding factors, all-cause mortality was increased by between 20% and 70% according to the level of psychological distress experienced (Russ et al 2012). Effects were examined in relation to death from three major causes: cancer, cardiovascular disease and external causes such as unintentional accidents, assault, homicide and intentional self-harm. An increase in all categories was associated with all levels of emotional distress, although effects on mortality were pronounced for higher levels of distress, and greatest for cardiovascular disease (an increase of between 25% and 70%) and external causes (up to threefold increase among those with high distress levels) (Russ et al 2012).	0	Several prospective studies (Stansfeld et al 2002, #CITATION_TAG et al 2004, and a pooled analysis of population survey findings linked to death certification (Russ et al 2012), provided evidence that reduced life expectancy is not limited to specific diagnosed mental illnesses. It appears that there is a significant relationship between psychological distress and premature mortality. Findings based on nearly 70,000 adults from ten household population-based studies in England, showed that after controlling for confounding factors, all-cause mortality was increased by between 20% and 70% according to the level of psychological distress experienced (Russ et al 2012). Effects were examined in relation to death from three major causes: cancer, cardiovascular disease and external causes such as unintentional accidents, assault, homicide and intentional self-harm.	S
CCT288	An increased risk of death from all causes is not restricted to the most severe mental illnesses, but is also associated with conditions such as depression and anxiety disorders (Osborn 2001). Depression is associated with a near doubling of all-cause mortality rates (#CITATION_TAG andDewey 2001, Cuijpers andSmit 2002). This is important because the high prevalence of these common mental health problems means that there is a significant overall effect on mortality.	0	An increased risk of death from all causes is not restricted to the most severe mental illnesses, but is also associated with conditions such as depression and anxiety disorders (Osborn 2001). Depression is associated with a near doubling of all-cause mortality rates (#CITATION_TAG andDewey 2001, Cuijpers andSmit 2002). This is important because the high prevalence of these common mental health problems means that there is a significant overall effect on mortality.	e
CCT289	Selective approaches are used to prevent the onset of postpartum depression by identifying mothers who are at risk of developing the condition and providing individual support for postnatal women through intensive home visits by nurses and health visitors (Dennis and Creedy 2004). In addition, there is evidence that eating disorder prevention programmes delivered to at-risk females are effective in reducing risk factors involved in the development of eating disorders such as body dissatisfaction (#CITATION_TAG et al 2007).	0	Selective approaches are used to prevent the onset of postpartum depression by identifying mothers who are at risk of developing the condition and providing individual support for postnatal women through intensive home visits by nurses and health visitors (Dennis and Creedy 2004). In addition, there is evidence that eating disorder prevention programmes delivered to at-risk females are effective in reducing risk factors involved in the development of eating disorders such as body dissatisfaction (#CITATION_TAG et al 2007).	n
CCT290	Health promotion at the individual level seeks to develop protective factors such as feeling valued and supported, together with a sense of hopefulness about the future. Awareness of risk factors for mental health problems, such as neglect or abuse in early life, bereavement and loss, carer burdens and family history of mental disorders, may provide opportunities for specific preventive and supportive interventions (#CITATION_TAG et al 2007).	4	Health promotion at the individual level seeks to develop protective factors such as feeling valued and supported, together with a sense of hopefulness about the future. Awareness of risk factors for mental health problems, such as neglect or abuse in early life, bereavement and loss, carer burdens and family history of mental disorders, may provide opportunities for specific preventive and supportive interventions (#CITATION_TAG et al 2007).	w
CCT291	The effect of mental health problems also relates to when they first began. Although mental health problems may occur at any age, onset is typically in childhood or adolescence, although treatment often does not begin until many years later (#CITATION_TAG et al 2007). Evidence from large-scale international population studies indicates that the median age of onset is earliest for phobias, attention deficit hyperactivity disorder (ADHD) and conduct disorder, which usually arise in childhood or the early teenage years. Anxiety disorders other than phobiaswhich include generalised anxiety disorder and panic disorder, depression, alcohol and substance misuse disorders, and schizophreniabegin most commonly between the late teens and early adulthood (Kessler et al 2007). Because of the typically early age of onset of mental health problems, there is increased likelihood for disruption of educational performance, personal relationships and social participation, with consequent effects on employment and income.	0	The effect of mental health problems also relates to when they first began. Although mental health problems may occur at any age, onset is typically in childhood or adolescence, although treatment often does not begin until many years later (#CITATION_TAG et al 2007). Evidence from large-scale international population studies indicates that the median age of onset is earliest for phobias, attention deficit hyperactivity disorder (ADHD) and conduct disorder, which usually arise in childhood or the early teenage years. Anxiety disorders other than phobiaswhich include generalised anxiety disorder and panic disorder, depression, alcohol and substance misuse disorders, and schizophreniabegin most commonly between the late teens and early adulthood (Kessler et al 2007). Because of the typically early age of onset of mental health problems, there is increased likelihood for disruption of educational performance, personal relationships and social participation, with consequent effects on employment and income.	l
CCT292	It appears that in response to stressors, there may be a tendency for women to internalise emotions, possibly leading to withdrawal, anxiety and depression, while men may be more likely to externalise emotions, leading to aggressive, impulsive or antisocial behaviour (Eaton et al 2012). Gender differences in the prevalence of these conditions appear to relate to a complex array of influences rather than simple biological factors, and these differences interact with social markers such as education, income, housing tenure, employment, marital status and ethnicity (WHO 2012a). For example, although lower socio-economic status is associated with increased prevalence of common mental disorders, its influence may be more pronounced among men: those with the lowest household income in England were found to be three times more likely to have depression or an anxiety condition as those in the highest income households (23.5% and 8.8% respectively), while for women, household income appeared to have less of an influence on mental health (McManus et al 2009). Job insecurity and high levels of job strain have been identified as risk factors for depression (#CITATION_TAG et al 2012). Links have also been made between the economic recession and its effects on work and traditional roles, particularly in terms of increased likelihood of depression among men (Dunlop and Mletzko 2011). Analysis of suicide rates in England reveals that regions with the greatest rise in unemployment related to the economic recession have had the greatest rise in suicide rates, particularly among men (Barr et al 2012).	4	It appears that in response to stressors, there may be a tendency for women to internalise emotions, possibly leading to withdrawal, anxiety and depression, while men may be more likely to externalise emotions, leading to aggressive, impulsive or antisocial behaviour (Eaton et al 2012). Gender differences in the prevalence of these conditions appear to relate to a complex array of influences rather than simple biological factors, and these differences interact with social markers such as education, income, housing tenure, employment, marital status and ethnicity (WHO 2012a). For example, although lower socio-economic status is associated with increased prevalence of common mental disorders, its influence may be more pronounced among men: those with the lowest household income in England were found to be three times more likely to have depression or an anxiety condition as those in the highest income households (23.5% and 8.8% respectively), while for women, household income appeared to have less of an influence on mental health (McManus et al 2009). Job insecurity and high levels of job strain have been identified as risk factors for depression (#CITATION_TAG et al 2012). Links have also been made between the economic recession and its effects on work and traditional roles, particularly in terms of increased likelihood of depression among men (Dunlop and Mletzko 2011). Analysis of suicide rates in England reveals that regions with the greatest rise in unemployment related to the economic recession have had the greatest rise in suicide rates, particularly among men (Barr et al 2012).	 
CCT293	There are variations in the suicide rates for different parts of the world, with the highest rates in the Russian Federation, Baltic States, Sri Lanka and Japan, and the lowest rates in Latin America (Haddad and Gunn 2011). Although suicide rates are highest in older people in most countries, it is one of the three leading causes of death among those aged 15-44 (WHO 2012b). Suicide rates have risen in young people, especially men. In 21 of the 30 countries in the WHO European region, suicide rates in young men aged 15-19 increased between 1979 and 1996, and similar changes in suicide rates were evident in Australia and the US (#CITATION_TAGet al 2005). However, suicide rates in young men have generally decreased in the UK over the past decade (Samaritans 2012), although this trend has altered since 2008, with an increase in suicide among men and women that appears to be linked to the economic recession and in particular, rising unemployment (Barr et al 2012).	0	There are variations in the suicide rates for different parts of the world, with the highest rates in the Russian Federation, Baltic States, Sri Lanka and Japan, and the lowest rates in Latin America (Haddad and Gunn 2011). Although suicide rates are highest in older people in most countries, it is one of the three leading causes of death among those aged 15-44 (WHO 2012b). Suicide rates have risen in young people, especially men. In 21 of the 30 countries in the WHO European region, suicide rates in young men aged 15-19 increased between 1979 and 1996, and similar changes in suicide rates were evident in Australia and the US (#CITATION_TAGet al 2005). However, suicide rates in young men have generally decreased in the UK over the past decade (Samaritans 2012), although this trend has altered since 2008, with an increase in suicide among men and women that appears to be linked to the economic recession and in particular, rising unemployment (Barr et al 2012).	2
CCT294	There is an increased risk of suicide and deliberate self-harm in men and women who are unemployed (#CITATION_TAG 2001), although findings suggest that risks may be increased for unemployed men (Ying and Chang 2009). Risks of self-harm and suicide are increased among particular groups who are marginalised within society. As previously noted, offenders in prison and homeless people are particularly vulnerable, with male prisoners five times more likely to die by suicide than men in the general population (Rivlin et al 2010), and a sevenfold increased risk of suicide in homeless men (Nielsen et al 2011).	0	There is an increased risk of suicide and deliberate self-harm in men and women who are unemployed (#CITATION_TAG 2001), although findings suggest that risks may be increased for unemployed men (Ying and Chang 2009). Risks of self-harm and suicide are increased among particular groups who are marginalised within society. As previously noted, offenders in prison and homeless people are particularly vulnerable, with male prisoners five times more likely to die by suicide than men in the general population (Rivlin et al 2010), and a sevenfold increased risk of suicide in homeless men (Nielsen et al 2011).	T
CCT295	There is an increased risk of suicide and deliberate self-harm in men and women who are unemployed (Kposowa 2001), although findings suggest that risks may be increased for unemployed men (#CITATION_TAG and Chang 2009). Risks of self-harm and suicide are increased among particular groups who are marginalised within society. As previously noted, offenders in prison and homeless people are particularly vulnerable, with male prisoners five times more likely to die by suicide than men in the general population (Rivlin et al 2010), and a sevenfold increased risk of suicide in homeless men (Nielsen et al 2011).	0	There is an increased risk of suicide and deliberate self-harm in men and women who are unemployed (Kposowa 2001), although findings suggest that risks may be increased for unemployed men (#CITATION_TAG and Chang 2009). Risks of self-harm and suicide are increased among particular groups who are marginalised within society. As previously noted, offenders in prison and homeless people are particularly vulnerable, with male prisoners five times more likely to die by suicide than men in the general population (Rivlin et al 2010), and a sevenfold increased risk of suicide in homeless men (Nielsen et al 2011).	T
CCT296	The effect of mental health problems also relates to when they first began. Although mental health problems may occur at any age, onset is typically in childhood or adolescence, although treatment often does not begin until many years later (Wang et al 2007). Evidence from large-scale international population studies indicates that the median age of onset is earliest for phobias, attention deficit hyperactivity disorder (ADHD) and conduct disorder, which usually arise in childhood or the early teenage years. Anxiety disorders other than phobiaswhich include generalised anxiety disorder and panic disorder, depression, alcohol and substance misuse disorders, and schizophreniabegin most commonly between the late teens and early adulthood (#CITATION_TAG et al 2007). Because of the typically early age of onset of mental health problems, there is increased likelihood for disruption of educational performance, personal relationships and social participation, with consequent effects on employment and income.	0	The effect of mental health problems also relates to when they first began. Although mental health problems may occur at any age, onset is typically in childhood or adolescence, although treatment often does not begin until many years later (Wang et al 2007). Evidence from large-scale international population studies indicates that the median age of onset is earliest for phobias, attention deficit hyperactivity disorder (ADHD) and conduct disorder, which usually arise in childhood or the early teenage years. Anxiety disorders other than phobiaswhich include generalised anxiety disorder and panic disorder, depression, alcohol and substance misuse disorders, and schizophreniabegin most commonly between the late teens and early adulthood (#CITATION_TAG et al 2007). Because of the typically early age of onset of mental health problems, there is increased likelihood for disruption of educational performance, personal relationships and social participation, with consequent effects on employment and income.	i
CCT297	Medical illnesses, particularly long-term conditions such as diabetes, coronary heart disease, renal disease, asthma and arthritis, have been associated with increased prevalence of mental health problems, including depression and anxiety disorders (#CITATION_TAG 2009)	0	Medical illnesses, particularly long-term conditions such as diabetes, coronary heart disease, renal disease, asthma and arthritis, have been associated with increased prevalence of mental health problems, including depression and anxiety disorders (#CITATION_TAG 2009)	M
CCT298	"The most common mental disorder in childhood is conduct disorder, characterised by persistent defiant and antisocial behaviour. The disorder is twice as common in boys as girls, affecting 8% of boys and 4% of girls in Great Britain (Green et al 2005). Hyperkinetic disorder and ADHD are more common in boys and men: in Great Britain, eight times as many boys as girls have hyperkinetic disorder (Green et al 2005). Findings from the most recent national adult household study of mental disorders in England for key conditions exhibiting marked gender differences in prevalence are shown in  There are particular groups in society at increased risk of mental ill health, such as ""looked-after children"" (children looked after by the state or in the care system), refugees, homeless rough sleepers and those in prison. Some of these groups, such as offenders in prison and homeless people, are mainly comprised of men. The US federal inmate population is 93.5% male (US Department of Justice 2012) and in England and Wales, males make up 95.2% of this population (#CITATION_TAG 2012). Nine out of ten rough sleepers in the UK are estimated to be male (Crisis 2012). These groups are particularly vulnerable to mental health problems, most commonly alcohol and substance misuse, and personality disorders. They are also vulnerable to mortality from accidents, violence and suicide."	0	"Hyperkinetic disorder and ADHD are more common in boys and men: in Great Britain, eight times as many boys as girls have hyperkinetic disorder (Green et al 2005). Findings from the most recent national adult household study of mental disorders in England for key conditions exhibiting marked gender differences in prevalence are shown in  There are particular groups in society at increased risk of mental ill health, such as ""looked-after children"" (children looked after by the state or in the care system), refugees, homeless rough sleepers and those in prison. Some of these groups, such as offenders in prison and homeless people, are mainly comprised of men. The US federal inmate population is 93.5% male (US Department of Justice 2012) and in England and Wales, males make up 95.2% of this population (#CITATION_TAG 2012). Nine out of ten rough sleepers in the UK are estimated to be male (Crisis 2012). These groups are particularly vulnerable to mental health problems, most commonly alcohol and substance misuse, and personality disorders. They are also vulnerable to mortality from accidents, violence and suicide."	S
CCT299	"Gender and other patient characteristics, in addition to affecting help-seeking behaviour, may influence healthcare professionals"" responses. GPs"" detection of mental health problems, including depression, may be affected by patients"" gender, with some studies identifying that detection is less likely in men (#CITATION_TAG et al 2000). However, a range of other factors, such as comorbid medical illness, age and ethnicity, play a part in the recognition of mental disorders (Maginn et al 2004)."	4	"Gender and other patient characteristics, in addition to affecting help-seeking behaviour, may influence healthcare professionals"" responses. GPs"" detection of mental health problems, including depression, may be affected by patients"" gender, with some studies identifying that detection is less likely in men (#CITATION_TAG et al 2000). However, a range of other factors, such as comorbid medical illness, age and ethnicity, play a part in the recognition of mental disorders (Maginn et al 2004)."	P
CCT300	An increased risk of death from all causes is not restricted to the most severe mental illnesses, but is also associated with conditions such as depression and anxiety disorders (Osborn 2001). Depression is associated with a near doubling of all-cause mortality rates (Saz andDewey 2001, #CITATION_TAG andSmit 2002). This is important because the high prevalence of these common mental health problems means that there is a significant overall effect on mortality.	0	An increased risk of death from all causes is not restricted to the most severe mental illnesses, but is also associated with conditions such as depression and anxiety disorders (Osborn 2001). Depression is associated with a near doubling of all-cause mortality rates (Saz andDewey 2001, #CITATION_TAG andSmit 2002). This is important because the high prevalence of these common mental health problems means that there is a significant overall effect on mortality.	e
CCT301	Hazardous alcohol use and binge drinking are especially prevalent among young adults, and are associated with cigarette smoking and other substance use, road traffic accidents, violence, unwanted sexual experiences, depression and suicide (NICE 2011). Screening and brief targeted interventions in primary care settings and emergency departments have been found to reduce hazardous and harmful alcohol use. Around 10-15% of people respond to these interventions, with men appearing more likely than women to reduce alcohol use following advice about behaviour change (#CITATION_TAG et al 2007).	0	Hazardous alcohol use and binge drinking are especially prevalent among young adults, and are associated with cigarette smoking and other substance use, road traffic accidents, violence, unwanted sexual experiences, depression and suicide (NICE 2011). Screening and brief targeted interventions in primary care settings and emergency departments have been found to reduce hazardous and harmful alcohol use. Around 10-15% of people respond to these interventions, with men appearing more likely than women to reduce alcohol use following advice about behaviour change (#CITATION_TAG et al 2007).	o
CCT302	Selective approaches are used to prevent the onset of postpartum depression by identifying mothers who are at risk of developing the condition and providing individual support for postnatal women through intensive home visits by nurses and health visitors (#CITATION_TAG and Creedy 2004). In addition, there is evidence that eating disorder prevention programmes delivered to at-risk females are effective in reducing risk factors involved in the development of eating disorders such as body dissatisfaction (Stice et al 2007).	0	Selective approaches are used to prevent the onset of postpartum depression by identifying mothers who are at risk of developing the condition and providing individual support for postnatal women through intensive home visits by nurses and health visitors (#CITATION_TAG and Creedy 2004). In addition, there is evidence that eating disorder prevention programmes delivered to at-risk females are effective in reducing risk factors involved in the development of eating disorders such as body dissatisfaction (Stice et al 2007).	S
CCT303	"We have recorded butterflies in Wisconsin bogs since 1986. In this paper, we analyze these results to expand and extend Nekola""s study in order to describe the fauna in relatively undegraded examples of a vegetation type occurring in naturally fragmented patches comprising relatively little of the landscape as a whole. During the same period, we conducted surveys of butterflies in prairies in seven midwestern states (#CITATION_TAG 1996;Swengel and Swengel 1999a, 1999b and Wisconsin pine barrens (Swengel 1998b;Swengel 2005, 2007). Based on this field work and others"" studies, we contrast the occurrence of specialist butterflies between vegetations altered and fragmented by humans (prairie, barrens: Curtis 1959;Samson and Knopf 1994;Riegler 1995) and naturally fragmented ones (bogs). These results should be useful for application to conservation of bog butterflies where they are vulnerable, and vulnerable butterflies in other fragmented vegetations."	2	"We have recorded butterflies in Wisconsin bogs since 1986. In this paper, we analyze these results to expand and extend Nekola""s study in order to describe the fauna in relatively undegraded examples of a vegetation type occurring in naturally fragmented patches comprising relatively little of the landscape as a whole. During the same period, we conducted surveys of butterflies in prairies in seven midwestern states (#CITATION_TAG 1996;Swengel and Swengel 1999a, 1999b and Wisconsin pine barrens (Swengel 1998b;Swengel 2005, 2007). Based on this field work and others"" studies, we contrast the occurrence of specialist butterflies between vegetations altered and fragmented by humans (prairie, barrens: Curtis 1959;Samson and Knopf 1994;Riegler 1995) and naturally fragmented ones (bogs). These results should be useful for application to conservation of bog butterflies where they are vulnerable, and vulnerable butterflies in other fragmented vegetations."	r
CCT304	In temperate areas of North America and Europe, bog (peatland) vegetation is also rare, being naturally isolated and forming a low proportion of the natural landscape. Although often viewed as a long-lived successional stage between open water and forest in glaciated landscapes, peatlands can get reset to an earlier successional stage (Curtis 1959). Since bogs are well known for their relatively stable vegetations and insect faunas over the long term, they can also be viewed as a climax community (#CITATION_TAG et al. 1999;Spitzer and Danks 2006;Whitehouse 2006;Whitehouse et al. 2008). While often considered relatively uniform floristically both within and among sites, bogs actually contain many microhabitats (V√§is√§nen 1992;Spitzer and Danks 2006;Turlure et al. 2009). In Wisconsin, bogs occur primarily in central and northern areas (Curtis 1959). Prior to European settlement, peatlands occurred in \\1% of the Wisconsin landscape (even counting only the northern third of the state), and most of that vegetation is still extant, with only 9% loss (Hoffman 2002), more lost in central than northern Wisconsin. Much of what is left, especially in northern Wisconsin, is relatively undegraded. Primary human impacts are roads and ditches; adjacent lands are more affected by timber harvesting, agriculture, and urbanization (pers. obs.). Conversion to cranberry agriculture and peat harvesting has occurred more in central Wisconsin bogs (Curtis 1959). By contrast, in Europe bog vegetation is much destroyed and degraded by human activities, along with the associated butterfly species of high conservation concern (Vandewoestijne and Baguette 2004;Schtickzelle et al. 2006;Spencer and Collins 2008;Turlure et al. 2009). The four bog-related vegetation types ranked highest in proportion of threatened butterfly species of their typical faunas (van Swaay et al. 2006).	2	In temperate areas of North America and Europe, bog (peatland) vegetation is also rare, being naturally isolated and forming a low proportion of the natural landscape. Although often viewed as a long-lived successional stage between open water and forest in glaciated landscapes, peatlands can get reset to an earlier successional stage (Curtis 1959). Since bogs are well known for their relatively stable vegetations and insect faunas over the long term, they can also be viewed as a climax community (#CITATION_TAG et al. 1999;Spitzer and Danks 2006;Whitehouse 2006;Whitehouse et al. 2008). While often considered relatively uniform floristically both within and among sites, bogs actually contain many microhabitats (V√§is√§nen 1992;Spitzer and Danks 2006;Turlure et al. 2009). In Wisconsin, bogs occur primarily in central and northern areas (Curtis 1959). Prior to European settlement, peatlands occurred in \\1% of the Wisconsin landscape (even counting only the northern third of the state), and most of that vegetation is still extant, with only 9% loss (Hoffman 2002), more lost in central than northern Wisconsin.	n
CCT305	In temperate areas of North America and Europe, bog (peatland) vegetation is also rare, being naturally isolated and forming a low proportion of the natural landscape. Although often viewed as a long-lived successional stage between open water and forest in glaciated landscapes, peatlands can get reset to an earlier successional stage (#CITATION_TAG 1959). Since bogs are well known for their relatively stable vegetations and insect faunas over the long term, they can also be viewed as a climax community (Spitzer et al. 1999;Spitzer and Danks 2006;Whitehouse 2006;Whitehouse et al. 2008). While often considered relatively uniform floristically both within and among sites, bogs actually contain many microhabitats (V√§is√§nen 1992;Spitzer and Danks 2006;Turlure et al. 2009). In Wisconsin, bogs occur primarily in central and northern areas (Curtis 1959). Prior to European settlement, peatlands occurred in \\1% of the Wisconsin landscape (even counting only the northern third of the state), and most of that vegetation is still extant, with only 9% loss (Hoffman 2002), more lost in central than northern Wisconsin. Much of what is left, especially in northern Wisconsin, is relatively undegraded. Primary human impacts are roads and ditches; adjacent lands are more affected by timber harvesting, agriculture, and urbanization (pers. obs.). Conversion to cranberry agriculture and peat harvesting has occurred more in central Wisconsin bogs (Curtis 1959). By contrast, in Europe bog vegetation is much destroyed and degraded by human activities, along with the associated butterfly species of high conservation concern (Vandewoestijne and Baguette 2004;Schtickzelle et al. 2006;Spencer and Collins 2008;Turlure et al. 2009). The four bog-related vegetation types ranked highest in proportion of threatened butterfly species of their typical faunas (van Swaay et al. 2006).	0	In temperate areas of North America and Europe, bog (peatland) vegetation is also rare, being naturally isolated and forming a low proportion of the natural landscape. Although often viewed as a long-lived successional stage between open water and forest in glaciated landscapes, peatlands can get reset to an earlier successional stage (#CITATION_TAG 1959). Since bogs are well known for their relatively stable vegetations and insect faunas over the long term, they can also be viewed as a climax community (Spitzer et al. 1999;Spitzer and Danks 2006;Whitehouse 2006;Whitehouse et al. 2008). While often considered relatively uniform floristically both within and among sites, bogs actually contain many microhabitats (V√§is√§nen 1992;Spitzer and Danks 2006;Turlure et al. 2009). In Wisconsin, bogs occur primarily in central and northern areas (Curtis 1959).	l
CCT306	"The vegetative approach to defining habitats may be called the """"ecosystem"""" approach but it""s typically focused on floristic composition (Wisconsin Department of Natural Resources 1995, Packard and Mutel 1997;#CITATION_TAG and Schwartz 1998). This approach has value: some bog specialist butterflies have remarkable frequency of occurrence in northern Wisconsin bogs (Table 9). This faunistic similarity of specialists across these bogs may be particularly pronounced due to the long-term stability typical of this vegetation and remarkably pristine condition of these sites (see """"Introduction""""). Characteristic"""" butterflies are frequently identified for """"zones"""" or """"biomes"""" (e.g., Layberry et al. 1998, pp 9-11); on that large scale, these are typically """"matrix"""" butterflies of a general vegetation type. But even in highly destroyed and fragmented tallgrass prairie, characteristic specialists (if in range) occurred in many examples of that vegetation (Speyeria idalia in Missouri and Minnesota, Oarisma poweshiek in Minnesota) (Swengel 1998b;Swengel 1999a, 1999b). Thus, vegetative classifications are efficacious at grouping insects by their floristic associations (e.g., Panzer and Schwartz 1998;Shuey 2005)."	0	"The vegetative approach to defining habitats may be called the """"ecosystem"""" approach but it""s typically focused on floristic composition (Wisconsin Department of Natural Resources 1995, Packard and Mutel 1997;#CITATION_TAG and Schwartz 1998). This approach has value: some bog specialist butterflies have remarkable frequency of occurrence in northern Wisconsin bogs (Table 9). This faunistic similarity of specialists across these bogs may be particularly pronounced due to the long-term stability typical of this vegetation and remarkably pristine condition of these sites (see """"Introduction""""). Characteristic"""" butterflies are frequently identified for """"zones"""" or """"biomes"""" (e.g., Layberry et al. 1998, pp 9-11); on that large scale, these are typically """"matrix"""" butterflies of a general vegetation type."	T
CCT307	Various studies (e.g. Hu and Fu, 2007;Seidel and Randel, 2007), and others as reviewed by Seidel et al. (2008), have found that the Hadley Cell has, in fact, expanded to a greater or lesser extent over the past few decades -indeed from tropopause observations Seidel and Randel (2007) suggest that the tropical belt may have widened by as much as 5-8 ‚Ä¢ from 1979 to 2005! A note of caution to such large estimates was injected by Birner (2010), who noted that trend estimates for the width of the tropical belt are not all consistent with each other; nevertheless, that there is a slight widening trend of the Hadley Cell has become widely accepted. Various models, both idealized and comprehensive, have also simulated a widening trend, if not always as noticeable as that suggested by some of the observations (#CITATION_TAG et al., 2007;Lu et al., 2008;Tandon et al., 2013). For example, Frierson et al. (2007) found an increase in Hadley Cell width of about 0.25 ‚Ä¢ per 1 K temperature increase, similar to that found in some of the CMIP3 integrations by Lu et al. (2007).	4	Various studies (e.g. Hu and Fu, 2007;Seidel and Randel, 2007), and others as reviewed by Seidel et al. (2008), have found that the Hadley Cell has, in fact, expanded to a greater or lesser extent over the past few decades -indeed from tropopause observations Seidel and Randel (2007) suggest that the tropical belt may have widened by as much as 5-8 ‚Ä¢ from 1979 to 2005! A note of caution to such large estimates was injected by Birner (2010), who noted that trend estimates for the width of the tropical belt are not all consistent with each other; nevertheless, that there is a slight widening trend of the Hadley Cell has become widely accepted. Various models, both idealized and comprehensive, have also simulated a widening trend, if not always as noticeable as that suggested by some of the observations (#CITATION_TAG et al., 2007;Lu et al., 2008;Tandon et al., 2013). For example, Frierson et al. (2007) found an increase in Hadley Cell width of about 0.25 ‚Ä¢ per 1 K temperature increase, similar to that found in some of the CMIP3 integrations by Lu et al. (2007).	r
CCT308	But even if the climate sensitivity were known with little uncertainty, a problem arises in understanding the regional changes in climate, and that in turn involves the dynamical issue of understanding changes in the general circulation of the atmosphere. As a step toward that, our primary goal in this article is to better understand what changes in large-scale atmospheric structure are likely, or robust, as the planet warms. Our approach is two-fold. On the one hand, as an empirical tool we use the archive of coupled climate models used for the fifth assessment report (AR5) of the Intergovernmental Panel on Climate Change (IPCC) to assess the robustness of model responses to a given warming or given emissions scenario. In addition, we try to assess whether the response is consistent with or explainable by simple physical arguments, some of which have been presented in the literature before (see also the review by #CITATION_TAG et al., 2010). Our general point of view is that robustness is most assured if there is agreement across a range of comprehensive and idealized models and if there is a well understood physical argument that captures the phenomenon. We spend more time describing arguments that are clear and robust; thus we discuss the mechanism of an increase in tropopause height at some length but do not go into such detail regarding the various arguments for latitudinal shifts of the circulation.	1	As a step toward that, our primary goal in this article is to better understand what changes in large-scale atmospheric structure are likely, or robust, as the planet warms. Our approach is two-fold. On the one hand, as an empirical tool we use the archive of coupled climate models used for the fifth assessment report (AR5) of the Intergovernmental Panel on Climate Change (IPCC) to assess the robustness of model responses to a given warming or given emissions scenario. In addition, we try to assess whether the response is consistent with or explainable by simple physical arguments, some of which have been presented in the literature before (see also the review by #CITATION_TAG et al., 2010). Our general point of view is that robustness is most assured if there is agreement across a range of comprehensive and idealized models and if there is a well understood physical argument that captures the phenomenon. We spend more time describing arguments that are clear and robust; thus we discuss the mechanism of an increase in tropopause height at some length but do not go into such detail regarding the various arguments for latitudinal shifts of the circulation.	d
CCT309	A number of studies have found and/or argued that the strength of aspects of the tropical circulation will weaken with global warming (Knutson and Manabe, 1995;#CITATION_TAG and Soden, 2006;Vecchi and Soden, 2007;Kang et al., 2013), although there is some evidence from reanalyses that the boreal winter Hadley Cell has actually strengthened in recent decades (Mitas and Clement, 2005). Using the CMIP3 ensemble Kang et al. (2013) found a weakening of the Hadley Cell, but one that was confined to the NH and with more weakening in winter than in summer.	0	A number of studies have found and/or argued that the strength of aspects of the tropical circulation will weaken with global warming (Knutson and Manabe, 1995;#CITATION_TAG and Soden, 2006;Vecchi and Soden, 2007;Kang et al., 2013), although there is some evidence from reanalyses that the boreal winter Hadley Cell has actually strengthened in recent decades (Mitas and Clement, 2005). Using the CMIP3 ensemble Kang et al. (2013) found a weakening of the Hadley Cell, but one that was confined to the NH and with more weakening in winter than in summer.	A
CCT310	We now consider the possible shift in latitude of the midlatitude circulation, and in particular of the surface westerlies, in a warmer climate. A poleward shift of the storm track was noted by Hall et al. (1994) in simulations with doubled CO 2 , by Yin (2005) in a number of integrations of future climates in the CMIP3 archive, and recently Barnes and Polvani (2013) noted a poleward shift of the midlatitude jets in some of the CMIP5 integrations. In general consistency with these simulations, a number of authors have documented poleward trends in the observed or reanalysed position of the midlatitude jets, storminess, and/or the relevant annular mode over the past few decades (Thompson and Solomon, 2002;#CITATION_TAG and Held, 2007;Archer and Caldeira, 2008;Bender et al., 2011;Solman and Orlanski, 2014). However, some equatorward shifts have also been seen in simulations of future climates using models that have a well-developed stratosphere (Scaife et al., 2012;Karpechko and Manzini, 2012).	0	We now consider the possible shift in latitude of the midlatitude circulation, and in particular of the surface westerlies, in a warmer climate. A poleward shift of the storm track was noted by Hall et al. (1994) in simulations with doubled CO 2 , by Yin (2005) in a number of integrations of future climates in the CMIP3 archive, and recently Barnes and Polvani (2013) noted a poleward shift of the midlatitude jets in some of the CMIP5 integrations. In general consistency with these simulations, a number of authors have documented poleward trends in the observed or reanalysed position of the midlatitude jets, storminess, and/or the relevant annular mode over the past few decades (Thompson and Solomon, 2002;#CITATION_TAG and Held, 2007;Archer and Caldeira, 2008;Bender et al., 2011;Solman and Orlanski, 2014). However, some equatorward shifts have also been seen in simulations of future climates using models that have a well-developed stratosphere (Scaife et al., 2012;Karpechko and Manzini, 2012).	 
CCT311	We now consider the possible shift in latitude of the midlatitude circulation, and in particular of the surface westerlies, in a warmer climate. A poleward shift of the storm track was noted by Hall et al. (1994) in simulations with doubled CO 2 , by Yin (2005) in a number of integrations of future climates in the CMIP3 archive, and recently Barnes and Polvani (2013) noted a poleward shift of the midlatitude jets in some of the CMIP5 integrations. In general consistency with these simulations, a number of authors have documented poleward trends in the observed or reanalysed position of the midlatitude jets, storminess, and/or the relevant annular mode over the past few decades (Thompson and Solomon, 2002;Chen and Held, 2007;Archer and Caldeira, 2008;Bender et al., 2011;Solman and Orlanski, 2014). However, some equatorward shifts have also been seen in simulations of future climates using models that have a well-developed stratosphere (#CITATION_TAG et al., 2012;Karpechko and Manzini, 2012).	0	We now consider the possible shift in latitude of the midlatitude circulation, and in particular of the surface westerlies, in a warmer climate. A poleward shift of the storm track was noted by Hall et al. (1994) in simulations with doubled CO 2 , by Yin (2005) in a number of integrations of future climates in the CMIP3 archive, and recently Barnes and Polvani (2013) noted a poleward shift of the midlatitude jets in some of the CMIP5 integrations. In general consistency with these simulations, a number of authors have documented poleward trends in the observed or reanalysed position of the midlatitude jets, storminess, and/or the relevant annular mode over the past few decades (Thompson and Solomon, 2002;Chen and Held, 2007;Archer and Caldeira, 2008;Bender et al., 2011;Solman and Orlanski, 2014). However, some equatorward shifts have also been seen in simulations of future climates using models that have a well-developed stratosphere (#CITATION_TAG et al., 2012;Karpechko and Manzini, 2012).	e
CCT312	In both cases, the primary calibration data used to produce the maps is derived from profiles of tree height from the ICESat GLAS sensor. Although these data do include some information about the structural characteristics of the forest within the LiDAR footprints, canopy height is the principal parameter detected (Lefsky et al., 2005). However, allometric equations that relate physical attributes of trees to their above-ground biomass normally rely on three parameters: in addition to tree height (H), tree diameter at 1.3 m (D) and wood density (œÅ) are very important (#CITATION_TAG et al., 2005), and mean values and ratios between these parameters vary significantly between regions (Chave et al., 2005;Feldpausch et al., 2012;Quesada et al., 2012), associated with different species communities (ter Steege et al., 2006). We know that wood density increases from west to east across Amazonia (Baker et al., 2004;ter Steege et al., 2006), inversely correlated to stem turnover rate (Quesada et al., 2012). This gradient is driven by soil fertility, notably total soil phosphorus and the concentration of exchangeable potassium ions (Arag√£o et al., 2009), and especially by the physical qualities of the soil. Thus, the fertile but shallower soils of the western Amazon lead to higher productivity and faster turnover, and a set of species with low wood density; conversely, the low fertility but deep and freely-draining soils of the eastern Amazon tend to have lower productivity and slower turnover, and species with much higher wood density. The relationship between diameter and height also varies across the basin, but with more complexity than wood density, mostly related to climatic factors (Feldpausch et al., 2011). These are approximated into four zones (Feldpausch et al., 2011(Feldpausch et al., , 2012, with the use of a different D:H model in each zone, greatly reducing the error in the prediction of H from D compared to a pan-Amazonian model (Feldpausch et al., 2012).	0	In both cases, the primary calibration data used to produce the maps is derived from profiles of tree height from the ICESat GLAS sensor. Although these data do include some information about the structural characteristics of the forest within the LiDAR footprints, canopy height is the principal parameter detected (Lefsky et al., 2005). However, allometric equations that relate physical attributes of trees to their above-ground biomass normally rely on three parameters: in addition to tree height (H), tree diameter at 1.3 m (D) and wood density (œÅ) are very important (#CITATION_TAG et al., 2005), and mean values and ratios between these parameters vary significantly between regions (Chave et al., 2005;Feldpausch et al., 2012;Quesada et al., 2012), associated with different species communities (ter Steege et al., 2006). We know that wood density increases from west to east across Amazonia (Baker et al., 2004;ter Steege et al., 2006), inversely correlated to stem turnover rate (Quesada et al., 2012). This gradient is driven by soil fertility, notably total soil phosphorus and the concentration of exchangeable potassium ions (Arag√£o et al., 2009), and especially by the physical qualities of the soil. Thus, the fertile but shallower soils of the western Amazon lead to higher productivity and faster turnover, and a set of species with low wood density; conversely, the low fertility but deep and freely-draining soils of the eastern Amazon tend to have lower productivity and slower turnover, and species with much higher wood density.	w
CCT313	In both cases, the primary calibration data used to produce the maps is derived from profiles of tree height from the ICESat GLAS sensor. Although these data do include some information about the structural characteristics of the forest within the LiDAR footprints, canopy height is the principal parameter detected (Lefsky et al., 2005). However, allometric equations that relate physical attributes of trees to their above-ground biomass normally rely on three parameters: in addition to tree height (H), tree diameter at 1.3 m (D) and wood density (œÅ) are very important (Chave et al., 2005), and mean values and ratios between these parameters vary significantly between regions (Chave et al., 2005;Feldpausch et al., 2012;#CITATION_TAG et al., 2012), associated with different species communities (ter Steege et al., 2006). We know that wood density increases from west to east across Amazonia (Baker et al., 2004;ter Steege et al., 2006), inversely correlated to stem turnover rate (Quesada et al., 2012). This gradient is driven by soil fertility, notably total soil phosphorus and the concentration of exchangeable potassium ions (Arag√£o et al., 2009), and especially by the physical qualities of the soil. Thus, the fertile but shallower soils of the western Amazon lead to higher productivity and faster turnover, and a set of species with low wood density; conversely, the low fertility but deep and freely-draining soils of the eastern Amazon tend to have lower productivity and slower turnover, and species with much higher wood density. The relationship between diameter and height also varies across the basin, but with more complexity than wood density, mostly related to climatic factors (Feldpausch et al., 2011). These are approximated into four zones (Feldpausch et al., 2011(Feldpausch et al., , 2012, with the use of a different D:H model in each zone, greatly reducing the error in the prediction of H from D compared to a pan-Amazonian model (Feldpausch et al., 2012).	0	In both cases, the primary calibration data used to produce the maps is derived from profiles of tree height from the ICESat GLAS sensor. Although these data do include some information about the structural characteristics of the forest within the LiDAR footprints, canopy height is the principal parameter detected (Lefsky et al., 2005). However, allometric equations that relate physical attributes of trees to their above-ground biomass normally rely on three parameters: in addition to tree height (H), tree diameter at 1.3 m (D) and wood density (œÅ) are very important (Chave et al., 2005), and mean values and ratios between these parameters vary significantly between regions (Chave et al., 2005;Feldpausch et al., 2012;#CITATION_TAG et al., 2012), associated with different species communities (ter Steege et al., 2006). We know that wood density increases from west to east across Amazonia (Baker et al., 2004;ter Steege et al., 2006), inversely correlated to stem turnover rate (Quesada et al., 2012). This gradient is driven by soil fertility, notably total soil phosphorus and the concentration of exchangeable potassium ions (Arag√£o et al., 2009), and especially by the physical qualities of the soil. Thus, the fertile but shallower soils of the western Amazon lead to higher productivity and faster turnover, and a set of species with low wood density; conversely, the low fertility but deep and freely-draining soils of the eastern Amazon tend to have lower productivity and slower turnover, and species with much higher wood density.	w
CCT314	In both cases, the primary calibration data used to produce the maps is derived from profiles of tree height from the ICESat GLAS sensor. Although these data do include some information about the structural characteristics of the forest within the LiDAR footprints, canopy height is the principal parameter detected (Lefsky et al., 2005). However, allometric equations that relate physical attributes of trees to their above-ground biomass normally rely on three parameters: in addition to tree height (H), tree diameter at 1.3 m (D) and wood density (œÅ) are very important (Chave et al., 2005), and mean values and ratios between these parameters vary significantly between regions (Chave et al., 2005;Feldpausch et al., 2012;Quesada et al., 2012), associated with different species communities (ter Steege et al., 2006). We know that wood density increases from west to east across Amazonia (Baker et al., 2004;ter Steege et al., 2006), inversely correlated to stem turnover rate (Quesada et al., 2012). This gradient is driven by soil fertility, notably total soil phosphorus and the concentration of exchangeable potassium ions (Arag√£o et al., 2009), and especially by the physical qualities of the soil. Thus, the fertile but shallower soils of the western Amazon lead to higher productivity and faster turnover, and a set of species with low wood density; conversely, the low fertility but deep and freely-draining soils of the eastern Amazon tend to have lower productivity and slower turnover, and species with much higher wood density. The relationship between diameter and height also varies across the basin, but with more complexity than wood density, mostly related to climatic factors (#CITATION_TAG et al., 2011). These are approximated into four zones (Feldpausch et al., 2011(Feldpausch et al., , 2012, with the use of a different D:H model in each zone, greatly reducing the error in the prediction of H from D compared to a pan-Amazonian model (Feldpausch et al., 2012).	5	We know that wood density increases from west to east across Amazonia (Baker et al., 2004;ter Steege et al., 2006), inversely correlated to stem turnover rate (Quesada et al., 2012). This gradient is driven by soil fertility, notably total soil phosphorus and the concentration of exchangeable potassium ions (Arag√£o et al., 2009), and especially by the physical qualities of the soil. Thus, the fertile but shallower soils of the western Amazon lead to higher productivity and faster turnover, and a set of species with low wood density; conversely, the low fertility but deep and freely-draining soils of the eastern Amazon tend to have lower productivity and slower turnover, and species with much higher wood density. The relationship between diameter and height also varies across the basin, but with more complexity than wood density, mostly related to climatic factors (#CITATION_TAG et al., 2011). These are approximated into four zones (Feldpausch et al., 2011(Feldpausch et al., , 2012, with the use of a different D:H model in each zone, greatly reducing the error in the prediction of H from D compared to a pan-Amazonian model (Feldpausch et al., 2012).	l
CCT315	Amazonia contains half of all remaining tropical moist forest (Fritz et al., 2003). The total vegetation carbon storage of Amazon basin tropical forests has been subject to a wide range of estimates (Houghton et al., 2001;Malhi et al., 2006;#CITATION_TAG et al., 2007). These have varied from 58 Pg C (Olson et al., 1983) to 134 Pg C (Fearnside, 1997, scaled to whole basin), although there is now some general consensus in the middle of this range [e.g. 93 ¬± 23 Pg C (Malhi et al., 2006), 86 ¬± 17 Pg C (Saatchi et al., 2007) and 89 Pg C (FAO, 2010)]. However, these estimates of carbon stocks mask large differences at a smaller spatial scale, as local variations are cancelled out when summing over large areas: the spatial patterns visible in different maps of above-ground biomass (AGB) vary greatly, with little consistency even between studies that use similar methods and input data (Houghton et al., 2001).	0	Amazonia contains half of all remaining tropical moist forest (Fritz et al., 2003). The total vegetation carbon storage of Amazon basin tropical forests has been subject to a wide range of estimates (Houghton et al., 2001;Malhi et al., 2006;#CITATION_TAG et al., 2007). These have varied from 58 Pg C (Olson et al., 1983) to 134 Pg C (Fearnside, 1997, scaled to whole basin), although there is now some general consensus in the middle of this range [e.g. 93 ¬± 23 Pg C (Malhi et al., 2006), 86 ¬± 17 Pg C (Saatchi et al., 2007) and 89 Pg C (FAO, 2010)]. However, these estimates of carbon stocks mask large differences at a smaller spatial scale, as local variations are cancelled out when summing over large areas: the spatial patterns visible in different maps of above-ground biomass (AGB) vary greatly, with little consistency even between studies that use similar methods and input data (Houghton et al., 2001).	h
CCT316	All the plots entering the kriged map were located in forest areas with no recent anthropogenic disturbance, but a significant proportion of Amazonia is non-forest or degraded forest (Fig. 1a). Unsurprisingly, KDHœÅ overpredicted AGB in all areas dominated by non-forest land-cover types compared to the RS maps. Therefore the maps are most comparable in undisturbed forest areas, so all comparisons were performed in Intact Forest Landscape (IFL) (#CITATION_TAG et al., 2008) areas only, with the exception of the analysis of recent deforestation. IFLs are defined as forest areas minimally influenced by human economic activity, with an area of at least 50,000 ha and a minimum width of 10 km. The IFL layers are kept updated for new infrastructure, settlements or commercial activities by their developers using a combination of field data and remote-sensing data (Potapov et al., 2008).	5	All the plots entering the kriged map were located in forest areas with no recent anthropogenic disturbance, but a significant proportion of Amazonia is non-forest or degraded forest (Fig. 1a). Unsurprisingly, KDHœÅ overpredicted AGB in all areas dominated by non-forest land-cover types compared to the RS maps. Therefore the maps are most comparable in undisturbed forest areas, so all comparisons were performed in Intact Forest Landscape (IFL) (#CITATION_TAG et al., 2008) areas only, with the exception of the analysis of recent deforestation. IFLs are defined as forest areas minimally influenced by human economic activity, with an area of at least 50,000 ha and a minimum width of 10 km. The IFL layers are kept updated for new infrastructure, settlements or commercial activities by their developers using a combination of field data and remote-sensing data (Potapov et al., 2008).	e
CCT317	Amazonia contains half of all remaining tropical moist forest (Fritz et al., 2003). The total vegetation carbon storage of Amazon basin tropical forests has been subject to a wide range of estimates (Houghton et al., 2001;#CITATION_TAG et al., 2006;Saatchi et al., 2007). These have varied from 58 Pg C (Olson et al., 1983) to 134 Pg C (Fearnside, 1997, scaled to whole basin), although there is now some general consensus in the middle of this range [e.g. 93 ¬± 23 Pg C (Malhi et al., 2006), 86 ¬± 17 Pg C (Saatchi et al., 2007) and 89 Pg C (FAO, 2010)]. However, these estimates of carbon stocks mask large differences at a smaller spatial scale, as local variations are cancelled out when summing over large areas: the spatial patterns visible in different maps of above-ground biomass (AGB) vary greatly, with little consistency even between studies that use similar methods and input data (Houghton et al., 2001).	0	Amazonia contains half of all remaining tropical moist forest (Fritz et al., 2003). The total vegetation carbon storage of Amazon basin tropical forests has been subject to a wide range of estimates (Houghton et al., 2001;#CITATION_TAG et al., 2006;Saatchi et al., 2007). These have varied from 58 Pg C (Olson et al., 1983) to 134 Pg C (Fearnside, 1997, scaled to whole basin), although there is now some general consensus in the middle of this range [e.g. 93 ¬± 23 Pg C (Malhi et al., 2006), 86 ¬± 17 Pg C (Saatchi et al., 2007) and 89 Pg C (FAO, 2010)]. However, these estimates of carbon stocks mask large differences at a smaller spatial scale, as local variations are cancelled out when summing over large areas: the spatial patterns visible in different maps of above-ground biomass (AGB) vary greatly, with little consistency even between studies that use similar methods and input data (Houghton et al., 2001).	h
CCT318	In both cases, the primary calibration data used to produce the maps is derived from profiles of tree height from the ICESat GLAS sensor. Although these data do include some information about the structural characteristics of the forest within the LiDAR footprints, canopy height is the principal parameter detected (Lefsky et al., 2005). However, allometric equations that relate physical attributes of trees to their above-ground biomass normally rely on three parameters: in addition to tree height (H), tree diameter at 1.3 m (D) and wood density (œÅ) are very important (Chave et al., 2005), and mean values and ratios between these parameters vary significantly between regions (Chave et al., 2005;Feldpausch et al., 2012;Quesada et al., 2012), associated with different species communities (#CITATION_TAG et al., 2006). We know that wood density increases from west to east across Amazonia (Baker et al., 2004;ter Steege et al., 2006), inversely correlated to stem turnover rate (Quesada et al., 2012). This gradient is driven by soil fertility, notably total soil phosphorus and the concentration of exchangeable potassium ions (Arag√£o et al., 2009), and especially by the physical qualities of the soil. Thus, the fertile but shallower soils of the western Amazon lead to higher productivity and faster turnover, and a set of species with low wood density; conversely, the low fertility but deep and freely-draining soils of the eastern Amazon tend to have lower productivity and slower turnover, and species with much higher wood density. The relationship between diameter and height also varies across the basin, but with more complexity than wood density, mostly related to climatic factors (Feldpausch et al., 2011). These are approximated into four zones (Feldpausch et al., 2011(Feldpausch et al., , 2012, with the use of a different D:H model in each zone, greatly reducing the error in the prediction of H from D compared to a pan-Amazonian model (Feldpausch et al., 2012).	0	In both cases, the primary calibration data used to produce the maps is derived from profiles of tree height from the ICESat GLAS sensor. Although these data do include some information about the structural characteristics of the forest within the LiDAR footprints, canopy height is the principal parameter detected (Lefsky et al., 2005). However, allometric equations that relate physical attributes of trees to their above-ground biomass normally rely on three parameters: in addition to tree height (H), tree diameter at 1.3 m (D) and wood density (œÅ) are very important (Chave et al., 2005), and mean values and ratios between these parameters vary significantly between regions (Chave et al., 2005;Feldpausch et al., 2012;Quesada et al., 2012), associated with different species communities (#CITATION_TAG et al., 2006). We know that wood density increases from west to east across Amazonia (Baker et al., 2004;ter Steege et al., 2006), inversely correlated to stem turnover rate (Quesada et al., 2012). This gradient is driven by soil fertility, notably total soil phosphorus and the concentration of exchangeable potassium ions (Arag√£o et al., 2009), and especially by the physical qualities of the soil. Thus, the fertile but shallower soils of the western Amazon lead to higher productivity and faster turnover, and a set of species with low wood density; conversely, the low fertility but deep and freely-draining soils of the eastern Amazon tend to have lower productivity and slower turnover, and species with much higher wood density.	w
CCT319	In order to test this, we use a unique dataset of 413 field plots located throughout tropical South America, compiled as part of RAINFOR (Red Amaz√≥nica de Inventarios Forestales; Amazon Forest Inventory Network; Malhi et al., 2002), the Amazon Tree Diversity Network (#CITATION_TAG et al., 2003), TEAM (Tropical Ecology Assessment and Monitoring) and PPBio (Brazilian Program for Biodiversity Research) (Fig. 1). Data in these plots were collected using a consistent methodology, and AGB was calculated using a T-SQL query to a single database. We compare these field plots directly to the two remote-sensing-derived maps, and additionally create a plotbased AGB map using simple two-dimensional kriging (K DHœÅ) to allow a spatial comparison.	5	In order to test this, we use a unique dataset of 413 field plots located throughout tropical South America, compiled as part of RAINFOR (Red Amaz√≥nica de Inventarios Forestales; Amazon Forest Inventory Network; Malhi et al., 2002), the Amazon Tree Diversity Network (#CITATION_TAG et al., 2003), TEAM (Tropical Ecology Assessment and Monitoring) and PPBio (Brazilian Program for Biodiversity Research) (Fig. 1). Data in these plots were collected using a consistent methodology, and AGB was calculated using a T-SQL query to a single database. We compare these field plots directly to the two remote-sensing-derived maps, and additionally create a plotbased AGB map using simple two-dimensional kriging (K DHœÅ) to allow a spatial comparison.	I
CCT320	It is important to understand the drivers of the AGB gradient seen in the field plots. From an ecological point of view, AGB is ultimately a function of net primary production (NPP) and the turnover rate of the forest. Spatial differences in NPP and turnover rates are associated with different species with different life-history strategies and structures caused by different climatic conditions and the chemical and physical properties of the soil (Quesada et al., 2012), with these different floristic communities associated with different AGB values. The key ecological parameters associated with differing AGB are basal area, wood density and D:H ratios, all of which vary across the basin (Baker et al., 2004;ter Steege et al., 2006;#CITATION_TAG et al., 2012;Feldpausch et al., 2012;Quesada et al., 2012), but none of which is directly detected by RS. Mapping basal area and wood density from the plots shows that both increase from SW-NE, though wood density shows a larger proportional trend than basal area (Fig. 4a,c). It is also known that, in general, tropical South American trees are shorter for a given diameter than trees from other tropical regions (Banin et al., 2012), with the exception of the Guiana Shield where trees are comparatively tall for a given diameter, with D:H relationships statistically indistinguishable from the forests of Africa and Southeast Asia (Feldpausch et al., 2011). In order to assess the relative impact of wood density and tree height on AGB, we recalculated the AGB values of the 413 field plots using the same three-parameter allometric equations and diameter information, but applying three different approaches to the other two variables: 1 K DœÅ: Using a pan-Amazonian D:H model rather than the four regional height models (Feldpausch et al., 2012), but the same wood density values as KDHœÅ; 2 KDH: Using a constant value of 0.63 as the wood density for every stem, but the regional height models as in KDHœÅ; 3 KD: Using a pan-Amazonian D:H model and a constant wood density value, but the same allometric equations, so AGB varied between plots solely due to D.	0	It is important to understand the drivers of the AGB gradient seen in the field plots. From an ecological point of view, AGB is ultimately a function of net primary production (NPP) and the turnover rate of the forest. Spatial differences in NPP and turnover rates are associated with different species with different life-history strategies and structures caused by different climatic conditions and the chemical and physical properties of the soil (Quesada et al., 2012), with these different floristic communities associated with different AGB values. The key ecological parameters associated with differing AGB are basal area, wood density and D:H ratios, all of which vary across the basin (Baker et al., 2004;ter Steege et al., 2006;#CITATION_TAG et al., 2012;Feldpausch et al., 2012;Quesada et al., 2012), but none of which is directly detected by RS. Mapping basal area and wood density from the plots shows that both increase from SW-NE, though wood density shows a larger proportional trend than basal area (Fig. 4a,c). It is also known that, in general, tropical South American trees are shorter for a given diameter than trees from other tropical regions (Banin et al., 2012), with the exception of the Guiana Shield where trees are comparatively tall for a given diameter, with D:H relationships statistically indistinguishable from the forests of Africa and Southeast Asia (Feldpausch et al., 2011). In order to assess the relative impact of wood density and tree height on AGB, we recalculated the AGB values of the 413 field plots using the same three-parameter allometric equations and diameter information, but applying three different approaches to the other two variables: 1 K DœÅ: Using a pan-Amazonian D:H model rather than the four regional height models (Feldpausch et al., 2012), but the same wood density values as KDHœÅ; 2 KDH: Using a constant value of 0.63 as the wood density for every stem, but the regional height models as in KDHœÅ; 3 KD: Using a pan-Amazonian D:H model and a constant wood density value, but the same allometric equations, so AGB varied between plots solely due to D.	 
CCT321	In both cases, the primary calibration data used to produce the maps is derived from profiles of tree height from the ICESat GLAS sensor. Although these data do include some information about the structural characteristics of the forest within the LiDAR footprints, canopy height is the principal parameter detected (Lefsky et al., 2005). However, allometric equations that relate physical attributes of trees to their above-ground biomass normally rely on three parameters: in addition to tree height (H), tree diameter at 1.3 m (D) and wood density (œÅ) are very important (Chave et al., 2005), and mean values and ratios between these parameters vary significantly between regions (Chave et al., 2005;Feldpausch et al., 2012;Quesada et al., 2012), associated with different species communities (ter Steege et al., 2006). We know that wood density increases from west to east across Amazonia (#CITATION_TAG et al., 2004;ter Steege et al., 2006), inversely correlated to stem turnover rate (Quesada et al., 2012). This gradient is driven by soil fertility, notably total soil phosphorus and the concentration of exchangeable potassium ions (Arag√£o et al., 2009), and especially by the physical qualities of the soil. Thus, the fertile but shallower soils of the western Amazon lead to higher productivity and faster turnover, and a set of species with low wood density; conversely, the low fertility but deep and freely-draining soils of the eastern Amazon tend to have lower productivity and slower turnover, and species with much higher wood density. The relationship between diameter and height also varies across the basin, but with more complexity than wood density, mostly related to climatic factors (Feldpausch et al., 2011). These are approximated into four zones (Feldpausch et al., 2011(Feldpausch et al., , 2012, with the use of a different D:H model in each zone, greatly reducing the error in the prediction of H from D compared to a pan-Amazonian model (Feldpausch et al., 2012).	4	In both cases, the primary calibration data used to produce the maps is derived from profiles of tree height from the ICESat GLAS sensor. Although these data do include some information about the structural characteristics of the forest within the LiDAR footprints, canopy height is the principal parameter detected (Lefsky et al., 2005). However, allometric equations that relate physical attributes of trees to their above-ground biomass normally rely on three parameters: in addition to tree height (H), tree diameter at 1.3 m (D) and wood density (œÅ) are very important (Chave et al., 2005), and mean values and ratios between these parameters vary significantly between regions (Chave et al., 2005;Feldpausch et al., 2012;Quesada et al., 2012), associated with different species communities (ter Steege et al., 2006). We know that wood density increases from west to east across Amazonia (#CITATION_TAG et al., 2004;ter Steege et al., 2006), inversely correlated to stem turnover rate (Quesada et al., 2012). This gradient is driven by soil fertility, notably total soil phosphorus and the concentration of exchangeable potassium ions (Arag√£o et al., 2009), and especially by the physical qualities of the soil. Thus, the fertile but shallower soils of the western Amazon lead to higher productivity and faster turnover, and a set of species with low wood density; conversely, the low fertility but deep and freely-draining soils of the eastern Amazon tend to have lower productivity and slower turnover, and species with much higher wood density. The relationship between diameter and height also varies across the basin, but with more complexity than wood density, mostly related to climatic factors (Feldpausch et al., 2011).	k
CCT322	Details of field methods and error checking procedures involved in the RAINFOR permanent plot network are discussed in detail elsewhere (#CITATION_TAG et al., 2008(Phillips et al., , 2009a. The individual stem data for every plot used in this study are held in a database (http://www.forestplots.net/), which allowed us to calculate plot-level AGB consistently with a single T-SQL query (Lopez-Gonzalez et al., 2009. The TEAM plots were downloaded and added to the database in April 2013, with data set identifier codes of 20130415013221_3991 and 20130405063033_1587. We only used plots where data were available for every stem and trees had been measured consistently above buttresses. Plots above 1000 m elevation were excluded, as were plots in nonforest ecosystems. On average across plots, 77% of stems were identified to the species level, and 92% to the genus level. The dates at which the plots were most recently measured, and the number of times they had been re-censused, varied: in order to dampen the influence of short-term disturbances and to produce values that most closely represented the landscape AGB distribution, the value for each plot was calculated as the mean of all census values, weighted by census interval lengths before and after each measurement. Censuses collected from 2010 onwards were excluded as these post-date the remote-sensing data, apart from 41 plots that were only measured for the first time during or after 2010, in which case the earliest available census was used.	0	Details of field methods and error checking procedures involved in the RAINFOR permanent plot network are discussed in detail elsewhere (#CITATION_TAG et al., 2008(Phillips et al., , 2009a. The individual stem data for every plot used in this study are held in a database (http://www. forestplots.net/), which allowed us to calculate plot-level AGB consistently with a single T-SQL query (Lopez-Gonzalez et al., 2009. The TEAM plots were downloaded and added to the database in April 2013, with data set identifier codes of 20130415013221_3991 and 20130405063033_1587.	D
CCT323	Amazonia contains half of all remaining tropical moist forest (Fritz et al., 2003). The total vegetation carbon storage of Amazon basin tropical forests has been subject to a wide range of estimates (#CITATION_TAG et al., 2001;Malhi et al., 2006;Saatchi et al., 2007). These have varied from 58 Pg C (Olson et al., 1983) to 134 Pg C (Fearnside, 1997, scaled to whole basin), although there is now some general consensus in the middle of this range [e.g. 93 ¬± 23 Pg C (Malhi et al., 2006), 86 ¬± 17 Pg C (Saatchi et al., 2007) and 89 Pg C (FAO, 2010)]. However, these estimates of carbon stocks mask large differences at a smaller spatial scale, as local variations are cancelled out when summing over large areas: the spatial patterns visible in different maps of above-ground biomass (AGB) vary greatly, with little consistency even between studies that use similar methods and input data (Houghton et al., 2001).	2	Amazonia contains half of all remaining tropical moist forest (Fritz et al., 2003). The total vegetation carbon storage of Amazon basin tropical forests has been subject to a wide range of estimates (#CITATION_TAG et al., 2001;Malhi et al., 2006;Saatchi et al., 2007). These have varied from 58 Pg C (Olson et al., 1983) to 134 Pg C (Fearnside, 1997, scaled to whole basin), although there is now some general consensus in the middle of this range [e.g. 93 ¬± 23 Pg C (Malhi et al., 2006), 86 ¬± 17 Pg C (Saatchi et al., 2007) and 89 Pg C (FAO, 2010)]. However, these estimates of carbon stocks mask large differences at a smaller spatial scale, as local variations are cancelled out when summing over large areas: the spatial patterns visible in different maps of above-ground biomass (AGB) vary greatly, with little consistency even between studies that use similar methods and input data (Houghton et al., 2001).	h
CCT324	Amazonia contains half of all remaining tropical moist forest (Fritz et al., 2003). The total vegetation carbon storage of Amazon basin tropical forests has been subject to a wide range of estimates (Houghton et al., 2001;Malhi et al., 2006;Saatchi et al., 2007). These have varied from 58 Pg C (#CITATION_TAG et al., 1983) to 134 Pg C (Fearnside, 1997, scaled to whole basin), although there is now some general consensus in the middle of this range [e.g. 93 ¬± 23 Pg C (Malhi et al., 2006), 86 ¬± 17 Pg C (Saatchi et al., 2007) and 89 Pg C (FAO, 2010)]. However, these estimates of carbon stocks mask large differences at a smaller spatial scale, as local variations are cancelled out when summing over large areas: the spatial patterns visible in different maps of above-ground biomass (AGB) vary greatly, with little consistency even between studies that use similar methods and input data (Houghton et al., 2001).	0	Amazonia contains half of all remaining tropical moist forest (Fritz et al., 2003). The total vegetation carbon storage of Amazon basin tropical forests has been subject to a wide range of estimates (Houghton et al., 2001;Malhi et al., 2006;Saatchi et al., 2007). These have varied from 58 Pg C (#CITATION_TAG et al., 1983) to 134 Pg C (Fearnside, 1997, scaled to whole basin), although there is now some general consensus in the middle of this range [e.g. 93 ¬± 23 Pg C (Malhi et al., 2006), 86 ¬± 17 Pg C (Saatchi et al., 2007) and 89 Pg C (FAO, 2010)]. However, these estimates of carbon stocks mask large differences at a smaller spatial scale, as local variations are cancelled out when summing over large areas: the spatial patterns visible in different maps of above-ground biomass (AGB) vary greatly, with little consistency even between studies that use similar methods and input data (Houghton et al., 2001).	e
CCT325	The principal AGB dataset was calculated using the threeparameter moist tropical forest model from Chave et al. (2005), with height estimated from d.b.h. individually for each stem using the region-specific Weibull models from Feldpausch et al. (2012), and wood density values estimated for each stem using the mean value for the species in the Global Wood Density Database (Chave et al., 2009;#CITATION_TAG et al., 2009), or the mean for the genus using congeneric taxa from Mexico, Central America and tropical South America if no data were available for that species (K DHœÅ). For comparison, AGB was also calculated using the same allometric equation but with the pan-Amazon Weibull model from Feldpausch et al. (2012) (KDœÅ), regional height models but with a dataset mean wood density value of 0.63 applied to every stem (KDH), and with the pan-Amazonian height model and mean wood density applied to every stem (KD).	5	The principal AGB dataset was calculated using the threeparameter moist tropical forest model from Chave et al. (2005), with height estimated from d.b.h. individually for each stem using the region-specific Weibull models from Feldpausch et al. (2012), and wood density values estimated for each stem using the mean value for the species in the Global Wood Density Database (Chave et al., 2009;#CITATION_TAG et al., 2009), or the mean for the genus using congeneric taxa from Mexico, Central America and tropical South America if no data were available for that species (K DHœÅ). For comparison, AGB was also calculated using the same allometric equation but with the pan-Amazon Weibull model from Feldpausch et al. (2012) (KDœÅ), regional height models but with a dataset mean wood density value of 0.63 applied to every stem (KDH), and with the pan-Amazonian height model and mean wood density applied to every stem (KD).	T
CCT326	In order to test this, we use a unique dataset of 413 field plots located throughout tropical South America, compiled as part of RAINFOR (Red Amaz√≥nica de Inventarios Forestales; Amazon Forest Inventory Network; #CITATION_TAG et al., 2002), the Amazon Tree Diversity Network (ter Steege et al., 2003), TEAM (Tropical Ecology Assessment and Monitoring) and PPBio (Brazilian Program for Biodiversity Research) (Fig. 1). Data in these plots were collected using a consistent methodology, and AGB was calculated using a T-SQL query to a single database. We compare these field plots directly to the two remote-sensing-derived maps, and additionally create a plotbased AGB map using simple two-dimensional kriging (K DHœÅ) to allow a spatial comparison.	5	In order to test this, we use a unique dataset of 413 field plots located throughout tropical South America, compiled as part of RAINFOR (Red Amaz√≥nica de Inventarios Forestales; Amazon Forest Inventory Network; #CITATION_TAG et al., 2002), the Amazon Tree Diversity Network (ter Steege et al., 2003), TEAM (Tropical Ecology Assessment and Monitoring) and PPBio (Brazilian Program for Biodiversity Research) (Fig. 1). Data in these plots were collected using a consistent methodology, and AGB was calculated using a T-SQL query to a single database. We compare these field plots directly to the two remote-sensing-derived maps, and additionally create a plotbased AGB map using simple two-dimensional kriging (K DHœÅ) to allow a spatial comparison.	I
CCT327	For a wide variety of conservation and sustainable forest management projects, forest carbon stocks -and changes in these stocks -must be estimated with confidence. Accurate estimation, however, still faces major challenges: indeed, in a comparison of estimates of carbon emissions from deforestation in the Amazon, the biggest cause of discrepancies between estimates was found to be due to carbon mapping, higher than the uncertainty in the mapping of deforestation (Gutierrez-Velez & Pontius, 2012). AGB is the largest carbon pool in most tropical forests, and also tends to be the best characterized because it is relatively easy to measure, with other carbon pools often estimated as a simple ratio of AGB (GOFC-GOLD, 2009). Biomass maps of the Amazon region have been created in a number of ways. Some have used direct extrapolations from field-plot measurements, either multiplying the total area of forest by mean biomass density values (Olson et al., 1983;Fearnside, 1997;FAO, 2010) or by two-dimensional kriging (Malhi et al., 2006); others have used environmental gradients to co-krig field-plot measurements (U.S. Agency for International Development, 2012); and others have used remotesensing (RS) data (Saatchi et al., 2007). In the absence of continuous field measurements throughout an area of interest, RS datasets should provide the most accurate maps, because every location can be directly observed. Methods based solely on ground plots will only ever be able to sample a very small percentage of the total area, and due to access difficulties, a network of ground points will normally be biased towards more easily accessible regions (concentrated near rivers, roads and scientific field stations). However, using current technology AGB cannot be directly estimated from space (#CITATION_TAG et al., 2012), and thus field plots remain essential for calibrating and validating RS maps. Ground-based estimates, and thereby calibrations of RS maps, are themselves limited by the small quantity of destructive biomass data available, which reduces the confidence in allometric equations used to convert ground data into estimates of AGB (Feldpausch et al., 2012).	0	Some have used direct extrapolations from field-plot measurements, either multiplying the total area of forest by mean biomass density values (Olson et al., 1983;Fearnside, 1997;FAO, 2010) or by two-dimensional kriging (Malhi et al., 2006); others have used environmental gradients to co-krig field-plot measurements (U.S. Agency for International Development, 2012); and others have used remotesensing (RS) data (Saatchi et al., 2007). In the absence of continuous field measurements throughout an area of interest, RS datasets should provide the most accurate maps, because every location can be directly observed. Methods based solely on ground plots will only ever be able to sample a very small percentage of the total area, and due to access difficulties, a network of ground points will normally be biased towards more easily accessible regions (concentrated near rivers, roads and scientific field stations). However, using current technology AGB cannot be directly estimated from space (#CITATION_TAG et al., 2012), and thus field plots remain essential for calibrating and validating RS maps. Ground-based estimates, and thereby calibrations of RS maps, are themselves limited by the small quantity of destructive biomass data available, which reduces the confidence in allometric equations used to convert ground data into estimates of AGB (Feldpausch et al., 2012).	,
CCT328	"Forests in the Changing Earth System""), and Natural Environment Research Council (NERC) Urgency Grant and NERC Consortium Grants ""AMAZONICA"" (NE/F005806/1) and ""TROBIT"" (NE/D005590/1). Additional data were included from the Tropical Ecology Assessment and Monitoring (TEAM) Network, a collaboration between Conservation International, the Missouri Botanical Garden, the Smithsonian Institution and the Wildlife Conservation Society, and partly funded by these institutions, the Gordon and Betty Moore Foundation, and other donors. The unpublished field data summarized here involve contributions from numerous field assistants and rural communities in Bolivia, Brazil, Colombia, Ecuador, French Guiana, Guyana, Peru, Suriname and Venezuela, most of whom have been specifically acknowledged in #CITATION_TAG et al. (2009b). We also thank Edmar Almeida de Oliveira, Vega Arenas, Antonio Pe√±a Cruz, Camilo Diaz, Javier Silva Espejo, Leandro Ferreira, Luis Valenzuela Gamarra, Julio Iriaca, Eliana Jim√©nez, Diego Rojas Landivar, Carolina Levis, Rodolfo V√°squez Mart√≠nez, Maria Cristina Pe√±uela, Irina Mendoza Polo, Ednodio Quintero, Agustin Rudas, Paulo S√©rgio Morandi, Natalino Silva, Hugo V√°squez, and Jaim Ybarnegaray for their invaluable contributions. We thank Sue Grahame and Georgia Pickavance for their support with the ForestPlots.net database and Joana Ricardo for work supporting RAINFOR collaborators. We dedicate this work to the memory of Alwyn Gentry, Jean Pierre Veillon, Samuel Almeida and Sandra Pati√±o, whose pioneering efforts to understand Neotropical forest composition and structure from the ground up have been an inspiration for succeeding generations of ecologists."	0	"Forests in the Changing Earth System""), and Natural Environment Research Council (NERC) Urgency Grant and NERC Consortium Grants ""AMAZONICA"" (NE/F005806/1) and ""TROBIT"" (NE/D005590/1). Additional data were included from the Tropical Ecology Assessment and Monitoring (TEAM) Network, a collaboration between Conservation International, the Missouri Botanical Garden, the Smithsonian Institution and the Wildlife Conservation Society, and partly funded by these institutions, the Gordon and Betty Moore Foundation, and other donors. The unpublished field data summarized here involve contributions from numerous field assistants and rural communities in Bolivia, Brazil, Colombia, Ecuador, French Guiana, Guyana, Peru, Suriname and Venezuela, most of whom have been specifically acknowledged in #CITATION_TAG et al. (2009b). We also thank Edmar Almeida de Oliveira, Vega Arenas, Antonio Pe√±a Cruz, Camilo Diaz, Javier Silva Espejo, Leandro Ferreira, Luis Valenzuela Gamarra, Julio Iriaca, Eliana Jim√©nez, Diego Rojas Landivar, Carolina Levis, Rodolfo V√°squez Mart√≠nez, Maria Cristina Pe√±uela, Irina Mendoza Polo, Ednodio Quintero, Agustin Rudas, Paulo S√©rgio Morandi, Natalino Silva, Hugo V√°squez, and Jaim Ybarnegaray for their invaluable contributions. We thank Sue Grahame and Georgia Pickavance for their support with the ForestPlots.net database and Joana Ricardo for work supporting RAINFOR collaborators. We dedicate this work to the memory of Alwyn Gentry, Jean Pierre Veillon, Samuel Almeida and Sandra Pati√±o, whose pioneering efforts to understand Neotropical forest composition and structure from the ground up have been an inspiration for succeeding generations of ecologists."	e
CCT329	The units of the maps were in tonnes of biomass per hectare (Mg ha ‚àí1 ). Total carbon stocks for subsets of the resulting layers were calculated by multiplying the mean biomass of a subset by its area in hectares, and then converting biomass to carbon by multiplying the result by 0.5 (as dry biomass is assumed to be 50% carbon; #CITATION_TAG et al., 2003).	5	The units of the maps were in tonnes of biomass per hectare (Mg ha ‚àí1 ). Total carbon stocks for subsets of the resulting layers were calculated by multiplying the mean biomass of a subset by its area in hectares, and then converting biomass to carbon by multiplying the result by 0.5 (as dry biomass is assumed to be 50% carbon; #CITATION_TAG et al., 2003).	o
CCT330	The field plots with our best estimate of AGB (P DHœÅ) show a robust trend of increasing AGB with increasing latitude, longitude and distance along a SW-NE line (Fig. 2a-c; the parameters of the best-fit lines are given in Table S1; input plot biomass data are available in #CITATION_TAG et al., 2014). The kriged map of the same field plots (Fig. 3c) shows that the latitudinal and longitudinal trends seen in the graphs are clearly driven by the dominant SW-NE gradient. By contrast, the remote-sensing layers RS1 and RS2 show significant decreasing trends with dis-tance along a SW-NE line (Fig. 2c, Table S1). Subtracting the two RS layers from the plot AGB values emphasizes the trends described above, with positive differences (i.e. RS1 and RS2 greater than P DHœÅ) in the south and west, and negative differences in the north and east (Fig. 2d-f, Table S1).	5	The field plots with our best estimate of AGB (P DHœÅ) show a robust trend of increasing AGB with increasing latitude, longitude and distance along a SW-NE line (Fig. 2a-c; the parameters of the best-fit lines are given in Table S1; input plot biomass data are available in #CITATION_TAG et al., 2014). The kriged map of the same field plots (Fig. 3c) shows that the latitudinal and longitudinal trends seen in the graphs are clearly driven by the dominant SW-NE gradient. By contrast, the remote-sensing layers RS1 and RS2 show significant decreasing trends with dis-tance along a SW-NE line (Fig. 2c, Table S1). Subtracting the two RS layers from the plot AGB values emphasizes the trends described above, with positive differences (i.e. RS1 and RS2 greater than P DHœÅ) in the south and west, and negative differences in the north and east (Fig. 2d-f, Table S1).	T
CCT331	Amazonia contains half of all remaining tropical moist forest (#CITATION_TAG et al., 2003). The total vegetation carbon storage of Amazon basin tropical forests has been subject to a wide range of estimates (Houghton et al., 2001;Malhi et al., 2006;Saatchi et al., 2007). These have varied from 58 Pg C (Olson et al., 1983) to 134 Pg C (Fearnside, 1997, scaled to whole basin), although there is now some general consensus in the middle of this range [e.g. 93 ¬± 23 Pg C (Malhi et al., 2006), 86 ¬± 17 Pg C (Saatchi et al., 2007) and 89 Pg C (FAO, 2010)]. However, these estimates of carbon stocks mask large differences at a smaller spatial scale, as local variations are cancelled out when summing over large areas: the spatial patterns visible in different maps of above-ground biomass (AGB) vary greatly, with little consistency even between studies that use similar methods and input data (Houghton et al., 2001).	0	Amazonia contains half of all remaining tropical moist forest (#CITATION_TAG et al., 2003). The total vegetation carbon storage of Amazon basin tropical forests has been subject to a wide range of estimates (Houghton et al., 2001;Malhi et al., 2006;Saatchi et al., 2007). These have varied from 58 Pg C (Olson et al., 1983) to 134 Pg C (Fearnside, 1997, scaled to whole basin), although there is now some general consensus in the middle of this range [e.g. 93 ¬± 23 Pg C (Malhi et al., 2006), 86 ¬± 17 Pg C (Saatchi et al., 2007) and 89 Pg C (FAO, 2010)]. However, these estimates of carbon stocks mask large differences at a smaller spatial scale, as local variations are cancelled out when summing over large areas: the spatial patterns visible in different maps of above-ground biomass (AGB) vary greatly, with little consistency even between studies that use similar methods and input data (Houghton et al., 2001).	A
CCT332	For a wide variety of conservation and sustainable forest management projects, forest carbon stocks -and changes in these stocks -must be estimated with confidence. Accurate estimation, however, still faces major challenges: indeed, in a comparison of estimates of carbon emissions from deforestation in the Amazon, the biggest cause of discrepancies between estimates was found to be due to carbon mapping, higher than the uncertainty in the mapping of deforestation (Gutierrez-Velez & Pontius, 2012). AGB is the largest carbon pool in most tropical forests, and also tends to be the best characterized because it is relatively easy to measure, with other carbon pools often estimated as a simple ratio of AGB (GOFC-GOLD, 2009). Biomass maps of the Amazon region have been created in a number of ways. Some have used direct extrapolations from field-plot measurements, either multiplying the total area of forest by mean biomass density values (Olson et al., 1983;#CITATION_TAG, 1997;FAO, 2010) or by two-dimensional kriging (Malhi et al., 2006); others have used environmental gradients to co-krig field-plot measurements (U.S. Agency for International Development, 2012); and others have used remotesensing (RS) data (Saatchi et al., 2007). In the absence of continuous field measurements throughout an area of interest, RS datasets should provide the most accurate maps, because every location can be directly observed. Methods based solely on ground plots will only ever be able to sample a very small percentage of the total area, and due to access difficulties, a network of ground points will normally be biased towards more easily accessible regions (concentrated near rivers, roads and scientific field stations). However, using current technology AGB cannot be directly estimated from space (Woodhouse et al., 2012), and thus field plots remain essential for calibrating and validating RS maps. Ground-based estimates, and thereby calibrations of RS maps, are themselves limited by the small quantity of destructive biomass data available, which reduces the confidence in allometric equations used to convert ground data into estimates of AGB (Feldpausch et al., 2012).	0	Accurate estimation, however, still faces major challenges: indeed, in a comparison of estimates of carbon emissions from deforestation in the Amazon, the biggest cause of discrepancies between estimates was found to be due to carbon mapping, higher than the uncertainty in the mapping of deforestation (Gutierrez-Velez & Pontius, 2012). AGB is the largest carbon pool in most tropical forests, and also tends to be the best characterized because it is relatively easy to measure, with other carbon pools often estimated as a simple ratio of AGB (GOFC-GOLD, 2009). Biomass maps of the Amazon region have been created in a number of ways. Some have used direct extrapolations from field-plot measurements, either multiplying the total area of forest by mean biomass density values (Olson et al., 1983;#CITATION_TAG, 1997;FAO, 2010) or by two-dimensional kriging (Malhi et al., 2006); others have used environmental gradients to co-krig field-plot measurements (U.S. Agency for International Development, 2012); and others have used remotesensing (RS) data (Saatchi et al., 2007). In the absence of continuous field measurements throughout an area of interest, RS datasets should provide the most accurate maps, because every location can be directly observed. Methods based solely on ground plots will only ever be able to sample a very small percentage of the total area, and due to access difficulties, a network of ground points will normally be biased towards more easily accessible regions (concentrated near rivers, roads and scientific field stations). However, using current technology AGB cannot be directly estimated from space (Woodhouse et al., 2012), and thus field plots remain essential for calibrating and validating RS maps.	 
CCT333	"It is of great importance that the distribution of carbon storage across the Amazon be well-characterized. Although there are many reasons that make it desirable to protect tropical forests, the protection of their carbon stocks and potential as a future carbon sink have made their preservation a current policy priority. A major initiative in international climate negotiations, Reducing Emissions from Deforestation and forest Degradation (REDD+), envisages payments in return for forest conservation. Though REDD+ is not yet operational, voluntary-sector afforestation/reforestation and REDD+ projects already exist, with REDD+ credit sales equal to $85 million in 2010 (#CITATION_TAG et al., 2011). Country-to-country cash transfers have also taken place, with Norway leading the way, committing US$1 billion to the government of Indonesia, a similar amount to Brazil""s Amazon Fund, and $250 million to Guyana, in return for their meeting goals for reducing rates of forest loss (Caravani et al., 2012). Other sources of conservation and development funding also assess projects based on their carbon impact: indeed, one of the stated criteria applied to all USAID funding (equivalent to US$40 billion in 2012) is to be carbonpositive where possible (U.S. Agency for International Development, 2012)."	0	"It is of great importance that the distribution of carbon storage across the Amazon be well-characterized. Although there are many reasons that make it desirable to protect tropical forests, the protection of their carbon stocks and potential as a future carbon sink have made their preservation a current policy priority. A major initiative in international climate negotiations, Reducing Emissions from Deforestation and forest Degradation (REDD+), envisages payments in return for forest conservation. Though REDD+ is not yet operational, voluntary-sector afforestation/reforestation and REDD+ projects already exist, with REDD+ credit sales equal to $85 million in 2010 (#CITATION_TAG et al., 2011). Country-to-country cash transfers have also taken place, with Norway leading the way, committing US$1 billion to the government of Indonesia, a similar amount to Brazil""s Amazon Fund, and $250 million to Guyana, in return for their meeting goals for reducing rates of forest loss (Caravani et al., 2012). Other sources of conservation and development funding also assess projects based on their carbon impact: indeed, one of the stated criteria applied to all USAID funding (equivalent to US$40 billion in 2012) is to be carbonpositive where possible (U.S. Agency for International Development, 2012)."	u
CCT334	"It is of great importance that the distribution of carbon storage across the Amazon be well-characterized. Although there are many reasons that make it desirable to protect tropical forests, the protection of their carbon stocks and potential as a future carbon sink have made their preservation a current policy priority. A major initiative in international climate negotiations, Reducing Emissions from Deforestation and forest Degradation (REDD+), envisages payments in return for forest conservation. Though REDD+ is not yet operational, voluntary-sector afforestation/reforestation and REDD+ projects already exist, with REDD+ credit sales equal to $85 million in 2010 (Diaz et al., 2011). Country-to-country cash transfers have also taken place, with Norway leading the way, committing US$1 billion to the government of Indonesia, a similar amount to Brazil""s Amazon Fund, and $250 million to Guyana, in return for their meeting goals for reducing rates of forest loss (#CITATION_TAG et al., 2012). Other sources of conservation and development funding also assess projects based on their carbon impact: indeed, one of the stated criteria applied to all USAID funding (equivalent to US$40 billion in 2012) is to be carbonpositive where possible (U.S. Agency for International Development, 2012)."	0	"Although there are many reasons that make it desirable to protect tropical forests, the protection of their carbon stocks and potential as a future carbon sink have made their preservation a current policy priority. A major initiative in international climate negotiations, Reducing Emissions from Deforestation and forest Degradation (REDD+), envisages payments in return for forest conservation. Though REDD+ is not yet operational, voluntary-sector afforestation/reforestation and REDD+ projects already exist, with REDD+ credit sales equal to $85 million in 2010 (Diaz et al., 2011). Country-to-country cash transfers have also taken place, with Norway leading the way, committing US$1 billion to the government of Indonesia, a similar amount to Brazil""s Amazon Fund, and $250 million to Guyana, in return for their meeting goals for reducing rates of forest loss (#CITATION_TAG et al., 2012). Other sources of conservation and development funding also assess projects based on their carbon impact: indeed, one of the stated criteria applied to all USAID funding (equivalent to US$40 billion in 2012) is to be carbonpositive where possible (U.S. Agency for International Development, 2012)."	t
CCT335	In both cases, the primary calibration data used to produce the maps is derived from profiles of tree height from the ICESat GLAS sensor. Although these data do include some information about the structural characteristics of the forest within the LiDAR footprints, canopy height is the principal parameter detected (#CITATION_TAG et al., 2005). However, allometric equations that relate physical attributes of trees to their above-ground biomass normally rely on three parameters: in addition to tree height (H), tree diameter at 1.3 m (D) and wood density (œÅ) are very important (Chave et al., 2005), and mean values and ratios between these parameters vary significantly between regions (Chave et al., 2005;Feldpausch et al., 2012;Quesada et al., 2012), associated with different species communities (ter Steege et al., 2006). We know that wood density increases from west to east across Amazonia (Baker et al., 2004;ter Steege et al., 2006), inversely correlated to stem turnover rate (Quesada et al., 2012). This gradient is driven by soil fertility, notably total soil phosphorus and the concentration of exchangeable potassium ions (Arag√£o et al., 2009), and especially by the physical qualities of the soil. Thus, the fertile but shallower soils of the western Amazon lead to higher productivity and faster turnover, and a set of species with low wood density; conversely, the low fertility but deep and freely-draining soils of the eastern Amazon tend to have lower productivity and slower turnover, and species with much higher wood density. The relationship between diameter and height also varies across the basin, but with more complexity than wood density, mostly related to climatic factors (Feldpausch et al., 2011). These are approximated into four zones (Feldpausch et al., 2011(Feldpausch et al., , 2012, with the use of a different D:H model in each zone, greatly reducing the error in the prediction of H from D compared to a pan-Amazonian model (Feldpausch et al., 2012).	0	In both cases, the primary calibration data used to produce the maps is derived from profiles of tree height from the ICESat GLAS sensor. Although these data do include some information about the structural characteristics of the forest within the LiDAR footprints, canopy height is the principal parameter detected (#CITATION_TAG et al., 2005). However, allometric equations that relate physical attributes of trees to their above-ground biomass normally rely on three parameters: in addition to tree height (H), tree diameter at 1.3 m (D) and wood density (œÅ) are very important (Chave et al., 2005), and mean values and ratios between these parameters vary significantly between regions (Chave et al., 2005;Feldpausch et al., 2012;Quesada et al., 2012), associated with different species communities (ter Steege et al., 2006). We know that wood density increases from west to east across Amazonia (Baker et al., 2004;ter Steege et al., 2006), inversely correlated to stem turnover rate (Quesada et al., 2012). This gradient is driven by soil fertility, notably total soil phosphorus and the concentration of exchangeable potassium ions (Arag√£o et al., 2009), and especially by the physical qualities of the soil.	l
CCT336	The study was approved by our local ethical committee and was carried out according to the declaration of Helsinki and subsequent revisions [28]. Patients (or caregivers) signed a written informed consent and authorization was obtained for disclosure (consent-to-disclose) of any recognizable persons in videos. All patients received a full neurological, neuropsychological, neuroimaging and neuropsychiatric evaluation, as reported in Online Resource 1, and as described in previous studies on the same cohort [29][30][31]#CITATION_TAG. Observation and recording of tremors were performed only in dopaminergic drugs naive patients (all DLB and 52 PD patients) or after withdrawal of L-Dopa (48 h) or dopamine agonist (72 h) treatments (13 PD patients).	0	The study was approved by our local ethical committee and was carried out according to the declaration of Helsinki and subsequent revisions [28]. Patients (or caregivers) signed a written informed consent and authorization was obtained for disclosure (consent-to-disclose) of any recognizable persons in videos. All patients received a full neurological, neuropsychological, neuroimaging and neuropsychiatric evaluation, as reported in Online Resource 1, and as described in previous studies on the same cohort [29][30][31]#CITATION_TAG. Observation and recording of tremors were performed only in dopaminergic drugs naive patients (all DLB and 52 PD patients) or after withdrawal of L-Dopa (48 h) or dopamine agonist (72 h) treatments (13 PD patients).	l
CCT337	"The last consensus on diagnostic criteria for dementia with Lewy Bodies (DLB), states that """"tremor is less frequent than in Parkinson""s disease (PD)"""" [1] but does not detail the types and relative prevalence of tremor, despite earlier studies reporting a prevalence of 40 % for rest and 30 % for action (kinetic-postural) tremor [2,#CITATION_TAG]."	0	"The last consensus on diagnostic criteria for dementia with Lewy Bodies (DLB), states that """"tremor is less frequent than in Parkinson""s disease (PD)"""" [1] but does not detail the types and relative prevalence of tremor, despite earlier studies reporting a prevalence of 40 % for rest and 30 % for action (kinetic-postural) tremor [2,#CITATION_TAG]."	T
CCT338	Generally rest tremor is considered specific for PD, while postural and action (or intentional) tremor are attributed to essential tremor (ET), although exceptions to this rule are clearly reported [4][5][6]. The prevalence of these tremors have not been investigated in DLB after the early reports, nor was described the prevalence of other types of tremor which are considered infrequent but specific to PD, as head and face tremors [7,8], re-emergent [6,9], pseudoorthostatic or standing tremor [5,[10]#CITATION_TAG[12][13]. In addition, while there are some small studies reporting an improvement of general motor features in DLB with acute L-Dopa challenge [14], the specific response of tremors to treatments has been investigated in only one early study [15].	4	Generally rest tremor is considered specific for PD, while postural and action (or intentional) tremor are attributed to essential tremor (ET), although exceptions to this rule are clearly reported [4][5][6]. The prevalence of these tremors have not been investigated in DLB after the early reports, nor was described the prevalence of other types of tremor which are considered infrequent but specific to PD, as head and face tremors [7,8], re-emergent [6,9], pseudoorthostatic or standing tremor [5,[10]#CITATION_TAG[12][13]. In addition, while there are some small studies reporting an improvement of general motor features in DLB with acute L-Dopa challenge [14], the specific response of tremors to treatments has been investigated in only one early study [15].	h
CCT339	Generally rest tremor is considered specific for PD, while postural and action (or intentional) tremor are attributed to essential tremor (ET), although exceptions to this rule are clearly reported [4][5][6]. The prevalence of these tremors have not been investigated in DLB after the early reports, nor was described the prevalence of other types of tremor which are considered infrequent but specific to PD, as head and face tremors [7,8], re-emergent [6,9], pseudoorthostatic or standing tremor [5,[10][11]#CITATION_TAG[13]. In addition, while there are some small studies reporting an improvement of general motor features in DLB with acute L-Dopa challenge [14], the specific response of tremors to treatments has been investigated in only one early study [15].	4	Generally rest tremor is considered specific for PD, while postural and action (or intentional) tremor are attributed to essential tremor (ET), although exceptions to this rule are clearly reported [4][5][6]. The prevalence of these tremors have not been investigated in DLB after the early reports, nor was described the prevalence of other types of tremor which are considered infrequent but specific to PD, as head and face tremors [7,8], re-emergent [6,9], pseudoorthostatic or standing tremor [5,[10][11]#CITATION_TAG[13]. In addition, while there are some small studies reporting an improvement of general motor features in DLB with acute L-Dopa challenge [14], the specific response of tremors to treatments has been investigated in only one early study [15].	h
CCT340	Generally rest tremor is considered specific for PD, while postural and action (or intentional) tremor are attributed to essential tremor (ET), although exceptions to this rule are clearly reported [4]#CITATION_TAG[6]. The prevalence of these tremors have not been investigated in DLB after the early reports, nor was described the prevalence of other types of tremor which are considered infrequent but specific to PD, as head and face tremors [7,8], re-emergent [6,9], pseudoorthostatic or standing tremor [5,[10][11][12][13]. In addition, while there are some small studies reporting an improvement of general motor features in DLB with acute L-Dopa challenge [14], the specific response of tremors to treatments has been investigated in only one early study [15].	0	Generally rest tremor is considered specific for PD, while postural and action (or intentional) tremor are attributed to essential tremor (ET), although exceptions to this rule are clearly reported [4]#CITATION_TAG[6]. The prevalence of these tremors have not been investigated in DLB after the early reports, nor was described the prevalence of other types of tremor which are considered infrequent but specific to PD, as head and face tremors [7,8], re-emergent [6,9], pseudoorthostatic or standing tremor [5,[10][11][12][13]. In addition, while there are some small studies reporting an improvement of general motor features in DLB with acute L-Dopa challenge [14], the specific response of tremors to treatments has been investigated in only one early study [15].	G
CCT341	The clarification of the different tremor types and response to treatment in DLB could improve clinical recognition of DLB, but mostly, understanding tremor in DLB, would provide clarity to recent controversial debates [16][17]#CITATION_TAG[19][20][21][22][23][24] on the long term outcome of patients putatively affected by ET. Several reports showed that some ET patients, during follow-up may present with additional PD features, dopamine transporter capitation abnormalities, or cognitive abnormalities, and may present with Lewy bodies at the autopsy [16][17][18][19][20][21]. These observations were, more or less dismissively, challenged in three different editorials [22][23][24]. Yet, these discussions did not consider at all that the action (kinetic, postural) tremors, of DLB may be erroneously attributed to ET.	1	The clarification of the different tremor types and response to treatment in DLB could improve clinical recognition of DLB, but mostly, understanding tremor in DLB, would provide clarity to recent controversial debates [16][17]#CITATION_TAG[19][20][21][22][23][24] on the long term outcome of patients putatively affected by ET. Several reports showed that some ET patients, during follow-up may present with additional PD features, dopamine transporter capitation abnormalities, or cognitive abnormalities, and may present with Lewy bodies at the autopsy [16][17][18][19][20][21]. These observations were, more or less dismissively, challenged in three different editorials [22][23][24]. Yet, these discussions did not consider at all that the action (kinetic, postural) tremors, of DLB may be erroneously attributed to ET.	T
CCT342	The clarification of the different tremor types and response to treatment in DLB could improve clinical recognition of DLB, but mostly, understanding tremor in DLB, would provide clarity to recent controversial debates [16]#CITATION_TAG[18][19][20][21][22][23][24] on the long term outcome of patients putatively affected by ET. Several reports showed that some ET patients, during follow-up may present with additional PD features, dopamine transporter capitation abnormalities, or cognitive abnormalities, and may present with Lewy bodies at the autopsy [16][17][18][19][20][21]. These observations were, more or less dismissively, challenged in three different editorials [22][23][24]. Yet, these discussions did not consider at all that the action (kinetic, postural) tremors, of DLB may be erroneously attributed to ET.	1	The clarification of the different tremor types and response to treatment in DLB could improve clinical recognition of DLB, but mostly, understanding tremor in DLB, would provide clarity to recent controversial debates [16]#CITATION_TAG[18][19][20][21][22][23][24] on the long term outcome of patients putatively affected by ET. Several reports showed that some ET patients, during follow-up may present with additional PD features, dopamine transporter capitation abnormalities, or cognitive abnormalities, and may present with Lewy bodies at the autopsy [16][17][18][19][20][21]. These observations were, more or less dismissively, challenged in three different editorials [22][23][24]. Yet, these discussions did not consider at all that the action (kinetic, postural) tremors, of DLB may be erroneously attributed to ET.	T
CCT343	Acute drug challenge was performed in 34 ET, 24 DLB and 27 PD patients. Acute treatments were evaluated in the three groups with blinded procedures. Alcohol test and acute L-Dopa challenges were performed according to the described protocols [15,[34][35]#CITATION_TAG]. An alcohol test was performed in all ET, PD and DLB patients with tremor, in blinded protocols. A target of 0.8 % (0.8 g/L) alcohol was reached by administering in 5 min, 8 fluid oz of orange juice with artificial nonalcohol Rum flavour (placebo) or orange juice with 40 % alcohol Rum. The needed amount of alcohol was calculated for each patient according to published body water formulas. The TRGRS rating was performed by examiners unaware of the administered substance 30-45 min after the administration according to published observations on maximal tremor responses to ethanol administration [34].	5	Acute drug challenge was performed in 34 ET, 24 DLB and 27 PD patients. Acute treatments were evaluated in the three groups with blinded procedures. Alcohol test and acute L-Dopa challenges were performed according to the described protocols [15,[34][35]#CITATION_TAG]. An alcohol test was performed in all ET, PD and DLB patients with tremor, in blinded protocols. A target of 0.8 % (0.8 g/L) alcohol was reached by administering in 5 min, 8 fluid oz of orange juice with artificial nonalcohol Rum flavour (placebo) or orange juice with 40 % alcohol Rum. The needed amount of alcohol was calculated for each patient according to published body water formulas.	c
CCT344	The study was approved by our local ethical committee and was carried out according to the declaration of Helsinki and subsequent revisions [28]. Patients (or caregivers) signed a written informed consent and authorization was obtained for disclosure (consent-to-disclose) of any recognizable persons in videos. All patients received a full neurological, neuropsychological, neuroimaging and neuropsychiatric evaluation, as reported in Online Resource 1, and as described in previous studies on the same cohort [29]#CITATION_TAG[31][32]. Observation and recording of tremors were performed only in dopaminergic drugs naive patients (all DLB and 52 PD patients) or after withdrawal of L-Dopa (48 h) or dopamine agonist (72 h) treatments (13 PD patients).	0	The study was approved by our local ethical committee and was carried out according to the declaration of Helsinki and subsequent revisions [28]. Patients (or caregivers) signed a written informed consent and authorization was obtained for disclosure (consent-to-disclose) of any recognizable persons in videos. All patients received a full neurological, neuropsychological, neuroimaging and neuropsychiatric evaluation, as reported in Online Resource 1, and as described in previous studies on the same cohort [29]#CITATION_TAG[31][32]. Observation and recording of tremors were performed only in dopaminergic drugs naive patients (all DLB and 52 PD patients) or after withdrawal of L-Dopa (48 h) or dopamine agonist (72 h) treatments (13 PD patients).	l
CCT345	The study was approved by our local ethical committee and was carried out according to the declaration of Helsinki and subsequent revisions [28]. Patients (or caregivers) signed a written informed consent and authorization was obtained for disclosure (consent-to-disclose) of any recognizable persons in videos. All patients received a full neurological, neuropsychological, neuroimaging and neuropsychiatric evaluation, as reported in Online Resource 1, and as described in previous studies on the same cohort #CITATION_TAG[30][31][32]. Observation and recording of tremors were performed only in dopaminergic drugs naive patients (all DLB and 52 PD patients) or after withdrawal of L-Dopa (48 h) or dopamine agonist (72 h) treatments (13 PD patients).	0	The study was approved by our local ethical committee and was carried out according to the declaration of Helsinki and subsequent revisions [28]. Patients (or caregivers) signed a written informed consent and authorization was obtained for disclosure (consent-to-disclose) of any recognizable persons in videos. All patients received a full neurological, neuropsychological, neuroimaging and neuropsychiatric evaluation, as reported in Online Resource 1, and as described in previous studies on the same cohort #CITATION_TAG[30][31][32]. Observation and recording of tremors were performed only in dopaminergic drugs naive patients (all DLB and 52 PD patients) or after withdrawal of L-Dopa (48 h) or dopamine agonist (72 h) treatments (13 PD patients).	l
CCT346	The clarification of the different tremor types and response to treatment in DLB could improve clinical recognition of DLB, but mostly, understanding tremor in DLB, would provide clarity to recent controversial debates [16][17][18][19][20][21][22][23]#CITATION_TAG on the long term outcome of patients putatively affected by ET. Several reports showed that some ET patients, during follow-up may present with additional PD features, dopamine transporter capitation abnormalities, or cognitive abnormalities, and may present with Lewy bodies at the autopsy [16][17][18][19][20][21]. These observations were, more or less dismissively, challenged in three different editorials [22][23][24]. Yet, these discussions did not consider at all that the action (kinetic, postural) tremors, of DLB may be erroneously attributed to ET.	1	The clarification of the different tremor types and response to treatment in DLB could improve clinical recognition of DLB, but mostly, understanding tremor in DLB, would provide clarity to recent controversial debates [16][17][18][19][20][21][22][23]#CITATION_TAG on the long term outcome of patients putatively affected by ET. Several reports showed that some ET patients, during follow-up may present with additional PD features, dopamine transporter capitation abnormalities, or cognitive abnormalities, and may present with Lewy bodies at the autopsy [16][17][18][19][20][21]. These observations were, more or less dismissively, challenged in three different editorials [22][23][24]. Yet, these discussions did not consider at all that the action (kinetic, postural) tremors, of DLB may be erroneously attributed to ET.	T
CCT347	The clarification of the different tremor types and response to treatment in DLB could improve clinical recognition of DLB, but mostly, understanding tremor in DLB, would provide clarity to recent controversial debates [16][17][18][19][20][21][22]#CITATION_TAG[24] on the long term outcome of patients putatively affected by ET. Several reports showed that some ET patients, during follow-up may present with additional PD features, dopamine transporter capitation abnormalities, or cognitive abnormalities, and may present with Lewy bodies at the autopsy [16][17][18][19][20][21]. These observations were, more or less dismissively, challenged in three different editorials [22][23][24]. Yet, these discussions did not consider at all that the action (kinetic, postural) tremors, of DLB may be erroneously attributed to ET.	1	The clarification of the different tremor types and response to treatment in DLB could improve clinical recognition of DLB, but mostly, understanding tremor in DLB, would provide clarity to recent controversial debates [16][17][18][19][20][21][22]#CITATION_TAG[24] on the long term outcome of patients putatively affected by ET. Several reports showed that some ET patients, during follow-up may present with additional PD features, dopamine transporter capitation abnormalities, or cognitive abnormalities, and may present with Lewy bodies at the autopsy [16][17][18][19][20][21]. These observations were, more or less dismissively, challenged in three different editorials [22][23][24]. Yet, these discussions did not consider at all that the action (kinetic, postural) tremors, of DLB may be erroneously attributed to ET.	T
CCT348	The clarification of the different tremor types and response to treatment in DLB could improve clinical recognition of DLB, but mostly, understanding tremor in DLB, would provide clarity to recent controversial debates [16][17][18][19][20][21]#CITATION_TAG[23][24] on the long term outcome of patients putatively affected by ET. Several reports showed that some ET patients, during follow-up may present with additional PD features, dopamine transporter capitation abnormalities, or cognitive abnormalities, and may present with Lewy bodies at the autopsy [16][17][18][19][20][21]. These observations were, more or less dismissively, challenged in three different editorials [22][23][24]. Yet, these discussions did not consider at all that the action (kinetic, postural) tremors, of DLB may be erroneously attributed to ET.	1	The clarification of the different tremor types and response to treatment in DLB could improve clinical recognition of DLB, but mostly, understanding tremor in DLB, would provide clarity to recent controversial debates [16][17][18][19][20][21]#CITATION_TAG[23][24] on the long term outcome of patients putatively affected by ET. Several reports showed that some ET patients, during follow-up may present with additional PD features, dopamine transporter capitation abnormalities, or cognitive abnormalities, and may present with Lewy bodies at the autopsy [16][17][18][19][20][21]. These observations were, more or less dismissively, challenged in three different editorials [22][23][24]. Yet, these discussions did not consider at all that the action (kinetic, postural) tremors, of DLB may be erroneously attributed to ET.	T
CCT349	The clarification of the different tremor types and response to treatment in DLB could improve clinical recognition of DLB, but mostly, understanding tremor in DLB, would provide clarity to recent controversial debates [16][17][18][19][20]#CITATION_TAG[22][23][24] on the long term outcome of patients putatively affected by ET. Several reports showed that some ET patients, during follow-up may present with additional PD features, dopamine transporter capitation abnormalities, or cognitive abnormalities, and may present with Lewy bodies at the autopsy [16][17][18][19][20][21]. These observations were, more or less dismissively, challenged in three different editorials [22][23][24]. Yet, these discussions did not consider at all that the action (kinetic, postural) tremors, of DLB may be erroneously attributed to ET.	1	The clarification of the different tremor types and response to treatment in DLB could improve clinical recognition of DLB, but mostly, understanding tremor in DLB, would provide clarity to recent controversial debates [16][17][18][19][20]#CITATION_TAG[22][23][24] on the long term outcome of patients putatively affected by ET. Several reports showed that some ET patients, during follow-up may present with additional PD features, dopamine transporter capitation abnormalities, or cognitive abnormalities, and may present with Lewy bodies at the autopsy [16][17][18][19][20][21]. These observations were, more or less dismissively, challenged in three different editorials [22][23][24]. Yet, these discussions did not consider at all that the action (kinetic, postural) tremors, of DLB may be erroneously attributed to ET.	T
CCT350	"The last consensus on diagnostic criteria for dementia with Lewy Bodies (DLB), states that """"tremor is less frequent than in Parkinson""s disease (PD)"""" [1] but does not detail the types and relative prevalence of tremor, despite earlier studies reporting a prevalence of 40 % for rest and 30 % for action (kinetic-postural) tremor [#CITATION_TAG,3]."	0	"The last consensus on diagnostic criteria for dementia with Lewy Bodies (DLB), states that """"tremor is less frequent than in Parkinson""s disease (PD)"""" [1] but does not detail the types and relative prevalence of tremor, despite earlier studies reporting a prevalence of 40 % for rest and 30 % for action (kinetic-postural) tremor [#CITATION_TAG,3]."	T
CCT351	The clarification of the different tremor types and response to treatment in DLB could improve clinical recognition of DLB, but mostly, understanding tremor in DLB, would provide clarity to recent controversial debates [16][17][18]#CITATION_TAG[20][21][22][23][24] on the long term outcome of patients putatively affected by ET. Several reports showed that some ET patients, during follow-up may present with additional PD features, dopamine transporter capitation abnormalities, or cognitive abnormalities, and may present with Lewy bodies at the autopsy [16][17][18][19][20][21]. These observations were, more or less dismissively, challenged in three different editorials [22][23][24]. Yet, these discussions did not consider at all that the action (kinetic, postural) tremors, of DLB may be erroneously attributed to ET.	1	The clarification of the different tremor types and response to treatment in DLB could improve clinical recognition of DLB, but mostly, understanding tremor in DLB, would provide clarity to recent controversial debates [16][17][18]#CITATION_TAG[20][21][22][23][24] on the long term outcome of patients putatively affected by ET. Several reports showed that some ET patients, during follow-up may present with additional PD features, dopamine transporter capitation abnormalities, or cognitive abnormalities, and may present with Lewy bodies at the autopsy [16][17][18][19][20][21]. These observations were, more or less dismissively, challenged in three different editorials [22][23][24]. Yet, these discussions did not consider at all that the action (kinetic, postural) tremors, of DLB may be erroneously attributed to ET.	T
CCT352	The clarification of the different tremor types and response to treatment in DLB could improve clinical recognition of DLB, but mostly, understanding tremor in DLB, would provide clarity to recent controversial debates [16][17][18][19]#CITATION_TAG[21][22][23][24] on the long term outcome of patients putatively affected by ET. Several reports showed that some ET patients, during follow-up may present with additional PD features, dopamine transporter capitation abnormalities, or cognitive abnormalities, and may present with Lewy bodies at the autopsy [16][17][18][19][20][21]. These observations were, more or less dismissively, challenged in three different editorials [22][23][24]. Yet, these discussions did not consider at all that the action (kinetic, postural) tremors, of DLB may be erroneously attributed to ET.	1	The clarification of the different tremor types and response to treatment in DLB could improve clinical recognition of DLB, but mostly, understanding tremor in DLB, would provide clarity to recent controversial debates [16][17][18][19]#CITATION_TAG[21][22][23][24] on the long term outcome of patients putatively affected by ET. Several reports showed that some ET patients, during follow-up may present with additional PD features, dopamine transporter capitation abnormalities, or cognitive abnormalities, and may present with Lewy bodies at the autopsy [16][17][18][19][20][21]. These observations were, more or less dismissively, challenged in three different editorials [22][23][24]. Yet, these discussions did not consider at all that the action (kinetic, postural) tremors, of DLB may be erroneously attributed to ET.	T
CCT353	The clarification of the different tremor types and response to treatment in DLB could improve clinical recognition of DLB, but mostly, understanding tremor in DLB, would provide clarity to recent controversial debates #CITATION_TAG[17][18][19][20][21][22][23][24] on the long term outcome of patients putatively affected by ET. Several reports showed that some ET patients, during follow-up may present with additional PD features, dopamine transporter capitation abnormalities, or cognitive abnormalities, and may present with Lewy bodies at the autopsy [16][17][18][19][20][21]. These observations were, more or less dismissively, challenged in three different editorials [22][23][24]. Yet, these discussions did not consider at all that the action (kinetic, postural) tremors, of DLB may be erroneously attributed to ET.	1	The clarification of the different tremor types and response to treatment in DLB could improve clinical recognition of DLB, but mostly, understanding tremor in DLB, would provide clarity to recent controversial debates #CITATION_TAG[17][18][19][20][21][22][23][24] on the long term outcome of patients putatively affected by ET. Several reports showed that some ET patients, during follow-up may present with additional PD features, dopamine transporter capitation abnormalities, or cognitive abnormalities, and may present with Lewy bodies at the autopsy [16][17][18][19][20][21]. These observations were, more or less dismissively, challenged in three different editorials [22][23][24]. Yet, these discussions did not consider at all that the action (kinetic, postural) tremors, of DLB may be erroneously attributed to ET.	T
CCT354	Generally rest tremor is considered specific for PD, while postural and action (or intentional) tremor are attributed to essential tremor (ET), although exceptions to this rule are clearly reported #CITATION_TAG[5][6]. The prevalence of these tremors have not been investigated in DLB after the early reports, nor was described the prevalence of other types of tremor which are considered infrequent but specific to PD, as head and face tremors [7,8], re-emergent [6,9], pseudoorthostatic or standing tremor [5,[10][11][12][13]. In addition, while there are some small studies reporting an improvement of general motor features in DLB with acute L-Dopa challenge [14], the specific response of tremors to treatments has been investigated in only one early study [15].	0	Generally rest tremor is considered specific for PD, while postural and action (or intentional) tremor are attributed to essential tremor (ET), although exceptions to this rule are clearly reported #CITATION_TAG[5][6]. The prevalence of these tremors have not been investigated in DLB after the early reports, nor was described the prevalence of other types of tremor which are considered infrequent but specific to PD, as head and face tremors [7,8], re-emergent [6,9], pseudoorthostatic or standing tremor [5,[10][11][12][13]. In addition, while there are some small studies reporting an improvement of general motor features in DLB with acute L-Dopa challenge [14], the specific response of tremors to treatments has been investigated in only one early study [15].	G
CCT355	Generally rest tremor is considered specific for PD, while postural and action (or intentional) tremor are attributed to essential tremor (ET), although exceptions to this rule are clearly reported [4][5][6]. The prevalence of these tremors have not been investigated in DLB after the early reports, nor was described the prevalence of other types of tremor which are considered infrequent but specific to PD, as head and face tremors [7,8], re-emergent [6,9], pseudoorthostatic or standing tremor [5,[10][11][12]#CITATION_TAG. In addition, while there are some small studies reporting an improvement of general motor features in DLB with acute L-Dopa challenge [14], the specific response of tremors to treatments has been investigated in only one early study [15].	4	Generally rest tremor is considered specific for PD, while postural and action (or intentional) tremor are attributed to essential tremor (ET), although exceptions to this rule are clearly reported [4][5][6]. The prevalence of these tremors have not been investigated in DLB after the early reports, nor was described the prevalence of other types of tremor which are considered infrequent but specific to PD, as head and face tremors [7,8], re-emergent [6,9], pseudoorthostatic or standing tremor [5,[10][11][12]#CITATION_TAG. In addition, while there are some small studies reporting an improvement of general motor features in DLB with acute L-Dopa challenge [14], the specific response of tremors to treatments has been investigated in only one early study [15].	h
CCT356	Generally rest tremor is considered specific for PD, while postural and action (or intentional) tremor are attributed to essential tremor (ET), although exceptions to this rule are clearly reported [4][5]#CITATION_TAG. The prevalence of these tremors have not been investigated in DLB after the early reports, nor was described the prevalence of other types of tremor which are considered infrequent but specific to PD, as head and face tremors [7,8], re-emergent [6,9], pseudoorthostatic or standing tremor [5,[10][11][12][13]. In addition, while there are some small studies reporting an improvement of general motor features in DLB with acute L-Dopa challenge [14], the specific response of tremors to treatments has been investigated in only one early study [15].	0	Generally rest tremor is considered specific for PD, while postural and action (or intentional) tremor are attributed to essential tremor (ET), although exceptions to this rule are clearly reported [4][5]#CITATION_TAG. The prevalence of these tremors have not been investigated in DLB after the early reports, nor was described the prevalence of other types of tremor which are considered infrequent but specific to PD, as head and face tremors [7,8], re-emergent [6,9], pseudoorthostatic or standing tremor [5,[10][11][12][13]. In addition, while there are some small studies reporting an improvement of general motor features in DLB with acute L-Dopa challenge [14], the specific response of tremors to treatments has been investigated in only one early study [15].	G
CCT357	The study was approved by our local ethical committee and was carried out according to the declaration of Helsinki and subsequent revisions [28]. Patients (or caregivers) signed a written informed consent and authorization was obtained for disclosure (consent-to-disclose) of any recognizable persons in videos. All patients received a full neurological, neuropsychological, neuroimaging and neuropsychiatric evaluation, as reported in Online Resource 1, and as described in previous studies on the same cohort [29][30]#CITATION_TAG[32]. Observation and recording of tremors were performed only in dopaminergic drugs naive patients (all DLB and 52 PD patients) or after withdrawal of L-Dopa (48 h) or dopamine agonist (72 h) treatments (13 PD patients).	0	The study was approved by our local ethical committee and was carried out according to the declaration of Helsinki and subsequent revisions [28]. Patients (or caregivers) signed a written informed consent and authorization was obtained for disclosure (consent-to-disclose) of any recognizable persons in videos. All patients received a full neurological, neuropsychological, neuroimaging and neuropsychiatric evaluation, as reported in Online Resource 1, and as described in previous studies on the same cohort [29][30]#CITATION_TAG[32]. Observation and recording of tremors were performed only in dopaminergic drugs naive patients (all DLB and 52 PD patients) or after withdrawal of L-Dopa (48 h) or dopamine agonist (72 h) treatments (13 PD patients).	l
CCT358	Generally rest tremor is considered specific for PD, while postural and action (or intentional) tremor are attributed to essential tremor (ET), although exceptions to this rule are clearly reported [4][5][6]. The prevalence of these tremors have not been investigated in DLB after the early reports, nor was described the prevalence of other types of tremor which are considered infrequent but specific to PD, as head and face tremors [#CITATION_TAG,8], re-emergent [6,9], pseudoorthostatic or standing tremor [5,[10][11][12][13]. In addition, while there are some small studies reporting an improvement of general motor features in DLB with acute L-Dopa challenge [14], the specific response of tremors to treatments has been investigated in only one early study [15].	4	Generally rest tremor is considered specific for PD, while postural and action (or intentional) tremor are attributed to essential tremor (ET), although exceptions to this rule are clearly reported [4][5][6]. The prevalence of these tremors have not been investigated in DLB after the early reports, nor was described the prevalence of other types of tremor which are considered infrequent but specific to PD, as head and face tremors [#CITATION_TAG,8], re-emergent [6,9], pseudoorthostatic or standing tremor [5,[10][11][12][13]. In addition, while there are some small studies reporting an improvement of general motor features in DLB with acute L-Dopa challenge [14], the specific response of tremors to treatments has been investigated in only one early study [15].	h
CCT359	All patients tested negative for the G20195 mutations in the LRRK2 gene [26] as a high prevalence of mixed tremor has been described in this condition #CITATION_TAG. All patients were followed for a minimum of two years to confirm/challenge diagnosis.	4	All patients tested negative for the G20195 mutations in the LRRK2 gene [26] as a high prevalence of mixed tremor has been described in this condition #CITATION_TAG. All patients were followed for a minimum of two years to confirm/challenge diagnosis.	A
CCT360	Generally rest tremor is considered specific for PD, while postural and action (or intentional) tremor are attributed to essential tremor (ET), although exceptions to this rule are clearly reported [4][5][6]. The prevalence of these tremors have not been investigated in DLB after the early reports, nor was described the prevalence of other types of tremor which are considered infrequent but specific to PD, as head and face tremors [7,#CITATION_TAG], re-emergent [6,9], pseudoorthostatic or standing tremor [5,[10][11][12][13]. In addition, while there are some small studies reporting an improvement of general motor features in DLB with acute L-Dopa challenge [14], the specific response of tremors to treatments has been investigated in only one early study [15].	4	Generally rest tremor is considered specific for PD, while postural and action (or intentional) tremor are attributed to essential tremor (ET), although exceptions to this rule are clearly reported [4][5][6]. The prevalence of these tremors have not been investigated in DLB after the early reports, nor was described the prevalence of other types of tremor which are considered infrequent but specific to PD, as head and face tremors [7,#CITATION_TAG], re-emergent [6,9], pseudoorthostatic or standing tremor [5,[10][11][12][13]. In addition, while there are some small studies reporting an improvement of general motor features in DLB with acute L-Dopa challenge [14], the specific response of tremors to treatments has been investigated in only one early study [15].	h
CCT361	Generally rest tremor is considered specific for PD, while postural and action (or intentional) tremor are attributed to essential tremor (ET), although exceptions to this rule are clearly reported [4][5][6]. The prevalence of these tremors have not been investigated in DLB after the early reports, nor was described the prevalence of other types of tremor which are considered infrequent but specific to PD, as head and face tremors [7,8], re-emergent [6,9], pseudoorthostatic or standing tremor [5,#CITATION_TAG[11][12][13]. In addition, while there are some small studies reporting an improvement of general motor features in DLB with acute L-Dopa challenge [14], the specific response of tremors to treatments has been investigated in only one early study [15].	4	Generally rest tremor is considered specific for PD, while postural and action (or intentional) tremor are attributed to essential tremor (ET), although exceptions to this rule are clearly reported [4][5][6]. The prevalence of these tremors have not been investigated in DLB after the early reports, nor was described the prevalence of other types of tremor which are considered infrequent but specific to PD, as head and face tremors [7,8], re-emergent [6,9], pseudoorthostatic or standing tremor [5,#CITATION_TAG[11][12][13]. In addition, while there are some small studies reporting an improvement of general motor features in DLB with acute L-Dopa challenge [14], the specific response of tremors to treatments has been investigated in only one early study [15].	h
CCT362	All patients tested negative for the G20195 mutations in the LRRK2 gene #CITATION_TAG as a high prevalence of mixed tremor has been described in this condition [27]. All patients were followed for a minimum of two years to confirm/challenge diagnosis.	0	All patients tested negative for the G20195 mutations in the LRRK2 gene #CITATION_TAG as a high prevalence of mixed tremor has been described in this condition [27]. All patients were followed for a minimum of two years to confirm/challenge diagnosis.	A
CCT363	All new referrals to our movement disorders and memory clinics in the years 2005-2009, (202 patients) diagnosed with DLB, PD, or ET, according to the accepted clinical criteria [1,4,#CITATION_TAG] were enrolled in the study. Exclusion criteria were any prior exposure to neuroleptic drugs, the presence of dystonia and the presence of classic orthostatic tremor. The PD patients with dementia (PDD) were excluded because of the confounding effects of treatments.	0	All new referrals to our movement disorders and memory clinics in the years 2005-2009, (202 patients) diagnosed with DLB, PD, or ET, according to the accepted clinical criteria [1,4,#CITATION_TAG] were enrolled in the study. Exclusion criteria were any prior exposure to neuroleptic drugs, the presence of dystonia and the presence of classic orthostatic tremor. The PD patients with dementia (PDD) were excluded because of the confounding effects of treatments.	A
CCT364	"Tremor was rated using the Tremor Research Group Rating Scale (TRGRS) [6] quantified clinically according to the TRGRS items. Face and jaw tremor were clustered in a single item, tongue tremor was omitted as this was not observed, and items 10 and 11 (hand writing and holding pencil) were omitted as these items were not collected in all patients. Two supplementary categories, absent in the TRGRS rating scale were also applied: re-emergent tremor of the arm indicating """"delayed re-emergence of rest tremor when the arm was postured"""" [9] and standing overflow indicating overflow of rest or postural tremor, when standing, to body districts not primarily affected by the tremor. Standing tremor was defined according to the TRGRS scale, and indicated the pseudoorthostatic tremor with the low frequency of parkinsonian tremor or ET, described in PD or genetic PD [10][11][12][13]. Tremors frequencies and amplitudes were also quantified by Electromyography (EMG) as described in our previous papers [11,12,#CITATION_TAG] and in Online Resource 1."	4	"Face and jaw tremor were clustered in a single item, tongue tremor was omitted as this was not observed, and items 10 and 11 (hand writing and holding pencil) were omitted as these items were not collected in all patients. Two supplementary categories, absent in the TRGRS rating scale were also applied: re-emergent tremor of the arm indicating """"delayed re-emergence of rest tremor when the arm was postured"""" [9] and standing overflow indicating overflow of rest or postural tremor, when standing, to body districts not primarily affected by the tremor. Standing tremor was defined according to the TRGRS scale, and indicated the pseudoorthostatic tremor with the low frequency of parkinsonian tremor or ET, described in PD or genetic PD [10][11][12][13]. Tremors frequencies and amplitudes were also quantified by Electromyography (EMG) as described in our previous papers [11,12,#CITATION_TAG] and in Online Resource 1."	o
CCT365	Albeit prudent considerations are needed, in the absence of neuropathology, this finding may provide additional Rest tremor is the sum of head, face, rest arms and rest leg items; postural tremor is the sum of forward arm and lateral arm items; action is the sum of kinetic, action leg, spiral and water items, mixed tremor defines any combination of rest, postural, action, standing and walking tremors clarity to the on-going debate [#CITATION_TAG], opposing two factions, suggesting [16][17][18][19][20][21] or denying [22][23][24] the possibility that ET might evolve to PD or DLB, implicitly challenging the assumption that the three do represent distinct clinical entities rather than syndromes.	0	Albeit prudent considerations are needed, in the absence of neuropathology, this finding may provide additional Rest tremor is the sum of head, face, rest arms and rest leg items; postural tremor is the sum of forward arm and lateral arm items; action is the sum of kinetic, action leg, spiral and water items, mixed tremor defines any combination of rest, postural, action, standing and walking tremors clarity to the on-going debate [#CITATION_TAG], opposing two factions, suggesting [16][17][18][19][20][21] or denying [22][23][24] the possibility that ET might evolve to PD or DLB, implicitly challenging the assumption that the three do represent distinct clinical entities rather than syndromes.	A
CCT366	While recent studies [#CITATION_TAG,40] might further help to clarify this controversy, by adding new concepts to the debate, our concluding remark would be focused to a simple take home message: the appropriate examination and investigation of patients with tremor should not be simply addressed to motor aspects but should also consider non-motor features and specifically the core and supportive features of DLB [1][2][3] i.e., cognitive, visuo-spatial and dysexecutive abnormalities, RBD, and EEG abnormalities, before reaching definite conclusions.	1	While recent studies [#CITATION_TAG,40] might further help to clarify this controversy, by adding new concepts to the debate, our concluding remark would be focused to a simple take home message: the appropriate examination and investigation of patients with tremor should not be simply addressed to motor aspects but should also consider non-motor features and specifically the core and supportive features of DLB [1][2][3] i.e., cognitive, visuo-spatial and dysexecutive abnormalities, RBD, and EEG abnormalities, before reaching definite conclusions.	W
CCT367	While recent studies [39,#CITATION_TAG] might further help to clarify this controversy, by adding new concepts to the debate, our concluding remark would be focused to a simple take home message: the appropriate examination and investigation of patients with tremor should not be simply addressed to motor aspects but should also consider non-motor features and specifically the core and supportive features of DLB [1][2][3] i.e., cognitive, visuo-spatial and dysexecutive abnormalities, RBD, and EEG abnormalities, before reaching definite conclusions.	1	While recent studies [39,#CITATION_TAG] might further help to clarify this controversy, by adding new concepts to the debate, our concluding remark would be focused to a simple take home message: the appropriate examination and investigation of patients with tremor should not be simply addressed to motor aspects but should also consider non-motor features and specifically the core and supportive features of DLB [1][2][3] i.e., cognitive, visuo-spatial and dysexecutive abnormalities, RBD, and EEG abnormalities, before reaching definite conclusions.	W
CCT368	"These EoSs describe the nuclear composition as a mix of free nucleons, Œ± particles, and a representative heavy nucleus, whose mass and charge numbers depend on density, temperature, and neutronization of the matter. Although largely different mass and charge numbers are returned by both EoSs during the infall stage and affect, for example, neutrino trapping through coherent neutrino-nuclei scatterings, 1D simulations yield basically the same behavior. Quantitative differences occur only on the modest level of 5% to 25% in quantities characterizing collapse, bounce, and early postbounce evolution, for instance, in the central lepton fraction at neutrino trapping, the position of shock formation, the peak luminosity of the ŒΩ e burst, and the maximum radius to which the shock expands before it retreats again (17,(129)#CITATION_TAG(131). This outcome is even more astonishing in view of the appreciably different adiabatic index = (‚àÇ ln P/‚àÇ ln œÅ) s (where P, œÅ, and s are pressure, density, and entropy per nucleon, respectively) for both EoSs around nuclear density ( LS ‚àº 2.2; STOS ‚àº 2.9) and the correspondingly different maximum compression and rebound behavior at bounce. Mazurek""s law applies; according to this law, the effects of any change in the microphysics on collapsing stellar cores are moderated by strong feedback between the EoS, weak interactions, neutrino transport, and hydrodynamics (132)."	0	"These EoSs describe the nuclear composition as a mix of free nucleons, Œ± particles, and a representative heavy nucleus, whose mass and charge numbers depend on density, temperature, and neutronization of the matter. Although largely different mass and charge numbers are returned by both EoSs during the infall stage and affect, for example, neutrino trapping through coherent neutrino-nuclei scatterings, 1D simulations yield basically the same behavior. Quantitative differences occur only on the modest level of 5% to 25% in quantities characterizing collapse, bounce, and early postbounce evolution, for instance, in the central lepton fraction at neutrino trapping, the position of shock formation, the peak luminosity of the ŒΩ e burst, and the maximum radius to which the shock expands before it retreats again (17,(129)#CITATION_TAG(131). This outcome is even more astonishing in view of the appreciably different adiabatic index = (‚àÇ ln P/‚àÇ ln œÅ) s (where P, œÅ, and s are pressure, density, and entropy per nucleon, respectively) for both EoSs around nuclear density ( LS ‚àº 2.2; STOS ‚àº 2.9) and the correspondingly different maximum compression and rebound behavior at bounce. Mazurek""s law applies; according to this law, the effects of any change in the microphysics on collapsing stellar cores are moderated by strong feedback between the EoS, weak interactions, neutrino transport, and hydrodynamics (132)."	a
CCT369	However, in a dynamical situation, as in the gain layer, where the matter is not at rest, the optical depth (which determines the interaction probability of a crossing neutrino) is not a perfectly appropriate measure for the heating efficiency. This statement holds in particular in the multidimensional case, wherein accretion funnels carry cold (low-entropy) matter from the shock toward the NS while neutrino-heated matter expands outward in high-entropy bubbles. At such conditions, the residence time of the matter in the gain layer accounts for the duration of its exposure to neutrino heating. Whereas in the 1D case the advection time t adv ‚àº (R s ‚àí R g )/|v 1 | (where v = v 0 /Œ≤) measures how long the accretion flow requires to go from R s to R g (156,#CITATION_TAG), the dwell time in the gain region is better captured in the multidimensional situation by the more general expression (104, 106)	5	However, in a dynamical situation, as in the gain layer, where the matter is not at rest, the optical depth (which determines the interaction probability of a crossing neutrino) is not a perfectly appropriate measure for the heating efficiency. This statement holds in particular in the multidimensional case, wherein accretion funnels carry cold (low-entropy) matter from the shock toward the NS while neutrino-heated matter expands outward in high-entropy bubbles. At such conditions, the residence time of the matter in the gain layer accounts for the duration of its exposure to neutrino heating. Whereas in the 1D case the advection time t adv ‚àº (R s ‚àí R g )/|v 1 | (where v = v 0 /Œ≤) measures how long the accretion flow requires to go from R s to R g (156,#CITATION_TAG), the dwell time in the gain region is better captured in the multidimensional situation by the more general expression (104, 106)	r
CCT370	Remnant masses and explosion properties (e.g., energy, ejected 56 Ni mass) and their systematics with the progenitor mass also carry information about the explosion mechanism. The observational foundation of determined or constrained NS and BH masses (124,253,#CITATION_TAG), SN-progenitor connections (26,27), and estimated explosion parameters (Figure 3) (e.g., References 24 and 25) is becoming increasingly strong.	3	Remnant masses and explosion properties (e.g., energy, ejected 56 Ni mass) and their systematics with the progenitor mass also carry information about the explosion mechanism. The observational foundation of determined or constrained NS and BH masses (124,253,#CITATION_TAG), SN-progenitor connections (26,27), and estimated explosion parameters (Figure 3) (e.g., References 24 and 25) is becoming increasingly strong.	h
CCT371	However, in a dynamical situation, as in the gain layer, where the matter is not at rest, the optical depth (which determines the interaction probability of a crossing neutrino) is not a perfectly appropriate measure for the heating efficiency. This statement holds in particular in the multidimensional case, wherein accretion funnels carry cold (low-entropy) matter from the shock toward the NS while neutrino-heated matter expands outward in high-entropy bubbles. At such conditions, the residence time of the matter in the gain layer accounts for the duration of its exposure to neutrino heating. Whereas in the 1D case the advection time t adv ‚àº (R s ‚àí R g )/|v 1 | (where v = v 0 /Œ≤) measures how long the accretion flow requires to go from R s to R g (#CITATION_TAG,157), the dwell time in the gain region is better captured in the multidimensional situation by the more general expression (104, 106)	5	However, in a dynamical situation, as in the gain layer, where the matter is not at rest, the optical depth (which determines the interaction probability of a crossing neutrino) is not a perfectly appropriate measure for the heating efficiency. This statement holds in particular in the multidimensional case, wherein accretion funnels carry cold (low-entropy) matter from the shock toward the NS while neutrino-heated matter expands outward in high-entropy bubbles. At such conditions, the residence time of the matter in the gain layer accounts for the duration of its exposure to neutrino heating. Whereas in the 1D case the advection time t adv ‚àº (R s ‚àí R g )/|v 1 | (where v = v 0 /Œ≤) measures how long the accretion flow requires to go from R s to R g (#CITATION_TAG,157), the dwell time in the gain region is better captured in the multidimensional situation by the more general expression (104, 106)	r
CCT372	"The study will use #CITATION_TAG""s (1975) methods for confirming content validity"	5	"The study will use #CITATION_TAG""s (1975) methods for confirming content validity"	T
CCT373	This is the most popular paradigm based on the assumption that human actions are rational and organizational behaviour can be hypothesized. The intervention goal of this paradigm is to help individuals or group to adapt to the existing structures without the need for major institutional structure change #CITATION_TAG. Society is assumed to have shared values that help establish social order to the benefit of every member. The functionalist paradigm is based on the assumption that organizations are stable and rarely undergo a radical change. In addition to that reality is taken as a given and associated with standard and rational decision making.	4	This is the most popular paradigm based on the assumption that human actions are rational and organizational behaviour can be hypothesized. The intervention goal of this paradigm is to help individuals or group to adapt to the existing structures without the need for major institutional structure change #CITATION_TAG. Society is assumed to have shared values that help establish social order to the benefit of every member. The functionalist paradigm is based on the assumption that organizations are stable and rarely undergo a radical change. In addition to that reality is taken as a given and associated with standard and rational decision making.	h
CCT374	Burrell and Morgan #CITATION_TAG claim that sociological paradigms of social theory can be classified into the categories: functionalist, interpretive, radical structuralism and radical humanism as shown in Figure 1. Sociological paradigms have been classified into four categories based on the nature of reality (subjectiveobjective) and the aspect of social order (radical changeregulation). The assumptions of objectivists are that realities are independent of individual as they are external to individuals.	0	Burrell and Morgan #CITATION_TAG claim that sociological paradigms of social theory can be classified into the categories: functionalist, interpretive, radical structuralism and radical humanism as shown in Figure 1. Sociological paradigms have been classified into four categories based on the nature of reality (subjectiveobjective) and the aspect of social order (radical changeregulation). The assumptions of objectivists are that realities are independent of individual as they are external to individuals.	B
CCT375	A major challenge is to decide who makes decisions on IT adoption issues in an organization. Many researchers have questioned whether IT adoption decisions are made in the interest of executives or other stakeholders [#CITATION_TAG,28]. Stakeholders are defined as individuals or groups with an organizational interest and who may be impacted by the decisions [15]. Although stakeholder theory has been widely accepted in the information systems research, examination of the impact of stakeholder conflicts in IT adoption is relatively new [11].	4	A major challenge is to decide who makes decisions on IT adoption issues in an organization. Many researchers have questioned whether IT adoption decisions are made in the interest of executives or other stakeholders [#CITATION_TAG,28]. Stakeholders are defined as individuals or groups with an organizational interest and who may be impacted by the decisions [15]. Although stakeholder theory has been widely accepted in the information systems research, examination of the impact of stakeholder conflicts in IT adoption is relatively new [11].	a
CCT376	Information Technologies have long been identified as a key factor in competitiveness and have even radically modified the basis of competition #CITATION_TAG. The influence of IT determines the competitive posture of many businesses in most countries globally [5]. However, the literature on IT is often characterized by an assumption that the benefits of such technology are selfevident, and that decision makers realize what is needed is to adopt the specific technology in an organization [5].	4	Information Technologies have long been identified as a key factor in competitiveness and have even radically modified the basis of competition #CITATION_TAG. The influence of IT determines the competitive posture of many businesses in most countries globally [5]. However, the literature on IT is often characterized by an assumption that the benefits of such technology are selfevident, and that decision makers realize what is needed is to adopt the specific technology in an organization [5].	I
CCT377	According to the literature there are still some knowledge gaps and disparities in thinking with regard to Information Technologies (IT) adoption in organizations. IT adoption denotes the taking and execution of a conscious decision to use a particular technology from an individual or an organizational perspective in the organization [36]. Diffusion in turn is the decision to implement such technology after adoption #CITATION_TAG. Naturally any IT adoption ought to be done for the benefit of the organization [28].	0	According to the literature there are still some knowledge gaps and disparities in thinking with regard to Information Technologies (IT) adoption in organizations. IT adoption denotes the taking and execution of a conscious decision to use a particular technology from an individual or an organizational perspective in the organization [36]. Diffusion in turn is the decision to implement such technology after adoption #CITATION_TAG. Naturally any IT adoption ought to be done for the benefit of the organization [28].	f
CCT378	According to the literature there are still some knowledge gaps and disparities in thinking with regard to Information Technologies (IT) adoption in organizations. IT adoption denotes the taking and execution of a conscious decision to use a particular technology from an individual or an organizational perspective in the organization #CITATION_TAG. Diffusion in turn is the decision to implement such technology after adoption [42]. Naturally any IT adoption ought to be done for the benefit of the organization [28].	0	According to the literature there are still some knowledge gaps and disparities in thinking with regard to Information Technologies (IT) adoption in organizations. IT adoption denotes the taking and execution of a conscious decision to use a particular technology from an individual or an organizational perspective in the organization #CITATION_TAG. Diffusion in turn is the decision to implement such technology after adoption [42]. Naturally any IT adoption ought to be done for the benefit of the organization [28].	T
CCT379	According to previous research e.g. [6], it has become sufficiently clear that the adoption of a new technology does not always result in all the anticipated benefits from the investment. The sustained investment and deployment of modern technology have increased interest in the study of IT adoption. Although technology adoption has been extensively researched, understanding IT adoption decision making is still one of the most challenging issues in IT research [5]. The importance of understanding the IT adoption decision making process in organizations has been highlighted by many researchers [#CITATION_TAG,24].	0	According to previous research e.g. [6], it has become sufficiently clear that the adoption of a new technology does not always result in all the anticipated benefits from the investment. The sustained investment and deployment of modern technology have increased interest in the study of IT adoption. Although technology adoption has been extensively researched, understanding IT adoption decision making is still one of the most challenging issues in IT research [5]. The importance of understanding the IT adoption decision making process in organizations has been highlighted by many researchers [#CITATION_TAG,24].	 
CCT380	Evidence from the literature suggests that to achieve sustainable IT adoption benefits in organizations remains a problem [28]. The ever-increasing use of IT and the diversity of applications result in making decisions on IT adoption a major challenge to organizations [5]. The implicit assumption in most frameworks is that there is always consensus in IT adoption decisions #CITATION_TAG. The decision of using a particular technology from an organizational perspective is problematic since individual users have different worldviews [36]. Most of the studies on IT adoption have been based on a positivist paradigm with primary focus on the perception of individual uses with little attention given to multiple stakeholders in the organization.	0	Evidence from the literature suggests that to achieve sustainable IT adoption benefits in organizations remains a problem [28]. The ever-increasing use of IT and the diversity of applications result in making decisions on IT adoption a major challenge to organizations [5]. The implicit assumption in most frameworks is that there is always consensus in IT adoption decisions #CITATION_TAG. The decision of using a particular technology from an organizational perspective is problematic since individual users have different worldviews [36]. Most of the studies on IT adoption have been based on a positivist paradigm with primary focus on the perception of individual uses with little attention given to multiple stakeholders in the organization.	e
CCT381	According to the literature there are still some knowledge gaps and disparities in thinking with regard to Information Technologies (IT) adoption in organizations. IT adoption denotes the taking and execution of a conscious decision to use a particular technology from an individual or an organizational perspective in the organization [36]. Diffusion in turn is the decision to implement such technology after adoption [42]. Naturally any IT adoption ought to be done for the benefit of the organization #CITATION_TAG.	5	According to the literature there are still some knowledge gaps and disparities in thinking with regard to Information Technologies (IT) adoption in organizations. IT adoption denotes the taking and execution of a conscious decision to use a particular technology from an individual or an organizational perspective in the organization [36]. Diffusion in turn is the decision to implement such technology after adoption [42]. Naturally any IT adoption ought to be done for the benefit of the organization #CITATION_TAG.	u
CCT382	Although IT governance as a framework may improve controls with respect to the alignment of IT and business objectives, it pays less attention to how IT adoption decisions are made [30]. Amongst other things, IT governance is tasked with deciding on how decision rights and accountability are distributed in organizations to avoid ad hoc decision making #CITATION_TAG. In order to improve IT governance in an organization, Weill [43] proposes the assignment of decision rights to five IT decision areas (architecture, infrastructure, principle, applications and investment) in an organization. The assignment of responsibilities and roles to decision-making domain areas helps to achieve a balanced governance structure for IT adoption decisions [22].	5	Although IT governance as a framework may improve controls with respect to the alignment of IT and business objectives, it pays less attention to how IT adoption decisions are made [30]. Amongst other things, IT governance is tasked with deciding on how decision rights and accountability are distributed in organizations to avoid ad hoc decision making #CITATION_TAG. In order to improve IT governance in an organization, Weill [43] proposes the assignment of decision rights to five IT decision areas (architecture, infrastructure, principle, applications and investment) in an organization. The assignment of responsibilities and roles to decision-making domain areas helps to achieve a balanced governance structure for IT adoption decisions [22].	m
CCT383	According to Cordoba [11], systems approaches encourages the analysis of stakeholder perspectives prior to IT adoption and it allows for reflection to occur on possible improvements. The appreciation of interdependencies among elements of systems following systems approaches is vital as it improves on IT adoption decision making, since this in turn reduces the chances of overlooking important elements [18]. Checkland #CITATION_TAG points to information systems as being social artifacts that people can shape according to their interests and a particular context. He urges managers to take a holistic approach rather than a functionalistic approach when addressing problem situations.	4	According to Cordoba [11], systems approaches encourages the analysis of stakeholder perspectives prior to IT adoption and it allows for reflection to occur on possible improvements. The appreciation of interdependencies among elements of systems following systems approaches is vital as it improves on IT adoption decision making, since this in turn reduces the chances of overlooking important elements [18]. Checkland #CITATION_TAG points to information systems as being social artifacts that people can shape according to their interests and a particular context. He urges managers to take a holistic approach rather than a functionalistic approach when addressing problem situations.	e
CCT384	According to previous research e.g. [6], it has become sufficiently clear that the adoption of a new technology does not always result in all the anticipated benefits from the investment. The sustained investment and deployment of modern technology have increased interest in the study of IT adoption. Although technology adoption has been extensively researched, understanding IT adoption decision making is still one of the most challenging issues in IT research [5]. The importance of understanding the IT adoption decision making process in organizations has been highlighted by many researchers [2,#CITATION_TAG].	5	According to previous research e.g. [6], it has become sufficiently clear that the adoption of a new technology does not always result in all the anticipated benefits from the investment. The sustained investment and deployment of modern technology have increased interest in the study of IT adoption. Although technology adoption has been extensively researched, understanding IT adoption decision making is still one of the most challenging issues in IT research [5]. The importance of understanding the IT adoption decision making process in organizations has been highlighted by many researchers [2,#CITATION_TAG].	 
CCT385	The classic diffusion of innovation theory by Rogers (1995) has also been criticized for ignoring the social context of IT adoption in organizations as well as being too simplistic to address issues of social context in which the adoption and diffusion of IT take place #CITATION_TAG. The limitation of mechanistic causal relationships to socially construct IT adoption in organizations is the failure to understand the human environment and organizational context [14]. In order for IT adoption to be successful there is a need for social and environmental perspectives to complement technical perspectives [42]. IT adoption processes need to be based on social-technical adoption models instead of a technological linear phenomenon [42].	4	The classic diffusion of innovation theory by Rogers (1995) has also been criticized for ignoring the social context of IT adoption in organizations as well as being too simplistic to address issues of social context in which the adoption and diffusion of IT take place #CITATION_TAG. The limitation of mechanistic causal relationships to socially construct IT adoption in organizations is the failure to understand the human environment and organizational context [14]. In order for IT adoption to be successful there is a need for social and environmental perspectives to complement technical perspectives [42]. IT adoption processes need to be based on social-technical adoption models instead of a technological linear phenomenon [42].	T
CCT386	Most IT adoption frameworks are too deterministic by assuming that stakeholders will automatically see the benefits of IT adoption in organizations [42]. Benefits of most IT adoptions in organizations are not obvious to all stakeholders due to different perspectives. Many researchers have highlighted the importance of stakeholder participation in the success of IT adoption [32], hence the involvement and participation of stakeholders have been found desirable in IT adoption decision making #CITATION_TAG. Therefore, it is vital to involve stakeholders with very opposing interests in the IT adoption decision-making processes [28,36,38].	4	Most IT adoption frameworks are too deterministic by assuming that stakeholders will automatically see the benefits of IT adoption in organizations [42]. Benefits of most IT adoptions in organizations are not obvious to all stakeholders due to different perspectives. Many researchers have highlighted the importance of stakeholder participation in the success of IT adoption [32], hence the involvement and participation of stakeholders have been found desirable in IT adoption decision making #CITATION_TAG. Therefore, it is vital to involve stakeholders with very opposing interests in the IT adoption decision-making processes [28,36,38].	n
CCT387	IT adoption failure has been attributed to the independent creation of decisions, away from the social context and an inadequate exploring of stakeholder requirements [3,11,26,28,40]. The independent creation of IT adoption decisions away from the social context of their use results in a gap between actual needs and official requirements [1]. In a world characterized by diverse worldviews, consensus on IT adoption decision making has become a challenge to many organizations [11,17]. Organizations have been urged to also focus on meeting user requirements when adopting new systems [24,25,#CITATION_TAG].	4	IT adoption failure has been attributed to the independent creation of decisions, away from the social context and an inadequate exploring of stakeholder requirements [3,11,26,28,40]. The independent creation of IT adoption decisions away from the social context of their use results in a gap between actual needs and official requirements [1]. In a world characterized by diverse worldviews, consensus on IT adoption decision making has become a challenge to many organizations [11,17]. Organizations have been urged to also focus on meeting user requirements when adopting new systems [24,25,#CITATION_TAG].	a
CCT388	Although IT governance as a framework may improve controls with respect to the alignment of IT and business objectives, it pays less attention to how IT adoption decisions are made [30]. Amongst other things, IT governance is tasked with deciding on how decision rights and accountability are distributed in organizations to avoid ad hoc decision making [17]. In order to improve IT governance in an organization, Weill #CITATION_TAG proposes the assignment of decision rights to five IT decision areas (architecture, infrastructure, principle, applications and investment) in an organization. The assignment of responsibilities and roles to decision-making domain areas helps to achieve a balanced governance structure for IT adoption decisions [22].	4	Although IT governance as a framework may improve controls with respect to the alignment of IT and business objectives, it pays less attention to how IT adoption decisions are made [30]. Amongst other things, IT governance is tasked with deciding on how decision rights and accountability are distributed in organizations to avoid ad hoc decision making [17]. In order to improve IT governance in an organization, Weill #CITATION_TAG proposes the assignment of decision rights to five IT decision areas (architecture, infrastructure, principle, applications and investment) in an organization. The assignment of responsibilities and roles to decision-making domain areas helps to achieve a balanced governance structure for IT adoption decisions [22].	 
CCT389	IT adoption failure has been attributed to the independent creation of decisions, away from the social context and an inadequate exploring of stakeholder requirements [#CITATION_TAG,11,26,28,40]. The independent creation of IT adoption decisions away from the social context of their use results in a gap between actual needs and official requirements [1]. In a world characterized by diverse worldviews, consensus on IT adoption decision making has become a challenge to many organizations [11,17]. Organizations have been urged to also focus on meeting user requirements when adopting new systems [24,25,41].	0	IT adoption failure has been attributed to the independent creation of decisions, away from the social context and an inadequate exploring of stakeholder requirements [#CITATION_TAG,11,26,28,40]. The independent creation of IT adoption decisions away from the social context of their use results in a gap between actual needs and official requirements [1]. In a world characterized by diverse worldviews, consensus on IT adoption decision making has become a challenge to many organizations [11,17]. Organizations have been urged to also focus on meeting user requirements when adopting new systems [24,25,41].	I
CCT390	Although IT governance as a framework may improve controls with respect to the alignment of IT and business objectives, it pays less attention to how IT adoption decisions are made [30]. Amongst other things, IT governance is tasked with deciding on how decision rights and accountability are distributed in organizations to avoid ad hoc decision making [17]. In order to improve IT governance in an organization, Weill [43] proposes the assignment of decision rights to five IT decision areas (architecture, infrastructure, principle, applications and investment) in an organization. The assignment of responsibilities and roles to decision-making domain areas helps to achieve a balanced governance structure for IT adoption decisions #CITATION_TAG.	5	Although IT governance as a framework may improve controls with respect to the alignment of IT and business objectives, it pays less attention to how IT adoption decisions are made [30]. Amongst other things, IT governance is tasked with deciding on how decision rights and accountability are distributed in organizations to avoid ad hoc decision making [17]. In order to improve IT governance in an organization, Weill [43] proposes the assignment of decision rights to five IT decision areas (architecture, infrastructure, principle, applications and investment) in an organization. The assignment of responsibilities and roles to decision-making domain areas helps to achieve a balanced governance structure for IT adoption decisions #CITATION_TAG.	 
CCT391	"Systems approaches helps to include (sweep in) as many factors as possible of a problem situation looking from different perspectives (worldviews). A systems approach begins when first you see the world through the eyes of another"" [9:231]. Systems approaches emphasises understanding the whole as opposed to the parts in order to understand the relationships. Systems approaches are focused on understanding problem situations in order to improve the situations not solve the problem #CITATION_TAG. Systems approaches are an inquiry process into complex problem situations with interrelated multiple factors and human interests."	4	"Systems approaches helps to include (sweep in) as many factors as possible of a problem situation looking from different perspectives (worldviews). A systems approach begins when first you see the world through the eyes of another"" [9:231]. Systems approaches emphasises understanding the whole as opposed to the parts in order to understand the relationships. Systems approaches are focused on understanding problem situations in order to improve the situations not solve the problem #CITATION_TAG. Systems approaches are an inquiry process into complex problem situations with interrelated multiple factors and human interests."	t
CCT392	IT adoption failure has been attributed to the independent creation of decisions, away from the social context and an inadequate exploring of stakeholder requirements [3,11,26,28,#CITATION_TAG]. The independent creation of IT adoption decisions away from the social context of their use results in a gap between actual needs and official requirements [1]. In a world characterized by diverse worldviews, consensus on IT adoption decision making has become a challenge to many organizations [11,17]. Organizations have been urged to also focus on meeting user requirements when adopting new systems [24,25,41].	5	IT adoption failure has been attributed to the independent creation of decisions, away from the social context and an inadequate exploring of stakeholder requirements [3,11,26,28,#CITATION_TAG]. The independent creation of IT adoption decisions away from the social context of their use results in a gap between actual needs and official requirements [1]. In a world characterized by diverse worldviews, consensus on IT adoption decision making has become a challenge to many organizations [11,17]. Organizations have been urged to also focus on meeting user requirements when adopting new systems [24,25,41].	I
CCT393	"Jokonya and Hardman [20:2] write that ""systems approaches avoids hardening of some taken-for-granted assumptions that influence decision making in organizations as it enables collective reflection and debate on implication that the decision may have for different stakeholders"". Systems approaches assist organizations in reconciling different views of stakeholders in problem situations [8]. Organizations have been urged to view IT adoption decision making as a social phenomenon which needs systems approaches to reveal competing interests among stakeholders #CITATION_TAG."	0	"Jokonya and Hardman [20:2] write that ""systems approaches avoids hardening of some taken-for-granted assumptions that influence decision making in organizations as it enables collective reflection and debate on implication that the decision may have for different stakeholders"". Systems approaches assist organizations in reconciling different views of stakeholders in problem situations [8]. Organizations have been urged to view IT adoption decision making as a social phenomenon which needs systems approaches to reveal competing interests among stakeholders #CITATION_TAG."	g
CCT394	Most IT adoption frameworks are too deterministic by assuming that stakeholders will automatically see the benefits of IT adoption in organizations [42]. Benefits of most IT adoptions in organizations are not obvious to all stakeholders due to different perspectives. Many researchers have highlighted the importance of stakeholder participation in the success of IT adoption [32], hence the involvement and participation of stakeholders have been found desirable in IT adoption decision making #CITATION_TAG. Therefore, it is vital to involve stakeholders with very opposing interests in the IT adoption decision-making processes [28,36,38].	0	Most IT adoption frameworks are too deterministic by assuming that stakeholders will automatically see the benefits of IT adoption in organizations [42]. Benefits of most IT adoptions in organizations are not obvious to all stakeholders due to different perspectives. Many researchers have highlighted the importance of stakeholder participation in the success of IT adoption [32], hence the involvement and participation of stakeholders have been found desirable in IT adoption decision making #CITATION_TAG. Therefore, it is vital to involve stakeholders with very opposing interests in the IT adoption decision-making processes [28,36,38].	n
CCT395	Although IT governance as a framework may improve controls with respect to the alignment of IT and business objectives, it pays less attention to how IT adoption decisions are made #CITATION_TAG. Amongst other things, IT governance is tasked with deciding on how decision rights and accountability are distributed in organizations to avoid ad hoc decision making [17]. In order to improve IT governance in an organization, Weill [43] proposes the assignment of decision rights to five IT decision areas (architecture, infrastructure, principle, applications and investment) in an organization. The assignment of responsibilities and roles to decision-making domain areas helps to achieve a balanced governance structure for IT adoption decisions [22].	5	Although IT governance as a framework may improve controls with respect to the alignment of IT and business objectives, it pays less attention to how IT adoption decisions are made #CITATION_TAG. Amongst other things, IT governance is tasked with deciding on how decision rights and accountability are distributed in organizations to avoid ad hoc decision making [17]. In order to improve IT governance in an organization, Weill [43] proposes the assignment of decision rights to five IT decision areas (architecture, infrastructure, principle, applications and investment) in an organization. The assignment of responsibilities and roles to decision-making domain areas helps to achieve a balanced governance structure for IT adoption decisions [22].	A
CCT396	The paradigm is a way of classifying similar theorist perspectives together in ways they approach a problem situation [7]. In order for individuals to change their ways of thinking they first need to abandon their old worldview #CITATION_TAG. In order to understand a different paradigm we need to change from the taken-for-granted assumptions. The existence of multiple paradigms is therefore to expand our perception of the knowledge base. It is important to consider multiple paradigms when studying a complex social phenomenon such as IT adoption decision making in organization as each paradigm emphasises and highlights different, though overlapping, aspects of the phenomenon. Furthermore, each paradigm emphasises different sources of data and different analytical approaches [5].	5	The paradigm is a way of classifying similar theorist perspectives together in ways they approach a problem situation [7]. In order for individuals to change their ways of thinking they first need to abandon their old worldview #CITATION_TAG. In order to understand a different paradigm we need to change from the taken-for-granted assumptions. The existence of multiple paradigms is therefore to expand our perception of the knowledge base. It is important to consider multiple paradigms when studying a complex social phenomenon such as IT adoption decision making in organization as each paradigm emphasises and highlights different, though overlapping, aspects of the phenomenon.	n
CCT397	IT adoption failure has been attributed to the independent creation of decisions, away from the social context and an inadequate exploring of stakeholder requirements [3,11,#CITATION_TAG,28,40]. The independent creation of IT adoption decisions away from the social context of their use results in a gap between actual needs and official requirements [1]. In a world characterized by diverse worldviews, consensus on IT adoption decision making has become a challenge to many organizations [11,17]. Organizations have been urged to also focus on meeting user requirements when adopting new systems [24,25,41].	5	IT adoption failure has been attributed to the independent creation of decisions, away from the social context and an inadequate exploring of stakeholder requirements [3,11,#CITATION_TAG,28,40]. The independent creation of IT adoption decisions away from the social context of their use results in a gap between actual needs and official requirements [1]. In a world characterized by diverse worldviews, consensus on IT adoption decision making has become a challenge to many organizations [11,17]. Organizations have been urged to also focus on meeting user requirements when adopting new systems [24,25,41].	I
CCT398	Within the context of 1 + 3 formalisms, there have been a number of studies of averaging and backreaction which focus principally on associated mathematical issues. These include the Ricci flow [43,[54][55]#CITATION_TAG, group averaging of the FLRW isometry group [57] and the characterization of constant mean (extrinsic) curvature (CMC) flows [58][59][60]. Such approaches might provide further insights into the general problem of averaging tensors. For example, the Ricci flow is a well-studied procedure in Riemannian geometry which may be used to realize a regional smoothing through a rescaling of the metrical structure [43,[54][55][56], in the spirit of renormalization group flows. Since the primary motivation of this paper is physical, I will not further discuss these approaches here.	0	Within the context of 1 + 3 formalisms, there have been a number of studies of averaging and backreaction which focus principally on associated mathematical issues. These include the Ricci flow [43,[54][55]#CITATION_TAG, group averaging of the FLRW isometry group [57] and the characterization of constant mean (extrinsic) curvature (CMC) flows [58][59][60]. Such approaches might provide further insights into the general problem of averaging tensors. For example, the Ricci flow is a well-studied procedure in Riemannian geometry which may be used to realize a regional smoothing through a rescaling of the metrical structure [43,[54][55][56], in the spirit of renormalization group flows. Since the primary motivation of this paper is physical, I will not further discuss these approaches here.	h
CCT399	"In formulating general relativity as a dynamical theory of spacetime, Einstein was guided philosophically by Mach""s principle-namely, the broad notion that spacetime does not have a separate existence from the material objects that inhabit it, but is a relational structure between things. As Einstein put it #CITATION_TAG: \""In a consistent theory of relativity there can be no inertia relatively to ""space but only an inertia of masses relatively to one another\"". This after all is the physical principle that underlies general covariance: there is no absolute space or time, and so the basic laws of physics should not depend on arbitrary choices of coordinates."	4	"In formulating general relativity as a dynamical theory of spacetime, Einstein was guided philosophically by Mach""s principle-namely, the broad notion that spacetime does not have a separate existence from the material objects that inhabit it, but is a relational structure between things. As Einstein put it #CITATION_TAG: \""In a consistent theory of relativity there can be no inertia relatively to ""space but only an inertia of masses relatively to one another\"". This after all is the physical principle that underlies general covariance: there is no absolute space or time, and so the basic laws of physics should not depend on arbitrary choices of coordinates."	s
CCT400	In proceeding to level (iv)-galaxy clusters-the fundamental issues become obviously nontrivial. Since many galaxy clusters are spherical in shape, there is a temptation to model them using the spherically symmetric dust Lema√Ætre-Tolman-Bondi (LTB) solutions [13]#CITATION_TAG[15]. While LTB models have certainly been applied to structure formation [16,17], their applicability is constrained by the uniform spherical shell approximation remaining valid, without shell crossings or the growth of angular momentum perturbations. This is probably unrealistically constraining for the case of a generic collapse, and LTB models are most obviously applicable to expanding spherical voids [18] with ionic or molecular sized dust. If we consider virialized spherical clusters of galaxies, then there is no obvious reason for the LTB model to be applicable. In many galaxy clusters, the motion of individual galaxies may be close to radial-however, the phases of the galaxies relative to passage through the centre of the cluster are completely uncorrelated. Individual galaxies will pass close to the core of the cluster and emerge from the other side; at any instant, the number of galaxies moving out from the centre might be comparable to the number falling in. Thus, virialized galaxy clusters certainly do not have the symmetry of a spherically symmetric dust solution if the galaxies are to be identified as the dust.	0	In proceeding to level (iv)-galaxy clusters-the fundamental issues become obviously nontrivial. Since many galaxy clusters are spherical in shape, there is a temptation to model them using the spherically symmetric dust Lema√Ætre-Tolman-Bondi (LTB) solutions [13]#CITATION_TAG[15]. While LTB models have certainly been applied to structure formation [16,17], their applicability is constrained by the uniform spherical shell approximation remaining valid, without shell crossings or the growth of angular momentum perturbations. This is probably unrealistically constraining for the case of a generic collapse, and LTB models are most obviously applicable to expanding spherical voids [18] with ionic or molecular sized dust. If we consider virialized spherical clusters of galaxies, then there is no obvious reason for the LTB model to be applicable.	i
CCT401	"In the foregoing literature, two central arguments have been employed to connect individuals"" memberships in voluntary associations and their civic attitudes (Wollebaek & Selle, 2007). The first rests on a self-selection argument stating that people with sufficiently ""prosocial"" characteristics are more likely to engage in society and join voluntary associations compared to people lacking such characteristics. As a result, individuals in voluntary associations display higher levels of desirable social attitudes simply because they selected themselves into such associations due to their pro-social attitudes (e.g., van Deth et al., 1999). The second view rests on a socialization argument and states that membership in voluntary associations induces a process of appropriating norms, attitudes, values and roles (e.g., Putnam, 2000). In this case, membership is expected to lead individuals to develop ""new"" values through interactions with co-members. 2 Given the importance of formal and informal institutions for governing people""s behaviour (e.g., North, 1990;Thelen, 1999) and earlier findings linking the institutional environment to the development of specific types of voluntary associations (e.g., Berman, 1997;K√§√§ri√§inen & Lehtonen, 2006;Schofer & Fourcade-Gourinchas, 2001), it is surprising that both lines of argument ignore the socio-political and institutional environment within which the individual and the association exist. This is especially injudicious since the nature and internal homogeneity of the voluntary organization that arises in specific contexts, as well as the societal relevance of that group and the issues it stands for, influence members"" integration process within the association. Indeed, these characterizing elements of the organizational identity are shown to be crucial determinants of individuals"" integration processes in the socialization literature (e.g., Checkel & Katzenstein, 2009), and play a key role to explain ""peer effects"" in research on group interaction in social psychology. 3 Consequently, as ""the definition of interests and objectives is created in institutional contexts and is not separable from them"" (Zysman, 1994, p. 244), any self-selection and socialization processes are unlikely to be unconditional, but rather will depend on, and be influenced by, the broader institutional environment. Hooghe (2003, p. 93) implies a similar idea when arguing that association membership is unlikely to ""introduce qualitatively new values, but enforces already existing values"" (see also #CITATION_TAG & Goodwin, 2011;Katz & Lazersfeld, 1955)."	0	"This is especially injudicious since the nature and internal homogeneity of the voluntary organization that arises in specific contexts, as well as the societal relevance of that group and the issues it stands for, influence members"" integration process within the association. Indeed, these characterizing elements of the organizational identity are shown to be crucial determinants of individuals"" integration processes in the socialization literature (e.g., Checkel & Katzenstein, 2009), and play a key role to explain ""peer effects"" in research on group interaction in social psychology. 3 Consequently, as ""the definition of interests and objectives is created in institutional contexts and is not separable from them"" (Zysman, 1994, p. 244), any self-selection and socialization processes are unlikely to be unconditional, but rather will depend on, and be influenced by, the broader institutional environment. Hooghe (2003, p. 93) implies a similar idea when arguing that association membership is unlikely to ""introduce qualitatively new values, but enforces already existing values"" (see also #CITATION_TAG & Goodwin, 2011;Katz & Lazersfeld, 1955)."	0
CCT402	"The empirical analysis thereby builds on recent work by #CITATION_TAG (2007) to allow easy reference to existing findings. Building on social identity theory (e.g., Tajfel, 1978) and social network analysis (e.g., Coleman, 1990), Paxton (2007, p. 51, italics in original) argues that the generalization of trust beyond a given voluntary association ""is critically dependent on whether an individual belongs to an association that is connected to other associations or one that is isolated"". For ease of reference, the former will in the remainder of this article be referred to as ""connected memberships while the latter are designated as ""isolated memberships"". Using this terminology, connected memberships are argued to expand individuals"" networks beyond one single association (Paxton, 2007; see also Cornwell & Harrison, 2004;Moody & White, 2003), thus allowing members to ""transfer trust gained within their association to individuals outside the association"" (Paxton, 2007, p. 51). Isolated memberships, however, ""are inherently bounded, and should therefore be less likely to transfer trust"" (Paxton, 2007, pp. 53-54). Empirical evidence using data from the 1990 wave of the World Values Survey (WVS) supports this theoretical argument."	5	"The empirical analysis thereby builds on recent work by #CITATION_TAG (2007) to allow easy reference to existing findings. Building on social identity theory (e.g., Tajfel, 1978) and social network analysis (e.g., Coleman, 1990), Paxton (2007, p. 51, italics in original) argues that the generalization of trust beyond a given voluntary association ""is critically dependent on whether an individual belongs to an association that is connected to other associations or one that is isolated"". For ease of reference, the former will in the remainder of this article be referred to as ""connected memberships while the latter are designated as ""isolated memberships"". Using this terminology, connected memberships are argued to expand individuals"" networks beyond one single association (Paxton, 2007; see also Cornwell & Harrison, 2004;Moody & White, 2003), thus allowing members to ""transfer trust gained within their association to individuals outside the association"" (Paxton, 2007, p. 51)."	T
CCT403	"Over the past decade, a lively debate has developed regarding the decline in civic participation observed by some, but not by others, across a number of Western democracies (Dekker & van den Broek, 2005;Listhaug & Gr√∏nflaten, 2007;Paxton, 1999;#CITATION_TAG, 2000;Stolle & Hooghe, 2003). The importance of this debate lies not only in establishing whether Western societies have become more individualistic over time and its citizens increasingly ""hunker down"" (to borrow the colloquialism introduced in this respect by Putnam, 2007), but also reflects the central role often attributed to civic engagement for the development and maintenance of democratic values, generalized trust, cooperative norms, racial and religious tolerance, and so on (e.g., Delhey & Newton, 2005;Li, Pickles, & Savage, 2005;Putnam, 2000;Terriquez, 2011). When civic engagement is intimately associated with a wide range of social values, its decline can be feared to provoke a concomitant decline throughout society in inter-personal trust, tolerance, cooperation and so on (Putnam, 2000). Conversely, however, a close engagement-values relation also holds significant promise, especially to politicians, as it would imply that policies to stimulate civic engagement can become reflected in a parallel change in social and democratic values. Exactly for this reason, political leaders in, for instance, the United States, United Kingdom, Germany and the European Union have in recent years shown a strong interest in stimulating civic engagement as a means to (help) address societal changes induced by, for instance, large-scale migration and globalization. To give only one example from the United Kingdom, the Conservative Party""s election manifesto for the May 2010 general election stated that the restoration of the United Kingdom""s social fabric and citizen involvement was a top priority. After the election, David Cameron again stressed this point in his first speech as Prime Minister."	0	"Over the past decade, a lively debate has developed regarding the decline in civic participation observed by some, but not by others, across a number of Western democracies (Dekker & van den Broek, 2005;Listhaug & Gr√∏nflaten, 2007;Paxton, 1999;#CITATION_TAG, 2000;Stolle & Hooghe, 2003). The importance of this debate lies not only in establishing whether Western societies have become more individualistic over time and its citizens increasingly ""hunker down"" (to borrow the colloquialism introduced in this respect by Putnam, 2007), but also reflects the central role often attributed to civic engagement for the development and maintenance of democratic values, generalized trust, cooperative norms, racial and religious tolerance, and so on (e.g., Delhey & Newton, 2005;Li, Pickles, & Savage, 2005;Putnam, 2000;Terriquez, 2011). When civic engagement is intimately associated with a wide range of social values, its decline can be feared to provoke a concomitant decline throughout society in inter-personal trust, tolerance, cooperation and so on (Putnam, 2000). Conversely, however, a close engagement-values relation also holds significant promise, especially to politicians, as it would imply that policies to stimulate civic engagement can become reflected in a parallel change in social and democratic values."	O
CCT404	"Over the past decade, a lively debate has developed regarding the decline in civic participation observed by some, but not by others, across a number of Western democracies (Dekker & van den Broek, 2005;Listhaug & Gr√∏nflaten, 2007;Paxton, 1999;Putnam, 2000;Stolle & Hooghe, 2003). The importance of this debate lies not only in establishing whether Western societies have become more individualistic over time and its citizens increasingly ""hunker down"" (to borrow the colloquialism introduced in this respect by Putnam, 2007), but also reflects the central role often attributed to civic engagement for the development and maintenance of democratic values, generalized trust, cooperative norms, racial and religious tolerance, and so on (e.g., Delhey & Newton, 2005;Li, Pickles, & Savage, 2005;#CITATION_TAG, 2000;Terriquez, 2011). When civic engagement is intimately associated with a wide range of social values, its decline can be feared to provoke a concomitant decline throughout society in inter-personal trust, tolerance, cooperation and so on (Putnam, 2000). Conversely, however, a close engagement-values relation also holds significant promise, especially to politicians, as it would imply that policies to stimulate civic engagement can become reflected in a parallel change in social and democratic values. Exactly for this reason, political leaders in, for instance, the United States, United Kingdom, Germany and the European Union have in recent years shown a strong interest in stimulating civic engagement as a means to (help) address societal changes induced by, for instance, large-scale migration and globalization. To give only one example from the United Kingdom, the Conservative Party""s election manifesto for the May 2010 general election stated that the restoration of the United Kingdom""s social fabric and citizen involvement was a top priority. After the election, David Cameron again stressed this point in his first speech as Prime Minister."	4	"Over the past decade, a lively debate has developed regarding the decline in civic participation observed by some, but not by others, across a number of Western democracies (Dekker & van den Broek, 2005;Listhaug & Gr√∏nflaten, 2007;Paxton, 1999;Putnam, 2000;Stolle & Hooghe, 2003). The importance of this debate lies not only in establishing whether Western societies have become more individualistic over time and its citizens increasingly ""hunker down"" (to borrow the colloquialism introduced in this respect by Putnam, 2007), but also reflects the central role often attributed to civic engagement for the development and maintenance of democratic values, generalized trust, cooperative norms, racial and religious tolerance, and so on (e.g., Delhey & Newton, 2005;Li, Pickles, & Savage, 2005;#CITATION_TAG, 2000;Terriquez, 2011). When civic engagement is intimately associated with a wide range of social values, its decline can be feared to provoke a concomitant decline throughout society in inter-personal trust, tolerance, cooperation and so on (Putnam, 2000). Conversely, however, a close engagement-values relation also holds significant promise, especially to politicians, as it would imply that policies to stimulate civic engagement can become reflected in a parallel change in social and democratic values. Exactly for this reason, political leaders in, for instance, the United States, United Kingdom, Germany and the European Union have in recent years shown a strong interest in stimulating civic engagement as a means to (help) address societal changes induced by, for instance, large-scale migration and globalization."	h
CCT405	"Whether change is incremental or substantive, the above discussion strongly suggests that the engagement-values relation will generally lack temporal stability. This argument obviously need not be constrained to civic engagement in general, but is likely to similarly hold for diverse types of civic engagement. In the empirical analysis below, this will be verified for the isolated/connected distinction discussed in Paxton (2007; see above). Nonetheless, the same might likewise hold for other distinctions recently proposed in the literature: e.g., the bridging/bonding distinction based on the socio-demographic diversity of an association""s memberships (see Coff√© & Geys, 2007;Putnam, 2000;#CITATION_TAG & Rochon, 1998), the inclusive/exclusive distinction based on associations"" constitutive purposes (Geys & Griesshaber, 2012;Warren, 2001Warren, , 2004Zmerli, 2003), or the typology based on associations"" ""primary concerns"" (i.e., recreational, members"" interests, or broad social interests; see van der Meer, Te Grotenhuis, & Scheepers, 2009). Moreover, in principle, nothing constrains any temporal trends in the engagement-values relation to be similar across such subtypes of civic engagement. That is, the connection between, say, exclusive civic engagement and generalized trust may be weakening over time, while trust""s association to inclusive engagement may remain unchanged (or strengthen)."	1	"Whether change is incremental or substantive, the above discussion strongly suggests that the engagement-values relation will generally lack temporal stability. This argument obviously need not be constrained to civic engagement in general, but is likely to similarly hold for diverse types of civic engagement. In the empirical analysis below, this will be verified for the isolated/connected distinction discussed in Paxton (2007; see above). Nonetheless, the same might likewise hold for other distinctions recently proposed in the literature: e.g., the bridging/bonding distinction based on the socio-demographic diversity of an association""s memberships (see Coff√© & Geys, 2007;Putnam, 2000;#CITATION_TAG & Rochon, 1998), the inclusive/exclusive distinction based on associations"" constitutive purposes (Geys & Griesshaber, 2012;Warren, 2001Warren, , 2004Zmerli, 2003), or the typology based on associations"" ""primary concerns"" (i.e., recreational, members"" interests, or broad social interests; see van der Meer, Te Grotenhuis, & Scheepers, 2009). Moreover, in principle, nothing constrains any temporal trends in the engagement-values relation to be similar across such subtypes of civic engagement. That is, the connection between, say, exclusive civic engagement and generalized trust may be weakening over time, while trust""s association to inclusive engagement may remain unchanged (or strengthen)."	e
CCT406	"Over the past decade, a lively debate has developed regarding the decline in civic participation observed by some, but not by others, across a number of Western democracies (Dekker & van den Broek, 2005;Listhaug & Gr√∏nflaten, 2007;Paxton, 1999;Putnam, 2000;#CITATION_TAG & Hooghe, 2003). The importance of this debate lies not only in establishing whether Western societies have become more individualistic over time and its citizens increasingly ""hunker down"" (to borrow the colloquialism introduced in this respect by Putnam, 2007), but also reflects the central role often attributed to civic engagement for the development and maintenance of democratic values, generalized trust, cooperative norms, racial and religious tolerance, and so on (e.g., Delhey & Newton, 2005;Li, Pickles, & Savage, 2005;Putnam, 2000;Terriquez, 2011). When civic engagement is intimately associated with a wide range of social values, its decline can be feared to provoke a concomitant decline throughout society in inter-personal trust, tolerance, cooperation and so on (Putnam, 2000). Conversely, however, a close engagement-values relation also holds significant promise, especially to politicians, as it would imply that policies to stimulate civic engagement can become reflected in a parallel change in social and democratic values. Exactly for this reason, political leaders in, for instance, the United States, United Kingdom, Germany and the European Union have in recent years shown a strong interest in stimulating civic engagement as a means to (help) address societal changes induced by, for instance, large-scale migration and globalization. To give only one example from the United Kingdom, the Conservative Party""s election manifesto for the May 2010 general election stated that the restoration of the United Kingdom""s social fabric and citizen involvement was a top priority. After the election, David Cameron again stressed this point in his first speech as Prime Minister."	0	"Over the past decade, a lively debate has developed regarding the decline in civic participation observed by some, but not by others, across a number of Western democracies (Dekker & van den Broek, 2005;Listhaug & Gr√∏nflaten, 2007;Paxton, 1999;Putnam, 2000;#CITATION_TAG & Hooghe, 2003). The importance of this debate lies not only in establishing whether Western societies have become more individualistic over time and its citizens increasingly ""hunker down"" (to borrow the colloquialism introduced in this respect by Putnam, 2007), but also reflects the central role often attributed to civic engagement for the development and maintenance of democratic values, generalized trust, cooperative norms, racial and religious tolerance, and so on (e.g., Delhey & Newton, 2005;Li, Pickles, & Savage, 2005;Putnam, 2000;Terriquez, 2011). When civic engagement is intimately associated with a wide range of social values, its decline can be feared to provoke a concomitant decline throughout society in inter-personal trust, tolerance, cooperation and so on (Putnam, 2000). Conversely, however, a close engagement-values relation also holds significant promise, especially to politicians, as it would imply that policies to stimulate civic engagement can become reflected in a parallel change in social and democratic values."	O
CCT407	"Over the past decade, a lively debate has developed regarding the decline in civic participation observed by some, but not by others, across a number of Western democracies (Dekker & van den Broek, 2005;Listhaug & Gr√∏nflaten, 2007;Paxton, 1999;Putnam, 2000;Stolle & Hooghe, 2003). The importance of this debate lies not only in establishing whether Western societies have become more individualistic over time and its citizens increasingly ""hunker down"" (to borrow the colloquialism introduced in this respect by Putnam, 2007), but also reflects the central role often attributed to civic engagement for the development and maintenance of democratic values, generalized trust, cooperative norms, racial and religious tolerance, and so on (e.g., #CITATION_TAG & Newton, 2005;Li, Pickles, & Savage, 2005;Putnam, 2000;Terriquez, 2011). When civic engagement is intimately associated with a wide range of social values, its decline can be feared to provoke a concomitant decline throughout society in inter-personal trust, tolerance, cooperation and so on (Putnam, 2000). Conversely, however, a close engagement-values relation also holds significant promise, especially to politicians, as it would imply that policies to stimulate civic engagement can become reflected in a parallel change in social and democratic values. Exactly for this reason, political leaders in, for instance, the United States, United Kingdom, Germany and the European Union have in recent years shown a strong interest in stimulating civic engagement as a means to (help) address societal changes induced by, for instance, large-scale migration and globalization. To give only one example from the United Kingdom, the Conservative Party""s election manifesto for the May 2010 general election stated that the restoration of the United Kingdom""s social fabric and citizen involvement was a top priority. After the election, David Cameron again stressed this point in his first speech as Prime Minister."	4	"Over the past decade, a lively debate has developed regarding the decline in civic participation observed by some, but not by others, across a number of Western democracies (Dekker & van den Broek, 2005;Listhaug & Gr√∏nflaten, 2007;Paxton, 1999;Putnam, 2000;Stolle & Hooghe, 2003). The importance of this debate lies not only in establishing whether Western societies have become more individualistic over time and its citizens increasingly ""hunker down"" (to borrow the colloquialism introduced in this respect by Putnam, 2007), but also reflects the central role often attributed to civic engagement for the development and maintenance of democratic values, generalized trust, cooperative norms, racial and religious tolerance, and so on (e.g., #CITATION_TAG & Newton, 2005;Li, Pickles, & Savage, 2005;Putnam, 2000;Terriquez, 2011). When civic engagement is intimately associated with a wide range of social values, its decline can be feared to provoke a concomitant decline throughout society in inter-personal trust, tolerance, cooperation and so on (Putnam, 2000). Conversely, however, a close engagement-values relation also holds significant promise, especially to politicians, as it would imply that policies to stimulate civic engagement can become reflected in a parallel change in social and democratic values. Exactly for this reason, political leaders in, for instance, the United States, United Kingdom, Germany and the European Union have in recent years shown a strong interest in stimulating civic engagement as a means to (help) address societal changes induced by, for instance, large-scale migration and globalization."	h
CCT408	"Over the past decade, a lively debate has developed regarding the decline in civic participation observed by some, but not by others, across a number of Western democracies (Dekker & van den Broek, 2005;Listhaug & Gr√∏nflaten, 2007;#CITATION_TAG, 1999;Putnam, 2000;Stolle & Hooghe, 2003). The importance of this debate lies not only in establishing whether Western societies have become more individualistic over time and its citizens increasingly ""hunker down"" (to borrow the colloquialism introduced in this respect by Putnam, 2007), but also reflects the central role often attributed to civic engagement for the development and maintenance of democratic values, generalized trust, cooperative norms, racial and religious tolerance, and so on (e.g., Delhey & Newton, 2005;Li, Pickles, & Savage, 2005;Putnam, 2000;Terriquez, 2011). When civic engagement is intimately associated with a wide range of social values, its decline can be feared to provoke a concomitant decline throughout society in inter-personal trust, tolerance, cooperation and so on (Putnam, 2000). Conversely, however, a close engagement-values relation also holds significant promise, especially to politicians, as it would imply that policies to stimulate civic engagement can become reflected in a parallel change in social and democratic values. Exactly for this reason, political leaders in, for instance, the United States, United Kingdom, Germany and the European Union have in recent years shown a strong interest in stimulating civic engagement as a means to (help) address societal changes induced by, for instance, large-scale migration and globalization. To give only one example from the United Kingdom, the Conservative Party""s election manifesto for the May 2010 general election stated that the restoration of the United Kingdom""s social fabric and citizen involvement was a top priority. After the election, David Cameron again stressed this point in his first speech as Prime Minister."	0	"Over the past decade, a lively debate has developed regarding the decline in civic participation observed by some, but not by others, across a number of Western democracies (Dekker & van den Broek, 2005;Listhaug & Gr√∏nflaten, 2007;#CITATION_TAG, 1999;Putnam, 2000;Stolle & Hooghe, 2003). The importance of this debate lies not only in establishing whether Western societies have become more individualistic over time and its citizens increasingly ""hunker down"" (to borrow the colloquialism introduced in this respect by Putnam, 2007), but also reflects the central role often attributed to civic engagement for the development and maintenance of democratic values, generalized trust, cooperative norms, racial and religious tolerance, and so on (e.g., Delhey & Newton, 2005;Li, Pickles, & Savage, 2005;Putnam, 2000;Terriquez, 2011). When civic engagement is intimately associated with a wide range of social values, its decline can be feared to provoke a concomitant decline throughout society in inter-personal trust, tolerance, cooperation and so on (Putnam, 2000). Conversely, however, a close engagement-values relation also holds significant promise, especially to politicians, as it would imply that policies to stimulate civic engagement can become reflected in a parallel change in social and democratic values."	O
CCT409	"Clearly, however, not all institutional change occurs gradually. Exogenous shocks can function as ""critical junctures"" that instigate ""broadly different development paths"" and lead to a substantive institutional readjustment (Thelen, 1999, p. 387; see also Capoccia & Kelemen, 2007;Collier & Collier, 1991). Such unsettled times ""open possibilities for change"" (Thelen, 1999, p. 397) because ""groups or entire societies (. . .) are involved in constructing new strategies for action"" (Swidler, 1986, p. 278). Wars, terrorist activity or natural disasters therefore have the potential to induce sudden, although possibly temporary, shifts in people""s attitudes and value patterns (e.g., Ladd & Cairns, 1996;#CITATION_TAG et al., 2000). 4 For the same reason as above, this may lead the societal implications of association memberships to shift abruptly."	0	"Exogenous shocks can function as ""critical junctures"" that instigate ""broadly different development paths"" and lead to a substantive institutional readjustment (Thelen, 1999, p. 387; see also Capoccia & Kelemen, 2007;Collier & Collier, 1991). Such unsettled times ""open possibilities for change"" (Thelen, 1999, p. 397) because ""groups or entire societies (. . .) are involved in constructing new strategies for action"" (Swidler, 1986, p. 278). Wars, terrorist activity or natural disasters therefore have the potential to induce sudden, although possibly temporary, shifts in people""s attitudes and value patterns (e.g., Ladd & Cairns, 1996;#CITATION_TAG et al., 2000). 4 For the same reason as above, this may lead the societal implications of association memberships to shift abruptly."	,
CCT410	"Why does this relative neglect of the socio-political and institutional environment matter? Why does this relative neglect of the socio-political and institutional environment matter? Based on the idea that institutions get ""locked in"" as a result of self-reinforcement, self-reproduction and path dependence (e.g., Collier & Collier, 1991;Mahoney, 2000;#CITATION_TAG, 2000), institutions have long been viewed as stable and resistant to change until ""exogenous shocks (. . .) bring about radical institutional reconfigurations"" (Mahoney & Thelen, 2010, p. 2). In recent work, however, scholars have moved away from this emphasis on what could be termed ""interrupted stability"" (resembling the idea of punctuated equilibria in evolutionary biology) and explicitly recognize the existence of ""shifts that unfold incrementally"" (Mahoney & Thelen, 2010, p. 2). Although such endogenous incremental changes can take different forms (see Boas, 2007;Mahoney & Thelen, 2010;Streeck & Thelen, 2005), they all have in common that ""the effect of the institution is transformed"" in a gradual process (Boas, 2007, p. 34, italics in original). This changing environment, in turn, generates an adjustment process in terms of individuals"" membership decisions, the core values of voluntary associations and any intraassociation socialization processes (see above). Although during this transformation process individual A may (but need not) still be in association B, changes in the institutional environment induce changes in individual A as well as association B. As a direct consequence, the societal implications of association memberships will likewise exhibit a gradual transformation over time."	0	"Why does this relative neglect of the socio-political and institutional environment matter? Why does this relative neglect of the socio-political and institutional environment matter? Based on the idea that institutions get ""locked in"" as a result of self-reinforcement, self-reproduction and path dependence (e.g., Collier & Collier, 1991;Mahoney, 2000;#CITATION_TAG, 2000), institutions have long been viewed as stable and resistant to change until ""exogenous shocks (. . .) bring about radical institutional reconfigurations"" (Mahoney & Thelen, 2010, p. 2). In recent work, however, scholars have moved away from this emphasis on what could be termed ""interrupted stability"" (resembling the idea of punctuated equilibria in evolutionary biology) and explicitly recognize the existence of ""shifts that unfold incrementally"" (Mahoney & Thelen, 2010, p. 2). Although such endogenous incremental changes can take different forms (see Boas, 2007;Mahoney & Thelen, 2010;Streeck & Thelen, 2005), they all have in common that ""the effect of the institution is transformed"" in a gradual process (Boas, 2007, p. 34, italics in original)."	s
CCT411	"In the foregoing literature, two central arguments have been employed to connect individuals"" memberships in voluntary associations and their civic attitudes (Wollebaek & Selle, 2007). The first rests on a self-selection argument stating that people with sufficiently ""prosocial"" characteristics are more likely to engage in society and join voluntary associations compared to people lacking such characteristics. As a result, individuals in voluntary associations display higher levels of desirable social attitudes simply because they selected themselves into such associations due to their pro-social attitudes (e.g., van Deth et al., 1999). The second view rests on a socialization argument and states that membership in voluntary associations induces a process of appropriating norms, attitudes, values and roles (e.g., Putnam, 2000). In this case, membership is expected to lead individuals to develop ""new"" values through interactions with co-members. 2 Given the importance of formal and informal institutions for governing people""s behaviour (e.g., #CITATION_TAG, 1990;Thelen, 1999) and earlier findings linking the institutional environment to the development of specific types of voluntary associations (e.g., Berman, 1997;K√§√§ri√§inen & Lehtonen, 2006;Schofer & Fourcade-Gourinchas, 2001), it is surprising that both lines of argument ignore the socio-political and institutional environment within which the individual and the association exist. This is especially injudicious since the nature and internal homogeneity of the voluntary organization that arises in specific contexts, as well as the societal relevance of that group and the issues it stands for, influence members"" integration process within the association. Indeed, these characterizing elements of the organizational identity are shown to be crucial determinants of individuals"" integration processes in the socialization literature (e.g., Checkel & Katzenstein, 2009), and play a key role to explain ""peer effects"" in research on group interaction in social psychology. 3 Consequently, as ""the definition of interests and objectives is created in institutional contexts and is not separable from them"" (Zysman, 1994, p. 244), any self-selection and socialization processes are unlikely to be unconditional, but rather will depend on, and be influenced by, the broader institutional environment. Hooghe (2003, p. 93) implies a similar idea when arguing that association membership is unlikely to ""introduce qualitatively new values, but enforces already existing values"" (see also Bardi & Goodwin, 2011;Katz & Lazersfeld, 1955)."	0	"As a result, individuals in voluntary associations display higher levels of desirable social attitudes simply because they selected themselves into such associations due to their pro-social attitudes (e.g., van Deth et al., 1999). The second view rests on a socialization argument and states that membership in voluntary associations induces a process of appropriating norms, attitudes, values and roles (e.g., Putnam, 2000). In this case, membership is expected to lead individuals to develop ""new"" values through interactions with co-members. 2 Given the importance of formal and informal institutions for governing people""s behaviour (e.g., #CITATION_TAG, 1990;Thelen, 1999) and earlier findings linking the institutional environment to the development of specific types of voluntary associations (e.g., Berman, 1997;K√§√§ri√§inen & Lehtonen, 2006;Schofer & Fourcade-Gourinchas, 2001), it is surprising that both lines of argument ignore the socio-political and institutional environment within which the individual and the association exist. This is especially injudicious since the nature and internal homogeneity of the voluntary organization that arises in specific contexts, as well as the societal relevance of that group and the issues it stands for, influence members"" integration process within the association. Indeed, these characterizing elements of the organizational identity are shown to be crucial determinants of individuals"" integration processes in the socialization literature (e.g., Checkel & Katzenstein, 2009), and play a key role to explain ""peer effects"" in research on group interaction in social psychology. 3 Consequently, as ""the definition of interests and objectives is created in institutional contexts and is not separable from them"" (Zysman, 1994, p. 244), any self-selection and socialization processes are unlikely to be unconditional, but rather will depend on, and be influenced by, the broader institutional environment."	e
CCT412	"The control variables in X ij first of all include respondents"" age (in years) and level of education, which in the WVS is measured as age when obtaining one""s highest degree. Both age and education have in previous work been shown to be strongly associated with trust; in particular, individuals tend to become more trusting between 18 and 40, and with higher educational attainment (Robinson & Jackson, 2001). In the absence of data on individuals"" income levels that are fully comparable across countries, we follow Paxton (2007) in introducing a dummy variable equal to 1 when a respondent is employed and a measure of occupational prestige (based on Ganzeboom, et al., 1992) to capture the idea that individuals with more limited resources and a more disadvantaged position in life may find it harder and/or riskier to trust others (e.g., #CITATION_TAG, 1999;Whiteley, 1999). We also include an indicator variable equal to 1 if the respondent is divorced. As divorce is a defining event in one""s life, which may well ""reduce an individual""s assessment of the goodwill of others"" (Paxton, 2007, p. 49), it can be expected to reduce an individual""s confidence in others"" trustworthiness (e.g., Rahn & Yoon, 2009). Similarly, having children at home may ""increase an individual""s sense of vulnerability and thereby decrease his level of trust"" (Paxton, 2007, p. 49), which we address via an indicator variable equal to 1 for respondents with children in their home. Finally, we include a variable measuring the importance the respondent attaches to friends (measured on a four-point scale from 1 ""very important"" to 4 ""not at all important""). This intends to capture ""individual-level extroversion, which could impact both association memberships and trust"" (Paxton, 2007, p. 58). Note that all ""non-dummy individual-level independent variables are grand-mean centered, (. . .) which is appropriate when aggregate versions of the variables are not included in the model"" (Paxton, 2007, p. 60)."	5	"The control variables in X ij first of all include respondents"" age (in years) and level of education, which in the WVS is measured as age when obtaining one""s highest degree. Both age and education have in previous work been shown to be strongly associated with trust; in particular, individuals tend to become more trusting between 18 and 40, and with higher educational attainment (Robinson & Jackson, 2001). In the absence of data on individuals"" income levels that are fully comparable across countries, we follow Paxton (2007) in introducing a dummy variable equal to 1 when a respondent is employed and a measure of occupational prestige (based on Ganzeboom, et al., 1992) to capture the idea that individuals with more limited resources and a more disadvantaged position in life may find it harder and/or riskier to trust others (e.g., #CITATION_TAG, 1999;Whiteley, 1999). We also include an indicator variable equal to 1 if the respondent is divorced. As divorce is a defining event in one""s life, which may well ""reduce an individual""s assessment of the goodwill of others"" (Paxton, 2007, p. 49), it can be expected to reduce an individual""s confidence in others"" trustworthiness (e.g., Rahn & Yoon, 2009). Similarly, having children at home may ""increase an individual""s sense of vulnerability and thereby decrease his level of trust"" (Paxton, 2007, p. 49), which we address via an indicator variable equal to 1 for respondents with children in their home."	 
CCT413	"The empirical analysis thereby builds on recent work by Paxton (2007) to allow easy reference to existing findings. Building on social identity theory (e.g., Tajfel, 1978) and social network analysis (e.g., Coleman, 1990), Paxton (2007, p. 51, italics in original) argues that the generalization of trust beyond a given voluntary association ""is critically dependent on whether an individual belongs to an association that is connected to other associations or one that is isolated"". For ease of reference, the former will in the remainder of this article be referred to as ""connected memberships while the latter are designated as ""isolated memberships"". Using this terminology, connected memberships are argued to expand individuals"" networks beyond one single association (Paxton, 2007; see also Cornwell & Harrison, 2004;#CITATION_TAG & White, 2003), thus allowing members to ""transfer trust gained within their association to individuals outside the association"" (Paxton, 2007, p. 51). Isolated memberships, however, ""are inherently bounded, and should therefore be less likely to transfer trust"" (Paxton, 2007, pp. 53-54). Empirical evidence using data from the 1990 wave of the World Values Survey (WVS) supports this theoretical argument."	5	"The empirical analysis thereby builds on recent work by Paxton (2007) to allow easy reference to existing findings. Building on social identity theory (e.g., Tajfel, 1978) and social network analysis (e.g., Coleman, 1990), Paxton (2007, p. 51, italics in original) argues that the generalization of trust beyond a given voluntary association ""is critically dependent on whether an individual belongs to an association that is connected to other associations or one that is isolated"". For ease of reference, the former will in the remainder of this article be referred to as ""connected memberships while the latter are designated as ""isolated memberships"". Using this terminology, connected memberships are argued to expand individuals"" networks beyond one single association (Paxton, 2007; see also Cornwell & Harrison, 2004;#CITATION_TAG & White, 2003), thus allowing members to ""transfer trust gained within their association to individuals outside the association"" (Paxton, 2007, p. 51). Isolated memberships, however, ""are inherently bounded, and should therefore be less likely to transfer trust"" (Paxton, 2007, pp. 53-54). Empirical evidence using data from the 1990 wave of the World Values Survey (WVS) supports this theoretical argument."	n
CCT414	"Why does this relative neglect of the socio-political and institutional environment matter? Based on the idea that institutions get ""locked in"" as a result of self-reinforcement, self-reproduction and path dependence (e.g., Collier & Collier, 1991;Mahoney, 2000;Pierson, 2000), institutions have long been viewed as stable and resistant to change until ""exogenous shocks (. . .) bring about radical institutional reconfigurations"" (Mahoney & Thelen, 2010, p. 2). In recent work, however, scholars have moved away from this emphasis on what could be termed ""interrupted stability"" (resembling the idea of punctuated equilibria in evolutionary biology) and explicitly recognize the existence of ""shifts that unfold incrementally"" (Mahoney & Thelen, 2010, p. 2). Although such endogenous incremental changes can take different forms (see Boas, 2007;#CITATION_TAG & Thelen, 2010;Streeck & Thelen, 2005), they all have in common that ""the effect of the institution is transformed"" in a gradual process (Boas, 2007, p. 34, italics in original). This changing environment, in turn, generates an adjustment process in terms of individuals"" membership decisions, the core values of voluntary associations and any intraassociation socialization processes (see above). Although during this transformation process individual A may (but need not) still be in association B, changes in the institutional environment induce changes in individual A as well as association B. As a direct consequence, the societal implications of association memberships will likewise exhibit a gradual transformation over time."	0	"Based on the idea that institutions get ""locked in"" as a result of self-reinforcement, self-reproduction and path dependence (e.g., Collier & Collier, 1991;Mahoney, 2000;Pierson, 2000), institutions have long been viewed as stable and resistant to change until ""exogenous shocks (. . .) bring about radical institutional reconfigurations"" (Mahoney & Thelen, 2010, p. 2). In recent work, however, scholars have moved away from this emphasis on what could be termed ""interrupted stability"" (resembling the idea of punctuated equilibria in evolutionary biology) and explicitly recognize the existence of ""shifts that unfold incrementally"" (Mahoney & Thelen, 2010, p. 2). Although such endogenous incremental changes can take different forms (see Boas, 2007;#CITATION_TAG & Thelen, 2010;Streeck & Thelen, 2005), they all have in common that ""the effect of the institution is transformed"" in a gradual process (Boas, 2007, p. 34, italics in original). This changing environment, in turn, generates an adjustment process in terms of individuals"" membership decisions, the core values of voluntary associations and any intraassociation socialization processes (see above). Although during this transformation process individual A may (but need not) still be in association B, changes in the institutional environment induce changes in individual A as well as association B. As a direct consequence, the societal implications of association memberships will likewise exhibit a gradual transformation over time."	o
CCT415	"The control variables in X ij first of all include respondents"" age (in years) and level of education, which in the WVS is measured as age when obtaining one""s highest degree. Both age and education have in previous work been shown to be strongly associated with trust; in particular, individuals tend to become more trusting between 18 and 40, and with higher educational attainment (Robinson & Jackson, 2001). In the absence of data on individuals"" income levels that are fully comparable across countries, we follow Paxton (2007) in introducing a dummy variable equal to 1 when a respondent is employed and a measure of occupational prestige (based on Ganzeboom, et al., 1992) to capture the idea that individuals with more limited resources and a more disadvantaged position in life may find it harder and/or riskier to trust others (e.g., Newton, 1999;Whiteley, 1999). We also include an indicator variable equal to 1 if the respondent is divorced. As divorce is a defining event in one""s life, which may well ""reduce an individual""s assessment of the goodwill of others"" (Paxton, 2007, p. 49), it can be expected to reduce an individual""s confidence in others"" trustworthiness (e.g., #CITATION_TAG & Yoon, 2009). Similarly, having children at home may ""increase an individual""s sense of vulnerability and thereby decrease his level of trust"" (Paxton, 2007, p. 49), which we address via an indicator variable equal to 1 for respondents with children in their home. Finally, we include a variable measuring the importance the respondent attaches to friends (measured on a four-point scale from 1 ""very important"" to 4 ""not at all important""). This intends to capture ""individual-level extroversion, which could impact both association memberships and trust"" (Paxton, 2007, p. 58). Note that all ""non-dummy individual-level independent variables are grand-mean centered, (. . .) which is appropriate when aggregate versions of the variables are not included in the model"" (Paxton, 2007, p. 60)."	0	"Both age and education have in previous work been shown to be strongly associated with trust; in particular, individuals tend to become more trusting between 18 and 40, and with higher educational attainment (Robinson & Jackson, 2001). In the absence of data on individuals"" income levels that are fully comparable across countries, we follow Paxton (2007) in introducing a dummy variable equal to 1 when a respondent is employed and a measure of occupational prestige (based on Ganzeboom, et al., 1992) to capture the idea that individuals with more limited resources and a more disadvantaged position in life may find it harder and/or riskier to trust others (e.g., Newton, 1999;Whiteley, 1999). We also include an indicator variable equal to 1 if the respondent is divorced. As divorce is a defining event in one""s life, which may well ""reduce an individual""s assessment of the goodwill of others"" (Paxton, 2007, p. 49), it can be expected to reduce an individual""s confidence in others"" trustworthiness (e.g., #CITATION_TAG & Yoon, 2009). Similarly, having children at home may ""increase an individual""s sense of vulnerability and thereby decrease his level of trust"" (Paxton, 2007, p. 49), which we address via an indicator variable equal to 1 for respondents with children in their home. Finally, we include a variable measuring the importance the respondent attaches to friends (measured on a four-point scale from 1 ""very important"" to 4 ""not at all important""). This intends to capture ""individual-level extroversion, which could impact both association memberships and trust"" (Paxton, 2007, p. 58)."	i
CCT416	"To account for potential country-level determinants of generalized trust, we allow the intercept b 0j above to vary across countries depending on a number of institutional, socio-demographic and cultural characteristics. First, democratic rule has been argued to enhance the protection of minority rights, which, in turn, may stimulate trust among people with diverse backgrounds (e.g., Tilly, 2004). As such, a country""s democratic nature (DEMO; i.e. Polity IV democracy score) is included to evaluate the idea that democracies are likely to enhance trust (see also Levi, 1988). Second, the relation between ethnic and religious diversity, on the one hand, and social capital, civic engagement and trust, on the other hand, has attracted significant scholarly discussion in recent years (e.g., #CITATION_TAG & La Ferrara, 2000, 2002Coff√© & Geys, 2006;Delhey & Newton, 2005; Gijsberts, van der Meer, & Dagevos, forthcoming; Hallberg & Lund, 2005;Putnam, 2007). We therefore control for ethnic-cultural diversity""s potential role as an impediment to trust by including a measure of ethnic and religious fractionalization (ETHNIC and RELIG; Herfindahl indices taken from Alesina et al., 2003). Third, if individuals with more limited resources find it harder and/or riskier to trust others (see above), the same might likewise hold at a more aggregated level. Hence, countries with lower levels of economic development might be characterized by lower levels of trust (Paxton, 2007). To control for this, we include the logarithm of a country""s energy consumption (INDUSTR; taken from World Development Indicators). Finally, we introduce an indicator variable equal to 1 for countries in Eastern Europe (EASTEUR) to accommodate their cultural and historical particularity. This generates the following specification at the country-level:"	0	"To account for potential country-level determinants of generalized trust, we allow the intercept b 0j above to vary across countries depending on a number of institutional, socio-demographic and cultural characteristics. First, democratic rule has been argued to enhance the protection of minority rights, which, in turn, may stimulate trust among people with diverse backgrounds (e.g., Tilly, 2004). As such, a country""s democratic nature (DEMO; i.e. Polity IV democracy score) is included to evaluate the idea that democracies are likely to enhance trust (see also Levi, 1988). Second, the relation between ethnic and religious diversity, on the one hand, and social capital, civic engagement and trust, on the other hand, has attracted significant scholarly discussion in recent years (e.g., #CITATION_TAG & La Ferrara, 2000, 2002Coff√© & Geys, 2006;Delhey & Newton, 2005; Gijsberts, van der Meer, & Dagevos, forthcoming; Hallberg & Lund, 2005;Putnam, 2007). We therefore control for ethnic-cultural diversity""s potential role as an impediment to trust by including a measure of ethnic and religious fractionalization (ETHNIC and RELIG; Herfindahl indices taken from Alesina et al., 2003). Third, if individuals with more limited resources find it harder and/or riskier to trust others (see above), the same might likewise hold at a more aggregated level. Hence, countries with lower levels of economic development might be characterized by lower levels of trust (Paxton, 2007)."	o
CCT417	"Why does this relative neglect of the socio-political and institutional environment matter? Based on the idea that institutions get ""locked in"" as a result of self-reinforcement, self-reproduction and path dependence (e.g., Collier & Collier, 1991;Mahoney, 2000;Pierson, 2000), institutions have long been viewed as stable and resistant to change until ""exogenous shocks (. . .) bring about radical institutional reconfigurations"" (Mahoney & Thelen, 2010, p. 2). In recent work, however, scholars have moved away from this emphasis on what could be termed ""interrupted stability"" (resembling the idea of punctuated equilibria in evolutionary biology) and explicitly recognize the existence of ""shifts that unfold incrementally"" (Mahoney & Thelen, 2010, p. 2). Although such endogenous incremental changes can take different forms (see Boas, 2007;Mahoney & Thelen, 2010;#CITATION_TAG & Thelen, 2005), they all have in common that ""the effect of the institution is transformed"" in a gradual process (Boas, 2007, p. 34, italics in original). This changing environment, in turn, generates an adjustment process in terms of individuals"" membership decisions, the core values of voluntary associations and any intraassociation socialization processes (see above). Although during this transformation process individual A may (but need not) still be in association B, changes in the institutional environment induce changes in individual A as well as association B. As a direct consequence, the societal implications of association memberships will likewise exhibit a gradual transformation over time."	0	"Based on the idea that institutions get ""locked in"" as a result of self-reinforcement, self-reproduction and path dependence (e.g., Collier & Collier, 1991;Mahoney, 2000;Pierson, 2000), institutions have long been viewed as stable and resistant to change until ""exogenous shocks (. . .) bring about radical institutional reconfigurations"" (Mahoney & Thelen, 2010, p. 2). In recent work, however, scholars have moved away from this emphasis on what could be termed ""interrupted stability"" (resembling the idea of punctuated equilibria in evolutionary biology) and explicitly recognize the existence of ""shifts that unfold incrementally"" (Mahoney & Thelen, 2010, p. 2). Although such endogenous incremental changes can take different forms (see Boas, 2007;Mahoney & Thelen, 2010;#CITATION_TAG & Thelen, 2005), they all have in common that ""the effect of the institution is transformed"" in a gradual process (Boas, 2007, p. 34, italics in original). This changing environment, in turn, generates an adjustment process in terms of individuals"" membership decisions, the core values of voluntary associations and any intraassociation socialization processes (see above). Although during this transformation process individual A may (but need not) still be in association B, changes in the institutional environment induce changes in individual A as well as association B. As a direct consequence, the societal implications of association memberships will likewise exhibit a gradual transformation over time."	o
CCT418	"The control variables in X ij first of all include respondents"" age (in years) and level of education, which in the WVS is measured as age when obtaining one""s highest degree. Both age and education have in previous work been shown to be strongly associated with trust; in particular, individuals tend to become more trusting between 18 and 40, and with higher educational attainment (#CITATION_TAG & Jackson, 2001). In the absence of data on individuals"" income levels that are fully comparable across countries, we follow Paxton (2007) in introducing a dummy variable equal to 1 when a respondent is employed and a measure of occupational prestige (based on Ganzeboom, et al., 1992) to capture the idea that individuals with more limited resources and a more disadvantaged position in life may find it harder and/or riskier to trust others (e.g., Newton, 1999;Whiteley, 1999). We also include an indicator variable equal to 1 if the respondent is divorced. As divorce is a defining event in one""s life, which may well ""reduce an individual""s assessment of the goodwill of others"" (Paxton, 2007, p. 49), it can be expected to reduce an individual""s confidence in others"" trustworthiness (e.g., Rahn & Yoon, 2009). Similarly, having children at home may ""increase an individual""s sense of vulnerability and thereby decrease his level of trust"" (Paxton, 2007, p. 49), which we address via an indicator variable equal to 1 for respondents with children in their home. Finally, we include a variable measuring the importance the respondent attaches to friends (measured on a four-point scale from 1 ""very important"" to 4 ""not at all important""). This intends to capture ""individual-level extroversion, which could impact both association memberships and trust"" (Paxton, 2007, p. 58). Note that all ""non-dummy individual-level independent variables are grand-mean centered, (. . .) which is appropriate when aggregate versions of the variables are not included in the model"" (Paxton, 2007, p. 60)."	5	"The control variables in X ij first of all include respondents"" age (in years) and level of education, which in the WVS is measured as age when obtaining one""s highest degree. Both age and education have in previous work been shown to be strongly associated with trust; in particular, individuals tend to become more trusting between 18 and 40, and with higher educational attainment (#CITATION_TAG & Jackson, 2001). In the absence of data on individuals"" income levels that are fully comparable across countries, we follow Paxton (2007) in introducing a dummy variable equal to 1 when a respondent is employed and a measure of occupational prestige (based on Ganzeboom, et al., 1992) to capture the idea that individuals with more limited resources and a more disadvantaged position in life may find it harder and/or riskier to trust others (e.g., Newton, 1999;Whiteley, 1999). We also include an indicator variable equal to 1 if the respondent is divorced. As divorce is a defining event in one""s life, which may well ""reduce an individual""s assessment of the goodwill of others"" (Paxton, 2007, p. 49), it can be expected to reduce an individual""s confidence in others"" trustworthiness (e.g., Rahn & Yoon, 2009)."	o
CCT419	"Over the past decade, a lively debate has developed regarding the decline in civic participation observed by some, but not by others, across a number of Western democracies (Dekker & van den Broek, 2005;Listhaug & Gr√∏nflaten, 2007;Paxton, 1999;Putnam, 2000;Stolle & Hooghe, 2003). The importance of this debate lies not only in establishing whether Western societies have become more individualistic over time and its citizens increasingly ""hunker down"" (to borrow the colloquialism introduced in this respect by Putnam, 2007), but also reflects the central role often attributed to civic engagement for the development and maintenance of democratic values, generalized trust, cooperative norms, racial and religious tolerance, and so on (e.g., Delhey & Newton, 2005;#CITATION_TAG, Pickles, & Savage, 2005;Putnam, 2000;Terriquez, 2011). When civic engagement is intimately associated with a wide range of social values, its decline can be feared to provoke a concomitant decline throughout society in inter-personal trust, tolerance, cooperation and so on (Putnam, 2000). Conversely, however, a close engagement-values relation also holds significant promise, especially to politicians, as it would imply that policies to stimulate civic engagement can become reflected in a parallel change in social and democratic values. Exactly for this reason, political leaders in, for instance, the United States, United Kingdom, Germany and the European Union have in recent years shown a strong interest in stimulating civic engagement as a means to (help) address societal changes induced by, for instance, large-scale migration and globalization. To give only one example from the United Kingdom, the Conservative Party""s election manifesto for the May 2010 general election stated that the restoration of the United Kingdom""s social fabric and citizen involvement was a top priority. After the election, David Cameron again stressed this point in his first speech as Prime Minister."	4	"Over the past decade, a lively debate has developed regarding the decline in civic participation observed by some, but not by others, across a number of Western democracies (Dekker & van den Broek, 2005;Listhaug & Gr√∏nflaten, 2007;Paxton, 1999;Putnam, 2000;Stolle & Hooghe, 2003). The importance of this debate lies not only in establishing whether Western societies have become more individualistic over time and its citizens increasingly ""hunker down"" (to borrow the colloquialism introduced in this respect by Putnam, 2007), but also reflects the central role often attributed to civic engagement for the development and maintenance of democratic values, generalized trust, cooperative norms, racial and religious tolerance, and so on (e.g., Delhey & Newton, 2005;#CITATION_TAG, Pickles, & Savage, 2005;Putnam, 2000;Terriquez, 2011). When civic engagement is intimately associated with a wide range of social values, its decline can be feared to provoke a concomitant decline throughout society in inter-personal trust, tolerance, cooperation and so on (Putnam, 2000). Conversely, however, a close engagement-values relation also holds significant promise, especially to politicians, as it would imply that policies to stimulate civic engagement can become reflected in a parallel change in social and democratic values. Exactly for this reason, political leaders in, for instance, the United States, United Kingdom, Germany and the European Union have in recent years shown a strong interest in stimulating civic engagement as a means to (help) address societal changes induced by, for instance, large-scale migration and globalization."	h
CCT420	"The empirical analysis thereby builds on recent work by Paxton (2007) to allow easy reference to existing findings. Building on social identity theory (e.g., #CITATION_TAG, 1978) and social network analysis (e.g., Coleman, 1990), Paxton (2007, p. 51, italics in original) argues that the generalization of trust beyond a given voluntary association ""is critically dependent on whether an individual belongs to an association that is connected to other associations or one that is isolated"". For ease of reference, the former will in the remainder of this article be referred to as ""connected memberships while the latter are designated as ""isolated memberships"". Using this terminology, connected memberships are argued to expand individuals"" networks beyond one single association (Paxton, 2007; see also Cornwell & Harrison, 2004;Moody & White, 2003), thus allowing members to ""transfer trust gained within their association to individuals outside the association"" (Paxton, 2007, p. 51). Isolated memberships, however, ""are inherently bounded, and should therefore be less likely to transfer trust"" (Paxton, 2007, pp. 53-54). Empirical evidence using data from the 1990 wave of the World Values Survey (WVS) supports this theoretical argument."	5	"The empirical analysis thereby builds on recent work by Paxton (2007) to allow easy reference to existing findings. Building on social identity theory (e.g., #CITATION_TAG, 1978) and social network analysis (e.g., Coleman, 1990), Paxton (2007, p. 51, italics in original) argues that the generalization of trust beyond a given voluntary association ""is critically dependent on whether an individual belongs to an association that is connected to other associations or one that is isolated"". For ease of reference, the former will in the remainder of this article be referred to as ""connected memberships while the latter are designated as ""isolated memberships"". Using this terminology, connected memberships are argued to expand individuals"" networks beyond one single association (Paxton, 2007; see also Cornwell & Harrison, 2004;Moody & White, 2003), thus allowing members to ""transfer trust gained within their association to individuals outside the association"" (Paxton, 2007, p. 51). Isolated memberships, however, ""are inherently bounded, and should therefore be less likely to transfer trust"" (Paxton, 2007, pp."	u
CCT421	"In the foregoing literature, two central arguments have been employed to connect individuals"" memberships in voluntary associations and their civic attitudes (Wollebaek & Selle, 2007). The first rests on a self-selection argument stating that people with sufficiently ""prosocial"" characteristics are more likely to engage in society and join voluntary associations compared to people lacking such characteristics. As a result, individuals in voluntary associations display higher levels of desirable social attitudes simply because they selected themselves into such associations due to their pro-social attitudes (e.g., van Deth et al., 1999). The second view rests on a socialization argument and states that membership in voluntary associations induces a process of appropriating norms, attitudes, values and roles (e.g., Putnam, 2000). In this case, membership is expected to lead individuals to develop ""new"" values through interactions with co-members. 2 Given the importance of formal and informal institutions for governing people""s behaviour (e.g., North, 1990;#CITATION_TAG, 1999) and earlier findings linking the institutional environment to the development of specific types of voluntary associations (e.g., Berman, 1997;K√§√§ri√§inen & Lehtonen, 2006;Schofer & Fourcade-Gourinchas, 2001), it is surprising that both lines of argument ignore the socio-political and institutional environment within which the individual and the association exist. This is especially injudicious since the nature and internal homogeneity of the voluntary organization that arises in specific contexts, as well as the societal relevance of that group and the issues it stands for, influence members"" integration process within the association. Indeed, these characterizing elements of the organizational identity are shown to be crucial determinants of individuals"" integration processes in the socialization literature (e.g., Checkel & Katzenstein, 2009), and play a key role to explain ""peer effects"" in research on group interaction in social psychology. 3 Consequently, as ""the definition of interests and objectives is created in institutional contexts and is not separable from them"" (Zysman, 1994, p. 244), any self-selection and socialization processes are unlikely to be unconditional, but rather will depend on, and be influenced by, the broader institutional environment. Hooghe (2003, p. 93) implies a similar idea when arguing that association membership is unlikely to ""introduce qualitatively new values, but enforces already existing values"" (see also Bardi & Goodwin, 2011;Katz & Lazersfeld, 1955)."	0	"As a result, individuals in voluntary associations display higher levels of desirable social attitudes simply because they selected themselves into such associations due to their pro-social attitudes (e.g., van Deth et al., 1999). The second view rests on a socialization argument and states that membership in voluntary associations induces a process of appropriating norms, attitudes, values and roles (e.g., Putnam, 2000). In this case, membership is expected to lead individuals to develop ""new"" values through interactions with co-members. 2 Given the importance of formal and informal institutions for governing people""s behaviour (e.g., North, 1990;#CITATION_TAG, 1999) and earlier findings linking the institutional environment to the development of specific types of voluntary associations (e.g., Berman, 1997;K√§√§ri√§inen & Lehtonen, 2006;Schofer & Fourcade-Gourinchas, 2001), it is surprising that both lines of argument ignore the socio-political and institutional environment within which the individual and the association exist. This is especially injudicious since the nature and internal homogeneity of the voluntary organization that arises in specific contexts, as well as the societal relevance of that group and the issues it stands for, influence members"" integration process within the association. Indeed, these characterizing elements of the organizational identity are shown to be crucial determinants of individuals"" integration processes in the socialization literature (e.g., Checkel & Katzenstein, 2009), and play a key role to explain ""peer effects"" in research on group interaction in social psychology. 3 Consequently, as ""the definition of interests and objectives is created in institutional contexts and is not separable from them"" (Zysman, 1994, p. 244), any self-selection and socialization processes are unlikely to be unconditional, but rather will depend on, and be influenced by, the broader institutional environment."	e
CCT422	"Whether change is incremental or substantive, the above discussion strongly suggests that the engagement-values relation will generally lack temporal stability. This argument obviously need not be constrained to civic engagement in general, but is likely to similarly hold for diverse types of civic engagement. In the empirical analysis below, this will be verified for the isolated/connected distinction discussed in Paxton (2007; see above). Nonetheless, the same might likewise hold for other distinctions recently proposed in the literature: e.g., the bridging/bonding distinction based on the socio-demographic diversity of an association""s memberships (see Coff√© & Geys, 2007;Putnam, 2000;Stolle & Rochon, 1998), the inclusive/exclusive distinction based on associations"" constitutive purposes (Geys & Griesshaber, 2012;Warren, 2001Warren, , 2004Zmerli, 2003), or the typology based on associations"" ""primary concerns"" (i.e., recreational, members"" interests, or broad social interests; see #CITATION_TAG, Te Grotenhuis, & Scheepers, 2009). Moreover, in principle, nothing constrains any temporal trends in the engagement-values relation to be similar across such subtypes of civic engagement. That is, the connection between, say, exclusive civic engagement and generalized trust may be weakening over time, while trust""s association to inclusive engagement may remain unchanged (or strengthen)."	5	"Whether change is incremental or substantive, the above discussion strongly suggests that the engagement-values relation will generally lack temporal stability. This argument obviously need not be constrained to civic engagement in general, but is likely to similarly hold for diverse types of civic engagement. In the empirical analysis below, this will be verified for the isolated/connected distinction discussed in Paxton (2007; see above). Nonetheless, the same might likewise hold for other distinctions recently proposed in the literature: e.g., the bridging/bonding distinction based on the socio-demographic diversity of an association""s memberships (see Coff√© & Geys, 2007;Putnam, 2000;Stolle & Rochon, 1998), the inclusive/exclusive distinction based on associations"" constitutive purposes (Geys & Griesshaber, 2012;Warren, 2001Warren, , 2004Zmerli, 2003), or the typology based on associations"" ""primary concerns"" (i.e., recreational, members"" interests, or broad social interests; see #CITATION_TAG, Te Grotenhuis, & Scheepers, 2009). Moreover, in principle, nothing constrains any temporal trends in the engagement-values relation to be similar across such subtypes of civic engagement. That is, the connection between, say, exclusive civic engagement and generalized trust may be weakening over time, while trust""s association to inclusive engagement may remain unchanged (or strengthen)."	e
CCT423	"In the foregoing literature, two central arguments have been employed to connect individuals"" memberships in voluntary associations and their civic attitudes (Wollebaek & Selle, 2007). The first rests on a self-selection argument stating that people with sufficiently ""prosocial"" characteristics are more likely to engage in society and join voluntary associations compared to people lacking such characteristics. As a result, individuals in voluntary associations display higher levels of desirable social attitudes simply because they selected themselves into such associations due to their pro-social attitudes (e.g., #CITATION_TAG et al., 1999). The second view rests on a socialization argument and states that membership in voluntary associations induces a process of appropriating norms, attitudes, values and roles (e.g., Putnam, 2000). In this case, membership is expected to lead individuals to develop ""new"" values through interactions with co-members. 2 Given the importance of formal and informal institutions for governing people""s behaviour (e.g., North, 1990;Thelen, 1999) and earlier findings linking the institutional environment to the development of specific types of voluntary associations (e.g., Berman, 1997;K√§√§ri√§inen & Lehtonen, 2006;Schofer & Fourcade-Gourinchas, 2001), it is surprising that both lines of argument ignore the socio-political and institutional environment within which the individual and the association exist. This is especially injudicious since the nature and internal homogeneity of the voluntary organization that arises in specific contexts, as well as the societal relevance of that group and the issues it stands for, influence members"" integration process within the association. Indeed, these characterizing elements of the organizational identity are shown to be crucial determinants of individuals"" integration processes in the socialization literature (e.g., Checkel & Katzenstein, 2009), and play a key role to explain ""peer effects"" in research on group interaction in social psychology. 3 Consequently, as ""the definition of interests and objectives is created in institutional contexts and is not separable from them"" (Zysman, 1994, p. 244), any self-selection and socialization processes are unlikely to be unconditional, but rather will depend on, and be influenced by, the broader institutional environment. Hooghe (2003, p. 93) implies a similar idea when arguing that association membership is unlikely to ""introduce qualitatively new values, but enforces already existing values"" (see also Bardi & Goodwin, 2011;Katz & Lazersfeld, 1955)."	0	"In the foregoing literature, two central arguments have been employed to connect individuals"" memberships in voluntary associations and their civic attitudes (Wollebaek & Selle, 2007). The first rests on a self-selection argument stating that people with sufficiently ""prosocial"" characteristics are more likely to engage in society and join voluntary associations compared to people lacking such characteristics. As a result, individuals in voluntary associations display higher levels of desirable social attitudes simply because they selected themselves into such associations due to their pro-social attitudes (e.g., #CITATION_TAG et al., 1999). The second view rests on a socialization argument and states that membership in voluntary associations induces a process of appropriating norms, attitudes, values and roles (e.g., Putnam, 2000). In this case, membership is expected to lead individuals to develop ""new"" values through interactions with co-members. 2 Given the importance of formal and informal institutions for governing people""s behaviour (e.g., North, 1990;Thelen, 1999) and earlier findings linking the institutional environment to the development of specific types of voluntary associations (e.g., Berman, 1997;K√§√§ri√§inen & Lehtonen, 2006;Schofer & Fourcade-Gourinchas, 2001), it is surprising that both lines of argument ignore the socio-political and institutional environment within which the individual and the association exist."	 
CCT424	"Why does this relative neglect of the socio-political and institutional environment matter? Why does this relative neglect of the socio-political and institutional environment matter? Based on the idea that institutions get ""locked in"" as a result of self-reinforcement, self-reproduction and path dependence (e.g., Collier & Collier, 1991;#CITATION_TAG, 2000;Pierson, 2000), institutions have long been viewed as stable and resistant to change until ""exogenous shocks (. . .) bring about radical institutional reconfigurations"" (Mahoney & Thelen, 2010, p. 2). In recent work, however, scholars have moved away from this emphasis on what could be termed ""interrupted stability"" (resembling the idea of punctuated equilibria in evolutionary biology) and explicitly recognize the existence of ""shifts that unfold incrementally"" (Mahoney & Thelen, 2010, p. 2). Although such endogenous incremental changes can take different forms (see Boas, 2007;Mahoney & Thelen, 2010;Streeck & Thelen, 2005), they all have in common that ""the effect of the institution is transformed"" in a gradual process (Boas, 2007, p. 34, italics in original). This changing environment, in turn, generates an adjustment process in terms of individuals"" membership decisions, the core values of voluntary associations and any intraassociation socialization processes (see above). Although during this transformation process individual A may (but need not) still be in association B, changes in the institutional environment induce changes in individual A as well as association B. As a direct consequence, the societal implications of association memberships will likewise exhibit a gradual transformation over time."	0	"Why does this relative neglect of the socio-political and institutional environment matter? Why does this relative neglect of the socio-political and institutional environment matter? Based on the idea that institutions get ""locked in"" as a result of self-reinforcement, self-reproduction and path dependence (e.g., Collier & Collier, 1991;#CITATION_TAG, 2000;Pierson, 2000), institutions have long been viewed as stable and resistant to change until ""exogenous shocks (. . .) bring about radical institutional reconfigurations"" (Mahoney & Thelen, 2010, p. 2). In recent work, however, scholars have moved away from this emphasis on what could be termed ""interrupted stability"" (resembling the idea of punctuated equilibria in evolutionary biology) and explicitly recognize the existence of ""shifts that unfold incrementally"" (Mahoney & Thelen, 2010, p. 2). Although such endogenous incremental changes can take different forms (see Boas, 2007;Mahoney & Thelen, 2010;Streeck & Thelen, 2005), they all have in common that ""the effect of the institution is transformed"" in a gradual process (Boas, 2007, p. 34, italics in original)."	s
CCT425	"Over the past decade, a lively debate has developed regarding the decline in civic participation observed by some, but not by others, across a number of Western democracies (Dekker & van den Broek, 2005;#CITATION_TAG & Gr√∏nflaten, 2007;Paxton, 1999;Putnam, 2000;Stolle & Hooghe, 2003). The importance of this debate lies not only in establishing whether Western societies have become more individualistic over time and its citizens increasingly ""hunker down"" (to borrow the colloquialism introduced in this respect by Putnam, 2007), but also reflects the central role often attributed to civic engagement for the development and maintenance of democratic values, generalized trust, cooperative norms, racial and religious tolerance, and so on (e.g., Delhey & Newton, 2005;Li, Pickles, & Savage, 2005;Putnam, 2000;Terriquez, 2011). When civic engagement is intimately associated with a wide range of social values, its decline can be feared to provoke a concomitant decline throughout society in inter-personal trust, tolerance, cooperation and so on (Putnam, 2000). Conversely, however, a close engagement-values relation also holds significant promise, especially to politicians, as it would imply that policies to stimulate civic engagement can become reflected in a parallel change in social and democratic values. Exactly for this reason, political leaders in, for instance, the United States, United Kingdom, Germany and the European Union have in recent years shown a strong interest in stimulating civic engagement as a means to (help) address societal changes induced by, for instance, large-scale migration and globalization. To give only one example from the United Kingdom, the Conservative Party""s election manifesto for the May 2010 general election stated that the restoration of the United Kingdom""s social fabric and citizen involvement was a top priority. After the election, David Cameron again stressed this point in his first speech as Prime Minister."	0	"Over the past decade, a lively debate has developed regarding the decline in civic participation observed by some, but not by others, across a number of Western democracies (Dekker & van den Broek, 2005;#CITATION_TAG & Gr√∏nflaten, 2007;Paxton, 1999;Putnam, 2000;Stolle & Hooghe, 2003). The importance of this debate lies not only in establishing whether Western societies have become more individualistic over time and its citizens increasingly ""hunker down"" (to borrow the colloquialism introduced in this respect by Putnam, 2007), but also reflects the central role often attributed to civic engagement for the development and maintenance of democratic values, generalized trust, cooperative norms, racial and religious tolerance, and so on (e.g., Delhey & Newton, 2005;Li, Pickles, & Savage, 2005;Putnam, 2000;Terriquez, 2011). When civic engagement is intimately associated with a wide range of social values, its decline can be feared to provoke a concomitant decline throughout society in inter-personal trust, tolerance, cooperation and so on (Putnam, 2000). Conversely, however, a close engagement-values relation also holds significant promise, especially to politicians, as it would imply that policies to stimulate civic engagement can become reflected in a parallel change in social and democratic values."	O
CCT426	"The empirical analysis thereby builds on recent work by Paxton (2007) to allow easy reference to existing findings. Building on social identity theory (e.g., Tajfel, 1978) and social network analysis (e.g., Coleman, 1990), Paxton (2007, p. 51, italics in original) argues that the generalization of trust beyond a given voluntary association ""is critically dependent on whether an individual belongs to an association that is connected to other associations or one that is isolated"". For ease of reference, the former will in the remainder of this article be referred to as ""connected memberships while the latter are designated as ""isolated memberships"". Using this terminology, connected memberships are argued to expand individuals"" networks beyond one single association (Paxton, 2007; see also #CITATION_TAG & Harrison, 2004;Moody & White, 2003), thus allowing members to ""transfer trust gained within their association to individuals outside the association"" (Paxton, 2007, p. 51). Isolated memberships, however, ""are inherently bounded, and should therefore be less likely to transfer trust"" (Paxton, 2007, pp. 53-54). Empirical evidence using data from the 1990 wave of the World Values Survey (WVS) supports this theoretical argument."	5	"The empirical analysis thereby builds on recent work by Paxton (2007) to allow easy reference to existing findings. Building on social identity theory (e.g., Tajfel, 1978) and social network analysis (e.g., Coleman, 1990), Paxton (2007, p. 51, italics in original) argues that the generalization of trust beyond a given voluntary association ""is critically dependent on whether an individual belongs to an association that is connected to other associations or one that is isolated"". For ease of reference, the former will in the remainder of this article be referred to as ""connected memberships while the latter are designated as ""isolated memberships"". Using this terminology, connected memberships are argued to expand individuals"" networks beyond one single association (Paxton, 2007; see also #CITATION_TAG & Harrison, 2004;Moody & White, 2003), thus allowing members to ""transfer trust gained within their association to individuals outside the association"" (Paxton, 2007, p. 51). Isolated memberships, however, ""are inherently bounded, and should therefore be less likely to transfer trust"" (Paxton, 2007, pp. 53-54). Empirical evidence using data from the 1990 wave of the World Values Survey (WVS) supports this theoretical argument."	n
CCT427	"Finally, we should point out that the connectedness measure employed in this article only regards connections between groups, and ignores those within associations (a differentiation of association types based exclusively on the socio-demographic composition of association membership is presented in Stolle & Rochon, 1998;Coff√© & Geys, 2007). When the relative importance of both these characteristics of voluntary associations for trust changes over time, reduced importance of one dimension may show up in an analysis focusing on this dimension, while the strengthening of the other is not picked up. Circumstantial, though suggestive, evidence of such an effect was recently presented in #CITATION_TAG and Murdoch (2010). They not only propose a simple procedure to integrate both approaches (i.e., connectedness/isolatedness and socio-demographic make-up of associations), but, crucially, illustrate that this combined measure generates more consistent empirical results using two distinct datasets from Flanders and the UK. Although the limited country-level sample sizes in WVS unfortunately do not allow evaluating to what extent a similar effect plays here, exploiting the often larger sample-size in country-specific surveys (such as the German and Swiss Freiwilligensurveys (volunteering surveys) or the US Social Capital Community Survey) may help remedy this in future work. Notes 1. While several scholars have admittedly employed time-series cross-section data, such studies have failed to exploit the time dimension present in their data. Rather, one coefficient estimate is provided for the entire sample, implicitly assuming that this reflects the (stable) engagement-values connection across both space and time. 2. Some scholars have argued that both effects are simultaneously at work -leading to a process where, say, some level of social trust is required to join, and joining subsequently reinfo rces trust (e.g., Brehm & Rahn, 1997). 3. Castells (1997 similarly argues that whoever constructs a collective identity determines the symbolic meaning of this identity for those identifying with it, and those placing themselves outside of it. As such, the formation of a collective (or group) identity directly shapes the identification processes relative to this group. 4. For instance, in the aftermath of the 9.0 earthquake and ensuing tsunami and nuclear crisis in Japan, the demand for weddings increased as people were ""jolted into adjusting priorities in l ife"" (Jiang, 2011). Similarly, the 9/11 attack on the New York World Trade Centre, and the subsequent 2004 Madrid and 2005 London bombings had a significant impact on ""the thoughts, feelings and behaviors of ind ividuals"" (Woods, 2011, p. 214; see also Best, Krueger, & Ladewig, 2006;Col√°s, 2010;Huddy, Khatib, & Capelos, 2002;Li & Brewer, 2004;Panagopoulos, 2006;Verkasalo, Goodwin, & Bezmenova, 2006;Yum & Schenck-Hamlin, 2005). 5. These countries are Austria, Belgium, Bulgaria, Canada, Chile, China, Czech Republic, Denmark, East-Germany, Estonia, Finland, France, Hungary, Iceland, Ireland, Italy, Japan, Latvia, Lithuania, Mexico, Netherlands, Romania, Russia, Slovenia, Spain, Sweden, UK, US and West-Germany. 6. Clearly, this is less than ideal, given that people may take time off from study and return to it later on. We experimented with trunc ating the education variable at age 21 (in line with Paxton, 2007), but this made no difference to our findings. Hence, we decided to report only the results with the untruncated education variable. Unfortunately, more direct measures such as an individual""s highest degree are unavailable in the WVS. 7. Note that we implicitly conflate the number of respondents in WVS claiming membership in a given type of association with the actual size of a real association of this type (i.e., the ideal data for the present analysis; see also Coff√© & Geys, 2007, 2008. While this is clearly incorrect, the assumptions necessary for nonetheless applying this correction to our data are that a) observed membership sizes of association types in WVS tell us something about the relative sizes of real associations of different types and b) multiple memberships observed in WVS approximate the extent of connections between real groups of different association types. Both these critical assumptions are evidently also required to employ the original measure proposed in Paxton (2002Paxton ( , 2007."	5	Finally, we should point out that the connectedness measure employed in this article only regards connections between groups, and ignores those within associations (a differentiation of association types based exclusively on the socio-demographic composition of association membership is presented in Stolle & Rochon, 1998;Coff√© & Geys, 2007). When the relative importance of both these characteristics of voluntary associations for trust changes over time, reduced importance of one dimension may show up in an analysis focusing on this dimension, while the strengthening of the other is not picked up. Circumstantial, though suggestive, evidence of such an effect was recently presented in #CITATION_TAG and Murdoch (2010). They not only propose a simple procedure to integrate both approaches (i.e., connectedness/isolatedness and socio-demographic make-up of associations), but, crucially, illustrate that this combined measure generates more consistent empirical results using two distinct datasets from Flanders and the UK. Although the limited country-level sample sizes in WVS unfortunately do not allow evaluating to what extent a similar effect plays here, exploiting the often larger sample-size in country-specific surveys (such as the German and Swiss Freiwilligensurveys (volunteering surveys) or the US Social Capital Community Survey) may help remedy this in future work. Notes 1.	r
CCT428	"The empirical analysis thereby builds on recent work by Paxton (2007) to allow easy reference to existing findings. Building on social identity theory (e.g., Tajfel, 1978) and social network analysis (e.g., #CITATION_TAG, 1990), Paxton (2007, p. 51, italics in original) argues that the generalization of trust beyond a given voluntary association ""is critically dependent on whether an individual belongs to an association that is connected to other associations or one that is isolated"". For ease of reference, the former will in the remainder of this article be referred to as ""connected memberships while the latter are designated as ""isolated memberships"". Using this terminology, connected memberships are argued to expand individuals"" networks beyond one single association (Paxton, 2007; see also Cornwell & Harrison, 2004;Moody & White, 2003), thus allowing members to ""transfer trust gained within their association to individuals outside the association"" (Paxton, 2007, p. 51). Isolated memberships, however, ""are inherently bounded, and should therefore be less likely to transfer trust"" (Paxton, 2007, pp. 53-54). Empirical evidence using data from the 1990 wave of the World Values Survey (WVS) supports this theoretical argument."	5	"The empirical analysis thereby builds on recent work by Paxton (2007) to allow easy reference to existing findings. Building on social identity theory (e.g., Tajfel, 1978) and social network analysis (e.g., #CITATION_TAG, 1990), Paxton (2007, p. 51, italics in original) argues that the generalization of trust beyond a given voluntary association ""is critically dependent on whether an individual belongs to an association that is connected to other associations or one that is isolated"". For ease of reference, the former will in the remainder of this article be referred to as ""connected memberships while the latter are designated as ""isolated memberships"". Using this terminology, connected memberships are argued to expand individuals"" networks beyond one single association (Paxton, 2007; see also Cornwell & Harrison, 2004;Moody & White, 2003), thus allowing members to ""transfer trust gained within their association to individuals outside the association"" (Paxton, 2007, p. 51). Isolated memberships, however, ""are inherently bounded, and should therefore be less likely to transfer trust"" (Paxton, 2007, pp."	u
CCT429	"Why does this relative neglect of the socio-political and institutional environment matter? Based on the idea that institutions get ""locked in"" as a result of self-reinforcement, self-reproduction and path dependence (e.g., #CITATION_TAG, 1991;Mahoney, 2000;Pierson, 2000), institutions have long been viewed as stable and resistant to change until ""exogenous shocks (. . .) bring about radical institutional reconfigurations"" (Mahoney & Thelen, 2010, p. 2). In recent work, however, scholars have moved away from this emphasis on what could be termed ""interrupted stability"" (resembling the idea of punctuated equilibria in evolutionary biology) and explicitly recognize the existence of ""shifts that unfold incrementally"" (Mahoney & Thelen, 2010, p. 2). Although such endogenous incremental changes can take different forms (see Boas, 2007;Mahoney & Thelen, 2010;Streeck & Thelen, 2005), they all have in common that ""the effect of the institution is transformed"" in a gradual process (Boas, 2007, p. 34, italics in original). This changing environment, in turn, generates an adjustment process in terms of individuals"" membership decisions, the core values of voluntary associations and any intraassociation socialization processes (see above). Although during this transformation process individual A may (but need not) still be in association B, changes in the institutional environment induce changes in individual A as well as association B. As a direct consequence, the societal implications of association memberships will likewise exhibit a gradual transformation over time."	0	"Why does this relative neglect of the socio-political and institutional environment matter? Based on the idea that institutions get ""locked in"" as a result of self-reinforcement, self-reproduction and path dependence (e.g., #CITATION_TAG, 1991;Mahoney, 2000;Pierson, 2000), institutions have long been viewed as stable and resistant to change until ""exogenous shocks (. . .) bring about radical institutional reconfigurations"" (Mahoney & Thelen, 2010, p. 2). In recent work, however, scholars have moved away from this emphasis on what could be termed ""interrupted stability"" (resembling the idea of punctuated equilibria in evolutionary biology) and explicitly recognize the existence of ""shifts that unfold incrementally"" (Mahoney & Thelen, 2010, p. 2). Although such endogenous incremental changes can take different forms (see Boas, 2007;Mahoney & Thelen, 2010;Streeck & Thelen, 2005), they all have in common that ""the effect of the institution is transformed"" in a gradual process (Boas, 2007, p. 34, italics in original)."	a
CCT430	"Why does this relative neglect of the socio-political and institutional environment matter? Based on the idea that institutions get ""locked in"" as a result of self-reinforcement, self-reproduction and path dependence (e.g., Collier & Collier, 1991;Mahoney, 2000;Pierson, 2000), institutions have long been viewed as stable and resistant to change until ""exogenous shocks (. . .) bring about radical institutional reconfigurations"" (Mahoney & Thelen, 2010, p. 2). In recent work, however, scholars have moved away from this emphasis on what could be termed ""interrupted stability"" (resembling the idea of punctuated equilibria in evolutionary biology) and explicitly recognize the existence of ""shifts that unfold incrementally"" (Mahoney & Thelen, 2010, p. 2). Although such endogenous incremental changes can take different forms (see #CITATION_TAG, 2007;Mahoney & Thelen, 2010;Streeck & Thelen, 2005), they all have in common that ""the effect of the institution is transformed"" in a gradual process (#CITATION_TAG, 2007, p. 34, italics in original). This changing environment, in turn, generates an adjustment process in terms of individuals"" membership decisions, the core values of voluntary associations and any intraassociation socialization processes (see above). Although during this transformation process individual A may (but need not) still be in association B, changes in the institutional environment induce changes in individual A as well as association B. As a direct consequence, the societal implications of association memberships will likewise exhibit a gradual transformation over time."	0	"Based on the idea that institutions get ""locked in"" as a result of self-reinforcement, self-reproduction and path dependence (e.g., Collier & Collier, 1991;Mahoney, 2000;Pierson, 2000), institutions have long been viewed as stable and resistant to change until ""exogenous shocks (. . .) bring about radical institutional reconfigurations"" (Mahoney & Thelen, 2010, p. 2). In recent work, however, scholars have moved away from this emphasis on what could be termed ""interrupted stability"" (resembling the idea of punctuated equilibria in evolutionary biology) and explicitly recognize the existence of ""shifts that unfold incrementally"" (Mahoney & Thelen, 2010, p. 2). Although such endogenous incremental changes can take different forms (see #CITATION_TAG, 2007;Mahoney & Thelen, 2010;Streeck & Thelen, 2005), they all have in common that ""the effect of the institution is transformed"" in a gradual process (#CITATION_TAG, 2007, p. 34, italics in original). This changing environment, in turn, generates an adjustment process in terms of individuals"" membership decisions, the core values of voluntary associations and any intraassociation socialization processes (see above). Although during this transformation process individual A may (but need not) still be in association B, changes in the institutional environment induce changes in individual A as well as association B. As a direct consequence, the societal implications of association memberships will likewise exhibit a gradual transformation over time."	o
CCT431	"Over the past decade, a lively debate has developed regarding the decline in civic participation observed by some, but not by others, across a number of Western democracies (#CITATION_TAG & van den Broek, 2005;Listhaug & Gr√∏nflaten, 2007;Paxton, 1999;Putnam, 2000;Stolle & Hooghe, 2003). The importance of this debate lies not only in establishing whether Western societies have become more individualistic over time and its citizens increasingly ""hunker down"" (to borrow the colloquialism introduced in this respect by Putnam, 2007), but also reflects the central role often attributed to civic engagement for the development and maintenance of democratic values, generalized trust, cooperative norms, racial and religious tolerance, and so on (e.g., Delhey & Newton, 2005;Li, Pickles, & Savage, 2005;Putnam, 2000;Terriquez, 2011). When civic engagement is intimately associated with a wide range of social values, its decline can be feared to provoke a concomitant decline throughout society in inter-personal trust, tolerance, cooperation and so on (Putnam, 2000). Conversely, however, a close engagement-values relation also holds significant promise, especially to politicians, as it would imply that policies to stimulate civic engagement can become reflected in a parallel change in social and democratic values. Exactly for this reason, political leaders in, for instance, the United States, United Kingdom, Germany and the European Union have in recent years shown a strong interest in stimulating civic engagement as a means to (help) address societal changes induced by, for instance, large-scale migration and globalization. To give only one example from the United Kingdom, the Conservative Party""s election manifesto for the May 2010 general election stated that the restoration of the United Kingdom""s social fabric and citizen involvement was a top priority. After the election, David Cameron again stressed this point in his first speech as Prime Minister."	0	"Over the past decade, a lively debate has developed regarding the decline in civic participation observed by some, but not by others, across a number of Western democracies (#CITATION_TAG & van den Broek, 2005;Listhaug & Gr√∏nflaten, 2007;Paxton, 1999;Putnam, 2000;Stolle & Hooghe, 2003). The importance of this debate lies not only in establishing whether Western societies have become more individualistic over time and its citizens increasingly ""hunker down"" (to borrow the colloquialism introduced in this respect by Putnam, 2007), but also reflects the central role often attributed to civic engagement for the development and maintenance of democratic values, generalized trust, cooperative norms, racial and religious tolerance, and so on (e.g., Delhey & Newton, 2005;Li, Pickles, & Savage, 2005;Putnam, 2000;Terriquez, 2011). When civic engagement is intimately associated with a wide range of social values, its decline can be feared to provoke a concomitant decline throughout society in inter-personal trust, tolerance, cooperation and so on (Putnam, 2000). Conversely, however, a close engagement-values relation also holds significant promise, especially to politicians, as it would imply that policies to stimulate civic engagement can become reflected in a parallel change in social and democratic values."	O
CCT432	"For civic engagement to act as a ""school for democracy citizen""s engagement should be coupled with a positive engagement-values relation. Both elements are mutually conditional in the sense that they are jointly necessary to obtain the desired outcome (#CITATION_TAG, Newton, & Welzel, 2011;Goertz, 2006). Whereas significant research has previously studied the presence/absence of inter-temporal shifts in civic engagement across Western democracies (Paxton, 1999;Putnam, 2000;Stolle & Hooghe, 2003), similar debates regarding the existence and/or drivers of inter-temporal shifts in the engagement-values relation have been much slower to emerge. This article took a first step to bridge this gap. Specifically, we argued that changes in the broader institutional environment within which such engagement takes place can induce alterations in the engagementvalues relation. In support of this theoretical proposition, empirical evidence from the 1990 and 2000 waves of the WVS illustrates the temporal instability of the engagement-values relation. Particularly, the empirical support for the idea that memberships in connected associations are better than in isolated associations has become weaker in more recent years. While voluntary association memberships are positively associated with generalized trust in both the 1990 and 2000 wave of WVS, memberships in connected voluntary associations no longer seem equally beneficial for generalized trust than memberships in isolated associations in 2000 than they were in 1990."	0	"For civic engagement to act as a ""school for democracy citizen""s engagement should be coupled with a positive engagement-values relation. Both elements are mutually conditional in the sense that they are jointly necessary to obtain the desired outcome (#CITATION_TAG, Newton, & Welzel, 2011;Goertz, 2006). Whereas significant research has previously studied the presence/absence of inter-temporal shifts in civic engagement across Western democracies (Paxton, 1999;Putnam, 2000;Stolle & Hooghe, 2003), similar debates regarding the existence and/or drivers of inter-temporal shifts in the engagement-values relation have been much slower to emerge. This article took a first step to bridge this gap. Specifically, we argued that changes in the broader institutional environment within which such engagement takes place can induce alterations in the engagementvalues relation."	o
CCT433	"To account for potential country-level determinants of generalized trust, we allow the intercept b 0j above to vary across countries depending on a number of institutional, socio-demographic and cultural characteristics. First, democratic rule has been argued to enhance the protection of minority rights, which, in turn, may stimulate trust among people with diverse backgrounds (e.g., Tilly, 2004). As such, a country""s democratic nature (DEMO; i.e. Polity IV democracy score) is included to evaluate the idea that democracies are likely to enhance trust (see also Levi, 1988). Second, the relation between ethnic and religious diversity, on the one hand, and social capital, civic engagement and trust, on the other hand, has attracted significant scholarly discussion in recent years (e.g., Alesina & La Ferrara, 2000, 2002Coff√© & Geys, 2006;Delhey & Newton, 2005; #CITATION_TAG, van der Meer, & Dagevos, forthcoming; Hallberg & Lund, 2005;Putnam, 2007). We therefore control for ethnic-cultural diversity""s potential role as an impediment to trust by including a measure of ethnic and religious fractionalization (ETHNIC and RELIG; Herfindahl indices taken from Alesina et al., 2003). Third, if individuals with more limited resources find it harder and/or riskier to trust others (see above), the same might likewise hold at a more aggregated level. Hence, countries with lower levels of economic development might be characterized by lower levels of trust (Paxton, 2007). To control for this, we include the logarithm of a country""s energy consumption (INDUSTR; taken from World Development Indicators). Finally, we introduce an indicator variable equal to 1 for countries in Eastern Europe (EASTEUR) to accommodate their cultural and historical particularity. This generates the following specification at the country-level:"	0	"To account for potential country-level determinants of generalized trust, we allow the intercept b 0j above to vary across countries depending on a number of institutional, socio-demographic and cultural characteristics. First, democratic rule has been argued to enhance the protection of minority rights, which, in turn, may stimulate trust among people with diverse backgrounds (e.g., Tilly, 2004). As such, a country""s democratic nature (DEMO; i.e. Polity IV democracy score) is included to evaluate the idea that democracies are likely to enhance trust (see also Levi, 1988). Second, the relation between ethnic and religious diversity, on the one hand, and social capital, civic engagement and trust, on the other hand, has attracted significant scholarly discussion in recent years (e.g., Alesina & La Ferrara, 2000, 2002Coff√© & Geys, 2006;Delhey & Newton, 2005; #CITATION_TAG, van der Meer, & Dagevos, forthcoming; Hallberg & Lund, 2005;Putnam, 2007). We therefore control for ethnic-cultural diversity""s potential role as an impediment to trust by including a measure of ethnic and religious fractionalization (ETHNIC and RELIG; Herfindahl indices taken from Alesina et al., 2003). Third, if individuals with more limited resources find it harder and/or riskier to trust others (see above), the same might likewise hold at a more aggregated level. Hence, countries with lower levels of economic development might be characterized by lower levels of trust (Paxton, 2007)."	o
CCT434	"To account for potential country-level determinants of generalized trust, we allow the intercept b 0j above to vary across countries depending on a number of institutional, socio-demographic and cultural characteristics. First, democratic rule has been argued to enhance the protection of minority rights, which, in turn, may stimulate trust among people with diverse backgrounds (e.g., Tilly, 2004). As such, a country""s democratic nature (DEMO; i.e. Polity IV democracy score) is included to evaluate the idea that democracies are likely to enhance trust (see also Levi, 1988). Second, the relation between ethnic and religious diversity, on the one hand, and social capital, civic engagement and trust, on the other hand, has attracted significant scholarly discussion in recent years (e.g., Alesina & La Ferrara, 2000, 2002Coff√© & Geys, 2006;Delhey & Newton, 2005; Gijsberts, van der Meer, & Dagevos, forthcoming; #CITATION_TAG & Lund, 2005;Putnam, 2007). We therefore control for ethnic-cultural diversity""s potential role as an impediment to trust by including a measure of ethnic and religious fractionalization (ETHNIC and RELIG; Herfindahl indices taken from Alesina et al., 2003). Third, if individuals with more limited resources find it harder and/or riskier to trust others (see above), the same might likewise hold at a more aggregated level. Hence, countries with lower levels of economic development might be characterized by lower levels of trust (Paxton, 2007). To control for this, we include the logarithm of a country""s energy consumption (INDUSTR; taken from World Development Indicators). Finally, we introduce an indicator variable equal to 1 for countries in Eastern Europe (EASTEUR) to accommodate their cultural and historical particularity. This generates the following specification at the country-level:"	0	"To account for potential country-level determinants of generalized trust, we allow the intercept b 0j above to vary across countries depending on a number of institutional, socio-demographic and cultural characteristics. First, democratic rule has been argued to enhance the protection of minority rights, which, in turn, may stimulate trust among people with diverse backgrounds (e.g., Tilly, 2004). As such, a country""s democratic nature (DEMO; i.e. Polity IV democracy score) is included to evaluate the idea that democracies are likely to enhance trust (see also Levi, 1988). Second, the relation between ethnic and religious diversity, on the one hand, and social capital, civic engagement and trust, on the other hand, has attracted significant scholarly discussion in recent years (e.g., Alesina & La Ferrara, 2000, 2002Coff√© & Geys, 2006;Delhey & Newton, 2005; Gijsberts, van der Meer, & Dagevos, forthcoming; #CITATION_TAG & Lund, 2005;Putnam, 2007). We therefore control for ethnic-cultural diversity""s potential role as an impediment to trust by including a measure of ethnic and religious fractionalization (ETHNIC and RELIG; Herfindahl indices taken from Alesina et al., 2003). Third, if individuals with more limited resources find it harder and/or riskier to trust others (see above), the same might likewise hold at a more aggregated level. Hence, countries with lower levels of economic development might be characterized by lower levels of trust (Paxton, 2007)."	o
CCT435	"Finally, we should point out that the connectedness measure employed in this article only regards connections between groups, and ignores those within associations (a differentiation of association types based exclusively on the socio-demographic composition of association membership is presented in Stolle & Rochon, 1998;Coff√© & Geys, 2007). When the relative importance of both these characteristics of voluntary associations for trust changes over time, reduced importance of one dimension may show up in an analysis focusing on this dimension, while the strengthening of the other is not picked up. Circumstantial, though suggestive, evidence of such an effect was recently presented in Geys and Murdoch (2010). They not only propose a simple procedure to integrate both approaches (i.e., connectedness/isolatedness and socio-demographic make-up of associations), but, crucially, illustrate that this combined measure generates more consistent empirical results using two distinct datasets from Flanders and the UK. Although the limited country-level sample sizes in WVS unfortunately do not allow evaluating to what extent a similar effect plays here, exploiting the often larger sample-size in country-specific surveys (such as the German and Swiss Freiwilligensurveys (volunteering surveys) or the US Social Capital Community Survey) may help remedy this in future work. Notes 1. While several scholars have admittedly employed time-series cross-section data, such studies have failed to exploit the time dimension present in their data. Rather, one coefficient estimate is provided for the entire sample, implicitly assuming that this reflects the (stable) engagement-values connection across both space and time. 2. Some scholars have argued that both effects are simultaneously at work -leading to a process where, say, some level of social trust is required to join, and joining subsequently reinfo rces trust (e.g., Brehm & Rahn, 1997). 3. Castells (1997 similarly argues that whoever constructs a collective identity determines the symbolic meaning of this identity for those identifying with it, and those placing themselves outside of it. As such, the formation of a collective (or group) identity directly shapes the identification processes relative to this group. 4. For instance, in the aftermath of the 9.0 earthquake and ensuing tsunami and nuclear crisis in Japan, the demand for weddings increased as people were ""jolted into adjusting priorities in l ife"" (#CITATION_TAG, 2011). Similarly, the 9/11 attack on the New York World Trade Centre, and the subsequent 2004 Madrid and 2005 London bombings had a significant impact on ""the thoughts, feelings and behaviors of ind ividuals"" (Woods, 2011, p. 214; see also Best, Krueger, & Ladewig, 2006;Col√°s, 2010;Huddy, Khatib, & Capelos, 2002;Li & Brewer, 2004;Panagopoulos, 2006;Verkasalo, Goodwin, & Bezmenova, 2006;Yum & Schenck-Hamlin, 2005). 5. These countries are Austria, Belgium, Bulgaria, Canada, Chile, China, Czech Republic, Denmark, East-Germany, Estonia, Finland, France, Hungary, Iceland, Ireland, Italy, Japan, Latvia, Lithuania, Mexico, Netherlands, Romania, Russia, Slovenia, Spain, Sweden, UK, US and West-Germany. 6. Clearly, this is less than ideal, given that people may take time off from study and return to it later on. We experimented with trunc ating the education variable at age 21 (in line with Paxton, 2007), but this made no difference to our findings. Hence, we decided to report only the results with the untruncated education variable. Unfortunately, more direct measures such as an individual""s highest degree are unavailable in the WVS. 7. Note that we implicitly conflate the number of respondents in WVS claiming membership in a given type of association with the actual size of a real association of this type (i.e., the ideal data for the present analysis; see also Coff√© & Geys, 2007, 2008. While this is clearly incorrect, the assumptions necessary for nonetheless applying this correction to our data are that a) observed membership sizes of association types in WVS tell us something about the relative sizes of real associations of different types and b) multiple memberships observed in WVS approximate the extent of connections between real groups of different association types. Both these critical assumptions are evidently also required to employ the original measure proposed in Paxton (2002Paxton ( , 2007."	0	"Castells (1997 similarly argues that whoever constructs a collective identity determines the symbolic meaning of this identity for those identifying with it, and those placing themselves outside of it. As such, the formation of a collective (or group) identity directly shapes the identification processes relative to this group. 4. For instance, in the aftermath of the 9.0 earthquake and ensuing tsunami and nuclear crisis in Japan, the demand for weddings increased as people were ""jolted into adjusting priorities in l ife"" (#CITATION_TAG, 2011). Similarly, the 9/11 attack on the New York World Trade Centre, and the subsequent 2004 Madrid and 2005 London bombings had a significant impact on ""the thoughts, feelings and behaviors of ind ividuals"" (Woods, 2011, p. 214; see also Best, Krueger, & Ladewig, 2006;Col√°s, 2010;Huddy, Khatib, & Capelos, 2002;Li & Brewer, 2004;Panagopoulos, 2006;Verkasalo, Goodwin, & Bezmenova, 2006;Yum & Schenck-Hamlin, 2005). 5. These countries are Austria, Belgium, Bulgaria, Canada, Chile, China, Czech Republic, Denmark, East-Germany, Estonia, Finland, France, Hungary, Iceland, Ireland, Italy, Japan, Latvia, Lithuania, Mexico, Netherlands, Romania, Russia, Slovenia, Spain, Sweden, UK, US and West-Germany."	i
CCT436	"In the foregoing literature, two central arguments have been employed to connect individuals"" memberships in voluntary associations and their civic attitudes (Wollebaek & Selle, 2007). The first rests on a self-selection argument stating that people with sufficiently ""prosocial"" characteristics are more likely to engage in society and join voluntary associations compared to people lacking such characteristics. As a result, individuals in voluntary associations display higher levels of desirable social attitudes simply because they selected themselves into such associations due to their pro-social attitudes (e.g., van Deth et al., 1999). The second view rests on a socialization argument and states that membership in voluntary associations induces a process of appropriating norms, attitudes, values and roles (e.g., Putnam, 2000). In this case, membership is expected to lead individuals to develop ""new"" values through interactions with co-members. 2 Given the importance of formal and informal institutions for governing people""s behaviour (e.g., North, 1990;Thelen, 1999) and earlier findings linking the institutional environment to the development of specific types of voluntary associations (e.g., #CITATION_TAG, 1997;K√§√§ri√§inen & Lehtonen, 2006;Schofer & Fourcade-Gourinchas, 2001), it is surprising that both lines of argument ignore the socio-political and institutional environment within which the individual and the association exist. This is especially injudicious since the nature and internal homogeneity of the voluntary organization that arises in specific contexts, as well as the societal relevance of that group and the issues it stands for, influence members"" integration process within the association. Indeed, these characterizing elements of the organizational identity are shown to be crucial determinants of individuals"" integration processes in the socialization literature (e.g., Checkel & Katzenstein, 2009), and play a key role to explain ""peer effects"" in research on group interaction in social psychology. 3 Consequently, as ""the definition of interests and objectives is created in institutional contexts and is not separable from them"" (Zysman, 1994, p. 244), any self-selection and socialization processes are unlikely to be unconditional, but rather will depend on, and be influenced by, the broader institutional environment. Hooghe (2003, p. 93) implies a similar idea when arguing that association membership is unlikely to ""introduce qualitatively new values, but enforces already existing values"" (see also Bardi & Goodwin, 2011;Katz & Lazersfeld, 1955)."	0	"As a result, individuals in voluntary associations display higher levels of desirable social attitudes simply because they selected themselves into such associations due to their pro-social attitudes (e.g., van Deth et al., 1999). The second view rests on a socialization argument and states that membership in voluntary associations induces a process of appropriating norms, attitudes, values and roles (e.g., Putnam, 2000). In this case, membership is expected to lead individuals to develop ""new"" values through interactions with co-members. 2 Given the importance of formal and informal institutions for governing people""s behaviour (e.g., North, 1990;Thelen, 1999) and earlier findings linking the institutional environment to the development of specific types of voluntary associations (e.g., #CITATION_TAG, 1997;K√§√§ri√§inen & Lehtonen, 2006;Schofer & Fourcade-Gourinchas, 2001), it is surprising that both lines of argument ignore the socio-political and institutional environment within which the individual and the association exist. This is especially injudicious since the nature and internal homogeneity of the voluntary organization that arises in specific contexts, as well as the societal relevance of that group and the issues it stands for, influence members"" integration process within the association. Indeed, these characterizing elements of the organizational identity are shown to be crucial determinants of individuals"" integration processes in the socialization literature (e.g., Checkel & Katzenstein, 2009), and play a key role to explain ""peer effects"" in research on group interaction in social psychology. 3 Consequently, as ""the definition of interests and objectives is created in institutional contexts and is not separable from them"" (Zysman, 1994, p. 244), any self-selection and socialization processes are unlikely to be unconditional, but rather will depend on, and be influenced by, the broader institutional environment."	e
CCT437	"In the foregoing literature, two central arguments have been employed to connect individuals"" memberships in voluntary associations and their civic attitudes (Wollebaek & Selle, 2007). The first rests on a self-selection argument stating that people with sufficiently ""prosocial"" characteristics are more likely to engage in society and join voluntary associations compared to people lacking such characteristics. As a result, individuals in voluntary associations display higher levels of desirable social attitudes simply because they selected themselves into such associations due to their pro-social attitudes (e.g., van Deth et al., 1999). The second view rests on a socialization argument and states that membership in voluntary associations induces a process of appropriating norms, attitudes, values and roles (e.g., Putnam, 2000). In this case, membership is expected to lead individuals to develop ""new"" values through interactions with co-members. 2 Given the importance of formal and informal institutions for governing people""s behaviour (e.g., North, 1990;Thelen, 1999) and earlier findings linking the institutional environment to the development of specific types of voluntary associations (e.g., Berman, 1997;K√§√§ri√§inen & Lehtonen, 2006;Schofer & Fourcade-Gourinchas, 2001), it is surprising that both lines of argument ignore the socio-political and institutional environment within which the individual and the association exist. This is especially injudicious since the nature and internal homogeneity of the voluntary organization that arises in specific contexts, as well as the societal relevance of that group and the issues it stands for, influence members"" integration process within the association. Indeed, these characterizing elements of the organizational identity are shown to be crucial determinants of individuals"" integration processes in the socialization literature (e.g., Checkel & Katzenstein, 2009), and play a key role to explain ""peer effects"" in research on group interaction in social psychology. 3 Consequently, as ""the definition of interests and objectives is created in institutional contexts and is not separable from them"" (Zysman, 1994, p. 244), any self-selection and socialization processes are unlikely to be unconditional, but rather will depend on, and be influenced by, the broader institutional environment. Hooghe (2003, p. 93) implies a similar idea when arguing that association membership is unlikely to ""introduce qualitatively new values, but enforces already existing values"" (see also Bardi & Goodwin, 2011;#CITATION_TAG & Lazersfeld, 1955)."	5	"This is especially injudicious since the nature and internal homogeneity of the voluntary organization that arises in specific contexts, as well as the societal relevance of that group and the issues it stands for, influence members"" integration process within the association. Indeed, these characterizing elements of the organizational identity are shown to be crucial determinants of individuals"" integration processes in the socialization literature (e.g., Checkel & Katzenstein, 2009), and play a key role to explain ""peer effects"" in research on group interaction in social psychology. 3 Consequently, as ""the definition of interests and objectives is created in institutional contexts and is not separable from them"" (Zysman, 1994, p. 244), any self-selection and socialization processes are unlikely to be unconditional, but rather will depend on, and be influenced by, the broader institutional environment. Hooghe (2003, p. 93) implies a similar idea when arguing that association membership is unlikely to ""introduce qualitatively new values, but enforces already existing values"" (see also Bardi & Goodwin, 2011;#CITATION_TAG & Lazersfeld, 1955)."	0
CCT438	"Clearly, however, not all institutional change occurs gradually. Exogenous shocks can function as ""critical junctures"" that instigate ""broadly different development paths"" and lead to a substantive institutional readjustment (Thelen, 1999, p. 387; see also Capoccia & Kelemen, 2007;Collier & Collier, 1991). Such unsettled times ""open possibilities for change"" (Thelen, 1999, p. 397) because ""groups or entire societies (. . .) are involved in constructing new strategies for action"" (Swidler, 1986, p. 278). Wars, terrorist activity or natural disasters therefore have the potential to induce sudden, although possibly temporary, shifts in people""s attitudes and value patterns (e.g., #CITATION_TAG & Cairns, 1996;Raviv et al., 2000). 4 For the same reason as above, this may lead the societal implications of association memberships to shift abruptly."	0	"Exogenous shocks can function as ""critical junctures"" that instigate ""broadly different development paths"" and lead to a substantive institutional readjustment (Thelen, 1999, p. 387; see also Capoccia & Kelemen, 2007;Collier & Collier, 1991). Such unsettled times ""open possibilities for change"" (Thelen, 1999, p. 397) because ""groups or entire societies (. . .) are involved in constructing new strategies for action"" (Swidler, 1986, p. 278). Wars, terrorist activity or natural disasters therefore have the potential to induce sudden, although possibly temporary, shifts in people""s attitudes and value patterns (e.g., #CITATION_TAG & Cairns, 1996;Raviv et al., 2000). 4 For the same reason as above, this may lead the societal implications of association memberships to shift abruptly."	,
CCT439	"In the foregoing literature, two central arguments have been employed to connect individuals"" memberships in voluntary associations and their civic attitudes (Wollebaek & Selle, 2007). The first rests on a self-selection argument stating that people with sufficiently ""prosocial"" characteristics are more likely to engage in society and join voluntary associations compared to people lacking such characteristics. As a result, individuals in voluntary associations display higher levels of desirable social attitudes simply because they selected themselves into such associations due to their pro-social attitudes (e.g., van Deth et al., 1999). The second view rests on a socialization argument and states that membership in voluntary associations induces a process of appropriating norms, attitudes, values and roles (e.g., Putnam, 2000). In this case, membership is expected to lead individuals to develop ""new"" values through interactions with co-members. 2 Given the importance of formal and informal institutions for governing people""s behaviour (e.g., North, 1990;Thelen, 1999) and earlier findings linking the institutional environment to the development of specific types of voluntary associations (e.g., Berman, 1997;K√§√§ri√§inen & Lehtonen, 2006;Schofer & Fourcade-Gourinchas, 2001), it is surprising that both lines of argument ignore the socio-political and institutional environment within which the individual and the association exist. This is especially injudicious since the nature and internal homogeneity of the voluntary organization that arises in specific contexts, as well as the societal relevance of that group and the issues it stands for, influence members"" integration process within the association. Indeed, these characterizing elements of the organizational identity are shown to be crucial determinants of individuals"" integration processes in the socialization literature (e.g., #CITATION_TAG & Katzenstein, 2009), and play a key role to explain ""peer effects"" in research on group interaction in social psychology. 3 Consequently, as ""the definition of interests and objectives is created in institutional contexts and is not separable from them"" (Zysman, 1994, p. 244), any self-selection and socialization processes are unlikely to be unconditional, but rather will depend on, and be influenced by, the broader institutional environment. Hooghe (2003, p. 93) implies a similar idea when arguing that association membership is unlikely to ""introduce qualitatively new values, but enforces already existing values"" (see also Bardi & Goodwin, 2011;Katz & Lazersfeld, 1955)."	5	"In this case, membership is expected to lead individuals to develop ""new"" values through interactions with co-members. 2 Given the importance of formal and informal institutions for governing people""s behaviour (e.g., North, 1990;Thelen, 1999) and earlier findings linking the institutional environment to the development of specific types of voluntary associations (e.g., Berman, 1997;K√§√§ri√§inen & Lehtonen, 2006;Schofer & Fourcade-Gourinchas, 2001), it is surprising that both lines of argument ignore the socio-political and institutional environment within which the individual and the association exist. This is especially injudicious since the nature and internal homogeneity of the voluntary organization that arises in specific contexts, as well as the societal relevance of that group and the issues it stands for, influence members"" integration process within the association. Indeed, these characterizing elements of the organizational identity are shown to be crucial determinants of individuals"" integration processes in the socialization literature (e.g., #CITATION_TAG & Katzenstein, 2009), and play a key role to explain ""peer effects"" in research on group interaction in social psychology. 3 Consequently, as ""the definition of interests and objectives is created in institutional contexts and is not separable from them"" (Zysman, 1994, p. 244), any self-selection and socialization processes are unlikely to be unconditional, but rather will depend on, and be influenced by, the broader institutional environment. Hooghe (2003, p. 93) implies a similar idea when arguing that association membership is unlikely to ""introduce qualitatively new values, but enforces already existing values"" (see also Bardi & Goodwin, 2011;Katz & Lazersfeld, 1955)."	 
CCT440	In fact, the assumption of large scale homogeneity and isotropy of the universe is the basis of most cosmological models (#CITATION_TAG 1917)	0	In fact, the assumption of large scale homogeneity and isotropy of the universe is the basis of most cosmological models (#CITATION_TAG 1917)	I
CCT441	The name fractal was introduced by Benoit B. Mandelbrot (Mandelbrot 1982) to characterize geometrical figures which may not be smooth or regular. One of the definitions of a fractal is that it is a shape made of parts similar to the whole in some way. It is useful to regard a fractal as a set of points that has properties such as those listed below, rather than to look for a more precise definition which will almost certainly exclude some interesting cases. A set F is a fractal if it satisfies most of the following (#CITATION_TAG 2003):	5	The name fractal was introduced by Benoit B. Mandelbrot (Mandelbrot 1982) to characterize geometrical figures which may not be smooth or regular. One of the definitions of a fractal is that it is a shape made of parts similar to the whole in some way. It is useful to regard a fractal as a set of points that has properties such as those listed below, rather than to look for a more precise definition which will almost certainly exclude some interesting cases. A set F is a fractal if it satisfies most of the following (#CITATION_TAG 2003):	e
CCT442	"To assess niche differences between phylogroups and between native and invasive parakeet populations, we used the Broennimann et al. (2012) framework. This framework applies kernel smoothers to densities of species occurrence in a gridded environmental space to calculate metrics of niche overlap (quantified by Schoener""s D, 0: no overlap, 1: complete overlap). Using a randomization test whereby the measured niche overlap is compared against a null distribution of 100 simulated overlap values, we test whether parakeet niches are more similar to each other than expected by chance (i.e. niche similarity, Broennimann et al., 2012). We first assessed whether ring-necked parakeet climatic niches differed significantly between phylogroups (i.e. Africa versus Asian, and phylogroups within each continent), using all biomes occupied by parakeets across their native range as background area (Guisan et al., 2014). Second, native and invasive ring-necked parakeet occurrences were used to assess whether native niche characteristics are conserved during the invasion process (using a niche similarity test), and to determine whether parakeets have colonized in the invaded range climates not occupied in the native range (i.e. niche expansion, Petitpierre et al., 2012). Niche metrics are calculated on the climate space shared by native and invasive ranges (sensu Petitpierre et al., 2012). Background areas should reflect the set of areas a species could potentially have encountered since its presence in the region (Barve et al., 2011). Therefore, in Europe, we buffered each locality where parakeets have been introduced with a distance equal to the minimum invasion speed recorded for birds (i.e. 4.59 km year √Ä1 , derived from #CITATION_TAG et al., 2009) multiplied by the number of years since introduction (see Strubbe et al., 2013 for details). In doing so, we obtained an ecologically realistic European background (models were also run using the whole of Europe as background, but this did not affect our main results, Appendix S3)."	5	Second, native and invasive ring-necked parakeet occurrences were used to assess whether native niche characteristics are conserved during the invasion process (using a niche similarity test), and to determine whether parakeets have colonized in the invaded range climates not occupied in the native range (i.e. niche expansion, Petitpierre et al., 2012). Niche metrics are calculated on the climate space shared by native and invasive ranges (sensu Petitpierre et al., 2012). Background areas should reflect the set of areas a species could potentially have encountered since its presence in the region (Barve et al., 2011). Therefore, in Europe, we buffered each locality where parakeets have been introduced with a distance equal to the minimum invasion speed recorded for birds (i.e. 4.59 km year √Ä1 , derived from #CITATION_TAG et al., 2009) multiplied by the number of years since introduction (see Strubbe et al., 2013 for details). In doing so, we obtained an ecologically realistic European background (models were also run using the whole of Europe as background, but this did not affect our main results, Appendix S3).	r
CCT443	Biological invasions are a major global environmental and economic problem (Sala et al., 2000). As eradication is frequently costly and sometimes impossible, attempting to limit the further introduction and spread of invasive species is the most effective and cost-efficient management strategy (Leung et al., 2002). To identify potentially invasive species, risk assessment protocols based on species traits associated with invasiveness have been developed (Keller et al., 2011). Spatially explicit predictions of invasion risk derived from bioclimatic envelope models [also referred to as species distribution models (SDM) or ecological niche models (ENM)] calibrated with native species distributions are increasingly incorporated into such invasive species risk assessments (Beaumont et al., 2014). To assess potential invasion risk, bioclimatic envelope models estimate the geographical distribution of climates suitable for invasive species (#CITATION_TAG & Peterson, 2012). Applications of these models to invasive species, however, fail to consider how association with human-modified habitats in the native range, a species trait strongly associated with invasion success (Keller et al., 2011), might modify the distributional limits sets by climate. Also, models typically do not appreciate how the existence of phylogeographic lineages with differing niche requirements can influence forecasts of invasion risk (Pearman et al., 2010). Ignoring these factors may result in mismatches between predicted potential and realized invasive distributions, fuelling doubts about the suitability of bioclimatic envelope models for anticipating biological invasions (Guisan et al., 2014).	0	As eradication is frequently costly and sometimes impossible, attempting to limit the further introduction and spread of invasive species is the most effective and cost-efficient management strategy (Leung et al., 2002). To identify potentially invasive species, risk assessment protocols based on species traits associated with invasiveness have been developed (Keller et al., 2011). Spatially explicit predictions of invasion risk derived from bioclimatic envelope models [also referred to as species distribution models (SDM) or ecological niche models (ENM)] calibrated with native species distributions are increasingly incorporated into such invasive species risk assessments (Beaumont et al., 2014). To assess potential invasion risk, bioclimatic envelope models estimate the geographical distribution of climates suitable for invasive species (#CITATION_TAG & Peterson, 2012). Applications of these models to invasive species, however, fail to consider how association with human-modified habitats in the native range, a species trait strongly associated with invasion success (Keller et al., 2011), might modify the distributional limits sets by climate. Also, models typically do not appreciate how the existence of phylogeographic lineages with differing niche requirements can influence forecasts of invasion risk (Pearman et al., 2010). Ignoring these factors may result in mismatches between predicted potential and realized invasive distributions, fuelling doubts about the suitability of bioclimatic envelope models for anticipating biological invasions (Guisan et al., 2014).	s
CCT444	Biological invasions are a major global environmental and economic problem (Sala et al., 2000). As eradication is frequently costly and sometimes impossible, attempting to limit the further introduction and spread of invasive species is the most effective and cost-efficient management strategy (Leung et al., 2002). To identify potentially invasive species, risk assessment protocols based on species traits associated with invasiveness have been developed (Keller et al., 2011). Spatially explicit predictions of invasion risk derived from bioclimatic envelope models [also referred to as species distribution models (SDM) or ecological niche models (ENM)] calibrated with native species distributions are increasingly incorporated into such invasive species risk assessments (Beaumont et al., 2014). To assess potential invasion risk, bioclimatic envelope models estimate the geographical distribution of climates suitable for invasive species (Ara ujo & Peterson, 2012). Applications of these models to invasive species, however, fail to consider how association with human-modified habitats in the native range, a species trait strongly associated with invasion success (Keller et al., 2011), might modify the distributional limits sets by climate. Also, models typically do not appreciate how the existence of phylogeographic lineages with differing niche requirements can influence forecasts of invasion risk (#CITATION_TAG et al., 2010). Ignoring these factors may result in mismatches between predicted potential and realized invasive distributions, fuelling doubts about the suitability of bioclimatic envelope models for anticipating biological invasions (Guisan et al., 2014).	5	Spatially explicit predictions of invasion risk derived from bioclimatic envelope models [also referred to as species distribution models (SDM) or ecological niche models (ENM)] calibrated with native species distributions are increasingly incorporated into such invasive species risk assessments (Beaumont et al., 2014). To assess potential invasion risk, bioclimatic envelope models estimate the geographical distribution of climates suitable for invasive species (Ara ujo & Peterson, 2012). Applications of these models to invasive species, however, fail to consider how association with human-modified habitats in the native range, a species trait strongly associated with invasion success (Keller et al., 2011), might modify the distributional limits sets by climate. Also, models typically do not appreciate how the existence of phylogeographic lineages with differing niche requirements can influence forecasts of invasion risk (#CITATION_TAG et al., 2010). Ignoring these factors may result in mismatches between predicted potential and realized invasive distributions, fuelling doubts about the suitability of bioclimatic envelope models for anticipating biological invasions (Guisan et al., 2014).	m
CCT445	Biological invasions are a major global environmental and economic problem (Sala et al., 2000). As eradication is frequently costly and sometimes impossible, attempting to limit the further introduction and spread of invasive species is the most effective and cost-efficient management strategy (Leung et al., 2002). To identify potentially invasive species, risk assessment protocols based on species traits associated with invasiveness have been developed (#CITATION_TAG et al., 2011). Spatially explicit predictions of invasion risk derived from bioclimatic envelope models [also referred to as species distribution models (SDM) or ecological niche models (ENM)] calibrated with native species distributions are increasingly incorporated into such invasive species risk assessments (Beaumont et al., 2014). To assess potential invasion risk, bioclimatic envelope models estimate the geographical distribution of climates suitable for invasive species (Ara ujo & Peterson, 2012). Applications of these models to invasive species, however, fail to consider how association with human-modified habitats in the native range, a species trait strongly associated with invasion success (Keller et al., 2011), might modify the distributional limits sets by climate. Also, models typically do not appreciate how the existence of phylogeographic lineages with differing niche requirements can influence forecasts of invasion risk (Pearman et al., 2010). Ignoring these factors may result in mismatches between predicted potential and realized invasive distributions, fuelling doubts about the suitability of bioclimatic envelope models for anticipating biological invasions (Guisan et al., 2014).	0	Biological invasions are a major global environmental and economic problem (Sala et al., 2000). As eradication is frequently costly and sometimes impossible, attempting to limit the further introduction and spread of invasive species is the most effective and cost-efficient management strategy (Leung et al., 2002). To identify potentially invasive species, risk assessment protocols based on species traits associated with invasiveness have been developed (#CITATION_TAG et al., 2011). Spatially explicit predictions of invasion risk derived from bioclimatic envelope models [also referred to as species distribution models (SDM) or ecological niche models (ENM)] calibrated with native species distributions are increasingly incorporated into such invasive species risk assessments (Beaumont et al., 2014). To assess potential invasion risk, bioclimatic envelope models estimate the geographical distribution of climates suitable for invasive species (Ara ujo & Peterson, 2012). Applications of these models to invasive species, however, fail to consider how association with human-modified habitats in the native range, a species trait strongly associated with invasion success (Keller et al., 2011), might modify the distributional limits sets by climate.	 
CCT446	"Bioclimatic envelope models assume that a species"" invasive distribution can be predicted from its native niche characteristics (Peterson, 2003). Niche theory indeed predicts that for relatively recent events such as biological invasions, conservatism of the fundamental native niche is expected (Peterson, 2011), although species may, in the invaded range, occupy different portions of their fundamental niche compared to the native range (Guisan et al., 2014). Empirical studies on the prevalence of (realized) niche conservatism have yielded mixed results. Two large scale studies on European plants introduced to North America found niche conservatism was the dominant pattern for weedy, widespread plant species (Petitpierre et al., 2012), while niche expansion into climates not occupied in the native range was common for plants with smaller native ranges (Early & Sax, 2014). Niche conservatism was the norm for non-native vertebrates introduced to Europe and North America (Strubbe et al., 2013(Strubbe et al., , 2014, whereas a global study on amphibians and reptiles found widespread evidence for niche expansion (#CITATION_TAG et al., 2014). To better understand the mechanisms underlying patterns of niche conservatism, here, we question the inherent assumption that pooling occurrence data from across the entire native range of a species adequately describes the full range of climatic conditions in which invasive populations can establish and survive. This assumption may be violated when phylogeographic lineages with differing niche requirements are present. Species may not represent a single evolutionary entity (Pearman et al., 2010), and as species-level models smooth across environmental response curves of specific lineages, ignoring within-taxon niche structure risks erroneous predictions of a species"" potential distribution (D""Amen et al., 2013). Despite their potential to improve predictions of invasion risk, within-taxon niche structures have only received scant attention in invasive species management (Beaumont et al., 2014)."	1	"Niche theory indeed predicts that for relatively recent events such as biological invasions, conservatism of the fundamental native niche is expected (Peterson, 2011), although species may, in the invaded range, occupy different portions of their fundamental niche compared to the native range (Guisan et al., 2014). Empirical studies on the prevalence of (realized) niche conservatism have yielded mixed results. Two large scale studies on European plants introduced to North America found niche conservatism was the dominant pattern for weedy, widespread plant species (Petitpierre et al., 2012), while niche expansion into climates not occupied in the native range was common for plants with smaller native ranges (Early & Sax, 2014). Niche conservatism was the norm for non-native vertebrates introduced to Europe and North America (Strubbe et al., 2013(Strubbe et al., , 2014, whereas a global study on amphibians and reptiles found widespread evidence for niche expansion (#CITATION_TAG et al., 2014). To better understand the mechanisms underlying patterns of niche conservatism, here, we question the inherent assumption that pooling occurrence data from across the entire native range of a species adequately describes the full range of climatic conditions in which invasive populations can establish and survive. This assumption may be violated when phylogeographic lineages with differing niche requirements are present. Species may not represent a single evolutionary entity (Pearman et al., 2010), and as species-level models smooth across environmental response curves of specific lineages, ignoring within-taxon niche structure risks erroneous predictions of a species"" potential distribution (D""Amen et al., 2013)."	e
CCT447	"Bioclimatic envelope models assume that a species"" invasive distribution can be predicted from its native niche characteristics (Peterson, 2003). Niche theory indeed predicts that for relatively recent events such as biological invasions, conservatism of the fundamental native niche is expected (Peterson, 2011), although species may, in the invaded range, occupy different portions of their fundamental niche compared to the native range (Guisan et al., 2014). Empirical studies on the prevalence of (realized) niche conservatism have yielded mixed results. Two large scale studies on European plants introduced to North America found niche conservatism was the dominant pattern for weedy, widespread plant species (#CITATION_TAG et al., 2012), while niche expansion into climates not occupied in the native range was common for plants with smaller native ranges (Early & Sax, 2014). Niche conservatism was the norm for non-native vertebrates introduced to Europe and North America (Strubbe et al., 2013(Strubbe et al., , 2014, whereas a global study on amphibians and reptiles found widespread evidence for niche expansion (Li et al., 2014). To better understand the mechanisms underlying patterns of niche conservatism, here, we question the inherent assumption that pooling occurrence data from across the entire native range of a species adequately describes the full range of climatic conditions in which invasive populations can establish and survive. This assumption may be violated when phylogeographic lineages with differing niche requirements are present. Species may not represent a single evolutionary entity (Pearman et al., 2010), and as species-level models smooth across environmental response curves of specific lineages, ignoring within-taxon niche structure risks erroneous predictions of a species"" potential distribution (D""Amen et al., 2013). Despite their potential to improve predictions of invasion risk, within-taxon niche structures have only received scant attention in invasive species management (Beaumont et al., 2014)."	1	"Bioclimatic envelope models assume that a species"" invasive distribution can be predicted from its native niche characteristics (Peterson, 2003). Niche theory indeed predicts that for relatively recent events such as biological invasions, conservatism of the fundamental native niche is expected (Peterson, 2011), although species may, in the invaded range, occupy different portions of their fundamental niche compared to the native range (Guisan et al., 2014). Empirical studies on the prevalence of (realized) niche conservatism have yielded mixed results. Two large scale studies on European plants introduced to North America found niche conservatism was the dominant pattern for weedy, widespread plant species (#CITATION_TAG et al., 2012), while niche expansion into climates not occupied in the native range was common for plants with smaller native ranges (Early & Sax, 2014). Niche conservatism was the norm for non-native vertebrates introduced to Europe and North America (Strubbe et al., 2013(Strubbe et al., , 2014, whereas a global study on amphibians and reptiles found widespread evidence for niche expansion (Li et al., 2014). To better understand the mechanisms underlying patterns of niche conservatism, here, we question the inherent assumption that pooling occurrence data from across the entire native range of a species adequately describes the full range of climatic conditions in which invasive populations can establish and survive. This assumption may be violated when phylogeographic lineages with differing niche requirements are present."	 
CCT448	"Bioclimatic envelope models assume that a species"" invasive distribution can be predicted from its native niche characteristics (Peterson, 2003). Niche theory indeed predicts that for relatively recent events such as biological invasions, conservatism of the fundamental native niche is expected (Peterson, 2011), although species may, in the invaded range, occupy different portions of their fundamental niche compared to the native range (Guisan et al., 2014). Empirical studies on the prevalence of (realized) niche conservatism have yielded mixed results. Two large scale studies on European plants introduced to North America found niche conservatism was the dominant pattern for weedy, widespread plant species (Petitpierre et al., 2012), while niche expansion into climates not occupied in the native range was common for plants with smaller native ranges (#CITATION_TAG & Sax, 2014). Niche conservatism was the norm for non-native vertebrates introduced to Europe and North America (Strubbe et al., 2013(Strubbe et al., , 2014, whereas a global study on amphibians and reptiles found widespread evidence for niche expansion (Li et al., 2014). To better understand the mechanisms underlying patterns of niche conservatism, here, we question the inherent assumption that pooling occurrence data from across the entire native range of a species adequately describes the full range of climatic conditions in which invasive populations can establish and survive. This assumption may be violated when phylogeographic lineages with differing niche requirements are present. Species may not represent a single evolutionary entity (Pearman et al., 2010), and as species-level models smooth across environmental response curves of specific lineages, ignoring within-taxon niche structure risks erroneous predictions of a species"" potential distribution (D""Amen et al., 2013). Despite their potential to improve predictions of invasion risk, within-taxon niche structures have only received scant attention in invasive species management (Beaumont et al., 2014)."	1	"Bioclimatic envelope models assume that a species"" invasive distribution can be predicted from its native niche characteristics (Peterson, 2003). Niche theory indeed predicts that for relatively recent events such as biological invasions, conservatism of the fundamental native niche is expected (Peterson, 2011), although species may, in the invaded range, occupy different portions of their fundamental niche compared to the native range (Guisan et al., 2014). Empirical studies on the prevalence of (realized) niche conservatism have yielded mixed results. Two large scale studies on European plants introduced to North America found niche conservatism was the dominant pattern for weedy, widespread plant species (Petitpierre et al., 2012), while niche expansion into climates not occupied in the native range was common for plants with smaller native ranges (#CITATION_TAG & Sax, 2014). Niche conservatism was the norm for non-native vertebrates introduced to Europe and North America (Strubbe et al., 2013(Strubbe et al., , 2014, whereas a global study on amphibians and reptiles found widespread evidence for niche expansion (Li et al., 2014). To better understand the mechanisms underlying patterns of niche conservatism, here, we question the inherent assumption that pooling occurrence data from across the entire native range of a species adequately describes the full range of climatic conditions in which invasive populations can establish and survive. This assumption may be violated when phylogeographic lineages with differing niche requirements are present."	 
CCT449	"To assess niche differences between phylogroups and between native and invasive parakeet populations, we used the Broennimann et al. (2012) framework. This framework applies kernel smoothers to densities of species occurrence in a gridded environmental space to calculate metrics of niche overlap (quantified by Schoener""s D, 0: no overlap, 1: complete overlap). Using a randomization test whereby the measured niche overlap is compared against a null distribution of 100 simulated overlap values, we test whether parakeet niches are more similar to each other than expected by chance (i.e. niche similarity, Broennimann et al., 2012). We first assessed whether ring-necked parakeet climatic niches differed significantly between phylogroups (i.e. Africa versus Asian, and phylogroups within each continent), using all biomes occupied by parakeets across their native range as background area (Guisan et al., 2014). Second, native and invasive ring-necked parakeet occurrences were used to assess whether native niche characteristics are conserved during the invasion process (using a niche similarity test), and to determine whether parakeets have colonized in the invaded range climates not occupied in the native range (i.e. niche expansion, Petitpierre et al., 2012). Niche metrics are calculated on the climate space shared by native and invasive ranges (sensu Petitpierre et al., 2012). Background areas should reflect the set of areas a species could potentially have encountered since its presence in the region (Barve et al., 2011). Therefore, in Europe, we buffered each locality where parakeets have been introduced with a distance equal to the minimum invasion speed recorded for birds (i.e. 4.59 km year √Ä1 , derived from Blackburn et al., 2009) multiplied by the number of years since introduction (see #CITATION_TAG et al., 2013 for details). In doing so, we obtained an ecologically realistic European background (models were also run using the whole of Europe as background, but this did not affect our main results, Appendix S3)."	5	Second, native and invasive ring-necked parakeet occurrences were used to assess whether native niche characteristics are conserved during the invasion process (using a niche similarity test), and to determine whether parakeets have colonized in the invaded range climates not occupied in the native range (i.e. niche expansion, Petitpierre et al., 2012). Niche metrics are calculated on the climate space shared by native and invasive ranges (sensu Petitpierre et al., 2012). Background areas should reflect the set of areas a species could potentially have encountered since its presence in the region (Barve et al., 2011). Therefore, in Europe, we buffered each locality where parakeets have been introduced with a distance equal to the minimum invasion speed recorded for birds (i.e. 4.59 km year √Ä1 , derived from Blackburn et al., 2009) multiplied by the number of years since introduction (see #CITATION_TAG et al., 2013 for details). In doing so, we obtained an ecologically realistic European background (models were also run using the whole of Europe as background, but this did not affect our main results, Appendix S3).	r
CCT450	"To assess niche differences between phylogroups and between native and invasive parakeet populations, we used the #CITATION_TAG et al. (2012) framework. This framework applies kernel smoothers to densities of species occurrence in a gridded environmental space to calculate metrics of niche overlap (quantified by Schoener""s D, 0: no overlap, 1: complete overlap). Using a randomization test whereby the measured niche overlap is compared against a null distribution of 100 simulated overlap values, we test whether parakeet niches are more similar to each other than expected by chance (i.e. niche similarity, Broennimann et al., 2012). We first assessed whether ring-necked parakeet climatic niches differed significantly between phylogroups (i.e. Africa versus Asian, and phylogroups within each continent), using all biomes occupied by parakeets across their native range as background area (Guisan et al., 2014). Second, native and invasive ring-necked parakeet occurrences were used to assess whether native niche characteristics are conserved during the invasion process (using a niche similarity test), and to determine whether parakeets have colonized in the invaded range climates not occupied in the native range (i.e. niche expansion, Petitpierre et al., 2012). Niche metrics are calculated on the climate space shared by native and invasive ranges (sensu Petitpierre et al., 2012). Background areas should reflect the set of areas a species could potentially have encountered since its presence in the region (Barve et al., 2011). Therefore, in Europe, we buffered each locality where parakeets have been introduced with a distance equal to the minimum invasion speed recorded for birds (i.e. 4.59 km year √Ä1 , derived from Blackburn et al., 2009) multiplied by the number of years since introduction (see Strubbe et al., 2013 for details). In doing so, we obtained an ecologically realistic European background (models were also run using the whole of Europe as background, but this did not affect our main results, Appendix S3)."	5	"To assess niche differences between phylogroups and between native and invasive parakeet populations, we used the #CITATION_TAG et al. (2012) framework. This framework applies kernel smoothers to densities of species occurrence in a gridded environmental space to calculate metrics of niche overlap (quantified by Schoener""s D, 0: no overlap, 1: complete overlap). Using a randomization test whereby the measured niche overlap is compared against a null distribution of 100 simulated overlap values, we test whether parakeet niches are more similar to each other than expected by chance (i.e. niche similarity, Broennimann et al., 2012). We first assessed whether ring-necked parakeet climatic niches differed significantly between phylogroups (i.e. Africa versus Asian, and phylogroups within each continent), using all biomes occupied by parakeets across their native range as background area (Guisan et al., 2014)."	T
CCT451	"Therefore, we assess three key assumptions underlying bioclimatic envelope models: (1) that species"" distributions are largely governed by climate (Ara ujo & Peterson, 2012), (2) that a species"" current native distribution corresponds with the total set of climate conditions under which it can persist (#CITATION_TAG, 2003) and (3) that the climatic niche remains conserved across time and space (Broennimann et al., 2007). Climate is generally recognized as a chief driver of species"" distributions at large spatial scales (Ara ujo & Peterson, 2012), although the broad distributional limits governed by climate may be modified by factors such as habitat availability, biotic interactions and dispersal limitations (Soberon, 2007). Erroneous predictions of the potential distribution of invasive species are often attributed to species adaptations in response to selection pressures imposed by the novel environment (Whitney & Gabler, 2008). However, within the native range, species may also evolve pre-adaptations to invasiveness; strong selection imposed by human modification of habitats within the native range is likely to lead to adaptation prior to introduction elsewhere (Hufbauer et al., 2012). As human activities tend to promote similar ecological conditions across biogeographical areas (Savard et al., 2000), species or populations associated with human-modified habitats in the native range can be expected to successfully invade similar areas elsewhere. It is therefore surprising that predic-tions of invasion risk obtained from bioclimatic envelope models have not yet explicitly considered how human modification of habitats might modify distributional limits set by climate."	0	"Therefore, we assess three key assumptions underlying bioclimatic envelope models: (1) that species"" distributions are largely governed by climate (Ara ujo & Peterson, 2012), (2) that a species"" current native distribution corresponds with the total set of climate conditions under which it can persist (#CITATION_TAG, 2003) and (3) that the climatic niche remains conserved across time and space (Broennimann et al., 2007). Climate is generally recognized as a chief driver of species"" distributions at large spatial scales (Ara ujo & Peterson, 2012), although the broad distributional limits governed by climate may be modified by factors such as habitat availability, biotic interactions and dispersal limitations (Soberon, 2007). Erroneous predictions of the potential distribution of invasive species are often attributed to species adaptations in response to selection pressures imposed by the novel environment (Whitney & Gabler, 2008). However, within the native range, species may also evolve pre-adaptations to invasiveness; strong selection imposed by human modification of habitats within the native range is likely to lead to adaptation prior to introduction elsewhere (Hufbauer et al., 2012)."	T
CCT452	"Ring-necked parakeet occurrence data (i.e. longitude-latitude) were extracted from a range of databases [Global Biodiversity Information Facility (GBIF, www.gbif.org), ORNIS (www.ornisnet.org) and natural history museums], scientific papers and grey literature (e.g. government or NGO reports, bird trip reports and parakeet observations posted on the image hosting website Flickr.com). Occurrence data were retained only when their spatial resolution was ‚â§ 5 0 (i.e. 0.083¬∞or~10 9 10 km, assessment of spatial accuracy based on information present in the source data, or through pers. comm. with observers). In the invaded range, to minimize the risk of including parakeet occurrences that do not correspond to an established population, we did not include observations from areas where evidence suggests introduced populations went extinct (see #CITATION_TAG & Matthysen, 2009b). Also, parakeet occurrences were checked against national and regional breeding bird atlases, and when in doubt about the status of a certain population, we sought advice from regional experts (through the COST Action network ""ParrotNet""). In total, we gathered 8667 ring-necked parakeet occurrences (Europe: 6634, Africa: 515, Asia: 1518), but as we used only one occurrence per grid cell, the final database comprised 1199 observations (Europe: 513, Africa: 211 and Asia: 475; Appendix S2). Data on parakeet introduction success were taken from Strubbe & Matthysen (2009b) (n = 123 introduction events). Minimum convex and Thiessen polygons circumscribing the geographical distribution of each mtDNA clade were then applied to assign parakeet occurrences to phylogroups (Appendix S2)."	0	"Occurrence data were retained only when their spatial resolution was ‚â§ 5 0 (i.e. 0.083¬∞or~10 9 10 km, assessment of spatial accuracy based on information present in the source data, or through pers. comm. with observers). In the invaded range, to minimize the risk of including parakeet occurrences that do not correspond to an established population, we did not include observations from areas where evidence suggests introduced populations went extinct (see #CITATION_TAG & Matthysen, 2009b). Also, parakeet occurrences were checked against national and regional breeding bird atlases, and when in doubt about the status of a certain population, we sought advice from regional experts (through the COST Action network ""ParrotNet""). In total, we gathered 8667 ring-necked parakeet occurrences (Europe: 6634, Africa: 515, Asia: 1518), but as we used only one occurrence per grid cell, the final database comprised 1199 observations (Europe: 513, Africa: 211 and Asia: 475; Appendix S2). Data on parakeet introduction success were taken from Strubbe & Matthysen (2009b) (n = 123 introduction events)."	 
CCT453	"Here, using a unique dataset on the distribution of a global avian invader, the ring-necked parakeet (Psittacula krameri), we test whether accounting for within-taxon niche structure and association with humans in the native range leads to more accurate predictions of invasion risk. Ringnecked parakeets are native to large parts of Africa and Asia. Across their native range, they have benefited from the conversion of natural habitats to agro-ecosystems (Bruggers & Beck, 1979;Khan, 2002) and reach their highest breeding densities near human settlements and cultivated crops (Khan et al., 2004). These parakeets are a globally widespread invasive species, and they compete with native birds and bats and cause damage to crops (Strubbe & Matthysen, 2009a;Hern andez-Brito et al., 2014;#CITATION_TAG et al., 2014). In this study, we present the most complete information on the distribution of ring-necked parakeets to date, comprising a set of about 1200 (686 native and 513 invasive) occurrences collected at a finer resolution than has previously been reported, 123 failed and successful introduction events across Europe, plus a high-resolution mtDNA molecular phylogeny derived from 98 museum specimens geospatially selected to cover the parakeet""s native range and from feather samples collected at 13 invaded sites across Europe. We expect that incorporating within-taxon niche structure into bioclimatic envelope models will result in important differences in the geographical distribution of climate predicted as suitable for parakeets across Europe and that accounting for association with human-modified habitats in the native range will allow for more accurate predictions of the potential European distribution of this ubiquitous avian invader."	0	"Here, using a unique dataset on the distribution of a global avian invader, the ring-necked parakeet (Psittacula krameri), we test whether accounting for within-taxon niche structure and association with humans in the native range leads to more accurate predictions of invasion risk. Ringnecked parakeets are native to large parts of Africa and Asia. Across their native range, they have benefited from the conversion of natural habitats to agro-ecosystems (Bruggers & Beck, 1979;Khan, 2002) and reach their highest breeding densities near human settlements and cultivated crops (Khan et al., 2004). These parakeets are a globally widespread invasive species, and they compete with native birds and bats and cause damage to crops (Strubbe & Matthysen, 2009a;Hern andez-Brito et al., 2014;#CITATION_TAG et al., 2014). In this study, we present the most complete information on the distribution of ring-necked parakeets to date, comprising a set of about 1200 (686 native and 513 invasive) occurrences collected at a finer resolution than has previously been reported, 123 failed and successful introduction events across Europe, plus a high-resolution mtDNA molecular phylogeny derived from 98 museum specimens geospatially selected to cover the parakeet""s native range and from feather samples collected at 13 invaded sites across Europe. We expect that incorporating within-taxon niche structure into bioclimatic envelope models will result in important differences in the geographical distribution of climate predicted as suitable for parakeets across Europe and that accounting for association with human-modified habitats in the native range will allow for more accurate predictions of the potential European distribution of this ubiquitous avian invader."	s
CCT454	Biological invasions are a major global environmental and economic problem (Sala et al., 2000). As eradication is frequently costly and sometimes impossible, attempting to limit the further introduction and spread of invasive species is the most effective and cost-efficient management strategy (Leung et al., 2002). To identify potentially invasive species, risk assessment protocols based on species traits associated with invasiveness have been developed (Keller et al., 2011). Spatially explicit predictions of invasion risk derived from bioclimatic envelope models [also referred to as species distribution models (SDM) or ecological niche models (ENM)] calibrated with native species distributions are increasingly incorporated into such invasive species risk assessments (#CITATION_TAG et al., 2014). To assess potential invasion risk, bioclimatic envelope models estimate the geographical distribution of climates suitable for invasive species (Ara ujo & Peterson, 2012). Applications of these models to invasive species, however, fail to consider how association with human-modified habitats in the native range, a species trait strongly associated with invasion success (Keller et al., 2011), might modify the distributional limits sets by climate. Also, models typically do not appreciate how the existence of phylogeographic lineages with differing niche requirements can influence forecasts of invasion risk (Pearman et al., 2010). Ignoring these factors may result in mismatches between predicted potential and realized invasive distributions, fuelling doubts about the suitability of bioclimatic envelope models for anticipating biological invasions (Guisan et al., 2014).	0	Biological invasions are a major global environmental and economic problem (Sala et al., 2000). As eradication is frequently costly and sometimes impossible, attempting to limit the further introduction and spread of invasive species is the most effective and cost-efficient management strategy (Leung et al., 2002). To identify potentially invasive species, risk assessment protocols based on species traits associated with invasiveness have been developed (Keller et al., 2011). Spatially explicit predictions of invasion risk derived from bioclimatic envelope models [also referred to as species distribution models (SDM) or ecological niche models (ENM)] calibrated with native species distributions are increasingly incorporated into such invasive species risk assessments (#CITATION_TAG et al., 2014). To assess potential invasion risk, bioclimatic envelope models estimate the geographical distribution of climates suitable for invasive species (Ara ujo & Peterson, 2012). Applications of these models to invasive species, however, fail to consider how association with human-modified habitats in the native range, a species trait strongly associated with invasion success (Keller et al., 2011), might modify the distributional limits sets by climate. Also, models typically do not appreciate how the existence of phylogeographic lineages with differing niche requirements can influence forecasts of invasion risk (Pearman et al., 2010).	t
CCT455	"The fact that lineages associated with cold climates in the native range are more prevalent across Europe suggests that these lineages may be better adapted to European climates. Such an invasion scenario has been found before; for example, #CITATION_TAG et al. (2012) showed that the invasion of Mediterranean Israel by the tropical ant Wasmannia auropunctata could be explained by adaptation to cold at the southern limit of the native range before introduction to Israel. Yet, although large numbers of parakeets from both Africa and Asia have been imported to Europe (Morgan, 1993), more detailed knowledge on propagule pressure is required to rule out alternative explanations such as the possibility that more birds originating from colder parts of the native rang have escaped or been released across Europe. Also, it should be noted that our phylogeny is based on a set of neutral genetic markers and that consequently, patterns of within-taxon niche variation may be due to regional differences in available climates, to adaptation to local environments or to other drivers such as biotic interactions. However, populations are often adapted to local environments and genotypeby-environment interactions are common in widespread species (Pearman et al., 2010). This study is the first fine-scale assessment of ring-necked parakeet genetic structure, but differences among lineages in morphology and life history traits such as timing of reproduction have been reported within and between Africa and Asia (Forshaw, 1978). Such traits may be genetically based and therefore likely to respond to selection (Bradshaw & Holzapfel, 2006) in the parakeet""s invasive range. Indeed, variance in laying dates between European and native (Asian) parakeet populations suggests that in Europe, parakeets are delaying their breeding in response to colder temperatures (Shwartz et al., 2009). These differences in morphology, life history and occupied climates suggest parakeet mtDNA-derived lineages may indeed diverge in features supplementary to the neutral genetic markers used to identify phylogeographic structure. Our results thus suggest the clade model captures lineage-specific responses to environmental gradients that are undetectable using the clade model (Appendix S8). Incorporating such within-taxon niche structure into bioclimatic envelope models only slightly increased model predictive accuracy, but nonetheless leads to important differences in spatial predictions of invasion risk for Europe (Figs 2 & 3). The climate-only clade model is strongly influenced by precipitation gradients (Appendix S8), resulting in erroneous predictions of parakeet occurrence for Europe""s wetter areas (i.e. parts of the Atlantic and Adriatic coast, and along mountain chains, Fig. 2a). The climate-only subclade model indicates certain phylogeographic lineages indeed respond strongly to precipitation gradients (Appendix S8), although in general, the subclade model is more strongly driven by temperature gradients. The climate-only subclade model accordingly correctly predicts some of the Mediterranean parakeet populations, and except for a high precipitation zone along the coast of Norway, it assigns a low invasion risk to coastal areas and mountain chains (Fig. 2b). Both climate-only models, however, fail to accurately forecast ringnecked parakeet occurrence across north-west Europe. When including the human footprint, the major difference between the clade and subclade model is that the latter places more weight on temperature and precipitation gradients (Appendix S8), whereas the clade model exhibits a higher dependency on human footprint. Consequently, the clade model predicts a higher invasion risk across human-dominated habitats in colder parts of continental Europe (Fig. 2c, d) as well. This becomes especially apparent when converting the predictions of invasion risk into discrete predictions of parakeet presence and absence (Fig. 3), showing that particularly in east and central Europe, the clade model predicts as suitable areas that are geographically peripheral to areas predicted as suitable by the subclade model. In contrast, in southern Europe, the subclade model predicts more extensive areas to be at risk of parakeet invasion, reflecting the different weightings given by the clade and subclade model to climate and human modification of habitats."	0	The fact that lineages associated with cold climates in the native range are more prevalent across Europe suggests that these lineages may be better adapted to European climates. Such an invasion scenario has been found before; for example, #CITATION_TAG et al. (2012) showed that the invasion of Mediterranean Israel by the tropical ant Wasmannia auropunctata could be explained by adaptation to cold at the southern limit of the native range before introduction to Israel. Yet, although large numbers of parakeets from both Africa and Asia have been imported to Europe (Morgan, 1993), more detailed knowledge on propagule pressure is required to rule out alternative explanations such as the possibility that more birds originating from colder parts of the native rang have escaped or been released across Europe. Also, it should be noted that our phylogeny is based on a set of neutral genetic markers and that consequently, patterns of within-taxon niche variation may be due to regional differences in available climates, to adaptation to local environments or to other drivers such as biotic interactions. However, populations are often adapted to local environments and genotypeby-environment interactions are common in widespread species (Pearman et al., 2010).	u
CCT456	"Taken together, our results agree with other findings (Strubbe et al., 2013(Strubbe et al., , 2014Early & Sax, 2014;Guisan et al., 2014;Li et al., 2014), suggesting that while rapid post-introduction evolution (i.e. a change in the fundamental Grinnellian niche, Soberon, 2007) cannot be ruled out, climatic niche differences between native and invasive ranges are probably related to ecological factors governing the occupancy of the fundamental niche in native versus invaded ranges. This has important ramifications for the use of bioclimatic envelope models as risk assessment tools, as well as, more fundamentally, for understanding how climate and local factors interact to determine species"" distributions. #CITATION_TAG & Dawson (2003) suggested a hierarchical approach to modelling environment-biota relationships whereby bioclimatic envelope models should form the first step, identifying the broad outlines of species"" distributions. Within the area designated as climatically suitable for a species, models including factors such as land cover and habitat preferences can then be applied to elucidate the finegrained structure of distributions. We suggest that, at least for invasive species, this framework may not be universally applicable, as association with human-modified habitats in the native range may allow species to overcome their (realized) native-range climatic limitations in human-modified landscapes elsewhere. Trait-based species risk assessments consider association with human-modified habitats in the native range to be a reliable predictor of invasion success (Keller et al., 2011), especially for mammals and birds (Jeschke & Strayer 2006). Our results show that applying a simple and universal variable such as the human footprint can considerably increase the accuracy of predictions of invasion risk, and this finding opens up real perspectives for devising and implementing more robust management strategies for a large number of invasive species. Information about the presence and geographical distribution of phylogeographic lineages may be not be readily available for all invasive species, but subspecies range maps can often be derived from the literature, at least for terrestrial vertebrates. Subspecies are generally based on discontinuities in the geographical distribution of phenotypic traits instead of molecular phylogenies, but can generally be considered useful proxies of patterns of divergence among populations (Phillimore & Owens, 2006). We therefore argue that, in order to provide to policymakers models that can accurately predict invasion risk, explicit evaluation of within-taxon niche structure and especially of association with humans in the native range is recommended."	5	"Taken together, our results agree with other findings (Strubbe et al., 2013(Strubbe et al., , 2014Early & Sax, 2014;Guisan et al., 2014;Li et al., 2014), suggesting that while rapid post-introduction evolution (i.e. a change in the fundamental Grinnellian niche, Soberon, 2007) cannot be ruled out, climatic niche differences between native and invasive ranges are probably related to ecological factors governing the occupancy of the fundamental niche in native versus invaded ranges. This has important ramifications for the use of bioclimatic envelope models as risk assessment tools, as well as, more fundamentally, for understanding how climate and local factors interact to determine species"" distributions. #CITATION_TAG & Dawson (2003) suggested a hierarchical approach to modelling environment-biota relationships whereby bioclimatic envelope models should form the first step, identifying the broad outlines of species"" distributions. Within the area designated as climatically suitable for a species, models including factors such as land cover and habitat preferences can then be applied to elucidate the finegrained structure of distributions. We suggest that, at least for invasive species, this framework may not be universally applicable, as association with human-modified habitats in the native range may allow species to overcome their (realized) native-range climatic limitations in human-modified landscapes elsewhere. Trait-based species risk assessments consider association with human-modified habitats in the native range to be a reliable predictor of invasion success (Keller et al., 2011), especially for mammals and birds (Jeschke & Strayer 2006)."	I
CCT457	"Bioclimatic envelope models assume that a species"" invasive distribution can be predicted from its native niche characteristics (Peterson, 2003). Niche theory indeed predicts that for relatively recent events such as biological invasions, conservatism of the fundamental native niche is expected (#CITATION_TAG, 2011), although species may, in the invaded range, occupy different portions of their fundamental niche compared to the native range (Guisan et al., 2014). Empirical studies on the prevalence of (realized) niche conservatism have yielded mixed results. Two large scale studies on European plants introduced to North America found niche conservatism was the dominant pattern for weedy, widespread plant species (Petitpierre et al., 2012), while niche expansion into climates not occupied in the native range was common for plants with smaller native ranges (Early & Sax, 2014). Niche conservatism was the norm for non-native vertebrates introduced to Europe and North America (Strubbe et al., 2013(Strubbe et al., , 2014, whereas a global study on amphibians and reptiles found widespread evidence for niche expansion (Li et al., 2014). To better understand the mechanisms underlying patterns of niche conservatism, here, we question the inherent assumption that pooling occurrence data from across the entire native range of a species adequately describes the full range of climatic conditions in which invasive populations can establish and survive. This assumption may be violated when phylogeographic lineages with differing niche requirements are present. Species may not represent a single evolutionary entity (Pearman et al., 2010), and as species-level models smooth across environmental response curves of specific lineages, ignoring within-taxon niche structure risks erroneous predictions of a species"" potential distribution (D""Amen et al., 2013). Despite their potential to improve predictions of invasion risk, within-taxon niche structures have only received scant attention in invasive species management (Beaumont et al., 2014)."	0	"Bioclimatic envelope models assume that a species"" invasive distribution can be predicted from its native niche characteristics (Peterson, 2003). Niche theory indeed predicts that for relatively recent events such as biological invasions, conservatism of the fundamental native niche is expected (#CITATION_TAG, 2011), although species may, in the invaded range, occupy different portions of their fundamental niche compared to the native range (Guisan et al., 2014). Empirical studies on the prevalence of (realized) niche conservatism have yielded mixed results. Two large scale studies on European plants introduced to North America found niche conservatism was the dominant pattern for weedy, widespread plant species (Petitpierre et al., 2012), while niche expansion into climates not occupied in the native range was common for plants with smaller native ranges (Early & Sax, 2014). Niche conservatism was the norm for non-native vertebrates introduced to Europe and North America (Strubbe et al., 2013(Strubbe et al., , 2014, whereas a global study on amphibians and reptiles found widespread evidence for niche expansion (Li et al., 2014)."	i
CCT458	"Taken together, our results agree with other findings (Strubbe et al., 2013(Strubbe et al., , 2014Early & Sax, 2014;Guisan et al., 2014;Li et al., 2014), suggesting that while rapid post-introduction evolution (i.e. a change in the fundamental Grinnellian niche, Soberon, 2007) cannot be ruled out, climatic niche differences between native and invasive ranges are probably related to ecological factors governing the occupancy of the fundamental niche in native versus invaded ranges. This has important ramifications for the use of bioclimatic envelope models as risk assessment tools, as well as, more fundamentally, for understanding how climate and local factors interact to determine species"" distributions. Pearson & Dawson (2003) suggested a hierarchical approach to modelling environment-biota relationships whereby bioclimatic envelope models should form the first step, identifying the broad outlines of species"" distributions. Within the area designated as climatically suitable for a species, models including factors such as land cover and habitat preferences can then be applied to elucidate the finegrained structure of distributions. We suggest that, at least for invasive species, this framework may not be universally applicable, as association with human-modified habitats in the native range may allow species to overcome their (realized) native-range climatic limitations in human-modified landscapes elsewhere. Trait-based species risk assessments consider association with human-modified habitats in the native range to be a reliable predictor of invasion success (Keller et al., 2011), especially for mammals and birds (Jeschke & Strayer 2006). Our results show that applying a simple and universal variable such as the human footprint can considerably increase the accuracy of predictions of invasion risk, and this finding opens up real perspectives for devising and implementing more robust management strategies for a large number of invasive species. Information about the presence and geographical distribution of phylogeographic lineages may be not be readily available for all invasive species, but subspecies range maps can often be derived from the literature, at least for terrestrial vertebrates. Subspecies are generally based on discontinuities in the geographical distribution of phenotypic traits instead of molecular phylogenies, but can generally be considered useful proxies of patterns of divergence among populations (#CITATION_TAG & Owens, 2006). We therefore argue that, in order to provide to policymakers models that can accurately predict invasion risk, explicit evaluation of within-taxon niche structure and especially of association with humans in the native range is recommended."	3	Trait-based species risk assessments consider association with human-modified habitats in the native range to be a reliable predictor of invasion success (Keller et al., 2011), especially for mammals and birds (Jeschke & Strayer 2006). Our results show that applying a simple and universal variable such as the human footprint can considerably increase the accuracy of predictions of invasion risk, and this finding opens up real perspectives for devising and implementing more robust management strategies for a large number of invasive species. Information about the presence and geographical distribution of phylogeographic lineages may be not be readily available for all invasive species, but subspecies range maps can often be derived from the literature, at least for terrestrial vertebrates. Subspecies are generally based on discontinuities in the geographical distribution of phenotypic traits instead of molecular phylogenies, but can generally be considered useful proxies of patterns of divergence among populations (#CITATION_TAG & Owens, 2006). We therefore argue that, in order to provide to policymakers models that can accurately predict invasion risk, explicit evaluation of within-taxon niche structure and especially of association with humans in the native range is recommended.	e
CCT459	"Given its strong effect on the accuracy of predictions of invasion risk, incorporating information on association with human-modified habitats in the native range should be integrated into bioclimatic envelope models, if they are to effectively guide invasive species management. Association with human-modified habitats in the native range may enable ringnecked parakeets to exploit equivalent human-modified landscapes in Europe, allowing them to colonize areas far colder than their native range. Ring-necked parakeets have almost 90% of their invasive distribution outside their native climatic niche (Fig. 1), and this is among the highest values of niche expansion known for vertebrates (Strubbe et al., 2013;Li et al., 2014). Previous studies suggest niche expansion into climates not occupied in the native range is more likely for species with small native ranges (plants, Early & Sax, 2014;amphibians and reptiles, Li et al., 2014), for species introduced longer ago or that have invaded areas located at lower latitudes than the native range (amphibians and reptiles, Early & Sax, 2014). Ring-necked parakeets, however, have a very large native range and have been introduced relatively recent (most European introductions stem from after 1970, Strubbe & Matthysen, 2009b) to much higher latitudes than their native range. Our results thus identify, for the first time, association with humans in the native range as a factor influencing climatic niche expansion during biological invasion. Climate influences species distributions directly through species"" physiological tolerances or indirectly through its effect on available habitats, food resources and biotic interactions such as the presence of competitors (Ara ujo & Peterson, 2012, Wisz et al. 2013. The fact that ring-necked parakeets thrive in Europe suggests they may be physiologically capable of colonizing colder parts of the climate space in their native range as well. Possibly, a lack of resources and/or competition with congeneric species such as slaty-headed (P. himalayana) and Lord Derby""s Parakeet (P. derbiana) restricts the ring-necked parakeets"" native northernmost distribution limits. Indeed, endotherms such as birds are often able to tolerate a wide range of environmental conditions, but this comes at a potentially high energetic cost (#CITATION_TAG & Kearney, 2009). In Europe, radio-tracking (Clergeau & Vergnes, 2011;Strubbe & Matthysen, 2011) and habitat selection studies (Strubbe & Matthysen, 2007;Newson et al., 2010) indicate that parakeets prefer to forage in city parks and gardens, where bird feeders and ornamental vegetation present parakeets with abundant food. Urban areas also offer an Figure 3 Predictions of invasion risk for ring-necked parakeet in Europe derived from bioclimatic envelope models including association with human-modified habitats in the native range. Continuous model outputs (Fig. 2) were converted to binary predictions of invasion risk. Areas at risk according to both models without (see Fig. 2c) and with (see Fig. 2d) phylogeographic structure are indicated in red. Green indicates predicted parakeet presence only by a model without phylogeographic structure. Yellow delineates areas only marked as suitable by a model with phylogeographic structure. abundance of suitable nesting sites, as large, old trees are often retained for their aesthetic value. In the colder parts of Europe, parakeets increasingly breed in holes and crevices within the thermal insulation layers of buildings; in Germany, for example, such a more favourable microclimate enables them to achieve a higher breeding success compared to natural cavities (Braun, 2007). Moreover, in urban gardens, parakeets have been shown to be behaviourally dominant over native birds during foraging (Peck et al., 2014). Abundant resources and a lack of competitors may underlie the invasion success of ringnecked parakeets in environments far removed from their native (realized) niche. Yet, to elucidate the extent to which thermal and energetic constraints influence ring-necked parakeet distributional limits in their native versus non-native ranges, mechanistic niche models (which use species"" functional traits and physiological tolerances for model fitting, Kearney et al., 2010) are required. Furthermore, although little is known about interactions between Psittacula species in their native range, the hypothesis of competitive release as an underlying driver of ring-necked parakeet invasion success in Europe may be tested by assessing whether predicted geographical distribution patterns across the native range (derived from bioclimatic models) match expectations under competitive exclusion (sensu Guti errez et al., 2014)."	0	"Possibly, a lack of resources and/or competition with congeneric species such as slaty-headed (P. himalayana) and Lord Derby""s Parakeet (P. derbiana) restricts the ring-necked parakeets"" native northernmost distribution limits. Indeed, endotherms such as birds are often able to tolerate a wide range of environmental conditions, but this comes at a potentially high energetic cost (#CITATION_TAG & Kearney, 2009). In Europe, radio-tracking (Clergeau & Vergnes, 2011;Strubbe & Matthysen, 2011) and habitat selection studies (Strubbe & Matthysen, 2007;Newson et al., 2010) indicate that parakeets prefer to forage in city parks and gardens, where bird feeders and ornamental vegetation present parakeets with abundant food. Urban areas also offer an Figure 3 Predictions of invasion risk for ring-necked parakeet in Europe derived from bioclimatic envelope models including association with human-modified habitats in the native range. Continuous model outputs (Fig. 2) were converted to binary predictions of invasion risk."	o
CCT460	"Therefore, we assess three key assumptions underlying bioclimatic envelope models: (1) that species"" distributions are largely governed by climate (Ara ujo & Peterson, 2012), (2) that a species"" current native distribution corresponds with the total set of climate conditions under which it can persist (Peterson, 2003) and (3) that the climatic niche remains conserved across time and space (Broennimann et al., 2007). Climate is generally recognized as a chief driver of species"" distributions at large spatial scales (Ara ujo & Peterson, 2012), although the broad distributional limits governed by climate may be modified by factors such as habitat availability, biotic interactions and dispersal limitations (Soberon, 2007). Erroneous predictions of the potential distribution of invasive species are often attributed to species adaptations in response to selection pressures imposed by the novel environment (Whitney & Gabler, 2008). However, within the native range, species may also evolve pre-adaptations to invasiveness; strong selection imposed by human modification of habitats within the native range is likely to lead to adaptation prior to introduction elsewhere (Hufbauer et al., 2012). As human activities tend to promote similar ecological conditions across biogeographical areas (#CITATION_TAG et al., 2000), species or populations associated with human-modified habitats in the native range can be expected to successfully invade similar areas elsewhere. It is therefore surprising that predic-tions of invasion risk obtained from bioclimatic envelope models have not yet explicitly considered how human modification of habitats might modify distributional limits set by climate."	0	"Climate is generally recognized as a chief driver of species"" distributions at large spatial scales (Ara ujo & Peterson, 2012), although the broad distributional limits governed by climate may be modified by factors such as habitat availability, biotic interactions and dispersal limitations (Soberon, 2007). Erroneous predictions of the potential distribution of invasive species are often attributed to species adaptations in response to selection pressures imposed by the novel environment (Whitney & Gabler, 2008). However, within the native range, species may also evolve pre-adaptations to invasiveness; strong selection imposed by human modification of habitats within the native range is likely to lead to adaptation prior to introduction elsewhere (Hufbauer et al., 2012). As human activities tend to promote similar ecological conditions across biogeographical areas (#CITATION_TAG et al., 2000), species or populations associated with human-modified habitats in the native range can be expected to successfully invade similar areas elsewhere. It is therefore surprising that predic-tions of invasion risk obtained from bioclimatic envelope models have not yet explicitly considered how human modification of habitats might modify distributional limits set by climate."	u
CCT461	To identify native phylogroups, Bayesian phylogenetic inference was implemented in MRBAYES v3.2 (#CITATION_TAG & Huelsenbeck, 2003) using the CIPRES Science Gateway (Miller et al., 2010) with 10 million generations over four parallel Monte Carlo Markov chains (MCMC), under an HKY evolutionary model (Felsenstein, 1981). TRACER v1.6 (Rambaut & Drummond, 2007) was used to assess convergence. After discarding the first 25% as burn-in, tree topologies were summarized in a 50% consensus tree. To identify native haplotypes in the invasive range, the combined native and invasive dataset was condensed into haplotypes using TCS (Clement et al., 2000). All node values with a posterior probability of > 50 were used to identify phylogroups.	5	To identify native phylogroups, Bayesian phylogenetic inference was implemented in MRBAYES v3.2 (#CITATION_TAG & Huelsenbeck, 2003) using the CIPRES Science Gateway (Miller et al., 2010) with 10 million generations over four parallel Monte Carlo Markov chains (MCMC), under an HKY evolutionary model (Felsenstein, 1981). TRACER v1.6 (Rambaut & Drummond, 2007) was used to assess convergence. After discarding the first 25% as burn-in, tree topologies were summarized in a 50% consensus tree. To identify native haplotypes in the invasive range, the combined native and invasive dataset was condensed into haplotypes using TCS (Clement et al., 2000).	T
CCT462	"Environmental variables considered are a set of eight climatic variables assumed to impose direct and indirect constraints on avian distributions (Ara ujo et al., 2009): annual mean temperature (bio_1), mean temperature of the warmest month (t_max), mean temperature of the coldest month (t_min), temperature seasonality (bio_4), annual precipitation (bio_12), precipitation of the wettest month (bio_13), precipitation of the driest month (bio_14) and precipitation seasonality (bio_15). These variables were derived from the WorldClim database (Hijmans et al., 2005) and represent mean values over the 1961-1990 period at a 0.083¬∞resolution. The ""human footprint"" a quantitative measure of human alteration of terrestrial environments based on human population size, land use and infrastructure was derived from #CITATION_TAG et al. (2002) at a resolution of 30‚Ä≥ and resampled to the 0.083¬∞resolution of the climate and parakeet occurrence data."	5	"Environmental variables considered are a set of eight climatic variables assumed to impose direct and indirect constraints on avian distributions (Ara ujo et al., 2009): annual mean temperature (bio_1), mean temperature of the warmest month (t_max), mean temperature of the coldest month (t_min), temperature seasonality (bio_4), annual precipitation (bio_12), precipitation of the wettest month (bio_13), precipitation of the driest month (bio_14) and precipitation seasonality (bio_15). These variables were derived from the WorldClim database (Hijmans et al., 2005) and represent mean values over the 1961-1990 period at a 0.083¬∞resolution. The ""human footprint"" a quantitative measure of human alteration of terrestrial environments based on human population size, land use and infrastructure was derived from #CITATION_TAG et al. (2002) at a resolution of 30‚Ä≥ and resampled to the 0.083¬∞resolution of the climate and parakeet occurrence data."	e
CCT463	"The fact that lineages associated with cold climates in the native range are more prevalent across Europe suggests that these lineages may be better adapted to European climates. Such an invasion scenario has been found before; for example, Rey et al. (2012) showed that the invasion of Mediterranean Israel by the tropical ant Wasmannia auropunctata could be explained by adaptation to cold at the southern limit of the native range before introduction to Israel. Yet, although large numbers of parakeets from both Africa and Asia have been imported to Europe (#CITATION_TAG, 1993), more detailed knowledge on propagule pressure is required to rule out alternative explanations such as the possibility that more birds originating from colder parts of the native rang have escaped or been released across Europe. Also, it should be noted that our phylogeny is based on a set of neutral genetic markers and that consequently, patterns of within-taxon niche variation may be due to regional differences in available climates, to adaptation to local environments or to other drivers such as biotic interactions. However, populations are often adapted to local environments and genotypeby-environment interactions are common in widespread species (Pearman et al., 2010). This study is the first fine-scale assessment of ring-necked parakeet genetic structure, but differences among lineages in morphology and life history traits such as timing of reproduction have been reported within and between Africa and Asia (Forshaw, 1978). Such traits may be genetically based and therefore likely to respond to selection (Bradshaw & Holzapfel, 2006) in the parakeet""s invasive range. Indeed, variance in laying dates between European and native (Asian) parakeet populations suggests that in Europe, parakeets are delaying their breeding in response to colder temperatures (Shwartz et al., 2009). These differences in morphology, life history and occupied climates suggest parakeet mtDNA-derived lineages may indeed diverge in features supplementary to the neutral genetic markers used to identify phylogeographic structure. Our results thus suggest the clade model captures lineage-specific responses to environmental gradients that are undetectable using the clade model (Appendix S8). Incorporating such within-taxon niche structure into bioclimatic envelope models only slightly increased model predictive accuracy, but nonetheless leads to important differences in spatial predictions of invasion risk for Europe (Figs 2 & 3). The climate-only clade model is strongly influenced by precipitation gradients (Appendix S8), resulting in erroneous predictions of parakeet occurrence for Europe""s wetter areas (i.e. parts of the Atlantic and Adriatic coast, and along mountain chains, Fig. 2a). The climate-only subclade model indicates certain phylogeographic lineages indeed respond strongly to precipitation gradients (Appendix S8), although in general, the subclade model is more strongly driven by temperature gradients. The climate-only subclade model accordingly correctly predicts some of the Mediterranean parakeet populations, and except for a high precipitation zone along the coast of Norway, it assigns a low invasion risk to coastal areas and mountain chains (Fig. 2b). Both climate-only models, however, fail to accurately forecast ringnecked parakeet occurrence across north-west Europe. When including the human footprint, the major difference between the clade and subclade model is that the latter places more weight on temperature and precipitation gradients (Appendix S8), whereas the clade model exhibits a higher dependency on human footprint. Consequently, the clade model predicts a higher invasion risk across human-dominated habitats in colder parts of continental Europe (Fig. 2c, d) as well. This becomes especially apparent when converting the predictions of invasion risk into discrete predictions of parakeet presence and absence (Fig. 3), showing that particularly in east and central Europe, the clade model predicts as suitable areas that are geographically peripheral to areas predicted as suitable by the subclade model. In contrast, in southern Europe, the subclade model predicts more extensive areas to be at risk of parakeet invasion, reflecting the different weightings given by the clade and subclade model to climate and human modification of habitats."	0	The fact that lineages associated with cold climates in the native range are more prevalent across Europe suggests that these lineages may be better adapted to European climates. Such an invasion scenario has been found before; for example, Rey et al. (2012) showed that the invasion of Mediterranean Israel by the tropical ant Wasmannia auropunctata could be explained by adaptation to cold at the southern limit of the native range before introduction to Israel. Yet, although large numbers of parakeets from both Africa and Asia have been imported to Europe (#CITATION_TAG, 1993), more detailed knowledge on propagule pressure is required to rule out alternative explanations such as the possibility that more birds originating from colder parts of the native rang have escaped or been released across Europe. Also, it should be noted that our phylogeny is based on a set of neutral genetic markers and that consequently, patterns of within-taxon niche variation may be due to regional differences in available climates, to adaptation to local environments or to other drivers such as biotic interactions. However, populations are often adapted to local environments and genotypeby-environment interactions are common in widespread species (Pearman et al., 2010). This study is the first fine-scale assessment of ring-necked parakeet genetic structure, but differences among lineages in morphology and life history traits such as timing of reproduction have been reported within and between Africa and Asia (Forshaw, 1978).	t
CCT464	"The fact that lineages associated with cold climates in the native range are more prevalent across Europe suggests that these lineages may be better adapted to European climates. Such an invasion scenario has been found before; for example, Rey et al. (2012) showed that the invasion of Mediterranean Israel by the tropical ant Wasmannia auropunctata could be explained by adaptation to cold at the southern limit of the native range before introduction to Israel. Yet, although large numbers of parakeets from both Africa and Asia have been imported to Europe (Morgan, 1993), more detailed knowledge on propagule pressure is required to rule out alternative explanations such as the possibility that more birds originating from colder parts of the native rang have escaped or been released across Europe. Also, it should be noted that our phylogeny is based on a set of neutral genetic markers and that consequently, patterns of within-taxon niche variation may be due to regional differences in available climates, to adaptation to local environments or to other drivers such as biotic interactions. However, populations are often adapted to local environments and genotypeby-environment interactions are common in widespread species (Pearman et al., 2010). This study is the first fine-scale assessment of ring-necked parakeet genetic structure, but differences among lineages in morphology and life history traits such as timing of reproduction have been reported within and between Africa and Asia (Forshaw, 1978). Such traits may be genetically based and therefore likely to respond to selection (Bradshaw & Holzapfel, 2006) in the parakeet""s invasive range. Indeed, variance in laying dates between European and native (Asian) parakeet populations suggests that in Europe, parakeets are delaying their breeding in response to colder temperatures (#CITATION_TAG et al., 2009). These differences in morphology, life history and occupied climates suggest parakeet mtDNA-derived lineages may indeed diverge in features supplementary to the neutral genetic markers used to identify phylogeographic structure. Our results thus suggest the clade model captures lineage-specific responses to environmental gradients that are undetectable using the clade model (Appendix S8). Incorporating such within-taxon niche structure into bioclimatic envelope models only slightly increased model predictive accuracy, but nonetheless leads to important differences in spatial predictions of invasion risk for Europe (Figs 2 & 3). The climate-only clade model is strongly influenced by precipitation gradients (Appendix S8), resulting in erroneous predictions of parakeet occurrence for Europe""s wetter areas (i.e. parts of the Atlantic and Adriatic coast, and along mountain chains, Fig. 2a). The climate-only subclade model indicates certain phylogeographic lineages indeed respond strongly to precipitation gradients (Appendix S8), although in general, the subclade model is more strongly driven by temperature gradients. The climate-only subclade model accordingly correctly predicts some of the Mediterranean parakeet populations, and except for a high precipitation zone along the coast of Norway, it assigns a low invasion risk to coastal areas and mountain chains (Fig. 2b). Both climate-only models, however, fail to accurately forecast ringnecked parakeet occurrence across north-west Europe. When including the human footprint, the major difference between the clade and subclade model is that the latter places more weight on temperature and precipitation gradients (Appendix S8), whereas the clade model exhibits a higher dependency on human footprint. Consequently, the clade model predicts a higher invasion risk across human-dominated habitats in colder parts of continental Europe (Fig. 2c, d) as well. This becomes especially apparent when converting the predictions of invasion risk into discrete predictions of parakeet presence and absence (Fig. 3), showing that particularly in east and central Europe, the clade model predicts as suitable areas that are geographically peripheral to areas predicted as suitable by the subclade model. In contrast, in southern Europe, the subclade model predicts more extensive areas to be at risk of parakeet invasion, reflecting the different weightings given by the clade and subclade model to climate and human modification of habitats."	0	"However, populations are often adapted to local environments and genotypeby-environment interactions are common in widespread species (Pearman et al., 2010). This study is the first fine-scale assessment of ring-necked parakeet genetic structure, but differences among lineages in morphology and life history traits such as timing of reproduction have been reported within and between Africa and Asia (Forshaw, 1978). Such traits may be genetically based and therefore likely to respond to selection (Bradshaw & Holzapfel, 2006) in the parakeet""s invasive range. Indeed, variance in laying dates between European and native (Asian) parakeet populations suggests that in Europe, parakeets are delaying their breeding in response to colder temperatures (#CITATION_TAG et al., 2009). These differences in morphology, life history and occupied climates suggest parakeet mtDNA-derived lineages may indeed diverge in features supplementary to the neutral genetic markers used to identify phylogeographic structure. Our results thus suggest the clade model captures lineage-specific responses to environmental gradients that are undetectable using the clade model (Appendix S8). Incorporating such within-taxon niche structure into bioclimatic envelope models only slightly increased model predictive accuracy, but nonetheless leads to important differences in spatial predictions of invasion risk for Europe (Figs 2 & 3)."	 
CCT465	"Therefore, we assess three key assumptions underlying bioclimatic envelope models: (1) that species"" distributions are largely governed by climate (Ara ujo & Peterson, 2012), (2) that a species"" current native distribution corresponds with the total set of climate conditions under which it can persist (Peterson, 2003) and (3) that the climatic niche remains conserved across time and space (Broennimann et al., 2007). Climate is generally recognized as a chief driver of species"" distributions at large spatial scales (Ara ujo & Peterson, 2012), although the broad distributional limits governed by climate may be modified by factors such as habitat availability, biotic interactions and dispersal limitations (#CITATION_TAG, 2007). Erroneous predictions of the potential distribution of invasive species are often attributed to species adaptations in response to selection pressures imposed by the novel environment (Whitney & Gabler, 2008). However, within the native range, species may also evolve pre-adaptations to invasiveness; strong selection imposed by human modification of habitats within the native range is likely to lead to adaptation prior to introduction elsewhere (Hufbauer et al., 2012). As human activities tend to promote similar ecological conditions across biogeographical areas (Savard et al., 2000), species or populations associated with human-modified habitats in the native range can be expected to successfully invade similar areas elsewhere. It is therefore surprising that predic-tions of invasion risk obtained from bioclimatic envelope models have not yet explicitly considered how human modification of habitats might modify distributional limits set by climate."	0	"Therefore, we assess three key assumptions underlying bioclimatic envelope models: (1) that species"" distributions are largely governed by climate (Ara ujo & Peterson, 2012), (2) that a species"" current native distribution corresponds with the total set of climate conditions under which it can persist (Peterson, 2003) and (3) that the climatic niche remains conserved across time and space (Broennimann et al., 2007). Climate is generally recognized as a chief driver of species"" distributions at large spatial scales (Ara ujo & Peterson, 2012), although the broad distributional limits governed by climate may be modified by factors such as habitat availability, biotic interactions and dispersal limitations (#CITATION_TAG, 2007). Erroneous predictions of the potential distribution of invasive species are often attributed to species adaptations in response to selection pressures imposed by the novel environment (Whitney & Gabler, 2008). However, within the native range, species may also evolve pre-adaptations to invasiveness; strong selection imposed by human modification of habitats within the native range is likely to lead to adaptation prior to introduction elsewhere (Hufbauer et al., 2012). As human activities tend to promote similar ecological conditions across biogeographical areas (Savard et al., 2000), species or populations associated with human-modified habitats in the native range can be expected to successfully invade similar areas elsewhere."	l
CCT466	"Given its strong effect on the accuracy of predictions of invasion risk, incorporating information on association with human-modified habitats in the native range should be integrated into bioclimatic envelope models, if they are to effectively guide invasive species management. Association with human-modified habitats in the native range may enable ringnecked parakeets to exploit equivalent human-modified landscapes in Europe, allowing them to colonize areas far colder than their native range. Ring-necked parakeets have almost 90% of their invasive distribution outside their native climatic niche (Fig. 1), and this is among the highest values of niche expansion known for vertebrates (Strubbe et al., 2013;Li et al., 2014). Previous studies suggest niche expansion into climates not occupied in the native range is more likely for species with small native ranges (plants, Early & Sax, 2014;amphibians and reptiles, Li et al., 2014), for species introduced longer ago or that have invaded areas located at lower latitudes than the native range (amphibians and reptiles, Early & Sax, 2014). Ring-necked parakeets, however, have a very large native range and have been introduced relatively recent (most European introductions stem from after 1970, Strubbe & Matthysen, 2009b) to much higher latitudes than their native range. Our results thus identify, for the first time, association with humans in the native range as a factor influencing climatic niche expansion during biological invasion. Climate influences species distributions directly through species"" physiological tolerances or indirectly through its effect on available habitats, food resources and biotic interactions such as the presence of competitors (Ara ujo & Peterson, 2012, Wisz et al. 2013. The fact that ring-necked parakeets thrive in Europe suggests they may be physiologically capable of colonizing colder parts of the climate space in their native range as well. Possibly, a lack of resources and/or competition with congeneric species such as slaty-headed (P. himalayana) and Lord Derby""s Parakeet (P. derbiana) restricts the ring-necked parakeets"" native northernmost distribution limits. Indeed, endotherms such as birds are often able to tolerate a wide range of environmental conditions, but this comes at a potentially high energetic cost (Porter & Kearney, 2009). In Europe, radio-tracking (Clergeau & Vergnes, 2011;Strubbe & Matthysen, 2011) and habitat selection studies (#CITATION_TAG & Matthysen, 2007;Newson et al., 2010) indicate that parakeets prefer to forage in city parks and gardens, where bird feeders and ornamental vegetation present parakeets with abundant food. Urban areas also offer an Figure 3 Predictions of invasion risk for ring-necked parakeet in Europe derived from bioclimatic envelope models including association with human-modified habitats in the native range. Continuous model outputs (Fig. 2) were converted to binary predictions of invasion risk. Areas at risk according to both models without (see Fig. 2c) and with (see Fig. 2d) phylogeographic structure are indicated in red. Green indicates predicted parakeet presence only by a model without phylogeographic structure. Yellow delineates areas only marked as suitable by a model with phylogeographic structure. abundance of suitable nesting sites, as large, old trees are often retained for their aesthetic value. In the colder parts of Europe, parakeets increasingly breed in holes and crevices within the thermal insulation layers of buildings; in Germany, for example, such a more favourable microclimate enables them to achieve a higher breeding success compared to natural cavities (Braun, 2007). Moreover, in urban gardens, parakeets have been shown to be behaviourally dominant over native birds during foraging (Peck et al., 2014). Abundant resources and a lack of competitors may underlie the invasion success of ringnecked parakeets in environments far removed from their native (realized) niche. Yet, to elucidate the extent to which thermal and energetic constraints influence ring-necked parakeet distributional limits in their native versus non-native ranges, mechanistic niche models (which use species"" functional traits and physiological tolerances for model fitting, Kearney et al., 2010) are required. Furthermore, although little is known about interactions between Psittacula species in their native range, the hypothesis of competitive release as an underlying driver of ring-necked parakeet invasion success in Europe may be tested by assessing whether predicted geographical distribution patterns across the native range (derived from bioclimatic models) match expectations under competitive exclusion (sensu Guti errez et al., 2014)."	0	"himalayana) and Lord Derby""s Parakeet (P. derbiana) restricts the ring-necked parakeets"" native northernmost distribution limits. Indeed, endotherms such as birds are often able to tolerate a wide range of environmental conditions, but this comes at a potentially high energetic cost (Porter & Kearney, 2009). In Europe, radio-tracking (Clergeau & Vergnes, 2011;Strubbe & Matthysen, 2011) and habitat selection studies (#CITATION_TAG & Matthysen, 2007;Newson et al., 2010) indicate that parakeets prefer to forage in city parks and gardens, where bird feeders and ornamental vegetation present parakeets with abundant food. Urban areas also offer an Figure 3 Predictions of invasion risk for ring-necked parakeet in Europe derived from bioclimatic envelope models including association with human-modified habitats in the native range. Continuous model outputs (Fig. 2) were converted to binary predictions of invasion risk. Areas at risk according to both models without (see Fig. 2c) and with (see Fig. 2d) phylogeographic structure are indicated in red."	a
CCT467	"Here, using a unique dataset on the distribution of a global avian invader, the ring-necked parakeet (Psittacula krameri), we test whether accounting for within-taxon niche structure and association with humans in the native range leads to more accurate predictions of invasion risk. Ringnecked parakeets are native to large parts of Africa and Asia. Across their native range, they have benefited from the conversion of natural habitats to agro-ecosystems (Bruggers & Beck, 1979;Khan, 2002) and reach their highest breeding densities near human settlements and cultivated crops (Khan et al., 2004). These parakeets are a globally widespread invasive species, and they compete with native birds and bats and cause damage to crops (#CITATION_TAG & Matthysen, 2009a;Hern andez-Brito et al., 2014;Peck et al., 2014). In this study, we present the most complete information on the distribution of ring-necked parakeets to date, comprising a set of about 1200 (686 native and 513 invasive) occurrences collected at a finer resolution than has previously been reported, 123 failed and successful introduction events across Europe, plus a high-resolution mtDNA molecular phylogeny derived from 98 museum specimens geospatially selected to cover the parakeet""s native range and from feather samples collected at 13 invaded sites across Europe. We expect that incorporating within-taxon niche structure into bioclimatic envelope models will result in important differences in the geographical distribution of climate predicted as suitable for parakeets across Europe and that accounting for association with human-modified habitats in the native range will allow for more accurate predictions of the potential European distribution of this ubiquitous avian invader."	0	"Here, using a unique dataset on the distribution of a global avian invader, the ring-necked parakeet (Psittacula krameri), we test whether accounting for within-taxon niche structure and association with humans in the native range leads to more accurate predictions of invasion risk. Ringnecked parakeets are native to large parts of Africa and Asia. Across their native range, they have benefited from the conversion of natural habitats to agro-ecosystems (Bruggers & Beck, 1979;Khan, 2002) and reach their highest breeding densities near human settlements and cultivated crops (Khan et al., 2004). These parakeets are a globally widespread invasive species, and they compete with native birds and bats and cause damage to crops (#CITATION_TAG & Matthysen, 2009a;Hern andez-Brito et al., 2014;Peck et al., 2014). In this study, we present the most complete information on the distribution of ring-necked parakeets to date, comprising a set of about 1200 (686 native and 513 invasive) occurrences collected at a finer resolution than has previously been reported, 123 failed and successful introduction events across Europe, plus a high-resolution mtDNA molecular phylogeny derived from 98 museum specimens geospatially selected to cover the parakeet""s native range and from feather samples collected at 13 invaded sites across Europe. We expect that incorporating within-taxon niche structure into bioclimatic envelope models will result in important differences in the geographical distribution of climate predicted as suitable for parakeets across Europe and that accounting for association with human-modified habitats in the native range will allow for more accurate predictions of the potential European distribution of this ubiquitous avian invader."	s
CCT468	"Taken together, our results agree with other findings (Strubbe et al., 2013(#CITATION_TAG et al., , 2014Early & Sax, 2014;Guisan et al., 2014;Li et al., 2014), suggesting that while rapid post-introduction evolution (i.e. a change in the fundamental Grinnellian niche, Soberon, 2007) cannot be ruled out, climatic niche differences between native and invasive ranges are probably related to ecological factors governing the occupancy of the fundamental niche in native versus invaded ranges. This has important ramifications for the use of bioclimatic envelope models as risk assessment tools, as well as, more fundamentally, for understanding how climate and local factors interact to determine species"" distributions. Pearson & Dawson (2003) suggested a hierarchical approach to modelling environment-biota relationships whereby bioclimatic envelope models should form the first step, identifying the broad outlines of species"" distributions. Within the area designated as climatically suitable for a species, models including factors such as land cover and habitat preferences can then be applied to elucidate the finegrained structure of distributions. We suggest that, at least for invasive species, this framework may not be universally applicable, as association with human-modified habitats in the native range may allow species to overcome their (realized) native-range climatic limitations in human-modified landscapes elsewhere. Trait-based species risk assessments consider association with human-modified habitats in the native range to be a reliable predictor of invasion success (Keller et al., 2011), especially for mammals and birds (Jeschke & Strayer 2006). Our results show that applying a simple and universal variable such as the human footprint can considerably increase the accuracy of predictions of invasion risk, and this finding opens up real perspectives for devising and implementing more robust management strategies for a large number of invasive species. Information about the presence and geographical distribution of phylogeographic lineages may be not be readily available for all invasive species, but subspecies range maps can often be derived from the literature, at least for terrestrial vertebrates. Subspecies are generally based on discontinuities in the geographical distribution of phenotypic traits instead of molecular phylogenies, but can generally be considered useful proxies of patterns of divergence among populations (Phillimore & Owens, 2006). We therefore argue that, in order to provide to policymakers models that can accurately predict invasion risk, explicit evaluation of within-taxon niche structure and especially of association with humans in the native range is recommended."	1	"Taken together, our results agree with other findings (Strubbe et al., 2013(#CITATION_TAG et al., , 2014Early & Sax, 2014;Guisan et al., 2014;Li et al., 2014), suggesting that while rapid post-introduction evolution (i.e. a change in the fundamental Grinnellian niche, Soberon, 2007) cannot be ruled out, climatic niche differences between native and invasive ranges are probably related to ecological factors governing the occupancy of the fundamental niche in native versus invaded ranges. This has important ramifications for the use of bioclimatic envelope models as risk assessment tools, as well as, more fundamentally, for understanding how climate and local factors interact to determine species"" distributions. Pearson & Dawson (2003) suggested a hierarchical approach to modelling environment-biota relationships whereby bioclimatic envelope models should form the first step, identifying the broad outlines of species"" distributions. Within the area designated as climatically suitable for a species, models including factors such as land cover and habitat preferences can then be applied to elucidate the finegrained structure of distributions."	T
CCT469	"Therefore, we assess three key assumptions underlying bioclimatic envelope models: (1) that species"" distributions are largely governed by climate (Ara ujo & Peterson, 2012), (2) that a species"" current native distribution corresponds with the total set of climate conditions under which it can persist (Peterson, 2003) and (3) that the climatic niche remains conserved across time and space (Broennimann et al., 2007). Climate is generally recognized as a chief driver of species"" distributions at large spatial scales (Ara ujo & Peterson, 2012), although the broad distributional limits governed by climate may be modified by factors such as habitat availability, biotic interactions and dispersal limitations (Soberon, 2007). Erroneous predictions of the potential distribution of invasive species are often attributed to species adaptations in response to selection pressures imposed by the novel environment (#CITATION_TAG & Gabler, 2008). However, within the native range, species may also evolve pre-adaptations to invasiveness; strong selection imposed by human modification of habitats within the native range is likely to lead to adaptation prior to introduction elsewhere (Hufbauer et al., 2012). As human activities tend to promote similar ecological conditions across biogeographical areas (Savard et al., 2000), species or populations associated with human-modified habitats in the native range can be expected to successfully invade similar areas elsewhere. It is therefore surprising that predic-tions of invasion risk obtained from bioclimatic envelope models have not yet explicitly considered how human modification of habitats might modify distributional limits set by climate."	0	"Therefore, we assess three key assumptions underlying bioclimatic envelope models: (1) that species"" distributions are largely governed by climate (Ara ujo & Peterson, 2012), (2) that a species"" current native distribution corresponds with the total set of climate conditions under which it can persist (Peterson, 2003) and (3) that the climatic niche remains conserved across time and space (Broennimann et al., 2007). Climate is generally recognized as a chief driver of species"" distributions at large spatial scales (Ara ujo & Peterson, 2012), although the broad distributional limits governed by climate may be modified by factors such as habitat availability, biotic interactions and dispersal limitations (Soberon, 2007). Erroneous predictions of the potential distribution of invasive species are often attributed to species adaptations in response to selection pressures imposed by the novel environment (#CITATION_TAG & Gabler, 2008). However, within the native range, species may also evolve pre-adaptations to invasiveness; strong selection imposed by human modification of habitats within the native range is likely to lead to adaptation prior to introduction elsewhere (Hufbauer et al., 2012). As human activities tend to promote similar ecological conditions across biogeographical areas (Savard et al., 2000), species or populations associated with human-modified habitats in the native range can be expected to successfully invade similar areas elsewhere. It is therefore surprising that predic-tions of invasion risk obtained from bioclimatic envelope models have not yet explicitly considered how human modification of habitats might modify distributional limits set by climate."	r
CCT470	Bioclimatic envelope models were run in R (R Core Team, 2014) using the ensemble modelling framework biomod2 (Thuiller et al., 2013). We applied five different modelling algorithms: generalized linear models (GLM), generalized boosted models (GBM), multivariate adaptive regression splines (MARS), random forest (RF) and maximum entropy (MAXENT) to identify areas at risk of invasion. Models were fitted with default settings unless stated otherwise. Models were run with a single set of 10,000 pseudo-absences drawn from the same native-range background area as used for the niche analyses described above. Pseudo-absences were generated randomly from all grid cells in background area that were not presences (#CITATION_TAG & Guisan 2009). For each modelling algorithm, presences and pseudo-absences used to calibrate the model were weighted such as to ensure neutral (0.5) prevalence (Petitpierre et al., 2012). Each model was subjected to 10-fold cross-validation with a 80-20% random split of the presence data for training-testing each replicate, respectively. Models were evaluated using the true skill statistic (TSS), and to exclude inaccurate models, only those with TSS > 0.7 were kept for generating ensemble projections (Thuiller et al., 2013) of parakeet invasion risk in Europe, using unweighted averaging across models. Relative variable importance (0-1) was obtained through the randomization procedure described by Thuiller et al. (2013).	5	We applied five different modelling algorithms: generalized linear models (GLM), generalized boosted models (GBM), multivariate adaptive regression splines (MARS), random forest (RF) and maximum entropy (MAXENT) to identify areas at risk of invasion. Models were fitted with default settings unless stated otherwise. Models were run with a single set of 10,000 pseudo-absences drawn from the same native-range background area as used for the niche analyses described above. Pseudo-absences were generated randomly from all grid cells in background area that were not presences (#CITATION_TAG & Guisan 2009). For each modelling algorithm, presences and pseudo-absences used to calibrate the model were weighted such as to ensure neutral (0.5) prevalence (Petitpierre et al., 2012). Each model was subjected to 10-fold cross-validation with a 80-20% random split of the presence data for training-testing each replicate, respectively. Models were evaluated using the true skill statistic (TSS), and to exclude inaccurate models, only those with TSS > 0.7 were kept for generating ensemble projections (Thuiller et al., 2013) of parakeet invasion risk in Europe, using unweighted averaging across models.	d
CCT471	"Given its strong effect on the accuracy of predictions of invasion risk, incorporating information on association with human-modified habitats in the native range should be integrated into bioclimatic envelope models, if they are to effectively guide invasive species management. Association with human-modified habitats in the native range may enable ringnecked parakeets to exploit equivalent human-modified landscapes in Europe, allowing them to colonize areas far colder than their native range. Ring-necked parakeets have almost 90% of their invasive distribution outside their native climatic niche (Fig. 1), and this is among the highest values of niche expansion known for vertebrates (Strubbe et al., 2013;Li et al., 2014). Previous studies suggest niche expansion into climates not occupied in the native range is more likely for species with small native ranges (plants, Early & Sax, 2014;amphibians and reptiles, Li et al., 2014), for species introduced longer ago or that have invaded areas located at lower latitudes than the native range (amphibians and reptiles, Early & Sax, 2014). Ring-necked parakeets, however, have a very large native range and have been introduced relatively recent (most European introductions stem from after 1970, Strubbe & Matthysen, 2009b) to much higher latitudes than their native range. Our results thus identify, for the first time, association with humans in the native range as a factor influencing climatic niche expansion during biological invasion. Climate influences species distributions directly through species"" physiological tolerances or indirectly through its effect on available habitats, food resources and biotic interactions such as the presence of competitors (Ara ujo & Peterson, 2012, Wisz et al. 2013. The fact that ring-necked parakeets thrive in Europe suggests they may be physiologically capable of colonizing colder parts of the climate space in their native range as well. Possibly, a lack of resources and/or competition with congeneric species such as slaty-headed (P. himalayana) and Lord Derby""s Parakeet (P. derbiana) restricts the ring-necked parakeets"" native northernmost distribution limits. Indeed, endotherms such as birds are often able to tolerate a wide range of environmental conditions, but this comes at a potentially high energetic cost (Porter & Kearney, 2009). In Europe, radio-tracking (Clergeau & Vergnes, 2011;Strubbe & Matthysen, 2011) and habitat selection studies (Strubbe & Matthysen, 2007;#CITATION_TAG et al., 2010) indicate that parakeets prefer to forage in city parks and gardens, where bird feeders and ornamental vegetation present parakeets with abundant food. Urban areas also offer an Figure 3 Predictions of invasion risk for ring-necked parakeet in Europe derived from bioclimatic envelope models including association with human-modified habitats in the native range. Continuous model outputs (Fig. 2) were converted to binary predictions of invasion risk. Areas at risk according to both models without (see Fig. 2c) and with (see Fig. 2d) phylogeographic structure are indicated in red. Green indicates predicted parakeet presence only by a model without phylogeographic structure. Yellow delineates areas only marked as suitable by a model with phylogeographic structure. abundance of suitable nesting sites, as large, old trees are often retained for their aesthetic value. In the colder parts of Europe, parakeets increasingly breed in holes and crevices within the thermal insulation layers of buildings; in Germany, for example, such a more favourable microclimate enables them to achieve a higher breeding success compared to natural cavities (Braun, 2007). Moreover, in urban gardens, parakeets have been shown to be behaviourally dominant over native birds during foraging (Peck et al., 2014). Abundant resources and a lack of competitors may underlie the invasion success of ringnecked parakeets in environments far removed from their native (realized) niche. Yet, to elucidate the extent to which thermal and energetic constraints influence ring-necked parakeet distributional limits in their native versus non-native ranges, mechanistic niche models (which use species"" functional traits and physiological tolerances for model fitting, Kearney et al., 2010) are required. Furthermore, although little is known about interactions between Psittacula species in their native range, the hypothesis of competitive release as an underlying driver of ring-necked parakeet invasion success in Europe may be tested by assessing whether predicted geographical distribution patterns across the native range (derived from bioclimatic models) match expectations under competitive exclusion (sensu Guti errez et al., 2014)."	0	"himalayana) and Lord Derby""s Parakeet (P. derbiana) restricts the ring-necked parakeets"" native northernmost distribution limits. Indeed, endotherms such as birds are often able to tolerate a wide range of environmental conditions, but this comes at a potentially high energetic cost (Porter & Kearney, 2009). In Europe, radio-tracking (Clergeau & Vergnes, 2011;Strubbe & Matthysen, 2011) and habitat selection studies (Strubbe & Matthysen, 2007;#CITATION_TAG et al., 2010) indicate that parakeets prefer to forage in city parks and gardens, where bird feeders and ornamental vegetation present parakeets with abundant food. Urban areas also offer an Figure 3 Predictions of invasion risk for ring-necked parakeet in Europe derived from bioclimatic envelope models including association with human-modified habitats in the native range. Continuous model outputs (Fig. 2) were converted to binary predictions of invasion risk. Areas at risk according to both models without (see Fig. 2c) and with (see Fig. 2d) phylogeographic structure are indicated in red."	a
CCT472	"Given its strong effect on the accuracy of predictions of invasion risk, incorporating information on association with human-modified habitats in the native range should be integrated into bioclimatic envelope models, if they are to effectively guide invasive species management. Association with human-modified habitats in the native range may enable ringnecked parakeets to exploit equivalent human-modified landscapes in Europe, allowing them to colonize areas far colder than their native range. Ring-necked parakeets have almost 90% of their invasive distribution outside their native climatic niche (Fig. 1), and this is among the highest values of niche expansion known for vertebrates (Strubbe et al., 2013;Li et al., 2014). Previous studies suggest niche expansion into climates not occupied in the native range is more likely for species with small native ranges (plants, Early & Sax, 2014;amphibians and reptiles, Li et al., 2014), for species introduced longer ago or that have invaded areas located at lower latitudes than the native range (amphibians and reptiles, Early & Sax, 2014). Ring-necked parakeets, however, have a very large native range and have been introduced relatively recent (most European introductions stem from after 1970, Strubbe & Matthysen, 2009b) to much higher latitudes than their native range. Our results thus identify, for the first time, association with humans in the native range as a factor influencing climatic niche expansion during biological invasion. Climate influences species distributions directly through species"" physiological tolerances or indirectly through its effect on available habitats, food resources and biotic interactions such as the presence of competitors (Ara ujo & Peterson, 2012, #CITATION_TAG et al. 2013. The fact that ring-necked parakeets thrive in Europe suggests they may be physiologically capable of colonizing colder parts of the climate space in their native range as well. Possibly, a lack of resources and/or competition with congeneric species such as slaty-headed (P. himalayana) and Lord Derby""s Parakeet (P. derbiana) restricts the ring-necked parakeets"" native northernmost distribution limits. Indeed, endotherms such as birds are often able to tolerate a wide range of environmental conditions, but this comes at a potentially high energetic cost (Porter & Kearney, 2009). In Europe, radio-tracking (Clergeau & Vergnes, 2011;Strubbe & Matthysen, 2011) and habitat selection studies (Strubbe & Matthysen, 2007;Newson et al., 2010) indicate that parakeets prefer to forage in city parks and gardens, where bird feeders and ornamental vegetation present parakeets with abundant food. Urban areas also offer an Figure 3 Predictions of invasion risk for ring-necked parakeet in Europe derived from bioclimatic envelope models including association with human-modified habitats in the native range. Continuous model outputs (Fig. 2) were converted to binary predictions of invasion risk. Areas at risk according to both models without (see Fig. 2c) and with (see Fig. 2d) phylogeographic structure are indicated in red. Green indicates predicted parakeet presence only by a model without phylogeographic structure. Yellow delineates areas only marked as suitable by a model with phylogeographic structure. abundance of suitable nesting sites, as large, old trees are often retained for their aesthetic value. In the colder parts of Europe, parakeets increasingly breed in holes and crevices within the thermal insulation layers of buildings; in Germany, for example, such a more favourable microclimate enables them to achieve a higher breeding success compared to natural cavities (Braun, 2007). Moreover, in urban gardens, parakeets have been shown to be behaviourally dominant over native birds during foraging (Peck et al., 2014). Abundant resources and a lack of competitors may underlie the invasion success of ringnecked parakeets in environments far removed from their native (realized) niche. Yet, to elucidate the extent to which thermal and energetic constraints influence ring-necked parakeet distributional limits in their native versus non-native ranges, mechanistic niche models (which use species"" functional traits and physiological tolerances for model fitting, Kearney et al., 2010) are required. Furthermore, although little is known about interactions between Psittacula species in their native range, the hypothesis of competitive release as an underlying driver of ring-necked parakeet invasion success in Europe may be tested by assessing whether predicted geographical distribution patterns across the native range (derived from bioclimatic models) match expectations under competitive exclusion (sensu Guti errez et al., 2014)."	0	"Previous studies suggest niche expansion into climates not occupied in the native range is more likely for species with small native ranges (plants, Early & Sax, 2014;amphibians and reptiles, Li et al., 2014), for species introduced longer ago or that have invaded areas located at lower latitudes than the native range (amphibians and reptiles, Early & Sax, 2014). Ring-necked parakeets, however, have a very large native range and have been introduced relatively recent (most European introductions stem from after 1970, Strubbe & Matthysen, 2009b) to much higher latitudes than their native range. Our results thus identify, for the first time, association with humans in the native range as a factor influencing climatic niche expansion during biological invasion. Climate influences species distributions directly through species"" physiological tolerances or indirectly through its effect on available habitats, food resources and biotic interactions such as the presence of competitors (Ara ujo & Peterson, 2012, #CITATION_TAG et al. 2013. The fact that ring-necked parakeets thrive in Europe suggests they may be physiologically capable of colonizing colder parts of the climate space in their native range as well. Possibly, a lack of resources and/or competition with congeneric species such as slaty-headed (P. himalayana) and Lord Derby""s Parakeet (P."	e
CCT473	"Environmental variables considered are a set of eight climatic variables assumed to impose direct and indirect constraints on avian distributions (#CITATION_TAG et al., 2009): annual mean temperature (bio_1), mean temperature of the warmest month (t_max), mean temperature of the coldest month (t_min), temperature seasonality (bio_4), annual precipitation (bio_12), precipitation of the wettest month (bio_13), precipitation of the driest month (bio_14) and precipitation seasonality (bio_15). These variables were derived from the WorldClim database (Hijmans et al., 2005) and represent mean values over the 1961-1990 period at a 0.083¬∞resolution. The ""human footprint"" a quantitative measure of human alteration of terrestrial environments based on human population size, land use and infrastructure was derived from Sanderson et al. (2002) at a resolution of 30‚Ä≥ and resampled to the 0.083¬∞resolution of the climate and parakeet occurrence data."	0	"Environmental variables considered are a set of eight climatic variables assumed to impose direct and indirect constraints on avian distributions (#CITATION_TAG et al., 2009): annual mean temperature (bio_1), mean temperature of the warmest month (t_max), mean temperature of the coldest month (t_min), temperature seasonality (bio_4), annual precipitation (bio_12), precipitation of the wettest month (bio_13), precipitation of the driest month (bio_14) and precipitation seasonality (bio_15). These variables were derived from the WorldClim database (Hijmans et al., 2005) and represent mean values over the 1961-1990 period at a 0.083¬∞resolution. The ""human footprint"" a quantitative measure of human alteration of terrestrial environments based on human population size, land use and infrastructure was derived from Sanderson et al. (2002) at a resolution of 30‚Ä≥ and resampled to the 0.083¬∞resolution of the climate and parakeet occurrence data."	E
CCT474	"Here, using a unique dataset on the distribution of a global avian invader, the ring-necked parakeet (Psittacula krameri), we test whether accounting for within-taxon niche structure and association with humans in the native range leads to more accurate predictions of invasion risk. Ringnecked parakeets are native to large parts of Africa and Asia. Across their native range, they have benefited from the conversion of natural habitats to agro-ecosystems (#CITATION_TAG & Beck, 1979;Khan, 2002) and reach their highest breeding densities near human settlements and cultivated crops (Khan et al., 2004). These parakeets are a globally widespread invasive species, and they compete with native birds and bats and cause damage to crops (Strubbe & Matthysen, 2009a;Hern andez-Brito et al., 2014;Peck et al., 2014). In this study, we present the most complete information on the distribution of ring-necked parakeets to date, comprising a set of about 1200 (686 native and 513 invasive) occurrences collected at a finer resolution than has previously been reported, 123 failed and successful introduction events across Europe, plus a high-resolution mtDNA molecular phylogeny derived from 98 museum specimens geospatially selected to cover the parakeet""s native range and from feather samples collected at 13 invaded sites across Europe. We expect that incorporating within-taxon niche structure into bioclimatic envelope models will result in important differences in the geographical distribution of climate predicted as suitable for parakeets across Europe and that accounting for association with human-modified habitats in the native range will allow for more accurate predictions of the potential European distribution of this ubiquitous avian invader."	0	"Here, using a unique dataset on the distribution of a global avian invader, the ring-necked parakeet (Psittacula krameri), we test whether accounting for within-taxon niche structure and association with humans in the native range leads to more accurate predictions of invasion risk. Ringnecked parakeets are native to large parts of Africa and Asia. Across their native range, they have benefited from the conversion of natural habitats to agro-ecosystems (#CITATION_TAG & Beck, 1979;Khan, 2002) and reach their highest breeding densities near human settlements and cultivated crops (Khan et al., 2004). These parakeets are a globally widespread invasive species, and they compete with native birds and bats and cause damage to crops (Strubbe & Matthysen, 2009a;Hern andez-Brito et al., 2014;Peck et al., 2014). In this study, we present the most complete information on the distribution of ring-necked parakeets to date, comprising a set of about 1200 (686 native and 513 invasive) occurrences collected at a finer resolution than has previously been reported, 123 failed and successful introduction events across Europe, plus a high-resolution mtDNA molecular phylogeny derived from 98 museum specimens geospatially selected to cover the parakeet""s native range and from feather samples collected at 13 invaded sites across Europe. We expect that incorporating within-taxon niche structure into bioclimatic envelope models will result in important differences in the geographical distribution of climate predicted as suitable for parakeets across Europe and that accounting for association with human-modified habitats in the native range will allow for more accurate predictions of the potential European distribution of this ubiquitous avian invader."	r
CCT475	"Given its strong effect on the accuracy of predictions of invasion risk, incorporating information on association with human-modified habitats in the native range should be integrated into bioclimatic envelope models, if they are to effectively guide invasive species management. Association with human-modified habitats in the native range may enable ringnecked parakeets to exploit equivalent human-modified landscapes in Europe, allowing them to colonize areas far colder than their native range. Ring-necked parakeets have almost 90% of their invasive distribution outside their native climatic niche (Fig. 1), and this is among the highest values of niche expansion known for vertebrates (Strubbe et al., 2013;Li et al., 2014). Previous studies suggest niche expansion into climates not occupied in the native range is more likely for species with small native ranges (plants, Early & Sax, 2014;amphibians and reptiles, Li et al., 2014), for species introduced longer ago or that have invaded areas located at lower latitudes than the native range (amphibians and reptiles, Early & Sax, 2014). Ring-necked parakeets, however, have a very large native range and have been introduced relatively recent (most European introductions stem from after 1970, Strubbe & Matthysen, 2009b) to much higher latitudes than their native range. Our results thus identify, for the first time, association with humans in the native range as a factor influencing climatic niche expansion during biological invasion. Climate influences species distributions directly through species"" physiological tolerances or indirectly through its effect on available habitats, food resources and biotic interactions such as the presence of competitors (Ara ujo & Peterson, 2012, Wisz et al. 2013. The fact that ring-necked parakeets thrive in Europe suggests they may be physiologically capable of colonizing colder parts of the climate space in their native range as well. Possibly, a lack of resources and/or competition with congeneric species such as slaty-headed (P. himalayana) and Lord Derby""s Parakeet (P. derbiana) restricts the ring-necked parakeets"" native northernmost distribution limits. Indeed, endotherms such as birds are often able to tolerate a wide range of environmental conditions, but this comes at a potentially high energetic cost (Porter & Kearney, 2009). In Europe, radio-tracking (#CITATION_TAG & Vergnes, 2011;Strubbe & Matthysen, 2011) and habitat selection studies (Strubbe & Matthysen, 2007;Newson et al., 2010) indicate that parakeets prefer to forage in city parks and gardens, where bird feeders and ornamental vegetation present parakeets with abundant food. Urban areas also offer an Figure 3 Predictions of invasion risk for ring-necked parakeet in Europe derived from bioclimatic envelope models including association with human-modified habitats in the native range. Continuous model outputs (Fig. 2) were converted to binary predictions of invasion risk. Areas at risk according to both models without (see Fig. 2c) and with (see Fig. 2d) phylogeographic structure are indicated in red. Green indicates predicted parakeet presence only by a model without phylogeographic structure. Yellow delineates areas only marked as suitable by a model with phylogeographic structure. abundance of suitable nesting sites, as large, old trees are often retained for their aesthetic value. In the colder parts of Europe, parakeets increasingly breed in holes and crevices within the thermal insulation layers of buildings; in Germany, for example, such a more favourable microclimate enables them to achieve a higher breeding success compared to natural cavities (Braun, 2007). Moreover, in urban gardens, parakeets have been shown to be behaviourally dominant over native birds during foraging (Peck et al., 2014). Abundant resources and a lack of competitors may underlie the invasion success of ringnecked parakeets in environments far removed from their native (realized) niche. Yet, to elucidate the extent to which thermal and energetic constraints influence ring-necked parakeet distributional limits in their native versus non-native ranges, mechanistic niche models (which use species"" functional traits and physiological tolerances for model fitting, Kearney et al., 2010) are required. Furthermore, although little is known about interactions between Psittacula species in their native range, the hypothesis of competitive release as an underlying driver of ring-necked parakeet invasion success in Europe may be tested by assessing whether predicted geographical distribution patterns across the native range (derived from bioclimatic models) match expectations under competitive exclusion (sensu Guti errez et al., 2014)."	0	"himalayana) and Lord Derby""s Parakeet (P. derbiana) restricts the ring-necked parakeets"" native northernmost distribution limits. Indeed, endotherms such as birds are often able to tolerate a wide range of environmental conditions, but this comes at a potentially high energetic cost (Porter & Kearney, 2009). In Europe, radio-tracking (#CITATION_TAG & Vergnes, 2011;Strubbe & Matthysen, 2011) and habitat selection studies (Strubbe & Matthysen, 2007;Newson et al., 2010) indicate that parakeets prefer to forage in city parks and gardens, where bird feeders and ornamental vegetation present parakeets with abundant food. Urban areas also offer an Figure 3 Predictions of invasion risk for ring-necked parakeet in Europe derived from bioclimatic envelope models including association with human-modified habitats in the native range. Continuous model outputs (Fig. 2) were converted to binary predictions of invasion risk. Areas at risk according to both models without (see Fig. 2c) and with (see Fig. 2d) phylogeographic structure are indicated in red."	a
CCT476	"Therefore, we assess three key assumptions underlying bioclimatic envelope models: (1) that species"" distributions are largely governed by climate (Ara ujo & Peterson, 2012), (2) that a species"" current native distribution corresponds with the total set of climate conditions under which it can persist (Peterson, 2003) and (3) that the climatic niche remains conserved across time and space (#CITATION_TAG et al., 2007). Climate is generally recognized as a chief driver of species"" distributions at large spatial scales (Ara ujo & Peterson, 2012), although the broad distributional limits governed by climate may be modified by factors such as habitat availability, biotic interactions and dispersal limitations (Soberon, 2007). Erroneous predictions of the potential distribution of invasive species are often attributed to species adaptations in response to selection pressures imposed by the novel environment (Whitney & Gabler, 2008). However, within the native range, species may also evolve pre-adaptations to invasiveness; strong selection imposed by human modification of habitats within the native range is likely to lead to adaptation prior to introduction elsewhere (Hufbauer et al., 2012). As human activities tend to promote similar ecological conditions across biogeographical areas (Savard et al., 2000), species or populations associated with human-modified habitats in the native range can be expected to successfully invade similar areas elsewhere. It is therefore surprising that predic-tions of invasion risk obtained from bioclimatic envelope models have not yet explicitly considered how human modification of habitats might modify distributional limits set by climate."	4	"Therefore, we assess three key assumptions underlying bioclimatic envelope models: (1) that species"" distributions are largely governed by climate (Ara ujo & Peterson, 2012), (2) that a species"" current native distribution corresponds with the total set of climate conditions under which it can persist (Peterson, 2003) and (3) that the climatic niche remains conserved across time and space (#CITATION_TAG et al., 2007). Climate is generally recognized as a chief driver of species"" distributions at large spatial scales (Ara ujo & Peterson, 2012), although the broad distributional limits governed by climate may be modified by factors such as habitat availability, biotic interactions and dispersal limitations (Soberon, 2007). Erroneous predictions of the potential distribution of invasive species are often attributed to species adaptations in response to selection pressures imposed by the novel environment (Whitney & Gabler, 2008). However, within the native range, species may also evolve pre-adaptations to invasiveness; strong selection imposed by human modification of habitats within the native range is likely to lead to adaptation prior to introduction elsewhere (Hufbauer et al., 2012)."	T
CCT477	To identify native phylogroups, Bayesian phylogenetic inference was implemented in MRBAYES v3.2 (Ronquist & Huelsenbeck, 2003) using the CIPRES Science Gateway (Miller et al., 2010) with 10 million generations over four parallel Monte Carlo Markov chains (MCMC), under an HKY evolutionary model (#CITATION_TAG, 1981). TRACER v1.6 (Rambaut & Drummond, 2007) was used to assess convergence. After discarding the first 25% as burn-in, tree topologies were summarized in a 50% consensus tree. To identify native haplotypes in the invasive range, the combined native and invasive dataset was condensed into haplotypes using TCS (Clement et al., 2000). All node values with a posterior probability of > 50 were used to identify phylogroups.	5	To identify native phylogroups, Bayesian phylogenetic inference was implemented in MRBAYES v3.2 (Ronquist & Huelsenbeck, 2003) using the CIPRES Science Gateway (Miller et al., 2010) with 10 million generations over four parallel Monte Carlo Markov chains (MCMC), under an HKY evolutionary model (#CITATION_TAG, 1981). TRACER v1.6 (Rambaut & Drummond, 2007) was used to assess convergence. After discarding the first 25% as burn-in, tree topologies were summarized in a 50% consensus tree. To identify native haplotypes in the invasive range, the combined native and invasive dataset was condensed into haplotypes using TCS (Clement et al., 2000).	T
CCT478	"Given its strong effect on the accuracy of predictions of invasion risk, incorporating information on association with human-modified habitats in the native range should be integrated into bioclimatic envelope models, if they are to effectively guide invasive species management. Association with human-modified habitats in the native range may enable ringnecked parakeets to exploit equivalent human-modified landscapes in Europe, allowing them to colonize areas far colder than their native range. Ring-necked parakeets have almost 90% of their invasive distribution outside their native climatic niche (Fig. 1), and this is among the highest values of niche expansion known for vertebrates (Strubbe et al., 2013;Li et al., 2014). Previous studies suggest niche expansion into climates not occupied in the native range is more likely for species with small native ranges (plants, Early & Sax, 2014;amphibians and reptiles, Li et al., 2014), for species introduced longer ago or that have invaded areas located at lower latitudes than the native range (amphibians and reptiles, Early & Sax, 2014). Ring-necked parakeets, however, have a very large native range and have been introduced relatively recent (most European introductions stem from after 1970, Strubbe & Matthysen, 2009b) to much higher latitudes than their native range. Our results thus identify, for the first time, association with humans in the native range as a factor influencing climatic niche expansion during biological invasion. Climate influences species distributions directly through species"" physiological tolerances or indirectly through its effect on available habitats, food resources and biotic interactions such as the presence of competitors (Ara ujo & Peterson, 2012, Wisz et al. 2013. The fact that ring-necked parakeets thrive in Europe suggests they may be physiologically capable of colonizing colder parts of the climate space in their native range as well. Possibly, a lack of resources and/or competition with congeneric species such as slaty-headed (P. himalayana) and Lord Derby""s Parakeet (P. derbiana) restricts the ring-necked parakeets"" native northernmost distribution limits. Indeed, endotherms such as birds are often able to tolerate a wide range of environmental conditions, but this comes at a potentially high energetic cost (Porter & Kearney, 2009). In Europe, radio-tracking (Clergeau & Vergnes, 2011;Strubbe & Matthysen, 2011) and habitat selection studies (Strubbe & Matthysen, 2007;Newson et al., 2010) indicate that parakeets prefer to forage in city parks and gardens, where bird feeders and ornamental vegetation present parakeets with abundant food. Urban areas also offer an Figure 3 Predictions of invasion risk for ring-necked parakeet in Europe derived from bioclimatic envelope models including association with human-modified habitats in the native range. Continuous model outputs (Fig. 2) were converted to binary predictions of invasion risk. Areas at risk according to both models without (see Fig. 2c) and with (see Fig. 2d) phylogeographic structure are indicated in red. Green indicates predicted parakeet presence only by a model without phylogeographic structure. Yellow delineates areas only marked as suitable by a model with phylogeographic structure. abundance of suitable nesting sites, as large, old trees are often retained for their aesthetic value. In the colder parts of Europe, parakeets increasingly breed in holes and crevices within the thermal insulation layers of buildings; in Germany, for example, such a more favourable microclimate enables them to achieve a higher breeding success compared to natural cavities (#CITATION_TAG, 2007). Moreover, in urban gardens, parakeets have been shown to be behaviourally dominant over native birds during foraging (Peck et al., 2014). Abundant resources and a lack of competitors may underlie the invasion success of ringnecked parakeets in environments far removed from their native (realized) niche. Yet, to elucidate the extent to which thermal and energetic constraints influence ring-necked parakeet distributional limits in their native versus non-native ranges, mechanistic niche models (which use species"" functional traits and physiological tolerances for model fitting, Kearney et al., 2010) are required. Furthermore, although little is known about interactions between Psittacula species in their native range, the hypothesis of competitive release as an underlying driver of ring-necked parakeet invasion success in Europe may be tested by assessing whether predicted geographical distribution patterns across the native range (derived from bioclimatic models) match expectations under competitive exclusion (sensu Guti errez et al., 2014)."	0	"Green indicates predicted parakeet presence only by a model without phylogeographic structure. Yellow delineates areas only marked as suitable by a model with phylogeographic structure. abundance of suitable nesting sites, as large, old trees are often retained for their aesthetic value. In the colder parts of Europe, parakeets increasingly breed in holes and crevices within the thermal insulation layers of buildings; in Germany, for example, such a more favourable microclimate enables them to achieve a higher breeding success compared to natural cavities (#CITATION_TAG, 2007). Moreover, in urban gardens, parakeets have been shown to be behaviourally dominant over native birds during foraging (Peck et al., 2014). Abundant resources and a lack of competitors may underlie the invasion success of ringnecked parakeets in environments far removed from their native (realized) niche. Yet, to elucidate the extent to which thermal and energetic constraints influence ring-necked parakeet distributional limits in their native versus non-native ranges, mechanistic niche models (which use species"" functional traits and physiological tolerances for model fitting, Kearney et al., 2010) are required."	 
CCT479	"Taken together, our results agree with other findings (Strubbe et al., 2013(Strubbe et al., , 2014Early & Sax, 2014;#CITATION_TAG et al., 2014;Li et al., 2014), suggesting that while rapid post-introduction evolution (i.e. a change in the fundamental Grinnellian niche, Soberon, 2007) cannot be ruled out, climatic niche differences between native and invasive ranges are probably related to ecological factors governing the occupancy of the fundamental niche in native versus invaded ranges. This has important ramifications for the use of bioclimatic envelope models as risk assessment tools, as well as, more fundamentally, for understanding how climate and local factors interact to determine species"" distributions. Pearson & Dawson (2003) suggested a hierarchical approach to modelling environment-biota relationships whereby bioclimatic envelope models should form the first step, identifying the broad outlines of species"" distributions. Within the area designated as climatically suitable for a species, models including factors such as land cover and habitat preferences can then be applied to elucidate the finegrained structure of distributions. We suggest that, at least for invasive species, this framework may not be universally applicable, as association with human-modified habitats in the native range may allow species to overcome their (realized) native-range climatic limitations in human-modified landscapes elsewhere. Trait-based species risk assessments consider association with human-modified habitats in the native range to be a reliable predictor of invasion success (Keller et al., 2011), especially for mammals and birds (Jeschke & Strayer 2006). Our results show that applying a simple and universal variable such as the human footprint can considerably increase the accuracy of predictions of invasion risk, and this finding opens up real perspectives for devising and implementing more robust management strategies for a large number of invasive species. Information about the presence and geographical distribution of phylogeographic lineages may be not be readily available for all invasive species, but subspecies range maps can often be derived from the literature, at least for terrestrial vertebrates. Subspecies are generally based on discontinuities in the geographical distribution of phenotypic traits instead of molecular phylogenies, but can generally be considered useful proxies of patterns of divergence among populations (Phillimore & Owens, 2006). We therefore argue that, in order to provide to policymakers models that can accurately predict invasion risk, explicit evaluation of within-taxon niche structure and especially of association with humans in the native range is recommended."	0	"Taken together, our results agree with other findings (Strubbe et al., 2013(Strubbe et al., , 2014Early & Sax, 2014;#CITATION_TAG et al., 2014;Li et al., 2014), suggesting that while rapid post-introduction evolution (i.e. a change in the fundamental Grinnellian niche, Soberon, 2007) cannot be ruled out, climatic niche differences between native and invasive ranges are probably related to ecological factors governing the occupancy of the fundamental niche in native versus invaded ranges. This has important ramifications for the use of bioclimatic envelope models as risk assessment tools, as well as, more fundamentally, for understanding how climate and local factors interact to determine species"" distributions. Pearson & Dawson (2003) suggested a hierarchical approach to modelling environment-biota relationships whereby bioclimatic envelope models should form the first step, identifying the broad outlines of species"" distributions. Within the area designated as climatically suitable for a species, models including factors such as land cover and habitat preferences can then be applied to elucidate the finegrained structure of distributions."	T
CCT480	Biological invasions are a major global environmental and economic problem (Sala et al., 2000). As eradication is frequently costly and sometimes impossible, attempting to limit the further introduction and spread of invasive species is the most effective and cost-efficient management strategy (#CITATION_TAG et al., 2002). To identify potentially invasive species, risk assessment protocols based on species traits associated with invasiveness have been developed (Keller et al., 2011). Spatially explicit predictions of invasion risk derived from bioclimatic envelope models [also referred to as species distribution models (SDM) or ecological niche models (ENM)] calibrated with native species distributions are increasingly incorporated into such invasive species risk assessments (Beaumont et al., 2014). To assess potential invasion risk, bioclimatic envelope models estimate the geographical distribution of climates suitable for invasive species (Ara ujo & Peterson, 2012). Applications of these models to invasive species, however, fail to consider how association with human-modified habitats in the native range, a species trait strongly associated with invasion success (Keller et al., 2011), might modify the distributional limits sets by climate. Also, models typically do not appreciate how the existence of phylogeographic lineages with differing niche requirements can influence forecasts of invasion risk (Pearman et al., 2010). Ignoring these factors may result in mismatches between predicted potential and realized invasive distributions, fuelling doubts about the suitability of bioclimatic envelope models for anticipating biological invasions (Guisan et al., 2014).	0	Biological invasions are a major global environmental and economic problem (Sala et al., 2000). As eradication is frequently costly and sometimes impossible, attempting to limit the further introduction and spread of invasive species is the most effective and cost-efficient management strategy (#CITATION_TAG et al., 2002). To identify potentially invasive species, risk assessment protocols based on species traits associated with invasiveness have been developed (Keller et al., 2011). Spatially explicit predictions of invasion risk derived from bioclimatic envelope models [also referred to as species distribution models (SDM) or ecological niche models (ENM)] calibrated with native species distributions are increasingly incorporated into such invasive species risk assessments (Beaumont et al., 2014). To assess potential invasion risk, bioclimatic envelope models estimate the geographical distribution of climates suitable for invasive species (Ara ujo & Peterson, 2012).	s
CCT481	"The fact that lineages associated with cold climates in the native range are more prevalent across Europe suggests that these lineages may be better adapted to European climates. Such an invasion scenario has been found before; for example, Rey et al. (2012) showed that the invasion of Mediterranean Israel by the tropical ant Wasmannia auropunctata could be explained by adaptation to cold at the southern limit of the native range before introduction to Israel. Yet, although large numbers of parakeets from both Africa and Asia have been imported to Europe (Morgan, 1993), more detailed knowledge on propagule pressure is required to rule out alternative explanations such as the possibility that more birds originating from colder parts of the native rang have escaped or been released across Europe. Also, it should be noted that our phylogeny is based on a set of neutral genetic markers and that consequently, patterns of within-taxon niche variation may be due to regional differences in available climates, to adaptation to local environments or to other drivers such as biotic interactions. However, populations are often adapted to local environments and genotypeby-environment interactions are common in widespread species (Pearman et al., 2010). This study is the first fine-scale assessment of ring-necked parakeet genetic structure, but differences among lineages in morphology and life history traits such as timing of reproduction have been reported within and between Africa and Asia (Forshaw, 1978). Such traits may be genetically based and therefore likely to respond to selection (#CITATION_TAG & Holzapfel, 2006) in the parakeet""s invasive range. Indeed, variance in laying dates between European and native (Asian) parakeet populations suggests that in Europe, parakeets are delaying their breeding in response to colder temperatures (Shwartz et al., 2009). These differences in morphology, life history and occupied climates suggest parakeet mtDNA-derived lineages may indeed diverge in features supplementary to the neutral genetic markers used to identify phylogeographic structure. Our results thus suggest the clade model captures lineage-specific responses to environmental gradients that are undetectable using the clade model (Appendix S8). Incorporating such within-taxon niche structure into bioclimatic envelope models only slightly increased model predictive accuracy, but nonetheless leads to important differences in spatial predictions of invasion risk for Europe (Figs 2 & 3). The climate-only clade model is strongly influenced by precipitation gradients (Appendix S8), resulting in erroneous predictions of parakeet occurrence for Europe""s wetter areas (i.e. parts of the Atlantic and Adriatic coast, and along mountain chains, Fig. 2a). The climate-only subclade model indicates certain phylogeographic lineages indeed respond strongly to precipitation gradients (Appendix S8), although in general, the subclade model is more strongly driven by temperature gradients. The climate-only subclade model accordingly correctly predicts some of the Mediterranean parakeet populations, and except for a high precipitation zone along the coast of Norway, it assigns a low invasion risk to coastal areas and mountain chains (Fig. 2b). Both climate-only models, however, fail to accurately forecast ringnecked parakeet occurrence across north-west Europe. When including the human footprint, the major difference between the clade and subclade model is that the latter places more weight on temperature and precipitation gradients (Appendix S8), whereas the clade model exhibits a higher dependency on human footprint. Consequently, the clade model predicts a higher invasion risk across human-dominated habitats in colder parts of continental Europe (Fig. 2c, d) as well. This becomes especially apparent when converting the predictions of invasion risk into discrete predictions of parakeet presence and absence (Fig. 3), showing that particularly in east and central Europe, the clade model predicts as suitable areas that are geographically peripheral to areas predicted as suitable by the subclade model. In contrast, in southern Europe, the subclade model predicts more extensive areas to be at risk of parakeet invasion, reflecting the different weightings given by the clade and subclade model to climate and human modification of habitats."	0	"Also, it should be noted that our phylogeny is based on a set of neutral genetic markers and that consequently, patterns of within-taxon niche variation may be due to regional differences in available climates, to adaptation to local environments or to other drivers such as biotic interactions. However, populations are often adapted to local environments and genotypeby-environment interactions are common in widespread species (Pearman et al., 2010). This study is the first fine-scale assessment of ring-necked parakeet genetic structure, but differences among lineages in morphology and life history traits such as timing of reproduction have been reported within and between Africa and Asia (Forshaw, 1978). Such traits may be genetically based and therefore likely to respond to selection (#CITATION_TAG & Holzapfel, 2006) in the parakeet""s invasive range. Indeed, variance in laying dates between European and native (Asian) parakeet populations suggests that in Europe, parakeets are delaying their breeding in response to colder temperatures (Shwartz et al., 2009). These differences in morphology, life history and occupied climates suggest parakeet mtDNA-derived lineages may indeed diverge in features supplementary to the neutral genetic markers used to identify phylogeographic structure. Our results thus suggest the clade model captures lineage-specific responses to environmental gradients that are undetectable using the clade model (Appendix S8)."	r
CCT482	"Here, using a unique dataset on the distribution of a global avian invader, the ring-necked parakeet (Psittacula krameri), we test whether accounting for within-taxon niche structure and association with humans in the native range leads to more accurate predictions of invasion risk. Ringnecked parakeets are native to large parts of Africa and Asia. Across their native range, they have benefited from the conversion of natural habitats to agro-ecosystems (Bruggers & Beck, 1979;Khan, 2002) and reach their highest breeding densities near human settlements and cultivated crops (Khan et al., 2004). These parakeets are a globally widespread invasive species, and they compete with native birds and bats and cause damage to crops (Strubbe & Matthysen, 2009a;#CITATION_TAG et al., 2014;Peck et al., 2014). In this study, we present the most complete information on the distribution of ring-necked parakeets to date, comprising a set of about 1200 (686 native and 513 invasive) occurrences collected at a finer resolution than has previously been reported, 123 failed and successful introduction events across Europe, plus a high-resolution mtDNA molecular phylogeny derived from 98 museum specimens geospatially selected to cover the parakeet""s native range and from feather samples collected at 13 invaded sites across Europe. We expect that incorporating within-taxon niche structure into bioclimatic envelope models will result in important differences in the geographical distribution of climate predicted as suitable for parakeets across Europe and that accounting for association with human-modified habitats in the native range will allow for more accurate predictions of the potential European distribution of this ubiquitous avian invader."	0	"Here, using a unique dataset on the distribution of a global avian invader, the ring-necked parakeet (Psittacula krameri), we test whether accounting for within-taxon niche structure and association with humans in the native range leads to more accurate predictions of invasion risk. Ringnecked parakeets are native to large parts of Africa and Asia. Across their native range, they have benefited from the conversion of natural habitats to agro-ecosystems (Bruggers & Beck, 1979;Khan, 2002) and reach their highest breeding densities near human settlements and cultivated crops (Khan et al., 2004). These parakeets are a globally widespread invasive species, and they compete with native birds and bats and cause damage to crops (Strubbe & Matthysen, 2009a;#CITATION_TAG et al., 2014;Peck et al., 2014). In this study, we present the most complete information on the distribution of ring-necked parakeets to date, comprising a set of about 1200 (686 native and 513 invasive) occurrences collected at a finer resolution than has previously been reported, 123 failed and successful introduction events across Europe, plus a high-resolution mtDNA molecular phylogeny derived from 98 museum specimens geospatially selected to cover the parakeet""s native range and from feather samples collected at 13 invaded sites across Europe. We expect that incorporating within-taxon niche structure into bioclimatic envelope models will result in important differences in the geographical distribution of climate predicted as suitable for parakeets across Europe and that accounting for association with human-modified habitats in the native range will allow for more accurate predictions of the potential European distribution of this ubiquitous avian invader."	s
CCT483	"Environmental variables considered are a set of eight climatic variables assumed to impose direct and indirect constraints on avian distributions (Ara ujo et al., 2009): annual mean temperature (bio_1), mean temperature of the warmest month (t_max), mean temperature of the coldest month (t_min), temperature seasonality (bio_4), annual precipitation (bio_12), precipitation of the wettest month (bio_13), precipitation of the driest month (bio_14) and precipitation seasonality (bio_15). These variables were derived from the WorldClim database (#CITATION_TAG et al., 2005) and represent mean values over the 1961-1990 period at a 0.083¬∞resolution. The ""human footprint"" a quantitative measure of human alteration of terrestrial environments based on human population size, land use and infrastructure was derived from Sanderson et al. (2002) at a resolution of 30‚Ä≥ and resampled to the 0.083¬∞resolution of the climate and parakeet occurrence data."	5	"Environmental variables considered are a set of eight climatic variables assumed to impose direct and indirect constraints on avian distributions (Ara ujo et al., 2009): annual mean temperature (bio_1), mean temperature of the warmest month (t_max), mean temperature of the coldest month (t_min), temperature seasonality (bio_4), annual precipitation (bio_12), precipitation of the wettest month (bio_13), precipitation of the driest month (bio_14) and precipitation seasonality (bio_15). These variables were derived from the WorldClim database (#CITATION_TAG et al., 2005) and represent mean values over the 1961-1990 period at a 0.083¬∞resolution. The ""human footprint"" a quantitative measure of human alteration of terrestrial environments based on human population size, land use and infrastructure was derived from Sanderson et al. (2002) at a resolution of 30‚Ä≥ and resampled to the 0.083¬∞resolution of the climate and parakeet occurrence data."	h
CCT484	"To assess niche differences between phylogroups and between native and invasive parakeet populations, we used the Broennimann et al. (2012) framework. This framework applies kernel smoothers to densities of species occurrence in a gridded environmental space to calculate metrics of niche overlap (quantified by Schoener""s D, 0: no overlap, 1: complete overlap). Using a randomization test whereby the measured niche overlap is compared against a null distribution of 100 simulated overlap values, we test whether parakeet niches are more similar to each other than expected by chance (i.e. niche similarity, Broennimann et al., 2012). We first assessed whether ring-necked parakeet climatic niches differed significantly between phylogroups (i.e. Africa versus Asian, and phylogroups within each continent), using all biomes occupied by parakeets across their native range as background area (Guisan et al., 2014). Second, native and invasive ring-necked parakeet occurrences were used to assess whether native niche characteristics are conserved during the invasion process (using a niche similarity test), and to determine whether parakeets have colonized in the invaded range climates not occupied in the native range (i.e. niche expansion, Petitpierre et al., 2012). Niche metrics are calculated on the climate space shared by native and invasive ranges (sensu Petitpierre et al., 2012). Background areas should reflect the set of areas a species could potentially have encountered since its presence in the region (#CITATION_TAG et al., 2011). Therefore, in Europe, we buffered each locality where parakeets have been introduced with a distance equal to the minimum invasion speed recorded for birds (i.e. 4.59 km year √Ä1 , derived from Blackburn et al., 2009) multiplied by the number of years since introduction (see Strubbe et al., 2013 for details). In doing so, we obtained an ecologically realistic European background (models were also run using the whole of Europe as background, but this did not affect our main results, Appendix S3)."	5	We first assessed whether ring-necked parakeet climatic niches differed significantly between phylogroups (i.e. Africa versus Asian, and phylogroups within each continent), using all biomes occupied by parakeets across their native range as background area (Guisan et al., 2014). Second, native and invasive ring-necked parakeet occurrences were used to assess whether native niche characteristics are conserved during the invasion process (using a niche similarity test), and to determine whether parakeets have colonized in the invaded range climates not occupied in the native range (i.e. niche expansion, Petitpierre et al., 2012). Niche metrics are calculated on the climate space shared by native and invasive ranges (sensu Petitpierre et al., 2012). Background areas should reflect the set of areas a species could potentially have encountered since its presence in the region (#CITATION_TAG et al., 2011). Therefore, in Europe, we buffered each locality where parakeets have been introduced with a distance equal to the minimum invasion speed recorded for birds (i.e. 4.59 km year √Ä1 , derived from Blackburn et al., 2009) multiplied by the number of years since introduction (see Strubbe et al., 2013 for details). In doing so, we obtained an ecologically realistic European background (models were also run using the whole of Europe as background, but this did not affect our main results, Appendix S3).	o
CCT485	"Following the procedures described above, we first fitted a ""clade"" model, using as presences all native-range grid cells occupied by parakeets (i.e. occurrences pooled across all phylogroups). Then, we built separate models for each phylogroup, using as presences all occupied grid cells located within phylogroup range boundaries. A composite ""subclade"" model was developed from the phylogroup predictions to summarize predictions of parakeet occurrence across all phylogroups. Because phylogroup models may differ in prevalence, to construct the subclade model, we first made the phylogroup models comparable by standardizing the average probabilities of occurrence for each phylogroup along the environmental gradients considered. Then, we calculated the mean probability of occurrence of at least one of the related phylogroups for grid cells using the multiplicative probability method described in Pearman et al. (2010). Clade and subclade models were fitted with and without human footprint, resulting in four different ensemble predictions of parakeet invasion risk in Europe. To exclude the possibility that differences in model performance are merely due to the adding of one predictor variable (human footprint) to the models, we also fitted models with a randomized version of the human footprint variable. To further assess the importance of human footprint, models described above were also run with the human footprint as sole predictor variable. Model transferability was assessed using European parakeet occurrence data (n = 513), applying the full range of evaluation statistics available in biomod2, plus two statistics specifically designed for presence-only models (the 10-fold and the continuous Boyce index, #CITATION_TAG et al., 2006). To convert the continuous clade and subclade ensemble predictions of invasion risk into discrete predictions of parakeet presence and absence across Europe, an optimal TSS threshold was calculated based on the European parakeet occurrences. Lastly, a climatic multivariate environmental similarity surface (MESS) map was calculated for Europe. This map indicates areas where climatic variables occur outside the range of values contained in model training regions, and predictions of invasion risk in these areas should be treated cautiously (Elith et al., 2010)."	5	Clade and subclade models were fitted with and without human footprint, resulting in four different ensemble predictions of parakeet invasion risk in Europe. To exclude the possibility that differences in model performance are merely due to the adding of one predictor variable (human footprint) to the models, we also fitted models with a randomized version of the human footprint variable. To further assess the importance of human footprint, models described above were also run with the human footprint as sole predictor variable. Model transferability was assessed using European parakeet occurrence data (n = 513), applying the full range of evaluation statistics available in biomod2, plus two statistics specifically designed for presence-only models (the 10-fold and the continuous Boyce index, #CITATION_TAG et al., 2006). To convert the continuous clade and subclade ensemble predictions of invasion risk into discrete predictions of parakeet presence and absence across Europe, an optimal TSS threshold was calculated based on the European parakeet occurrences. Lastly, a climatic multivariate environmental similarity surface (MESS) map was calculated for Europe. This map indicates areas where climatic variables occur outside the range of values contained in model training regions, and predictions of invasion risk in these areas should be treated cautiously (Elith et al., 2010).	a
CCT486	"Therefore, we assess three key assumptions underlying bioclimatic envelope models: (1) that species"" distributions are largely governed by climate (Ara ujo & Peterson, 2012), (2) that a species"" current native distribution corresponds with the total set of climate conditions under which it can persist (Peterson, 2003) and (3) that the climatic niche remains conserved across time and space (Broennimann et al., 2007). Climate is generally recognized as a chief driver of species"" distributions at large spatial scales (Ara ujo & Peterson, 2012), although the broad distributional limits governed by climate may be modified by factors such as habitat availability, biotic interactions and dispersal limitations (Soberon, 2007). Erroneous predictions of the potential distribution of invasive species are often attributed to species adaptations in response to selection pressures imposed by the novel environment (Whitney & Gabler, 2008). However, within the native range, species may also evolve pre-adaptations to invasiveness; strong selection imposed by human modification of habitats within the native range is likely to lead to adaptation prior to introduction elsewhere (#CITATION_TAG et al., 2012). As human activities tend to promote similar ecological conditions across biogeographical areas (Savard et al., 2000), species or populations associated with human-modified habitats in the native range can be expected to successfully invade similar areas elsewhere. It is therefore surprising that predic-tions of invasion risk obtained from bioclimatic envelope models have not yet explicitly considered how human modification of habitats might modify distributional limits set by climate."	4	"Therefore, we assess three key assumptions underlying bioclimatic envelope models: (1) that species"" distributions are largely governed by climate (Ara ujo & Peterson, 2012), (2) that a species"" current native distribution corresponds with the total set of climate conditions under which it can persist (Peterson, 2003) and (3) that the climatic niche remains conserved across time and space (Broennimann et al., 2007). Climate is generally recognized as a chief driver of species"" distributions at large spatial scales (Ara ujo & Peterson, 2012), although the broad distributional limits governed by climate may be modified by factors such as habitat availability, biotic interactions and dispersal limitations (Soberon, 2007). Erroneous predictions of the potential distribution of invasive species are often attributed to species adaptations in response to selection pressures imposed by the novel environment (Whitney & Gabler, 2008). However, within the native range, species may also evolve pre-adaptations to invasiveness; strong selection imposed by human modification of habitats within the native range is likely to lead to adaptation prior to introduction elsewhere (#CITATION_TAG et al., 2012). As human activities tend to promote similar ecological conditions across biogeographical areas (Savard et al., 2000), species or populations associated with human-modified habitats in the native range can be expected to successfully invade similar areas elsewhere. It is therefore surprising that predic-tions of invasion risk obtained from bioclimatic envelope models have not yet explicitly considered how human modification of habitats might modify distributional limits set by climate."	e
CCT487	"Taken together, our results agree with other findings (Strubbe et al., 2013(Strubbe et al., , 2014Early & Sax, 2014;Guisan et al., 2014;Li et al., 2014), suggesting that while rapid post-introduction evolution (i.e. a change in the fundamental Grinnellian niche, Soberon, 2007) cannot be ruled out, climatic niche differences between native and invasive ranges are probably related to ecological factors governing the occupancy of the fundamental niche in native versus invaded ranges. This has important ramifications for the use of bioclimatic envelope models as risk assessment tools, as well as, more fundamentally, for understanding how climate and local factors interact to determine species"" distributions. Pearson & Dawson (2003) suggested a hierarchical approach to modelling environment-biota relationships whereby bioclimatic envelope models should form the first step, identifying the broad outlines of species"" distributions. Within the area designated as climatically suitable for a species, models including factors such as land cover and habitat preferences can then be applied to elucidate the finegrained structure of distributions. We suggest that, at least for invasive species, this framework may not be universally applicable, as association with human-modified habitats in the native range may allow species to overcome their (realized) native-range climatic limitations in human-modified landscapes elsewhere. Trait-based species risk assessments consider association with human-modified habitats in the native range to be a reliable predictor of invasion success (Keller et al., 2011), especially for mammals and birds (#CITATION_TAG & Strayer 2006). Our results show that applying a simple and universal variable such as the human footprint can considerably increase the accuracy of predictions of invasion risk, and this finding opens up real perspectives for devising and implementing more robust management strategies for a large number of invasive species. Information about the presence and geographical distribution of phylogeographic lineages may be not be readily available for all invasive species, but subspecies range maps can often be derived from the literature, at least for terrestrial vertebrates. Subspecies are generally based on discontinuities in the geographical distribution of phenotypic traits instead of molecular phylogenies, but can generally be considered useful proxies of patterns of divergence among populations (Phillimore & Owens, 2006). We therefore argue that, in order to provide to policymakers models that can accurately predict invasion risk, explicit evaluation of within-taxon niche structure and especially of association with humans in the native range is recommended."	0	"Pearson & Dawson (2003) suggested a hierarchical approach to modelling environment-biota relationships whereby bioclimatic envelope models should form the first step, identifying the broad outlines of species"" distributions. Within the area designated as climatically suitable for a species, models including factors such as land cover and habitat preferences can then be applied to elucidate the finegrained structure of distributions. We suggest that, at least for invasive species, this framework may not be universally applicable, as association with human-modified habitats in the native range may allow species to overcome their (realized) native-range climatic limitations in human-modified landscapes elsewhere. Trait-based species risk assessments consider association with human-modified habitats in the native range to be a reliable predictor of invasion success (Keller et al., 2011), especially for mammals and birds (#CITATION_TAG & Strayer 2006). Our results show that applying a simple and universal variable such as the human footprint can considerably increase the accuracy of predictions of invasion risk, and this finding opens up real perspectives for devising and implementing more robust management strategies for a large number of invasive species. Information about the presence and geographical distribution of phylogeographic lineages may be not be readily available for all invasive species, but subspecies range maps can often be derived from the literature, at least for terrestrial vertebrates. Subspecies are generally based on discontinuities in the geographical distribution of phenotypic traits instead of molecular phylogenies, but can generally be considered useful proxies of patterns of divergence among populations (Phillimore & Owens, 2006)."	-
CCT488	"Mitochondrial DNA sequences comprising 868 bp (cytochrome b: 346 bp, control region: 522 bp) were sampled from 98 parakeet specimens (Africa: 38, Asia: 60). In total, 44 unique haplotypes were identified (Africa: 16, Asia: 26). A Bayesian phylogenetic tree provides support for 17 haplotype clades (Africa: 6, Asia: 11; posterior probabilities > 50, i.e. the ""phylogroups Appendix S1). The six African phylogroups correspond to six largely parapatric groupings arranged longitudinally along the Sahel region, whereby only the most eastern phylogroups show some range overlap. The 11 Asian phylogroups, in contrast, show a much more complex spatial pattern with varying levels of range overlap between phylogroups. Phylogroup sample sizes varied from 2 to 17 specimens (mean: 6) for African phylogroups, and from 1 to 17 (mean: 6) for Asia. Note that for the niche analyses and the bioclimatic envelope models, parakeet occurrences that fell within overlapping polygons were randomly assigned to one of the polygons. That way, each lineage was represented in the overlapping area, without sampling the same data point multiple times (#CITATION_TAG et al., 2012). Sample sizes used for modelling varied from 14 to 59 occurrences (mean: 35) for African phylogroups and from 6 to 126 (mean: 48) for Asia (Appendix S2)."	0	The 11 Asian phylogroups, in contrast, show a much more complex spatial pattern with varying levels of range overlap between phylogroups. Phylogroup sample sizes varied from 2 to 17 specimens (mean: 6) for African phylogroups, and from 1 to 17 (mean: 6) for Asia. Note that for the niche analyses and the bioclimatic envelope models, parakeet occurrences that fell within overlapping polygons were randomly assigned to one of the polygons. That way, each lineage was represented in the overlapping area, without sampling the same data point multiple times (#CITATION_TAG et al., 2012). Sample sizes used for modelling varied from 14 to 59 occurrences (mean: 35) for African phylogroups and from 6 to 126 (mean: 48) for Asia (Appendix S2).	y
CCT489	"Given its strong effect on the accuracy of predictions of invasion risk, incorporating information on association with human-modified habitats in the native range should be integrated into bioclimatic envelope models, if they are to effectively guide invasive species management. Association with human-modified habitats in the native range may enable ringnecked parakeets to exploit equivalent human-modified landscapes in Europe, allowing them to colonize areas far colder than their native range. Ring-necked parakeets have almost 90% of their invasive distribution outside their native climatic niche (Fig. 1), and this is among the highest values of niche expansion known for vertebrates (Strubbe et al., 2013;Li et al., 2014). Previous studies suggest niche expansion into climates not occupied in the native range is more likely for species with small native ranges (plants, Early & Sax, 2014;amphibians and reptiles, Li et al., 2014), for species introduced longer ago or that have invaded areas located at lower latitudes than the native range (amphibians and reptiles, Early & Sax, 2014). Ring-necked parakeets, however, have a very large native range and have been introduced relatively recent (most European introductions stem from after 1970, Strubbe & Matthysen, 2009b) to much higher latitudes than their native range. Our results thus identify, for the first time, association with humans in the native range as a factor influencing climatic niche expansion during biological invasion. Climate influences species distributions directly through species"" physiological tolerances or indirectly through its effect on available habitats, food resources and biotic interactions such as the presence of competitors (Ara ujo & Peterson, 2012, Wisz et al. 2013. The fact that ring-necked parakeets thrive in Europe suggests they may be physiologically capable of colonizing colder parts of the climate space in their native range as well. Possibly, a lack of resources and/or competition with congeneric species such as slaty-headed (P. himalayana) and Lord Derby""s Parakeet (P. derbiana) restricts the ring-necked parakeets"" native northernmost distribution limits. Indeed, endotherms such as birds are often able to tolerate a wide range of environmental conditions, but this comes at a potentially high energetic cost (Porter & Kearney, 2009). In Europe, radio-tracking (Clergeau & Vergnes, 2011;Strubbe & Matthysen, 2011) and habitat selection studies (Strubbe & Matthysen, 2007;Newson et al., 2010) indicate that parakeets prefer to forage in city parks and gardens, where bird feeders and ornamental vegetation present parakeets with abundant food. Urban areas also offer an Figure 3 Predictions of invasion risk for ring-necked parakeet in Europe derived from bioclimatic envelope models including association with human-modified habitats in the native range. Continuous model outputs (Fig. 2) were converted to binary predictions of invasion risk. Areas at risk according to both models without (see Fig. 2c) and with (see Fig. 2d) phylogeographic structure are indicated in red. Green indicates predicted parakeet presence only by a model without phylogeographic structure. Yellow delineates areas only marked as suitable by a model with phylogeographic structure. abundance of suitable nesting sites, as large, old trees are often retained for their aesthetic value. In the colder parts of Europe, parakeets increasingly breed in holes and crevices within the thermal insulation layers of buildings; in Germany, for example, such a more favourable microclimate enables them to achieve a higher breeding success compared to natural cavities (Braun, 2007). Moreover, in urban gardens, parakeets have been shown to be behaviourally dominant over native birds during foraging (Peck et al., 2014). Abundant resources and a lack of competitors may underlie the invasion success of ringnecked parakeets in environments far removed from their native (realized) niche. Yet, to elucidate the extent to which thermal and energetic constraints influence ring-necked parakeet distributional limits in their native versus non-native ranges, mechanistic niche models (which use species"" functional traits and physiological tolerances for model fitting, #CITATION_TAG et al., 2010) are required. Furthermore, although little is known about interactions between Psittacula species in their native range, the hypothesis of competitive release as an underlying driver of ring-necked parakeet invasion success in Europe may be tested by assessing whether predicted geographical distribution patterns across the native range (derived from bioclimatic models) match expectations under competitive exclusion (sensu Guti errez et al., 2014)."	0	"In the colder parts of Europe, parakeets increasingly breed in holes and crevices within the thermal insulation layers of buildings; in Germany, for example, such a more favourable microclimate enables them to achieve a higher breeding success compared to natural cavities (Braun, 2007). Moreover, in urban gardens, parakeets have been shown to be behaviourally dominant over native birds during foraging (Peck et al., 2014). Abundant resources and a lack of competitors may underlie the invasion success of ringnecked parakeets in environments far removed from their native (realized) niche. Yet, to elucidate the extent to which thermal and energetic constraints influence ring-necked parakeet distributional limits in their native versus non-native ranges, mechanistic niche models (which use species"" functional traits and physiological tolerances for model fitting, #CITATION_TAG et al., 2010) are required. Furthermore, although little is known about interactions between Psittacula species in their native range, the hypothesis of competitive release as an underlying driver of ring-necked parakeet invasion success in Europe may be tested by assessing whether predicted geographical distribution patterns across the native range (derived from bioclimatic models) match expectations under competitive exclusion (sensu Guti errez et al., 2014)."	e
CCT490	"Here, using a unique dataset on the distribution of a global avian invader, the ring-necked parakeet (Psittacula krameri), we test whether accounting for within-taxon niche structure and association with humans in the native range leads to more accurate predictions of invasion risk. Ringnecked parakeets are native to large parts of Africa and Asia. Across their native range, they have benefited from the conversion of natural habitats to agro-ecosystems (Bruggers & Beck, 1979;Khan, 2002) and reach their highest breeding densities near human settlements and cultivated crops (#CITATION_TAG et al., 2004). These parakeets are a globally widespread invasive species, and they compete with native birds and bats and cause damage to crops (Strubbe & Matthysen, 2009a;Hern andez-Brito et al., 2014;Peck et al., 2014). In this study, we present the most complete information on the distribution of ring-necked parakeets to date, comprising a set of about 1200 (686 native and 513 invasive) occurrences collected at a finer resolution than has previously been reported, 123 failed and successful introduction events across Europe, plus a high-resolution mtDNA molecular phylogeny derived from 98 museum specimens geospatially selected to cover the parakeet""s native range and from feather samples collected at 13 invaded sites across Europe. We expect that incorporating within-taxon niche structure into bioclimatic envelope models will result in important differences in the geographical distribution of climate predicted as suitable for parakeets across Europe and that accounting for association with human-modified habitats in the native range will allow for more accurate predictions of the potential European distribution of this ubiquitous avian invader."	0	"Here, using a unique dataset on the distribution of a global avian invader, the ring-necked parakeet (Psittacula krameri), we test whether accounting for within-taxon niche structure and association with humans in the native range leads to more accurate predictions of invasion risk. Ringnecked parakeets are native to large parts of Africa and Asia. Across their native range, they have benefited from the conversion of natural habitats to agro-ecosystems (Bruggers & Beck, 1979;Khan, 2002) and reach their highest breeding densities near human settlements and cultivated crops (#CITATION_TAG et al., 2004). These parakeets are a globally widespread invasive species, and they compete with native birds and bats and cause damage to crops (Strubbe & Matthysen, 2009a;Hern andez-Brito et al., 2014;Peck et al., 2014). In this study, we present the most complete information on the distribution of ring-necked parakeets to date, comprising a set of about 1200 (686 native and 513 invasive) occurrences collected at a finer resolution than has previously been reported, 123 failed and successful introduction events across Europe, plus a high-resolution mtDNA molecular phylogeny derived from 98 museum specimens geospatially selected to cover the parakeet""s native range and from feather samples collected at 13 invaded sites across Europe. We expect that incorporating within-taxon niche structure into bioclimatic envelope models will result in important differences in the geographical distribution of climate predicted as suitable for parakeets across Europe and that accounting for association with human-modified habitats in the native range will allow for more accurate predictions of the potential European distribution of this ubiquitous avian invader."	r
CCT491	To identify native phylogroups, Bayesian phylogenetic inference was implemented in MRBAYES v3.2 (Ronquist & Huelsenbeck, 2003) using the CIPRES Science Gateway (Miller et al., 2010) with 10 million generations over four parallel Monte Carlo Markov chains (MCMC), under an HKY evolutionary model (Felsenstein, 1981). TRACER v1.6 (Rambaut & Drummond, 2007) was used to assess convergence. After discarding the first 25% as burn-in, tree topologies were summarized in a 50% consensus tree. To identify native haplotypes in the invasive range, the combined native and invasive dataset was condensed into haplotypes using TCS (#CITATION_TAG et al., 2000). All node values with a posterior probability of > 50 were used to identify phylogroups.	5	To identify native phylogroups, Bayesian phylogenetic inference was implemented in MRBAYES v3.2 (Ronquist & Huelsenbeck, 2003) using the CIPRES Science Gateway (Miller et al., 2010) with 10 million generations over four parallel Monte Carlo Markov chains (MCMC), under an HKY evolutionary model (Felsenstein, 1981). TRACER v1.6 (Rambaut & Drummond, 2007) was used to assess convergence. After discarding the first 25% as burn-in, tree topologies were summarized in a 50% consensus tree. To identify native haplotypes in the invasive range, the combined native and invasive dataset was condensed into haplotypes using TCS (#CITATION_TAG et al., 2000). All node values with a posterior probability of > 50 were used to identify phylogroups.	i
CCT492	The vast majority of electromagnetic observatories are, by their very nature, directional. Thus, in order for gravitational wave observations to be useful to other astronomers, it is necessary to extract the sky location from the gravitational wave signal. However, gravitational 3 wave detectors are sensitive to signals from large fraction of the sky and a single gravitational wave detector provides essentially no directional information for a short duration source. Thus, the ability to reconstruct the location of a transient signal is primarily due to triangulation based on the observed time delays of the signal at several detectors. For more than two sites, requiring a consistency between the observed amplitudes will also serve to restrict the allowed sky positions. In particular, for three detectors, using only timing information, one obtains two sky locations that are mirror images with respect to the plane of the three detectors; generically the amplitude information can be used to break this degeneracy. The issue of localization of gravitational wave signals with a detector network has been discussed previously, and several different algorithms proposed [18]#CITATION_TAG[27].	2	Thus, the ability to reconstruct the location of a transient signal is primarily due to triangulation based on the observed time delays of the signal at several detectors. For more than two sites, requiring a consistency between the observed amplitudes will also serve to restrict the allowed sky positions. In particular, for three detectors, using only timing information, one obtains two sky locations that are mirror images with respect to the plane of the three detectors; generically the amplitude information can be used to break this degeneracy. The issue of localization of gravitational wave signals with a detector network has been discussed previously, and several different algorithms proposed [18]#CITATION_TAG[27].	s
CCT493	This is precisely the form in which calibration errors are expressed, for example in #CITATION_TAG.	0	This is precisely the form in which calibration errors are expressed, for example in #CITATION_TAG.	T
CCT494	Based on the results of recent searches #CITATION_TAG, we will take an SNR of 7 in each of the LIGO and Virgo detectors to be the approximate amplitude where a binary coalescence signal would stand above the noise background. For BNS signals of this amplitude, table 1 gives a timing accuracy of 0.27 ms for the LIGO detectors and 0.19 ms for Virgo. This gives at best case localization of 20 deg 2 . A signal would require an SNR of around 25 and a well located source to reduce the 90% localization ellipse to 1 deg 2 -certainly a possibility for the louder sources in the advanced detector era. The localization accuracy for 10-10M BBH waveforms is comparable to BNS, namely 20 deg 2 for optimally located signals at single detector SNR of 7. Interestingly, the inclusion of the merger and ringdown portions of the signal provide an order of magnitude improvement in the localization accuracy. This improvement is consistent with what was observed in a detailed study of parameter estimation for BBH [43].	4	Based on the results of recent searches #CITATION_TAG, we will take an SNR of 7 in each of the LIGO and Virgo detectors to be the approximate amplitude where a binary coalescence signal would stand above the noise background. For BNS signals of this amplitude, table 1 gives a timing accuracy of 0.27 ms for the LIGO detectors and 0.19 ms for Virgo. This gives at best case localization of 20 deg 2 . A signal would require an SNR of around 25 and a well located source to reduce the 90% localization ellipse to 1 deg 2 -certainly a possibility for the louder sources in the advanced detector era. The localization accuracy for 10-10M BBH waveforms is comparable to BNS, namely 20 deg 2 for optimally located signals at single detector SNR of 7.	B
CCT495	The vast majority of electromagnetic observatories are, by their very nature, directional. Thus, in order for gravitational wave observations to be useful to other astronomers, it is necessary to extract the sky location from the gravitational wave signal. However, gravitational 3 wave detectors are sensitive to signals from large fraction of the sky and a single gravitational wave detector provides essentially no directional information for a short duration source. Thus, the ability to reconstruct the location of a transient signal is primarily due to triangulation based on the observed time delays of the signal at several detectors. For more than two sites, requiring a consistency between the observed amplitudes will also serve to restrict the allowed sky positions. In particular, for three detectors, using only timing information, one obtains two sky locations that are mirror images with respect to the plane of the three detectors; generically the amplitude information can be used to break this degeneracy. The issue of localization of gravitational wave signals with a detector network has been discussed previously, and several different algorithms proposed #CITATION_TAG -[27].	2	Thus, the ability to reconstruct the location of a transient signal is primarily due to triangulation based on the observed time delays of the signal at several detectors. For more than two sites, requiring a consistency between the observed amplitudes will also serve to restrict the allowed sky positions. In particular, for three detectors, using only timing information, one obtains two sky locations that are mirror images with respect to the plane of the three detectors; generically the amplitude information can be used to break this degeneracy. The issue of localization of gravitational wave signals with a detector network has been discussed previously, and several different algorithms proposed #CITATION_TAG -[27].	s
CCT496	The vast majority of electromagnetic observatories are, by their very nature, directional. Thus, in order for gravitational wave observations to be useful to other astronomers, it is necessary to extract the sky location from the gravitational wave signal. However, gravitational 3 wave detectors are sensitive to signals from large fraction of the sky and a single gravitational wave detector provides essentially no directional information for a short duration source. Thus, the ability to reconstruct the location of a transient signal is primarily due to triangulation based on the observed time delays of the signal at several detectors. For more than two sites, requiring a consistency between the observed amplitudes will also serve to restrict the allowed sky positions. In particular, for three detectors, using only timing information, one obtains two sky locations that are mirror images with respect to the plane of the three detectors; generically the amplitude information can be used to break this degeneracy. The issue of localization of gravitational wave signals with a detector network has been discussed previously, and several different algorithms proposed [18]- #CITATION_TAG[27].	2	Thus, the ability to reconstruct the location of a transient signal is primarily due to triangulation based on the observed time delays of the signal at several detectors. For more than two sites, requiring a consistency between the observed amplitudes will also serve to restrict the allowed sky positions. In particular, for three detectors, using only timing information, one obtains two sky locations that are mirror images with respect to the plane of the three detectors; generically the amplitude information can be used to break this degeneracy. The issue of localization of gravitational wave signals with a detector network has been discussed previously, and several different algorithms proposed [18]- #CITATION_TAG[27].	s
CCT497	Our results showed that differences in BMC and BMD between cyclists and active controls were greater in adolescents over 17 years old than in those under that age. We also found a negative association between age and BMC, and BMD, in the cyclists. Unfortunately we only can compare our results with longitudinal studies conducted in adults. Nichols et al. [29] described the tracked changes in BMD over a 7-year period in competitive male master cyclists and non-athletes. Their results showed that at the beginning of the study, cyclists had lower lumbar and hip BMD than the control group; interestingly at the end of the study master cyclists had lost more BMD than controls #CITATION_TAG. A previous study examined BMD over a one year season in amateur male cyclists and found 1-1.5% decrease in BMD at the proximal femur but no changes at the lumbar spine [33]. Nichols et al. [8] observed that master cyclists (.50 yr) had lower total, lumbar and hip BMD than younger cyclists (mean 31 yr).	1	We also found a negative association between age and BMC, and BMD, in the cyclists. Unfortunately we only can compare our results with longitudinal studies conducted in adults. Nichols et al. [29] described the tracked changes in BMD over a 7-year period in competitive male master cyclists and non-athletes. Their results showed that at the beginning of the study, cyclists had lower lumbar and hip BMD than the control group; interestingly at the end of the study master cyclists had lost more BMD than controls #CITATION_TAG. A previous study examined BMD over a one year season in amateur male cyclists and found 1-1.5% decrease in BMD at the proximal femur but no changes at the lumbar spine [33]. Nichols et al. [8] observed that master cyclists (. 50 yr) had lower total, lumbar and hip BMD than younger cyclists (mean 31 yr).	r
CCT498	"(1) An environment offering abundant energy beyond homeostatic need ""pushes"" it into the body via some evolutionary appropriate gateway. The surplus, naturally, goes into depots. Peters and Langemann, however, remained in doubt about this concept partly due to the fact that this ""push"" does not work invariably for all animal or human subjects (Martin et al., 2010;#CITATION_TAG et al., 2011). (2) A somewhat alternative concept, well accepted for the last 50 years, concerns the ""pull"" character of the open system ""organism-environment,"" supposedly in accordance with homeostatic needs. In this system, either the size of fat depot (Kennedy, 1953;Woods and Ramsay, 2011) or glucose levels (Mayer, 1953) are being controlled."	1	"(1) An environment offering abundant energy beyond homeostatic need ""pushes"" it into the body via some evolutionary appropriate gateway. The surplus, naturally, goes into depots. Peters and Langemann, however, remained in doubt about this concept partly due to the fact that this ""push"" does not work invariably for all animal or human subjects (Martin et al., 2010;#CITATION_TAG et al., 2011). (2) A somewhat alternative concept, well accepted for the last 50 years, concerns the ""pull"" character of the open system ""organism-environment,"" supposedly in accordance with homeostatic needs. In this system, either the size of fat depot (Kennedy, 1953;Woods and Ramsay, 2011) or glucose levels (Mayer, 1953) are being controlled."	t
CCT499	The role of depots, as determined by a general principle in economic supply chains, is energy buffering in unstable environments (#CITATION_TAG et al., 2011). Peters and Langemann (2009) analyzed two concepts of environment-organism relationship with opposite views at depots:	0	The role of depots, as determined by a general principle in economic supply chains, is energy buffering in unstable environments (#CITATION_TAG et al., 2011). Peters and Langemann (2009) analyzed two concepts of environment-organism relationship with opposite views at depots:	T
CCT500	Oral stimulation with both sweet and non-sweet CHO activated brain regions associated with reward -insula/frontal operculum, orbitofrontal cortex, and striatum. These regions were unresponsive to sweet, non-CHO stimulation with saccharin (Jeukendrup and Chambers, 2010). On the other hand, experiments with the no-calorie fat substitute (Olestra) revealed an impaired ability to use sensory cues associated with fat to predict caloric outcomes (Swithers et al., 2011). In humans, the intra-amniotic injection of fat (Lipiodol) reduced fetal drinking, while injection of sodium saccharin stimulated it; infants consumed the same amounts of milk formulas with different fat contents. Oral fat stimulation had no positive or negative mood-related effects, whereas sucrose shifted emotional spectrum toward positive scores (#CITATION_TAG, 2005). CHO-rich food intake (buffet, KR 0.511:1) relieved neuroglycopenic and mood responses to stress independently from oral or i.v. administration of energy (Hitze et al., 2010).	0	These regions were unresponsive to sweet, non-CHO stimulation with saccharin (Jeukendrup and Chambers, 2010). On the other hand, experiments with the no-calorie fat substitute (Olestra) revealed an impaired ability to use sensory cues associated with fat to predict caloric outcomes (Swithers et al., 2011). In humans, the intra-amniotic injection of fat (Lipiodol) reduced fetal drinking, while injection of sodium saccharin stimulated it; infants consumed the same amounts of milk formulas with different fat contents. Oral fat stimulation had no positive or negative mood-related effects, whereas sucrose shifted emotional spectrum toward positive scores (#CITATION_TAG, 2005). CHO-rich food intake (buffet, KR 0.511:1) relieved neuroglycopenic and mood responses to stress independently from oral or i.v. administration of energy (Hitze et al., 2010).	 
CCT501	"Using the Woodyartt""s equation, I calculated KR of 45 experimental works (2005)(2006)(2007)(2008)(2009)(2010)(2011), wherever there was enough information regarding macronutrient composition. It is evident (Figure 1B) that in the HFD, KR is almost uniformly below the threshold of ketogenesis indicating a too-high proportion of CHO. It is interesting that even below the ketogenic threshold, the lower CHO proportion was, the higher neuroprotective effects were reported, e.g., against hypoxia (#CITATION_TAG et al., 2007(Puchowicz et al., , 2008."	1	"Using the Woodyartt""s equation, I calculated KR of 45 experimental works (2005)(2006)(2007)(2008)(2009)(2010)(2011), wherever there was enough information regarding macronutrient composition. It is evident (Figure 1B) that in the HFD, KR is almost uniformly below the threshold of ketogenesis indicating a too-high proportion of CHO. It is interesting that even below the ketogenic threshold, the lower CHO proportion was, the higher neuroprotective effects were reported, e.g., against hypoxia (#CITATION_TAG et al., 2007(Puchowicz et al., , 2008."	 
CCT502	To sum it up, fat per se is neither as highly rewarding as CHO nor it is as addictive (Wojnicki et al., 2008;Avena et al., 2009;#CITATION_TAG et al., 2009;Berthoud et al., 2011). obesity; it is CHO that is not limited enough in HFD; (2) KR may be an element of common language in experiments with different methodological approaches.	0	To sum it up, fat per se is neither as highly rewarding as CHO nor it is as addictive (Wojnicki et al., 2008;Avena et al., 2009;#CITATION_TAG et al., 2009;Berthoud et al., 2011). obesity; it is CHO that is not limited enough in HFD; (2) KR may be an element of common language in experiments with different methodological approaches.	T
CCT503	"(2) An elaborate (and rare for modern physiology) systemic concept explaining the fundamental ability of the brain to control priorities of energy allocation has been proposed by Peters and colleagues who also titled their theory the Selfish Brain. They wrote referring to DuPont\""s book: ""The brain looks after itself first. Such selfishness is reminiscent of an earlier concept in which the brain""s selfishness was addressed with respect to addiction. We chose our title by analogy but applied it in a different context, i.e., the competition for energy resources"" (#CITATION_TAG et al., 2004)."	0	"(2) An elaborate (and rare for modern physiology) systemic concept explaining the fundamental ability of the brain to control priorities of energy allocation has been proposed by Peters and colleagues who also titled their theory the Selfish Brain. They wrote referring to DuPont\""s book: ""The brain looks after itself first. Such selfishness is reminiscent of an earlier concept in which the brain""s selfishness was addressed with respect to addiction. We chose our title by analogy but applied it in a different context, i.e., the competition for energy resources"" (#CITATION_TAG et al., 2004)."	c
CCT504	"There is evidence that the brain favors consumption of carbohydrates (CHO) rather than fats, this preference resulting in glycolysis-based energy metabolism domination. This metabolic mode, typical for consumers of the ""Western diet"" (#CITATION_TAG et al., 2005;Seneff et al., 2011), is characterized by over-generation of reactive oxygen species and advanced glycation products both of which are implicated in many of the neurodegenerative diseases (Tessier, 2010;Vicente Miranda and Outeiro, 2010;Auburger and Kurz, 2011). However, it is not CHO but fat that is often held responsible for metabolic pathologies. This paper, based on analysis of experimental data, offers an opinion that the obesogenic and neurodegenerative effects of dietary fat in the high-fat diets (HFD) cannot be separated from the effects of the CHO compound in them. Since this is not a comprehensive literature review, only essential research results are presented."	0	"There is evidence that the brain favors consumption of carbohydrates (CHO) rather than fats, this preference resulting in glycolysis-based energy metabolism domination. This metabolic mode, typical for consumers of the ""Western diet"" (#CITATION_TAG et al., 2005;Seneff et al., 2011), is characterized by over-generation of reactive oxygen species and advanced glycation products both of which are implicated in many of the neurodegenerative diseases (Tessier, 2010;Vicente Miranda and Outeiro, 2010;Auburger and Kurz, 2011). However, it is not CHO but fat that is often held responsible for metabolic pathologies. This paper, based on analysis of experimental data, offers an opinion that the obesogenic and neurodegenerative effects of dietary fat in the high-fat diets (HFD) cannot be separated from the effects of the CHO compound in them. Since this is not a comprehensive literature review, only essential research results are presented."	h
CCT505	"Food reward, hyperphagia, and obesity. Am. J. Physiol. Regul. Integr. Comp. Physiol. 300, R1266-R1277. Bilsborough, S. A., and Crowe, T. C. (2003. Lowcarbohydrate diets: what are the potential short-and long-term health implications? Asia Pac. J. Clin. Nutr. 12, 396-404. Brinkworth, G. D., Noakes, M., Buckley, J. D., Keogh, J. B., and Clifton, P. M. (2009). Long-term effects of a very-low-carbohydrate weight loss diet compared with an isocaloric low-fat diet after 12 mo. Am. J. Clin. Nutr. 90,[23][24][25][26][27][28][29][30][31][32] be expected to decrease or stop. However, this is possible only in deterministic environments. In variable environments, energy storage becomes advantageous and approximately equal parts of energy are allocated for maintenance, reproduction, and depots (Fischer et al., 2011). Energy intake beyond rigid homeostatic regulation relies on behaviors with hedonic, rewarding, and addictive nuances more characteristic for CHO than for fat. Their traits notwithstanding, these behaviors are highly evolutionary significant: ""Although at first glance, hijacking of the homeostatic regulatory mechanisms by its hedonic counterpart may seem conflicting, it should be borne in mind that during evolution, humans have lived in an environment where food availability was restricted and uncertain (e.g., hunter-gatherers) and the biological system has been \""hard-wired\"" to maximize energy stores"" (#CITATION_TAG et al., 2011)."	0	"However, this is possible only in deterministic environments. In variable environments, energy storage becomes advantageous and approximately equal parts of energy are allocated for maintenance, reproduction, and depots (Fischer et al., 2011). Energy intake beyond rigid homeostatic regulation relies on behaviors with hedonic, rewarding, and addictive nuances more characteristic for CHO than for fat. Their traits notwithstanding, these behaviors are highly evolutionary significant: ""Although at first glance, hijacking of the homeostatic regulatory mechanisms by its hedonic counterpart may seem conflicting, it should be borne in mind that during evolution, humans have lived in an environment where food availability was restricted and uncertain (e.g., hunter-gatherers) and the biological system has been \""hard-wired\"" to maximize energy stores"" (#CITATION_TAG et al., 2011)."	n
CCT506	"There is evidence that the brain favors consumption of carbohydrates (CHO) rather than fats, this preference resulting in glycolysis-based energy metabolism domination. This metabolic mode, typical for consumers of the ""Western diet"" (Cordain et al., 2005;#CITATION_TAG et al., 2011), is characterized by over-generation of reactive oxygen species and advanced glycation products both of which are implicated in many of the neurodegenerative diseases (Tessier, 2010;Vicente Miranda and Outeiro, 2010;Auburger and Kurz, 2011). However, it is not CHO but fat that is often held responsible for metabolic pathologies. This paper, based on analysis of experimental data, offers an opinion that the obesogenic and neurodegenerative effects of dietary fat in the high-fat diets (HFD) cannot be separated from the effects of the CHO compound in them. Since this is not a comprehensive literature review, only essential research results are presented."	0	"There is evidence that the brain favors consumption of carbohydrates (CHO) rather than fats, this preference resulting in glycolysis-based energy metabolism domination. This metabolic mode, typical for consumers of the ""Western diet"" (Cordain et al., 2005;#CITATION_TAG et al., 2011), is characterized by over-generation of reactive oxygen species and advanced glycation products both of which are implicated in many of the neurodegenerative diseases (Tessier, 2010;Vicente Miranda and Outeiro, 2010;Auburger and Kurz, 2011). However, it is not CHO but fat that is often held responsible for metabolic pathologies. This paper, based on analysis of experimental data, offers an opinion that the obesogenic and neurodegenerative effects of dietary fat in the high-fat diets (HFD) cannot be separated from the effects of the CHO compound in them. Since this is not a comprehensive literature review, only essential research results are presented."	h
CCT507	"(1) An environment offering abundant energy beyond homeostatic need ""pushes"" it into the body via some evolutionary appropriate gateway. The surplus, naturally, goes into depots. Peters and Langemann, however, remained in doubt about this concept partly due to the fact that this ""push"" does not work invariably for all animal or human subjects (#CITATION_TAG et al., 2010;Cao et al., 2011). (2) A somewhat alternative concept, well accepted for the last 50 years, concerns the ""pull"" character of the open system ""organism-environment,"" supposedly in accordance with homeostatic needs. In this system, either the size of fat depot (Kennedy, 1953;Woods and Ramsay, 2011) or glucose levels (Mayer, 1953) are being controlled."	1	"(1) An environment offering abundant energy beyond homeostatic need ""pushes"" it into the body via some evolutionary appropriate gateway. The surplus, naturally, goes into depots. Peters and Langemann, however, remained in doubt about this concept partly due to the fact that this ""push"" does not work invariably for all animal or human subjects (#CITATION_TAG et al., 2010;Cao et al., 2011). (2) A somewhat alternative concept, well accepted for the last 50 years, concerns the ""pull"" character of the open system ""organism-environment,"" supposedly in accordance with homeostatic needs. In this system, either the size of fat depot (Kennedy, 1953;Woods and Ramsay, 2011) or glucose levels (Mayer, 1953) are being controlled."	t
CCT508	"(1) An environment offering abundant energy beyond homeostatic need ""pushes"" it into the body via some evolutionary appropriate gateway. The surplus, naturally, goes into depots. Peters and Langemann, however, remained in doubt about this concept partly due to the fact that this ""push"" does not work invariably for all animal or human subjects (Martin et al., 2010;Cao et al., 2011). (2) A somewhat alternative concept, well accepted for the last 50 years, concerns the ""pull"" character of the open system ""organism-environment,"" supposedly in accordance with homeostatic needs. In this system, either the size of fat depot (#CITATION_TAG, 1953;Woods and Ramsay, 2011) or glucose levels (Mayer, 1953) are being controlled."	0	"The surplus, naturally, goes into depots. Peters and Langemann, however, remained in doubt about this concept partly due to the fact that this ""push"" does not work invariably for all animal or human subjects (Martin et al., 2010;Cao et al., 2011). (2) A somewhat alternative concept, well accepted for the last 50 years, concerns the ""pull"" character of the open system ""organism-environment,"" supposedly in accordance with homeostatic needs. In this system, either the size of fat depot (#CITATION_TAG, 1953;Woods and Ramsay, 2011) or glucose levels (Mayer, 1953) are being controlled."	h
CCT509	"To maximize energy stores, energy intake relies on CHO-driven behaviors to allow the environmental ""push. Therefore: (1) dietary fat is not to blame for the diet-induced incidence. In a recent article entitled ""Using Marketing Muscle to Sell Fat: The Rise of Obesity in the Modern Economy,"" J. Zimmerman wrote: ""In this paradigm, overeating results from more extensive advertising, new product development, increased portion sizes, and other tactics of food marketers that have caused shifts in the underlying demand for total food calories"" (#CITATION_TAG, 2011)."	0	"To maximize energy stores, energy intake relies on CHO-driven behaviors to allow the environmental ""push. Therefore: (1) dietary fat is not to blame for the diet-induced incidence. In a recent article entitled ""Using Marketing Muscle to Sell Fat: The Rise of Obesity in the Modern Economy,"" J. Zimmerman wrote: ""In this paradigm, overeating results from more extensive advertising, new product development, increased portion sizes, and other tactics of food marketers that have caused shifts in the underlying demand for total food calories"" (#CITATION_TAG, 2011)."	 
CCT510	"A century ago, Woodyatt wrote: ""antiketogenesis is an effect due to certain products which occur in the oxidation of glucose, an interaction between these products on the one hand and one or more of the acetone bodies on the other"" (Woodyatt, 1910). Shaffer (1921) calculated the number of ""ketogenic"" molecules versus molecules of glucose and concluded that the maximal ratio compatible with the oxidation of the ""ketogenic"" molecules becomes possible when their ratio is at least 1:1. Later, #CITATION_TAG (1921)  Where KR is ""ketogenic ratio,"" g is grams, P is protein, F is fat, and C is CHO. Wilder and Winter (1922) defined the threshold of ketogenesis explaining it from the standpoint of condition where either ketone bodies or glucose can be oxidized. They arrived, together with Shaffer and Woodyatt, at the conclusion that KR for induction of ketogenesis should be 2:1 or higher. This is a very important point, not only methodologically, but also ideologically. The KR invariably indicates whether the CHO proportion is low enough for allowing the fat-mobilizing pathway and ketogenesis, or high enough for blocking it and supporting glycolysis instead. The latter option opens the energy ""push"" opportunity through CHO intake gateway with the consequences discussed above. On the other hand, ketogenesis introduces a fuel alternative to glucose, which can be crucial in metabolic pathologies."	0	"A century ago, Woodyatt wrote: ""antiketogenesis is an effect due to certain products which occur in the oxidation of glucose, an interaction between these products on the one hand and one or more of the acetone bodies on the other"" (Woodyatt, 1910). Shaffer (1921) calculated the number of ""ketogenic"" molecules versus molecules of glucose and concluded that the maximal ratio compatible with the oxidation of the ""ketogenic"" molecules becomes possible when their ratio is at least 1:1. Later, #CITATION_TAG (1921)  Where KR is ""ketogenic ratio,"" g is grams, P is protein, F is fat, and C is CHO. Wilder and Winter (1922) defined the threshold of ketogenesis explaining it from the standpoint of condition where either ketone bodies or glucose can be oxidized. They arrived, together with Shaffer and Woodyatt, at the conclusion that KR for induction of ketogenesis should be 2:1 or higher. This is a very important point, not only methodologically, but also ideologically."	t
CCT511	"A century ago, Woodyatt wrote: ""antiketogenesis is an effect due to certain products which occur in the oxidation of glucose, an interaction between these products on the one hand and one or more of the acetone bodies on the other"" (#CITATION_TAG, 1910). Shaffer (1921) calculated the number of ""ketogenic"" molecules versus molecules of glucose and concluded that the maximal ratio compatible with the oxidation of the ""ketogenic"" molecules becomes possible when their ratio is at least 1:1. Later, Woodyatt (1921)  Where KR is ""ketogenic ratio,"" g is grams, P is protein, F is fat, and C is CHO. Wilder and Winter (1922) defined the threshold of ketogenesis explaining it from the standpoint of condition where either ketone bodies or glucose can be oxidized. They arrived, together with Shaffer and Woodyatt, at the conclusion that KR for induction of ketogenesis should be 2:1 or higher. This is a very important point, not only methodologically, but also ideologically. The KR invariably indicates whether the CHO proportion is low enough for allowing the fat-mobilizing pathway and ketogenesis, or high enough for blocking it and supporting glycolysis instead. The latter option opens the energy ""push"" opportunity through CHO intake gateway with the consequences discussed above. On the other hand, ketogenesis introduces a fuel alternative to glucose, which can be crucial in metabolic pathologies."	0	"A century ago, Woodyatt wrote: ""antiketogenesis is an effect due to certain products which occur in the oxidation of glucose, an interaction between these products on the one hand and one or more of the acetone bodies on the other"" (#CITATION_TAG, 1910). Shaffer (1921) calculated the number of ""ketogenic"" molecules versus molecules of glucose and concluded that the maximal ratio compatible with the oxidation of the ""ketogenic"" molecules becomes possible when their ratio is at least 1:1. Later, Woodyatt (1921)  Where KR is ""ketogenic ratio,"" g is grams, P is protein, F is fat, and C is CHO. Wilder and Winter (1922) defined the threshold of ketogenesis explaining it from the standpoint of condition where either ketone bodies or glucose can be oxidized."	A
CCT512	"These two meaning of the Selfish Brain have important common points if we consider the addiction (highly non-homeostatic) as a result of the ""push"" principle borrowed from the economic ""push-pull"" paradigm of supply chains. As early as in 1998, Hill and Peters wrote: ""According to the \""push\"" principle, the environment pushes excess amounts of energy into the organism"" (#CITATION_TAG and Peters, 1998)."	0	"These two meaning of the Selfish Brain have important common points if we consider the addiction (highly non-homeostatic) as a result of the ""push"" principle borrowed from the economic ""push-pull"" paradigm of supply chains. As early as in 1998, Hill and Peters wrote: ""According to the \""push\"" principle, the environment pushes excess amounts of energy into the organism"" (#CITATION_TAG and Peters, 1998)."	s
CCT513	Oral stimulation with both sweet and non-sweet CHO activated brain regions associated with reward -insula/frontal operculum, orbitofrontal cortex, and striatum. These regions were unresponsive to sweet, non-CHO stimulation with saccharin (Jeukendrup and Chambers, 2010). On the other hand, experiments with the no-calorie fat substitute (Olestra) revealed an impaired ability to use sensory cues associated with fat to predict caloric outcomes (#CITATION_TAG et al., 2011). In humans, the intra-amniotic injection of fat (Lipiodol) reduced fetal drinking, while injection of sodium saccharin stimulated it; infants consumed the same amounts of milk formulas with different fat contents. Oral fat stimulation had no positive or negative mood-related effects, whereas sucrose shifted emotional spectrum toward positive scores (Mattes, 2005). CHO-rich food intake (buffet, KR 0.511:1) relieved neuroglycopenic and mood responses to stress independently from oral or i.v. administration of energy (Hitze et al., 2010).	2	Oral stimulation with both sweet and non-sweet CHO activated brain regions associated with reward -insula/frontal operculum, orbitofrontal cortex, and striatum. These regions were unresponsive to sweet, non-CHO stimulation with saccharin (Jeukendrup and Chambers, 2010). On the other hand, experiments with the no-calorie fat substitute (Olestra) revealed an impaired ability to use sensory cues associated with fat to predict caloric outcomes (#CITATION_TAG et al., 2011). In humans, the intra-amniotic injection of fat (Lipiodol) reduced fetal drinking, while injection of sodium saccharin stimulated it; infants consumed the same amounts of milk formulas with different fat contents. Oral fat stimulation had no positive or negative mood-related effects, whereas sucrose shifted emotional spectrum toward positive scores (Mattes, 2005). CHO-rich food intake (buffet, KR 0.511:1) relieved neuroglycopenic and mood responses to stress independently from oral or i.v. administration of energy (Hitze et al., 2010).	 
CCT514	Oral stimulation with both sweet and non-sweet CHO activated brain regions associated with reward -insula/frontal operculum, orbitofrontal cortex, and striatum. These regions were unresponsive to sweet, non-CHO stimulation with saccharin (#CITATION_TAG and Chambers, 2010). On the other hand, experiments with the no-calorie fat substitute (Olestra) revealed an impaired ability to use sensory cues associated with fat to predict caloric outcomes (Swithers et al., 2011). In humans, the intra-amniotic injection of fat (Lipiodol) reduced fetal drinking, while injection of sodium saccharin stimulated it; infants consumed the same amounts of milk formulas with different fat contents. Oral fat stimulation had no positive or negative mood-related effects, whereas sucrose shifted emotional spectrum toward positive scores (Mattes, 2005). CHO-rich food intake (buffet, KR 0.511:1) relieved neuroglycopenic and mood responses to stress independently from oral or i.v. administration of energy (Hitze et al., 2010).	0	Oral stimulation with both sweet and non-sweet CHO activated brain regions associated with reward -insula/frontal operculum, orbitofrontal cortex, and striatum. These regions were unresponsive to sweet, non-CHO stimulation with saccharin (#CITATION_TAG and Chambers, 2010). On the other hand, experiments with the no-calorie fat substitute (Olestra) revealed an impaired ability to use sensory cues associated with fat to predict caloric outcomes (Swithers et al., 2011). In humans, the intra-amniotic injection of fat (Lipiodol) reduced fetal drinking, while injection of sodium saccharin stimulated it; infants consumed the same amounts of milk formulas with different fat contents. Oral fat stimulation had no positive or negative mood-related effects, whereas sucrose shifted emotional spectrum toward positive scores (Mattes, 2005).	h
CCT515	"As far as the use of different methods explicitly involving paradigmatic reflections is concerned, we (the three of us involved in the focus groups in South Africa) chose to handle the focus group sessions in relation to the questionnaire results by adopting a position somewhere between a ""pragmatic"" and a ""transformative"" approach. Our pragmatism can be classed as what Onwuegbuzie, Johnson andCollins (2009:1268) refer to as a ""dialectical pragmatism""; this form of pragmatism embraces a philosophy of ""careful listening to multiple perspectives"" rather than upholding a strong form of realism. Furthermore, our form of pragmatism veers in the direction of including 1 features associated with the transformative paradigm as elucidated by #CITATION_TAG (2010). Mertens (2010) indicates that, within the transformative paradigmatic outlook, it is recognised that it is part of the researcher""s responsibility to consider the uses that might be made of their work, and to take into consideration the way in which research outcomes can be linked to social justice."	4	"As far as the use of different methods explicitly involving paradigmatic reflections is concerned, we (the three of us involved in the focus groups in South Africa) chose to handle the focus group sessions in relation to the questionnaire results by adopting a position somewhere between a ""pragmatic"" and a ""transformative"" approach. Our pragmatism can be classed as what Onwuegbuzie, Johnson andCollins (2009:1268) refer to as a ""dialectical pragmatism""; this form of pragmatism embraces a philosophy of ""careful listening to multiple perspectives"" rather than upholding a strong form of realism. Furthermore, our form of pragmatism veers in the direction of including 1 features associated with the transformative paradigm as elucidated by #CITATION_TAG (2010). Mertens (2010) indicates that, within the transformative paradigmatic outlook, it is recognised that it is part of the researcher""s responsibility to consider the uses that might be made of their work, and to take into consideration the way in which research outcomes can be linked to social justice."	r
CCT516	"As far as the organisation of the overall project is concerned, there are different teams handling the research process in different countries. Sometimes, in these various participating countries, the composition of teams for the questionnaires and those for the focus groups differed. We support #CITATION_TAG and Tashakkori""s (2010) suggestion that a methodologically eclectic approach enables all researchers involved in a project to contribute to that project, and to creatively add new contributions/ideas on how to develop the project. We also agree with Johnson (2009:449), who proposes that a pragmatic approach be geared to ""provide pragmatic, ethical solutions to local and societal problems"". This was the intention of the South African researchers involved in the questionnaire administration and in the focus groups -with a slightly different team handling the focus groups. (Nel and Tlale were part of both teams; in the questionnaire administration another researcher other than Romm was the third person on the team.) We suggest that a ""pragmatic"" umbrella can serve as a justification for mixing otherwise apparently contradictory philosophical and epistemological perspectives on what it means to conduct ""quality"" social research (Romm, 2010:438-439)."	1	"As far as the organisation of the overall project is concerned, there are different teams handling the research process in different countries. Sometimes, in these various participating countries, the composition of teams for the questionnaires and those for the focus groups differed. We support #CITATION_TAG and Tashakkori""s (2010) suggestion that a methodologically eclectic approach enables all researchers involved in a project to contribute to that project, and to creatively add new contributions/ideas on how to develop the project. We also agree with Johnson (2009:449), who proposes that a pragmatic approach be geared to ""provide pragmatic, ethical solutions to local and societal problems"". This was the intention of the South African researchers involved in the questionnaire administration and in the focus groups -with a slightly different team handling the focus groups. (Nel and Tlale were part of both teams; in the questionnaire administration another researcher other than Romm was the third person on the team."	 
CCT517	"In South Africa, as elsewhere, the complexity of the implementation of inclusive education policies is an ongoing concern for both theorists and practitioners of education (cf. #CITATION_TAG & Soudien, 2003;Tlale, 2008;Miles & Singal, 2010;Paugh & Dudley-Marling, 2011;Nel, M√ºller, Hugo, Helldin, B√§ckmann, Dwyer & Skarlind, 2011;Ngcobo & Muthukrishna, 2011;Ntombela, 2011;Hill, Baxen, Craig & Namakula, 2012). The focus group research reported in this article forms part of a broader international project exploring teachers"" roles in inclusive education. The project involves six countries: China, Finland, Lithuania, Slovenia, South Africa and the United Kingdom. In this comparative study, a mixed-method design was executed in two phases. The first phase consisted of the administration of questionnaires; the second phase employed focus group interviews (which, as we shall see, we prefer to call discussions). The rationale for this mixed-method design was that the questionnaires would offer statistically analysable data, while the focus groups would delve more fully into participants\"" experiences of teaching in inclusive classrooms and provide ""high quality data"" in specific contexts."	0	"In South Africa, as elsewhere, the complexity of the implementation of inclusive education policies is an ongoing concern for both theorists and practitioners of education (cf. #CITATION_TAG & Soudien, 2003;Tlale, 2008;Miles & Singal, 2010;Paugh & Dudley-Marling, 2011;Nel, M√ºller, Hugo, Helldin, B√§ckmann, Dwyer & Skarlind, 2011;Ngcobo & Muthukrishna, 2011;Ntombela, 2011;Hill, Baxen, Craig & Namakula, 2012). The focus group research reported in this article forms part of a broader international project exploring teachers"" roles in inclusive education. The project involves six countries: China, Finland, Lithuania, Slovenia, South Africa and the United Kingdom. In this comparative study, a mixed-method design was executed in two phases."	I
CCT518	"As far as the use of different methods explicitly involving paradigmatic reflections is concerned, we (the three of us involved in the focus groups in South Africa) chose to handle the focus group sessions in relation to the questionnaire results by adopting a position somewhere between a ""pragmatic"" and a ""transformative"" approach. Our pragmatism can be classed as what Onwuegbuzie, #CITATION_TAG andCollins (2009:1268) refer to as a ""dialectical pragmatism""; this form of pragmatism embraces a philosophy of ""careful listening to multiple perspectives"" rather than upholding a strong form of realism. Furthermore, our form of pragmatism veers in the direction of including 1 features associated with the transformative paradigm as elucidated by Mertens (2010). Mertens (2010) indicates that, within the transformative paradigmatic outlook, it is recognised that it is part of the researcher""s responsibility to consider the uses that might be made of their work, and to take into consideration the way in which research outcomes can be linked to social justice."	0	"As far as the use of different methods explicitly involving paradigmatic reflections is concerned, we (the three of us involved in the focus groups in South Africa) chose to handle the focus group sessions in relation to the questionnaire results by adopting a position somewhere between a ""pragmatic"" and a ""transformative"" approach. Our pragmatism can be classed as what Onwuegbuzie, #CITATION_TAG andCollins (2009:1268) refer to as a ""dialectical pragmatism""; this form of pragmatism embraces a philosophy of ""careful listening to multiple perspectives"" rather than upholding a strong form of realism. Furthermore, our form of pragmatism veers in the direction of including 1 features associated with the transformative paradigm as elucidated by Mertens (2010). Mertens (2010) indicates that, within the transformative paradigmatic outlook, it is recognised that it is part of the researcher""s responsibility to consider the uses that might be made of their work, and to take into consideration the way in which research outcomes can be linked to social justice."	u
CCT519	"1 See Romm (2010:1-8) for a discussion of realism in relation to epistemological alternatives. 2 This scale, which includes three subscales, was developed by Forlin, Earle, Loreman and Sharma (2011) to measure the perceived self-efficacy of teachers in implementing inclusive education. 3 We did not shy away from offering input at times in order to enrich the process of the discussion, as also advised by Gregory and Romm (2001). For example, the primary facilitator had, in the past, been a district officer serving a number of communities; she drew on her experience to suggest, among other things, how support structures could be accessed and also how buddy systems could be generated. Our active involvement in offering content interventions is in line, too, with #CITATION_TAG and Gubrium""s (1995) account of active interviewing -although they discuss this more in terms of one-to-one interview encounters (rather than focus group sessions). 4 One of our anonymous reviewers pointed out that this can be a dilemma in particular"	4	"2 This scale, which includes three subscales, was developed by Forlin, Earle, Loreman and Sharma (2011) to measure the perceived self-efficacy of teachers in implementing inclusive education. 3 We did not shy away from offering input at times in order to enrich the process of the discussion, as also advised by Gregory and Romm (2001). For example, the primary facilitator had, in the past, been a district officer serving a number of communities; she drew on her experience to suggest, among other things, how support structures could be accessed and also how buddy systems could be generated. Our active involvement in offering content interventions is in line, too, with #CITATION_TAG and Gubrium""s (1995) account of active interviewing -although they discuss this more in terms of one-to-one interview encounters (rather than focus group sessions). 4 One of our anonymous reviewers pointed out that this can be a dilemma in particular"	a
CCT520	"As detailed above, basic changes in respiration can have a significant impact on HRV. Pneumotachography is the gold standard for the monitoring of tidal volume, however, the use of a closed face-mask required to do so is cumbersome and impractical for most research in emotion and psychological science (e.g., faceto-face interactions). In lieu of this, the use of a strain gage to index the expansion of the chest can give sufficient informationmost importantly, a strain gage can identify gross deviations of typical cyclical respiration (e.g., sighs, coughs). Mirroring the importance of HR measures to reflect true sinus rhythm (as an ectopic beat does not represent ANS input to the SA node), ""true"" respiratory cycles must also be used to correctly draw inference on respiratory oscillations and coupling to HR. However, signals from strain gages do not necessarily have a linear relationship of circumference to signal (i.e., distension/signal output relationships may be different at different belt tensions) and that chest circumference is itself an indirect measure of the respiratory cycle (i.e., lung and chest wall volumes are not identical). In lieu of direct respiratory measures, established algorithms (Moody et al., 1985(Moody et al., , 1986) that have been successively improved (e.g., Park et al., 2008;#CITATION_TAG et al., 2010) can also provide an appropriate surrogate measure of respiration from based on ECG signal morphology."	0	"In lieu of this, the use of a strain gage to index the expansion of the chest can give sufficient informationmost importantly, a strain gage can identify gross deviations of typical cyclical respiration (e.g., sighs, coughs). Mirroring the importance of HR measures to reflect true sinus rhythm (as an ectopic beat does not represent ANS input to the SA node), ""true"" respiratory cycles must also be used to correctly draw inference on respiratory oscillations and coupling to HR. However, signals from strain gages do not necessarily have a linear relationship of circumference to signal (i.e., distension/signal output relationships may be different at different belt tensions) and that chest circumference is itself an indirect measure of the respiratory cycle (i.e., lung and chest wall volumes are not identical). In lieu of direct respiratory measures, established algorithms (Moody et al., 1985(Moody et al., , 1986) that have been successively improved (e.g., Park et al., 2008;#CITATION_TAG et al., 2010) can also provide an appropriate surrogate measure of respiration from based on ECG signal morphology."	e
CCT521	Coupling between respiration and heart rate (HR) has a long research history, and was noted in classical animal studies predating the electrocardiogram, which noticed fluctuations with breathing of heart beat and blood pressure (Ludwig, 1847). Consequently, the typically functioning respiratory system is presently characterized by complex breath-to-breath variations in respiratory rate and depth (Bruce, 1996) coupled with both heart period and blood pressure oscillations in a network of continual co-modification. For instance, a decrease in respiratory frequency generally corresponds with a lengthening of the heart period (Bruce, 1996). The traditional experimental approach of assessing the impact of the manipulation of one of these variables on another has led to important advancements in the understanding of cardiorespiratory coupling. However, perturbing the cardiorespiratory system does not allow the observation of casual relationships during spontaneous activity. Procedures developed to examine the coupling between time series may facilitate the identification of directionality and strength of cardiorespiratory coupling during spontaneous activity but these traditionally have only provided a limited insight into causality (e.g., Granger causality;Granger, 1969). Indeed, cardiorespiratory interaction has been variously quantified as primarily respiration-to-heart rate (Rosenblum et al., 2002;Zhu et al., 2013) heart rate-to-respiration (Larsen et al., 1999;#CITATION_TAG et al., 2003) or neither (i.e., bidirectional; Porta et al., 2013). These differences are likely to strongly depend on the analytical technique employed, but the details of this are unclear.	0	The traditional experimental approach of assessing the impact of the manipulation of one of these variables on another has led to important advancements in the understanding of cardiorespiratory coupling. However, perturbing the cardiorespiratory system does not allow the observation of casual relationships during spontaneous activity. Procedures developed to examine the coupling between time series may facilitate the identification of directionality and strength of cardiorespiratory coupling during spontaneous activity but these traditionally have only provided a limited insight into causality (e.g., Granger causality;Granger, 1969). Indeed, cardiorespiratory interaction has been variously quantified as primarily respiration-to-heart rate (Rosenblum et al., 2002;Zhu et al., 2013) heart rate-to-respiration (Larsen et al., 1999;#CITATION_TAG et al., 2003) or neither (i.e., bidirectional; Porta et al., 2013). These differences are likely to strongly depend on the analytical technique employed, but the details of this are unclear.	,
CCT522	"A number of external factors are usually controlled for in HRV research, including the intake of nicotine (Hayano et al., 1990;Sjoberg and Saint, 2011) and caffeine (Sondermeijer et al., 2002) preceding data collection. Cardioactive medication use, including some antidepressant classes (e.g., tricyclics; Kemp et al., 2010), some antipsychotic classes (e.g., clozapine; Cohen et al., 2001), benzodiazepines (Agelink et al., 2002), and antihypertensives (Schroeder et al., 2003) are also usually accounted for, although this may be somewhat difficult in practice when testing patient populations. Other factors that are usually accounted for include the time of day (Massin et al., 2000;van Eekelen et al., 2004), levels of habitual alcohol use (Quintana et al., 2013a,b), Woo et al. (1992). physical activity levels (Britton et al., 2007;Soares-Miranda et al., 2014), and age (O""Brien et al., 1986). Digestion of food and water are less commonly accounted for in HRV research, but both provoke a coordinated autonomic response. For instance, digesting food has been shown to reduce parasympathetic activity, even an hour after eating a 500 kcal meal (Lu et al., 1999). Even exposure to food-related cues elicits a similar response (Nederkoorn et al., 2000), suggesting a physiological response to the anticipation of a meal. Conversely, missing a meal (i.e., fasting) appears to have its own coordinated effects on HRV (Pivik et al., 2006), supporting the recommendation that participants consume a light meal approximately 2 h before the assessment of HRV (Tak et al., 2009). Water consumption has also been shown to increase HF-HRV in particular (#CITATION_TAG et al., 2002), due to the vagal buffering response to the pressor effect provoked by hypo-osmotic fluids (Scott et al., 2001). Notably, this buffering response to the pressor effect is attenuated in older individuals (Jordan et al., 2000) and not observed in those with cardiac vagal denervation (Routledge et al., 2002). In addition, both bladder and gastric distension can also have an appreciable influence on HRV; these have been associated with increases in blood pressure and sympathetic outflow (Fagius and Karhuvaara, 1989;Rossi et al., 1998). However, papers only very rarely report that participants were asked to empty their bladder before experimental participation (Heathers, 2014)."	0	For instance, digesting food has been shown to reduce parasympathetic activity, even an hour after eating a 500 kcal meal (Lu et al., 1999). Even exposure to food-related cues elicits a similar response (Nederkoorn et al., 2000), suggesting a physiological response to the anticipation of a meal. Conversely, missing a meal (i.e., fasting) appears to have its own coordinated effects on HRV (Pivik et al., 2006), supporting the recommendation that participants consume a light meal approximately 2 h before the assessment of HRV (Tak et al., 2009). Water consumption has also been shown to increase HF-HRV in particular (#CITATION_TAG et al., 2002), due to the vagal buffering response to the pressor effect provoked by hypo-osmotic fluids (Scott et al., 2001). Notably, this buffering response to the pressor effect is attenuated in older individuals (Jordan et al., 2000) and not observed in those with cardiac vagal denervation (Routledge et al., 2002). In addition, both bladder and gastric distension can also have an appreciable influence on HRV; these have been associated with increases in blood pressure and sympathetic outflow (Fagius and Karhuvaara, 1989;Rossi et al., 1998). However, papers only very rarely report that participants were asked to empty their bladder before experimental participation (Heathers, 2014).	n
CCT523	(1) Heart rate variability is affected by respiratory depth (Hirsch and Bishop, 1981) and frequency (Angelone and Coulter, 1964;Brown et al., 1993). Specifically, greater RSA magnitude occurs during higher tidal volumes and lower respiratory frequencies. In addition, basal respiratory frequency has a non-linear relationship with spectral power as breathing rate falls below approximately 0.15 Hz (as it occasionally does in athletes; #CITATION_TAG et al., 2014). Thus, any task that increases respiratory tidal volume and/or reduces respiratory frequency (e.g., meditation; Krygier et al., 2013), or conversely decreases tidal volume and/or increases respiratory frequency (e.g., mental stress; Houtveen et al., 2002) is likely to indirectly modify HRV. More recently, it has also been shown that the inspiration:expiration (I:E) ratio also effects HRV (Strauss-Blasche et al., 2000). Specifically, HRV increases when short inspiration is followed by long expiration -which has implications for tasks that require speech production (Cysarz et al., 2004) and many forms of meditation, for instance. Even monitoring spontaneous breathing has been found to reduce respiratory variability (Cysarz and B√ºssing, 2005;Conrad et al., 2007). HR driven cardiorespiratory coupling also appears to increase when HRV is higher (Galletly and Larsen, 2001).	0	(1) Heart rate variability is affected by respiratory depth (Hirsch and Bishop, 1981) and frequency (Angelone and Coulter, 1964;Brown et al., 1993). Specifically, greater RSA magnitude occurs during higher tidal volumes and lower respiratory frequencies. In addition, basal respiratory frequency has a non-linear relationship with spectral power as breathing rate falls below approximately 0.15 Hz (as it occasionally does in athletes; #CITATION_TAG et al., 2014). Thus, any task that increases respiratory tidal volume and/or reduces respiratory frequency (e.g., meditation; Krygier et al., 2013), or conversely decreases tidal volume and/or increases respiratory frequency (e.g., mental stress; Houtveen et al., 2002) is likely to indirectly modify HRV. More recently, it has also been shown that the inspiration:expiration (I:E) ratio also effects HRV (Strauss-Blasche et al., 2000). Specifically, HRV increases when short inspiration is followed by long expiration -which has implications for tasks that require speech production (Cysarz et al., 2004) and many forms of meditation, for instance.	 
CCT524	Coupling between respiration and heart rate (HR) has a long research history, and was noted in classical animal studies predating the electrocardiogram, which noticed fluctuations with breathing of heart beat and blood pressure (Ludwig, 1847). Consequently, the typically functioning respiratory system is presently characterized by complex breath-to-breath variations in respiratory rate and depth (#CITATION_TAG, 1996) coupled with both heart period and blood pressure oscillations in a network of continual co-modification. For instance, a decrease in respiratory frequency generally corresponds with a lengthening of the heart period (Bruce, 1996). The traditional experimental approach of assessing the impact of the manipulation of one of these variables on another has led to important advancements in the understanding of cardiorespiratory coupling. However, perturbing the cardiorespiratory system does not allow the observation of casual relationships during spontaneous activity. Procedures developed to examine the coupling between time series may facilitate the identification of directionality and strength of cardiorespiratory coupling during spontaneous activity but these traditionally have only provided a limited insight into causality (e.g., Granger causality;Granger, 1969). Indeed, cardiorespiratory interaction has been variously quantified as primarily respiration-to-heart rate (Rosenblum et al., 2002;Zhu et al., 2013) heart rate-to-respiration (Larsen et al., 1999;Tzeng et al., 2003) or neither (i.e., bidirectional; Porta et al., 2013). These differences are likely to strongly depend on the analytical technique employed, but the details of this are unclear.	0	Coupling between respiration and heart rate (HR) has a long research history, and was noted in classical animal studies predating the electrocardiogram, which noticed fluctuations with breathing of heart beat and blood pressure (Ludwig, 1847). Consequently, the typically functioning respiratory system is presently characterized by complex breath-to-breath variations in respiratory rate and depth (#CITATION_TAG, 1996) coupled with both heart period and blood pressure oscillations in a network of continual co-modification. For instance, a decrease in respiratory frequency generally corresponds with a lengthening of the heart period (Bruce, 1996). The traditional experimental approach of assessing the impact of the manipulation of one of these variables on another has led to important advancements in the understanding of cardiorespiratory coupling. However, perturbing the cardiorespiratory system does not allow the observation of casual relationships during spontaneous activity.	o
CCT525	While it may be the case that HRV can be used as a neurobiological index of interpersonal interaction, significant caveats exist due to the complicated nature of HRV and consequently uncertainty regarding what information is actually provided by common HRV indices (Berntson et al., 1997;Malpas, 2002;Billman, 2011). Additionally, the relationship between HRV and vagal modulation is complex in itself with a large interindividual variation (Picard et al., 2009). The problem is further compounded by the co-modulation of various respiratory and circulatory factors, which occur via numerous mechanisms and over multiple time-scales. Moreover, both breathing and blood pressure regulation have their own directly mediated relationships to the tasks employed in social, emotional, and cognitive experiments -if this is the case, we often have a complicated question of interlocking causalities. For instance, are observed changes in heart period epiphenomena that can be more parsimoniously described by changes in breathing or blood pressure? If the direction of causality between experimental task and the coordinated response within cardiac, circulatory, and respiratory variables is poorly understood, simple relationships between task and output changes may be obscured. Finally, experiments are often poorly designed as uncontrolled variables within typical experimental environments may drastically influence HRV. Few papers ideally control for medication, food, and water consumption, bladder filling, time of day, and other extraneous factors (Tak et al., 2009;#CITATION_TAG, 2014). The overall aim of this review is to highlight the interrelationships between the nature and extraneous control of HRV, with a particular emphasis on respiration, and discuss implications for research in emotion science and psychology. Firstly, a number of important factors for the assessment of HRV in general and in emotion psychology in particular will be outlined. Secondly, solutions will be presented to reduce the potential impact of these factors.	0	For instance, are observed changes in heart period epiphenomena that can be more parsimoniously described by changes in breathing or blood pressure? If the direction of causality between experimental task and the coordinated response within cardiac, circulatory, and respiratory variables is poorly understood, simple relationships between task and output changes may be obscured. Finally, experiments are often poorly designed as uncontrolled variables within typical experimental environments may drastically influence HRV. Few papers ideally control for medication, food, and water consumption, bladder filling, time of day, and other extraneous factors (Tak et al., 2009;#CITATION_TAG, 2014). The overall aim of this review is to highlight the interrelationships between the nature and extraneous control of HRV, with a particular emphasis on respiration, and discuss implications for research in emotion science and psychology. Firstly, a number of important factors for the assessment of HRV in general and in emotion psychology in particular will be outlined. Secondly, solutions will be presented to reduce the potential impact of these factors.	e
CCT526	Frequency analysis assumes the HR signal is stationary (Stratonovich, 1967) and that over time it can be modeled as the sum of cyclical processes, but this is demonstrably not the case. While removing slow or DC trends from short periods of HRV will create a quasi-stationary series (e.g., Tarvainen et al., 2002), HRV in general displays the characteristics of a non-linear signal, given the biological origin and the origin of HRV deriving from sum of processes that operate on a variety of time scales (Winfree, 2001;#CITATION_TAG and Guzik, 2007;Stein et al., 2008). The non-linear interaction of the PNS and SNS systems may also contribute to heart beat complexity observed in healthy participants (Levy, 1971). 1/f-like scaling of the heart beat signal, which is characteristic of a heart beat series from a healthy individual (Ivanov et al., 1999;Goldberger et al., 2002), also points to a nonlinear basis. A 1/f scaling of the heart beat signal (Œ± = 1) falls exactly between a completely random signal (Œ± = 0.5; i.e., white noise) and an entirely predictable signal (Œ± = 1.5). For instance, pathological heart rhythms tend to demonstrate Brownian noise (Peng et al., 1995). A complex interaction of linear and non-linear systems contribute to HRV (Voss et al., 2009), which suggests that measures of complexity may be a better measure of autonomic nervous system outflow (Kaplan et al., 1991). Indeed, non-linear measures of HRV have demonstrated improved prognostic information in heart failure patients with in comparison to linear HRV measures (Bigger et al., 1996;Huikuri et al., 2000). However, the utility of non-linear HRV measures have been questioned due to a lack of reproducibility (Tan et al., 2009). Intriguingly, non-linear analysis indicates that some elderly patients with cardiovascular disease unexpectedly display increased HRV indices (Stein et al., 2005) due to erratic, nonrespiratory sinus arrhythmia. These erratic rhythms have also been found to predict the onset of ventricular tachycardia (M√§kikallio et al., 1997) and mortality post-myocardial infarction (Stein et al., 2008). The source of this erratic non-respiratory sinus arrhythmia may be due to increased sympathetic activity (Tulppo et al., 1998), which is consistent with the higher concentrations of plasma noradrenaline observed in patients post-myocardial infarction (Christensen and Videbaek, 1974). Alternatively, erratic rhythms may be caused by poor coordination between the sinoatrial and atrioventricular nodes, which could reflect a pre-clinical manifestation of sick sinus syndrome (Stein et al., 2008).	0	Frequency analysis assumes the HR signal is stationary (Stratonovich, 1967) and that over time it can be modeled as the sum of cyclical processes, but this is demonstrably not the case. While removing slow or DC trends from short periods of HRV will create a quasi-stationary series (e.g., Tarvainen et al., 2002), HRV in general displays the characteristics of a non-linear signal, given the biological origin and the origin of HRV deriving from sum of processes that operate on a variety of time scales (Winfree, 2001;#CITATION_TAG and Guzik, 2007;Stein et al., 2008). The non-linear interaction of the PNS and SNS systems may also contribute to heart beat complexity observed in healthy participants (Levy, 1971). 1/f-like scaling of the heart beat signal, which is characteristic of a heart beat series from a healthy individual (Ivanov et al., 1999;Goldberger et al., 2002), also points to a nonlinear basis. A 1/f scaling of the heart beat signal (Œ± = 1) falls exactly between a completely random signal (Œ± = 0.5; i.e., white noise) and an entirely predictable signal (Œ± = 1.5).	h
CCT527	"A Poincar√© plot is a visual, non-linear HRV index comprised of points that represent two consecutive heart periods, with any point above the identity line (a 45 ‚Ä¢ slope that passes through the origin, which represents equal consecutive heart periods) representing a longer heart period, whereas points below the identity line represent a shortening of the heart period. A healthy participant typically displays a ""comet"" shaped plot (Figure 1A), with a wider dispersion of points as the beats lengthen. Even at different rates of breathing (ranging from 6 to 16 breaths/min) this shape persists in healthy participants (Guzik et al., 2007). On the other hand, patients with heart failure display atypical ""torpedo,"" ""fan,"" or ""complex"" (i.e., stepwise clusters of points) patterns (Woo et al., 1992). A torpedo shape (Figure 1B) is indicative of a lack of R-R interval increase when HR slows, whereas fan and complex patterns (Figure 1C) may represent general issues with cardiac autonomic regulation. Poincar√© plots have been demonstrated to shown to display significant asymmetry in approximately 80% of individuals (#CITATION_TAG et al., 2006;Piskorski and Guzik, 2007;Porta et al., 2008), with the plot ""cloud"" above the identity line appearing larger than the plot cloud below the line. Absent of longterm trends or very low frequency (VLF) power changes typically removed via detrending or high-pass filtering, HR acceleration will be matched with a roughly corresponding deceleration over time, and the Poincar√© plots might be expected to be symmetrical. However, this commonly observed asymmetry in Poincar√© plots suggests that HR accelerations operate in a different manner than decelerations, possibly due to baroreflex responses (Guzik et al., 2006). While the source of this asymmetry is unclear, it reinforces the fact that HRV is generated by complex non-linear dynamics. Together, this work emphasizes the importance of scrutinizing Poincar√© plots for irregularities, particularly for populations characterized by low HRV (e.g., older participants), and urges caution with the central assumption that IBIs over time can be meaningfully devolved into the sum of sine waves as in traditional frequency-domain analysis."	0	"Even at different rates of breathing (ranging from 6 to 16 breaths/min) this shape persists in healthy participants (Guzik et al., 2007). On the other hand, patients with heart failure display atypical ""torpedo,"" ""fan,"" or ""complex"" (i.e., stepwise clusters of points) patterns (Woo et al., 1992). A torpedo shape (Figure 1B) is indicative of a lack of R-R interval increase when HR slows, whereas fan and complex patterns (Figure 1C) may represent general issues with cardiac autonomic regulation. Poincar√© plots have been demonstrated to shown to display significant asymmetry in approximately 80% of individuals (#CITATION_TAG et al., 2006;Piskorski and Guzik, 2007;Porta et al., 2008), with the plot ""cloud"" above the identity line appearing larger than the plot cloud below the line. Absent of longterm trends or very low frequency (VLF) power changes typically removed via detrending or high-pass filtering, HR acceleration will be matched with a roughly corresponding deceleration over time, and the Poincar√© plots might be expected to be symmetrical. However, this commonly observed asymmetry in Poincar√© plots suggests that HR accelerations operate in a different manner than decelerations, possibly due to baroreflex responses (Guzik et al., 2006). While the source of this asymmetry is unclear, it reinforces the fact that HRV is generated by complex non-linear dynamics."	a
CCT528	"The autonomic nervous system has been studied as a correlate of emotion for almost a century (Cannon, 1916). A central technique within this tradition of research is heart rate variability (HRV), which refers to a variety of methods for assessing the beat-to-beat change in the heart over time; these are used to approximate various aspects of autonomic outflow to the heart. Improvements in computing technology and miniaturization have made the electrocardiographic collection of inter-beat intervals (IBIs) accessible, and the analysis of the resulting beat-to-beat intervals trivial. One consequence of this access is a sustained interest in the application of HRV within the behavioral sciences, and in the psychology of emotion in particular. There are major biobehavioral theories that suggest that HRV can be used to investigate the central relationship between autonomic regulation and interpersonal interaction (#CITATION_TAG, 1995;Thayer and Lane, 2000). The neurovisceral integration model suggests that HRV is an index of the capacity for the central autonomic network (Benarroch, 1993) -which includes the brainstem, hypothalamus, and prefrontal cortexto adjust to environmental demands (Thayer and Lane, 2000). Porges"" polyvagal theory takes a phylogenetic approach (i.e., it observes evolutionary and developmental commonalities within the structure and function of the vertebrate autonomic nervous system), arguing that social engagement is centrally facilitated by outflow and functional organization of vagus nerve (Porges, 1995). Consistent with this theory, reduced HRV has been observed in psychiatric disorders characterized by poor social cognition and emotion regulation (B√§r et al., 2007;Quintana et al., 2013b). Interestingly, psychiatric patients also demonstrate less HRV reactivity during different levels of mental loading in comparison to healthy controls (Valkonen-Korhonen et al., 2003), further highlighting the poor cardiorespiratory regulatory capacity of this population."	0	"A central technique within this tradition of research is heart rate variability (HRV), which refers to a variety of methods for assessing the beat-to-beat change in the heart over time; these are used to approximate various aspects of autonomic outflow to the heart. Improvements in computing technology and miniaturization have made the electrocardiographic collection of inter-beat intervals (IBIs) accessible, and the analysis of the resulting beat-to-beat intervals trivial. One consequence of this access is a sustained interest in the application of HRV within the behavioral sciences, and in the psychology of emotion in particular. There are major biobehavioral theories that suggest that HRV can be used to investigate the central relationship between autonomic regulation and interpersonal interaction (#CITATION_TAG, 1995;Thayer and Lane, 2000). The neurovisceral integration model suggests that HRV is an index of the capacity for the central autonomic network (Benarroch, 1993) -which includes the brainstem, hypothalamus, and prefrontal cortexto adjust to environmental demands (Thayer and Lane, 2000). Porges"" polyvagal theory takes a phylogenetic approach (i.e., it observes evolutionary and developmental commonalities within the structure and function of the vertebrate autonomic nervous system), arguing that social engagement is centrally facilitated by outflow and functional organization of vagus nerve (Porges, 1995). Consistent with this theory, reduced HRV has been observed in psychiatric disorders characterized by poor social cognition and emotion regulation (B√§r et al., 2007;Quintana et al., 2013b)."	e
CCT529	There has been considerable debate on the necessity of controlling for respiration when assessing HRV. Denver et al. (2007) have argued against the need to control for respiration -at least for resting state recordings -given the important influence of breathing on HRV. To wit, by controlling for breathing in HRV recordings the researcher is removing an important influence on HRV (but see #CITATION_TAG and Taylor, 2007). Denver et al. (2007) argue that if we assume that both respiration and heart beat oscillations are generated from the same central origin (e.g., Eckberg, 2009) then under resting state conditions controlling for respiration may not be necessary. Indeed, proponents for the control of respiration assume (either explicitly or implicitly) that alterations in respiratory frequency bring provoke HRV changes (i.e., the direction of causality moves from respiration to HR) without considering that HR adjustments may provoke changes in respiratory drive (Tzeng et al., 2003).	1	There has been considerable debate on the necessity of controlling for respiration when assessing HRV. Denver et al. (2007) have argued against the need to control for respiration -at least for resting state recordings -given the important influence of breathing on HRV. To wit, by controlling for breathing in HRV recordings the researcher is removing an important influence on HRV (but see #CITATION_TAG and Taylor, 2007). Denver et al. (2007) argue that if we assume that both respiration and heart beat oscillations are generated from the same central origin (e.g., Eckberg, 2009) then under resting state conditions controlling for respiration may not be necessary. Indeed, proponents for the control of respiration assume (either explicitly or implicitly) that alterations in respiratory frequency bring provoke HRV changes (i.e., the direction of causality moves from respiration to HR) without considering that HR adjustments may provoke changes in respiratory drive (Tzeng et al., 2003).	 
CCT530	"One compromise solution is to measure a participant""s natural breathing rate, and use the derived frequency for respiratory pacing (e.g., Elstad, 2012). While this approach has utility during resting state registration, this procedure may inadvertently influence HRV during emotional or cognitive tasks as the participant has to consciously follow the pacing cue, in addition to paying attention to the experimental task -dual attention, in a number of contexts, significantly increases task difficulty (Pashler, 1994). Zhang et al. (2010) argue that cardiorespiratory coupling during a cognitive task can be influenced either by activation of the motor cortex, which deceases cardiorespiratory coupling, or via increases in SNS activity from completing a cognitive task. However, here sympathetic outflow was indexed by normalized low frequency HRV -which is not straightforwardly related to SNS activity (e.g., Grassi and Esler, 1999;Moak et al., 2007;Goedhart et al., 2008;Billman, 2011#CITATION_TAG , 2013a -so this latter claim requires further empirical support using indices that more directly index cardiac sympathetic outflow."	0	"One compromise solution is to measure a participant""s natural breathing rate, and use the derived frequency for respiratory pacing (e.g., Elstad, 2012). While this approach has utility during resting state registration, this procedure may inadvertently influence HRV during emotional or cognitive tasks as the participant has to consciously follow the pacing cue, in addition to paying attention to the experimental task -dual attention, in a number of contexts, significantly increases task difficulty (Pashler, 1994). Zhang et al. (2010) argue that cardiorespiratory coupling during a cognitive task can be influenced either by activation of the motor cortex, which deceases cardiorespiratory coupling, or via increases in SNS activity from completing a cognitive task. However, here sympathetic outflow was indexed by normalized low frequency HRV -which is not straightforwardly related to SNS activity (e.g., Grassi and Esler, 1999;Moak et al., 2007;Goedhart et al., 2008;Billman, 2011#CITATION_TAG , 2013a -so this latter claim requires further empirical support using indices that more directly index cardiac sympathetic outflow."	e
CCT531	While it may be the case that HRV can be used as a neurobiological index of interpersonal interaction, significant caveats exist due to the complicated nature of HRV and consequently uncertainty regarding what information is actually provided by common HRV indices (Berntson et al., 1997;Malpas, 2002;#CITATION_TAG, 2011). Additionally, the relationship between HRV and vagal modulation is complex in itself with a large interindividual variation (Picard et al., 2009). The problem is further compounded by the co-modulation of various respiratory and circulatory factors, which occur via numerous mechanisms and over multiple time-scales. Moreover, both breathing and blood pressure regulation have their own directly mediated relationships to the tasks employed in social, emotional, and cognitive experiments -if this is the case, we often have a complicated question of interlocking causalities. For instance, are observed changes in heart period epiphenomena that can be more parsimoniously described by changes in breathing or blood pressure? If the direction of causality between experimental task and the coordinated response within cardiac, circulatory, and respiratory variables is poorly understood, simple relationships between task and output changes may be obscured. Finally, experiments are often poorly designed as uncontrolled variables within typical experimental environments may drastically influence HRV. Few papers ideally control for medication, food, and water consumption, bladder filling, time of day, and other extraneous factors (Tak et al., 2009;Heathers, 2014). The overall aim of this review is to highlight the interrelationships between the nature and extraneous control of HRV, with a particular emphasis on respiration, and discuss implications for research in emotion science and psychology. Firstly, a number of important factors for the assessment of HRV in general and in emotion psychology in particular will be outlined. Secondly, solutions will be presented to reduce the potential impact of these factors.	0	While it may be the case that HRV can be used as a neurobiological index of interpersonal interaction, significant caveats exist due to the complicated nature of HRV and consequently uncertainty regarding what information is actually provided by common HRV indices (Berntson et al., 1997;Malpas, 2002;#CITATION_TAG, 2011). Additionally, the relationship between HRV and vagal modulation is complex in itself with a large interindividual variation (Picard et al., 2009). The problem is further compounded by the co-modulation of various respiratory and circulatory factors, which occur via numerous mechanisms and over multiple time-scales. Moreover, both breathing and blood pressure regulation have their own directly mediated relationships to the tasks employed in social, emotional, and cognitive experiments -if this is the case, we often have a complicated question of interlocking causalities.	W
CCT532	In light of the complex interactions described above, a withinsubjects design is the most appropriate method to explore the role of cardiorespiratory oscillations on behavior. Indeed, to appropriately detect a difference between groups, a sample size between 30 and 77, depending on the HRV metric used, is needed (#CITATION_TAG et al., 2007). However, subgroups are commonly employed in these designs (e.g., gender, psychiatric comorbidities), which have been suggested to require 20 participants per cell (Simmons et al., 2011). Although some contexts make this difficult (i.e., comparison of psychiatric groups), within-subjects is the ideal design. The use of within-subjects design can eliminate any interindividual differences in coupling between HR, BP, and respiration. For instance, approximately 30% of individuals do not demonstrate any discernable synchrony between respiration and HR (Sch√§fer et al., 1998;Tzeng et al., 2003), with cardiorespiratory synchronization less likely to occur during higher breathing frequencies. While it is debatable if respiration should be controlled in HRV recordings, it is clear that sighs and long breaths have an effect on HRV as they generate non-sinus rhythm HR.	0	In light of the complex interactions described above, a withinsubjects design is the most appropriate method to explore the role of cardiorespiratory oscillations on behavior. Indeed, to appropriately detect a difference between groups, a sample size between 30 and 77, depending on the HRV metric used, is needed (#CITATION_TAG et al., 2007). However, subgroups are commonly employed in these designs (e.g., gender, psychiatric comorbidities), which have been suggested to require 20 participants per cell (Simmons et al., 2011). Although some contexts make this difficult (i.e., comparison of psychiatric groups), within-subjects is the ideal design. The use of within-subjects design can eliminate any interindividual differences in coupling between HR, BP, and respiration.	n
CCT533	"Social-emotional tasks have been shown to reduce breathing variability (Vlemincx et al., 2011(Vlemincx et al., , 2012a, even for positively valenced emotions (Boiten, 1998), due to the ""locked-in"" attention often required during social-emotional tasks. Moreover, the mental stress that usually accompanies these tasks can also disorder general respiratory coordination (#CITATION_TAG et al., 2012b). In addition to overall breathing variability, experimental stress induction can also influence the specific length of inspiration and expiration (Cohen et al., 1975). Thus, a social-emotional task that induces a change in respiratory time variables and/or depth may be indirectly influencing HRV. The rates of sighing also increase during these tasks (Vlemincx et al., 2011), with sighs shown to ""reset"" both respiratory variability and emotional states (Vlemincx et al., 2013). This is consistent with observations of increased sighing in a range of anxiety disorders (Abelson et al., 2001;Nardi et al., 2009), and increased sighing during experimentally induced stress (Vlemincx et al., 2012b). Finally, continual focused attention (e.g., during psychometrics tasks) has been shown in a number of studies (Mulder and Mulder, 1981;Aasman et al., 1987;Middleton et al., 1999) to reduce LF HRV, which creates further difficulties for interpretation."	0	"Social-emotional tasks have been shown to reduce breathing variability (Vlemincx et al., 2011(Vlemincx et al., , 2012a, even for positively valenced emotions (Boiten, 1998), due to the ""locked-in"" attention often required during social-emotional tasks. Moreover, the mental stress that usually accompanies these tasks can also disorder general respiratory coordination (#CITATION_TAG et al., 2012b). In addition to overall breathing variability, experimental stress induction can also influence the specific length of inspiration and expiration (Cohen et al., 1975). Thus, a social-emotional task that induces a change in respiratory time variables and/or depth may be indirectly influencing HRV. The rates of sighing also increase during these tasks (Vlemincx et al., 2011), with sighs shown to ""reset"" both respiratory variability and emotional states (Vlemincx et al., 2013)."	o
CCT534	"Social-emotional tasks have been shown to reduce breathing variability (#CITATION_TAG et al., 2011(Vlemincx et al., , 2012a, even for positively valenced emotions (Boiten, 1998), due to the ""locked-in"" attention often required during social-emotional tasks. Moreover, the mental stress that usually accompanies these tasks can also disorder general respiratory coordination (Vlemincx et al., 2012b). In addition to overall breathing variability, experimental stress induction can also influence the specific length of inspiration and expiration (Cohen et al., 1975). Thus, a social-emotional task that induces a change in respiratory time variables and/or depth may be indirectly influencing HRV. The rates of sighing also increase during these tasks (Vlemincx et al., 2011), with sighs shown to ""reset"" both respiratory variability and emotional states (Vlemincx et al., 2013). This is consistent with observations of increased sighing in a range of anxiety disorders (Abelson et al., 2001;Nardi et al., 2009), and increased sighing during experimentally induced stress (Vlemincx et al., 2012b). Finally, continual focused attention (e.g., during psychometrics tasks) has been shown in a number of studies (Mulder and Mulder, 1981;Aasman et al., 1987;Middleton et al., 1999) to reduce LF HRV, which creates further difficulties for interpretation."	0	"Social-emotional tasks have been shown to reduce breathing variability (#CITATION_TAG et al., 2011(Vlemincx et al., , 2012a, even for positively valenced emotions (Boiten, 1998), due to the ""locked-in"" attention often required during social-emotional tasks. Moreover, the mental stress that usually accompanies these tasks can also disorder general respiratory coordination (Vlemincx et al., 2012b). In addition to overall breathing variability, experimental stress induction can also influence the specific length of inspiration and expiration (Cohen et al., 1975). Thus, a social-emotional task that induces a change in respiratory time variables and/or depth may be indirectly influencing HRV."	S
CCT535	Coupling between respiration and heart rate (HR) has a long research history, and was noted in classical animal studies predating the electrocardiogram, which noticed fluctuations with breathing of heart beat and blood pressure (Ludwig, 1847). Consequently, the typically functioning respiratory system is presently characterized by complex breath-to-breath variations in respiratory rate and depth (Bruce, 1996) coupled with both heart period and blood pressure oscillations in a network of continual co-modification. For instance, a decrease in respiratory frequency generally corresponds with a lengthening of the heart period (Bruce, 1996). The traditional experimental approach of assessing the impact of the manipulation of one of these variables on another has led to important advancements in the understanding of cardiorespiratory coupling. However, perturbing the cardiorespiratory system does not allow the observation of casual relationships during spontaneous activity. Procedures developed to examine the coupling between time series may facilitate the identification of directionality and strength of cardiorespiratory coupling during spontaneous activity but these traditionally have only provided a limited insight into causality (e.g., Granger causality;Granger, 1969). Indeed, cardiorespiratory interaction has been variously quantified as primarily respiration-to-heart rate (Rosenblum et al., 2002;Zhu et al., 2013) heart rate-to-respiration (#CITATION_TAG et al., 1999;Tzeng et al., 2003) or neither (i.e., bidirectional; Porta et al., 2013). These differences are likely to strongly depend on the analytical technique employed, but the details of this are unclear.	0	The traditional experimental approach of assessing the impact of the manipulation of one of these variables on another has led to important advancements in the understanding of cardiorespiratory coupling. However, perturbing the cardiorespiratory system does not allow the observation of casual relationships during spontaneous activity. Procedures developed to examine the coupling between time series may facilitate the identification of directionality and strength of cardiorespiratory coupling during spontaneous activity but these traditionally have only provided a limited insight into causality (e.g., Granger causality;Granger, 1969). Indeed, cardiorespiratory interaction has been variously quantified as primarily respiration-to-heart rate (Rosenblum et al., 2002;Zhu et al., 2013) heart rate-to-respiration (#CITATION_TAG et al., 1999;Tzeng et al., 2003) or neither (i.e., bidirectional; Porta et al., 2013). These differences are likely to strongly depend on the analytical technique employed, but the details of this are unclear.	,
CCT536	The nature of cardiorespiratory coupling is of intense research interest, highlighted most centrally by a robust debate concerning the central (Eckberg, 2009) and baroreflex (Karemaker, 2009) mechanism contributions to respiratory sinus arrhythmia (RSA). There is also a common genetic influence on HRV and respiration (Kupper et al., 2005). To further complicate this already complex relationship, the degree of cardiorespiratory coupling depends on the respiratory rate. That is, as the respiratory rate increases, HR increases phase distance from respiration. For instance, a breathing rate of 5-6 breaths per minute corresponds with a phase angle increase of 90 ‚Ä¢ , continuing to a phase angle of 180 ‚Ä¢ with 10 breaths per minute (#CITATION_TAG and Coulter, 1964). Indeed, a presumed tenet of RSA -that shorter R-R intervals should be coupled with the apogee of inspiration -only occurs at a slow respiratory rate of six breaths per minute (Vaschillo et al., 2004), around half the natural respiration rate. However, there is no relationship between cardiorespiratory coupling and baroreflex sensitivity or blood pressure variability (Tzeng et al., 2003).	0	There is also a common genetic influence on HRV and respiration (Kupper et al., 2005). To further complicate this already complex relationship, the degree of cardiorespiratory coupling depends on the respiratory rate. That is, as the respiratory rate increases, HR increases phase distance from respiration. For instance, a breathing rate of 5-6 breaths per minute corresponds with a phase angle increase of 90 ‚Ä¢ , continuing to a phase angle of 180 ‚Ä¢ with 10 breaths per minute (#CITATION_TAG and Coulter, 1964). Indeed, a presumed tenet of RSA -that shorter R-R intervals should be coupled with the apogee of inspiration -only occurs at a slow respiratory rate of six breaths per minute (Vaschillo et al., 2004), around half the natural respiration rate. However, there is no relationship between cardiorespiratory coupling and baroreflex sensitivity or blood pressure variability (Tzeng et al., 2003).	i
CCT537	Further, shared neural networks for respiratory and HR oscillations (Evans et al., 2009) suggest that the manipulation on breathing may also lead to unintended effects on HRV by removing some of the variance in HRV that may relevantly covary with experimental task. Intriguingly, the degree of coupling may be higher when HRV is increased and at lower breathing frequencies (#CITATION_TAG and Larsen, 2001;Tzeng et al., 2003), suggesting that unhealthy populations or experiments that are designed to reduce HRV may be more prone to decoupling of cardiorespiratory oscillations. This observation is particularly relevant when comparing two populations that may display different breathing frequencies (e.g., anxious vs. non-anxious participants) or when an experimental manipulation modifies respiration. Notably, respiration is not a necessary condition to modify HR over time as variability is still observed (although significantly reduced) without mechanical respiratory input to the heart (Larsen et al., 1999). Conversely, individuals with no vagal input to the heart (e.g., heart transplant recipients) still demonstrate RSA (although to a much smaller degree) presumably due to mechanical effects on the sinoatrial node (Bernardi et al., 1989;Slovut et al., 1998). While respiration influences blood pressure via mechanical intrathoracic pressure changes, this is buffered by HRV (Toska and Eriksen, 1993;Elstad et al., 2001). The influence of respiration on blood pressure is likely to be caused by the mechanical influence on venous return, modulating cardiac output (Triedman and Saul, 1994) via changes in stroke volume, which in turn influences blood pressure (Elstad et al., 2001).	0	Further, shared neural networks for respiratory and HR oscillations (Evans et al., 2009) suggest that the manipulation on breathing may also lead to unintended effects on HRV by removing some of the variance in HRV that may relevantly covary with experimental task. Intriguingly, the degree of coupling may be higher when HRV is increased and at lower breathing frequencies (#CITATION_TAG and Larsen, 2001;Tzeng et al., 2003), suggesting that unhealthy populations or experiments that are designed to reduce HRV may be more prone to decoupling of cardiorespiratory oscillations. This observation is particularly relevant when comparing two populations that may display different breathing frequencies (e.g., anxious vs. non-anxious participants) or when an experimental manipulation modifies respiration. Notably, respiration is not a necessary condition to modify HR over time as variability is still observed (although significantly reduced) without mechanical respiratory input to the heart (Larsen et al., 1999). Conversely, individuals with no vagal input to the heart (e.g., heart transplant recipients) still demonstrate RSA (although to a much smaller degree) presumably due to mechanical effects on the sinoatrial node (Bernardi et al., 1989;Slovut et al., 1998).	n
CCT538	Coupling between respiration and heart rate (HR) has a long research history, and was noted in classical animal studies predating the electrocardiogram, which noticed fluctuations with breathing of heart beat and blood pressure (Ludwig, 1847). Consequently, the typically functioning respiratory system is presently characterized by complex breath-to-breath variations in respiratory rate and depth (Bruce, 1996) coupled with both heart period and blood pressure oscillations in a network of continual co-modification. For instance, a decrease in respiratory frequency generally corresponds with a lengthening of the heart period (Bruce, 1996). The traditional experimental approach of assessing the impact of the manipulation of one of these variables on another has led to important advancements in the understanding of cardiorespiratory coupling. However, perturbing the cardiorespiratory system does not allow the observation of casual relationships during spontaneous activity. Procedures developed to examine the coupling between time series may facilitate the identification of directionality and strength of cardiorespiratory coupling during spontaneous activity but these traditionally have only provided a limited insight into causality (e.g., Granger causality;Granger, 1969). Indeed, cardiorespiratory interaction has been variously quantified as primarily respiration-to-heart rate (Rosenblum et al., 2002;Zhu et al., 2013) heart rate-to-respiration (Larsen et al., 1999;Tzeng et al., 2003) or neither (i.e., bidirectional; #CITATION_TAG et al., 2013). These differences are likely to strongly depend on the analytical technique employed, but the details of this are unclear.	0	The traditional experimental approach of assessing the impact of the manipulation of one of these variables on another has led to important advancements in the understanding of cardiorespiratory coupling. However, perturbing the cardiorespiratory system does not allow the observation of casual relationships during spontaneous activity. Procedures developed to examine the coupling between time series may facilitate the identification of directionality and strength of cardiorespiratory coupling during spontaneous activity but these traditionally have only provided a limited insight into causality (e.g., Granger causality;Granger, 1969). Indeed, cardiorespiratory interaction has been variously quantified as primarily respiration-to-heart rate (Rosenblum et al., 2002;Zhu et al., 2013) heart rate-to-respiration (Larsen et al., 1999;Tzeng et al., 2003) or neither (i.e., bidirectional; #CITATION_TAG et al., 2013). These differences are likely to strongly depend on the analytical technique employed, but the details of this are unclear.	,
CCT539	(4) Differences in the prevailing HR can influence HRV both mathematically, due to the inverse curvilinear relationship between HR and RR interval (Sacha and Pluta, 2008) and physiologically, via the augmenting or diminishing effect of the autonomic constituent of HRV (Billman, 2013b). Consequently, emotional interventions that reduce PNS activation could inflate reductions in HRV via HR increases that are independent of changes in cardiac autonomic nerve activity. Nevertheless, it is possible to mathematically correct for the influence of the prevailing HR on HRV (Sacha, 2013;#CITATION_TAG et al., 2014), which may also improve the reproducibility of HRV (Sacha et al., 2013).	0	(4) Differences in the prevailing HR can influence HRV both mathematically, due to the inverse curvilinear relationship between HR and RR interval (Sacha and Pluta, 2008) and physiologically, via the augmenting or diminishing effect of the autonomic constituent of HRV (Billman, 2013b). Consequently, emotional interventions that reduce PNS activation could inflate reductions in HRV via HR increases that are independent of changes in cardiac autonomic nerve activity. Nevertheless, it is possible to mathematically correct for the influence of the prevailing HR on HRV (Sacha, 2013;#CITATION_TAG et al., 2014), which may also improve the reproducibility of HRV (Sacha et al., 2013).	v
CCT540	"The autonomic nervous system has been studied as a correlate of emotion for almost a century (Cannon, 1916). A central technique within this tradition of research is heart rate variability (HRV), which refers to a variety of methods for assessing the beat-to-beat change in the heart over time; these are used to approximate various aspects of autonomic outflow to the heart. Improvements in computing technology and miniaturization have made the electrocardiographic collection of inter-beat intervals (IBIs) accessible, and the analysis of the resulting beat-to-beat intervals trivial. One consequence of this access is a sustained interest in the application of HRV within the behavioral sciences, and in the psychology of emotion in particular. There are major biobehavioral theories that suggest that HRV can be used to investigate the central relationship between autonomic regulation and interpersonal interaction (Porges, 1995;Thayer and Lane, 2000). The neurovisceral integration model suggests that HRV is an index of the capacity for the central autonomic network (Benarroch, 1993) -which includes the brainstem, hypothalamus, and prefrontal cortexto adjust to environmental demands (Thayer and Lane, 2000). Porges"" polyvagal theory takes a phylogenetic approach (i.e., it observes evolutionary and developmental commonalities within the structure and function of the vertebrate autonomic nervous system), arguing that social engagement is centrally facilitated by outflow and functional organization of vagus nerve (Porges, 1995). Consistent with this theory, reduced HRV has been observed in psychiatric disorders characterized by poor social cognition and emotion regulation (B√§r et al., 2007;#CITATION_TAG et al., 2013b). Interestingly, psychiatric patients also demonstrate less HRV reactivity during different levels of mental loading in comparison to healthy controls (Valkonen-Korhonen et al., 2003), further highlighting the poor cardiorespiratory regulatory capacity of this population."	0	"There are major biobehavioral theories that suggest that HRV can be used to investigate the central relationship between autonomic regulation and interpersonal interaction (Porges, 1995;Thayer and Lane, 2000). The neurovisceral integration model suggests that HRV is an index of the capacity for the central autonomic network (Benarroch, 1993) -which includes the brainstem, hypothalamus, and prefrontal cortexto adjust to environmental demands (Thayer and Lane, 2000). Porges"" polyvagal theory takes a phylogenetic approach (i.e., it observes evolutionary and developmental commonalities within the structure and function of the vertebrate autonomic nervous system), arguing that social engagement is centrally facilitated by outflow and functional organization of vagus nerve (Porges, 1995). Consistent with this theory, reduced HRV has been observed in psychiatric disorders characterized by poor social cognition and emotion regulation (B√§r et al., 2007;#CITATION_TAG et al., 2013b). Interestingly, psychiatric patients also demonstrate less HRV reactivity during different levels of mental loading in comparison to healthy controls (Valkonen-Korhonen et al., 2003), further highlighting the poor cardiorespiratory regulatory capacity of this population."	e
CCT541	"(3) Heart rate variability continues to be used to form an index of putative autonomic outflow by measuring a point on a simple continuum of parasympathetic/sympathetic activity. While this model is still popular, it is directly at odds with a great deal of available evidence; for instance, that neuropeptide Y directly mediates transmission between adrenergic and muscarinic neurons (#CITATION_TAG and McCloskey, 1990). This approach, generally focused around the use of the LF/HF ratio (the ratio of low frequency power to high frequency power) to represent ""sympathovagal balance,"" has been criticized extensively for over two decades (e.g., Eckberg, 1997;Billman, 2013a). This obscures the interpretation of HRV from the approximately 65% of papers which still report metrics in this manner (Heathers, 2014). While it is clear that LF power does not represent sympathetic activity (Goldstein et al., 2011) it is important to note that there has also been robust debate surrounding the relationship between HF power and parasympathetic activity (for a review see Billman, 2011)."	0	"(3) Heart rate variability continues to be used to form an index of putative autonomic outflow by measuring a point on a simple continuum of parasympathetic/sympathetic activity. While this model is still popular, it is directly at odds with a great deal of available evidence; for instance, that neuropeptide Y directly mediates transmission between adrenergic and muscarinic neurons (#CITATION_TAG and McCloskey, 1990). This approach, generally focused around the use of the LF/HF ratio (the ratio of low frequency power to high frequency power) to represent ""sympathovagal balance,"" has been criticized extensively for over two decades (e.g., Eckberg, 1997;Billman, 2013a). This obscures the interpretation of HRV from the approximately 65% of papers which still report metrics in this manner (Heathers, 2014). While it is clear that LF power does not represent sympathetic activity (Goldstein et al., 2011) it is important to note that there has also been robust debate surrounding the relationship between HF power and parasympathetic activity (for a review see Billman, 2011)."	h
CCT542	"A Poincar√© plot is a visual, non-linear HRV index comprised of points that represent two consecutive heart periods, with any point above the identity line (a 45 ‚Ä¢ slope that passes through the origin, which represents equal consecutive heart periods) representing a longer heart period, whereas points below the identity line represent a shortening of the heart period. A healthy participant typically displays a ""comet"" shaped plot (Figure 1A), with a wider dispersion of points as the beats lengthen. Even at different rates of breathing (ranging from 6 to 16 breaths/min) this shape persists in healthy participants (Guzik et al., 2007). On the other hand, patients with heart failure display atypical ""torpedo,"" ""fan,"" or ""complex"" (i.e., stepwise clusters of points) patterns (Woo et al., 1992). A torpedo shape (Figure 1B) is indicative of a lack of R-R interval increase when HR slows, whereas fan and complex patterns (Figure 1C) may represent general issues with cardiac autonomic regulation. Poincar√© plots have been demonstrated to shown to display significant asymmetry in approximately 80% of individuals (Guzik et al., 2006;Piskorski and Guzik, 2007;#CITATION_TAG et al., 2008), with the plot ""cloud"" above the identity line appearing larger than the plot cloud below the line. Absent of longterm trends or very low frequency (VLF) power changes typically removed via detrending or high-pass filtering, HR acceleration will be matched with a roughly corresponding deceleration over time, and the Poincar√© plots might be expected to be symmetrical. However, this commonly observed asymmetry in Poincar√© plots suggests that HR accelerations operate in a different manner than decelerations, possibly due to baroreflex responses (Guzik et al., 2006). While the source of this asymmetry is unclear, it reinforces the fact that HRV is generated by complex non-linear dynamics. Together, this work emphasizes the importance of scrutinizing Poincar√© plots for irregularities, particularly for populations characterized by low HRV (e.g., older participants), and urges caution with the central assumption that IBIs over time can be meaningfully devolved into the sum of sine waves as in traditional frequency-domain analysis."	0	"Even at different rates of breathing (ranging from 6 to 16 breaths/min) this shape persists in healthy participants (Guzik et al., 2007). On the other hand, patients with heart failure display atypical ""torpedo,"" ""fan,"" or ""complex"" (i.e., stepwise clusters of points) patterns (Woo et al., 1992). A torpedo shape (Figure 1B) is indicative of a lack of R-R interval increase when HR slows, whereas fan and complex patterns (Figure 1C) may represent general issues with cardiac autonomic regulation. Poincar√© plots have been demonstrated to shown to display significant asymmetry in approximately 80% of individuals (Guzik et al., 2006;Piskorski and Guzik, 2007;#CITATION_TAG et al., 2008), with the plot ""cloud"" above the identity line appearing larger than the plot cloud below the line. Absent of longterm trends or very low frequency (VLF) power changes typically removed via detrending or high-pass filtering, HR acceleration will be matched with a roughly corresponding deceleration over time, and the Poincar√© plots might be expected to be symmetrical. However, this commonly observed asymmetry in Poincar√© plots suggests that HR accelerations operate in a different manner than decelerations, possibly due to baroreflex responses (Guzik et al., 2006). While the source of this asymmetry is unclear, it reinforces the fact that HRV is generated by complex non-linear dynamics."	a
CCT543	Coupling between respiration and heart rate (HR) has a long research history, and was noted in classical animal studies predating the electrocardiogram, which noticed fluctuations with breathing of heart beat and blood pressure (Ludwig, 1847). Consequently, the typically functioning respiratory system is presently characterized by complex breath-to-breath variations in respiratory rate and depth (Bruce, 1996) coupled with both heart period and blood pressure oscillations in a network of continual co-modification. For instance, a decrease in respiratory frequency generally corresponds with a lengthening of the heart period (Bruce, 1996). The traditional experimental approach of assessing the impact of the manipulation of one of these variables on another has led to important advancements in the understanding of cardiorespiratory coupling. However, perturbing the cardiorespiratory system does not allow the observation of casual relationships during spontaneous activity. Procedures developed to examine the coupling between time series may facilitate the identification of directionality and strength of cardiorespiratory coupling during spontaneous activity but these traditionally have only provided a limited insight into causality (e.g., Granger causality;Granger, 1969). Indeed, cardiorespiratory interaction has been variously quantified as primarily respiration-to-heart rate (#CITATION_TAG et al., 2002;Zhu et al., 2013) heart rate-to-respiration (Larsen et al., 1999;Tzeng et al., 2003) or neither (i.e., bidirectional; Porta et al., 2013). These differences are likely to strongly depend on the analytical technique employed, but the details of this are unclear.	0	The traditional experimental approach of assessing the impact of the manipulation of one of these variables on another has led to important advancements in the understanding of cardiorespiratory coupling. However, perturbing the cardiorespiratory system does not allow the observation of casual relationships during spontaneous activity. Procedures developed to examine the coupling between time series may facilitate the identification of directionality and strength of cardiorespiratory coupling during spontaneous activity but these traditionally have only provided a limited insight into causality (e.g., Granger causality;Granger, 1969). Indeed, cardiorespiratory interaction has been variously quantified as primarily respiration-to-heart rate (#CITATION_TAG et al., 2002;Zhu et al., 2013) heart rate-to-respiration (Larsen et al., 1999;Tzeng et al., 2003) or neither (i.e., bidirectional; Porta et al., 2013). These differences are likely to strongly depend on the analytical technique employed, but the details of this are unclear.	,
CCT544	"Social-emotional tasks have been shown to reduce breathing variability (Vlemincx et al., 2011(Vlemincx et al., , 2012a, even for positively valenced emotions (Boiten, 1998), due to the ""locked-in"" attention often required during social-emotional tasks. Moreover, the mental stress that usually accompanies these tasks can also disorder general respiratory coordination (Vlemincx et al., 2012b). In addition to overall breathing variability, experimental stress induction can also influence the specific length of inspiration and expiration (Cohen et al., 1975). Thus, a social-emotional task that induces a change in respiratory time variables and/or depth may be indirectly influencing HRV. The rates of sighing also increase during these tasks (Vlemincx et al., 2011), with sighs shown to ""reset"" both respiratory variability and emotional states (Vlemincx et al., 2013). This is consistent with observations of increased sighing in a range of anxiety disorders (Abelson et al., 2001;Nardi et al., 2009), and increased sighing during experimentally induced stress (Vlemincx et al., 2012b). Finally, continual focused attention (e.g., during psychometrics tasks) has been shown in a number of studies (Mulder and Mulder, 1981;#CITATION_TAG et al., 1987;Middleton et al., 1999) to reduce LF HRV, which creates further difficulties for interpretation."	0	"Thus, a social-emotional task that induces a change in respiratory time variables and/or depth may be indirectly influencing HRV. The rates of sighing also increase during these tasks (Vlemincx et al., 2011), with sighs shown to ""reset"" both respiratory variability and emotional states (Vlemincx et al., 2013). This is consistent with observations of increased sighing in a range of anxiety disorders (Abelson et al., 2001;Nardi et al., 2009), and increased sighing during experimentally induced stress (Vlemincx et al., 2012b). Finally, continual focused attention (e.g., during psychometrics tasks) has been shown in a number of studies (Mulder and Mulder, 1981;#CITATION_TAG et al., 1987;Middleton et al., 1999) to reduce LF HRV, which creates further difficulties for interpretation."	y
CCT545	"Several caveats exist to the establishment of a baseline as an appropriate point of comparison. Firstly, the baseline HR needs to be able to support the respiratory signal without aliasing (Witte et al., 1988) -for instance, a normative breathing rate of 0.3 Hz can only be observed successfully in a HR faster than 0.6 Hz (i.e., 36 bpm). In a regular ECG, this criterion is often met. However, during supine recording, transient beats and intervals in healthy young people are frequently below 0.8 Hz (i.e., 48 bpm) -this may extend up to the entire IBI series in the case of physically fit individuals or any other participant displaying bradycardia. This corresponds with the fastest criterion for RSA in the HF-HRV band (i.e., 0.4 Hz). While this is an abnormal situation (see Sacha and Grzeszczak, 2002), it is a potential confound to the establishment of a baseline, especially if IBI series are filtered incorrectly (Grossman and Taylor, 2007). Secondly, physically fit participants may not have sinus rhythm appropriate for analysis in the first instance due to potential changes to the sinoatrial node -hearts of such individuals have often been assumed to be slower at rest due to higher vagal tone but the balance of evidence does not presently favor this explanation (Boyett et al., 2013). However, the resumption of ""normal"" sinus rhythm may be observed during exercise, orthostatic stress, etc. -if this is an experimental condition, then the transition from resting baseline is affected. Thirdly, tasks often compare passive eyes-open rest as a baseline to the performance of a psychomotor, attentional, or emotional task, for instance. It is possible that this conflates the difference between passive rest vs. the act of paying attention to task with the difference between passive rest vs. the specific task demands of the experiment in question. A popular alternative to complete rest is the Vanilla baseline (Jennings et al., 1992), which requires subjects to perform a trivial counting task requiring sustained attention but minimal cognitive load, as opposed to what the authors term ""enforced relaxation."" Other similar approaches have been attempted (e.g., #CITATION_TAG et al., 2000). Other similar approaches have been attempted (e.g., Piferi et al., 2000). Finally, with individual recordings made over time, there is the complicated situation of the immediacy of baseline-toexperiment transition. HR is not stable over time, and can exhibit non-periodic phenomena or bifurcations, which may be in conflict with the assumption that an initial baseline well reflects a later experimental condition. Researchers must also consider the potential effect of decay between tasks if cardiorespiratory effects are observed, what a normalization to baseline might look like, and of course the fact that secondary baselines may conflict with experimental instructions or manipulations. It is inherent from the above that an appropriate baseline is not a singular measurement with""correct""parameters under all circumstances, but rather the non-task situation that best controls for the presence of task comparison. In many situations, the comparison of a task to a ""resting"" state will therefore vary in appropriateness."	0	"Thirdly, tasks often compare passive eyes-open rest as a baseline to the performance of a psychomotor, attentional, or emotional task, for instance. It is possible that this conflates the difference between passive rest vs. the act of paying attention to task with the difference between passive rest vs. the specific task demands of the experiment in question. A popular alternative to complete rest is the Vanilla baseline (Jennings et al., 1992), which requires subjects to perform a trivial counting task requiring sustained attention but minimal cognitive load, as opposed to what the authors term ""enforced relaxation"". Other similar approaches have been attempted (e.g., #CITATION_TAG et al., 2000). Other similar approaches have been attempted (e.g., Piferi et al., 2000). Finally, with individual recordings made over time, there is the complicated situation of the immediacy of baseline-toexperiment transition. HR is not stable over time, and can exhibit non-periodic phenomena or bifurcations, which may be in conflict with the assumption that an initial baseline well reflects a later experimental condition."	a
CCT546	While it may be the case that HRV can be used as a neurobiological index of interpersonal interaction, significant caveats exist due to the complicated nature of HRV and consequently uncertainty regarding what information is actually provided by common HRV indices (Berntson et al., 1997;Malpas, 2002;Billman, 2011). Additionally, the relationship between HRV and vagal modulation is complex in itself with a large interindividual variation (#CITATION_TAG et al., 2009). The problem is further compounded by the co-modulation of various respiratory and circulatory factors, which occur via numerous mechanisms and over multiple time-scales. Moreover, both breathing and blood pressure regulation have their own directly mediated relationships to the tasks employed in social, emotional, and cognitive experiments -if this is the case, we often have a complicated question of interlocking causalities. For instance, are observed changes in heart period epiphenomena that can be more parsimoniously described by changes in breathing or blood pressure? If the direction of causality between experimental task and the coordinated response within cardiac, circulatory, and respiratory variables is poorly understood, simple relationships between task and output changes may be obscured. Finally, experiments are often poorly designed as uncontrolled variables within typical experimental environments may drastically influence HRV. Few papers ideally control for medication, food, and water consumption, bladder filling, time of day, and other extraneous factors (Tak et al., 2009;Heathers, 2014). The overall aim of this review is to highlight the interrelationships between the nature and extraneous control of HRV, with a particular emphasis on respiration, and discuss implications for research in emotion science and psychology. Firstly, a number of important factors for the assessment of HRV in general and in emotion psychology in particular will be outlined. Secondly, solutions will be presented to reduce the potential impact of these factors.	0	While it may be the case that HRV can be used as a neurobiological index of interpersonal interaction, significant caveats exist due to the complicated nature of HRV and consequently uncertainty regarding what information is actually provided by common HRV indices (Berntson et al., 1997;Malpas, 2002;Billman, 2011). Additionally, the relationship between HRV and vagal modulation is complex in itself with a large interindividual variation (#CITATION_TAG et al., 2009). The problem is further compounded by the co-modulation of various respiratory and circulatory factors, which occur via numerous mechanisms and over multiple time-scales. Moreover, both breathing and blood pressure regulation have their own directly mediated relationships to the tasks employed in social, emotional, and cognitive experiments -if this is the case, we often have a complicated question of interlocking causalities. For instance, are observed changes in heart period epiphenomena that can be more parsimoniously described by changes in breathing or blood pressure?	d
CCT547	"A number of external factors are usually controlled for in HRV research, including the intake of nicotine (Hayano et al., 1990;Sjoberg and Saint, 2011) and caffeine (Sondermeijer et al., 2002) preceding data collection. Cardioactive medication use, including some antidepressant classes (e.g., tricyclics; Kemp et al., 2010), some antipsychotic classes (e.g., clozapine; Cohen et al., 2001), benzodiazepines (Agelink et al., 2002), and antihypertensives (Schroeder et al., 2003) are also usually accounted for, although this may be somewhat difficult in practice when testing patient populations. Other factors that are usually accounted for include the time of day (Massin et al., 2000;van Eekelen et al., 2004), levels of habitual alcohol use (Quintana et al., 2013a,b), Woo et al. (1992). physical activity levels (Britton et al., 2007;Soares-Miranda et al., 2014), and age (O""Brien et al., 1986). Digestion of food and water are less commonly accounted for in HRV research, but both provoke a coordinated autonomic response. For instance, digesting food has been shown to reduce parasympathetic activity, even an hour after eating a 500 kcal meal (Lu et al., 1999). Even exposure to food-related cues elicits a similar response (Nederkoorn et al., 2000), suggesting a physiological response to the anticipation of a meal. Conversely, missing a meal (i.e., fasting) appears to have its own coordinated effects on HRV (Pivik et al., 2006), supporting the recommendation that participants consume a light meal approximately 2 h before the assessment of HRV (Tak et al., 2009). Water consumption has also been shown to increase HF-HRV in particular (Routledge et al., 2002), due to the vagal buffering response to the pressor effect provoked by hypo-osmotic fluids (Scott et al., 2001). Notably, this buffering response to the pressor effect is attenuated in older individuals (Jordan et al., 2000) and not observed in those with cardiac vagal denervation (Routledge et al., 2002). In addition, both bladder and gastric distension can also have an appreciable influence on HRV; these have been associated with increases in blood pressure and sympathetic outflow (Fagius and Karhuvaara, 1989;#CITATION_TAG et al., 1998). However, papers only very rarely report that participants were asked to empty their bladder before experimental participation (Heathers, 2014)."	0	Conversely, missing a meal (i.e., fasting) appears to have its own coordinated effects on HRV (Pivik et al., 2006), supporting the recommendation that participants consume a light meal approximately 2 h before the assessment of HRV (Tak et al., 2009). Water consumption has also been shown to increase HF-HRV in particular (Routledge et al., 2002), due to the vagal buffering response to the pressor effect provoked by hypo-osmotic fluids (Scott et al., 2001). Notably, this buffering response to the pressor effect is attenuated in older individuals (Jordan et al., 2000) and not observed in those with cardiac vagal denervation (Routledge et al., 2002). In addition, both bladder and gastric distension can also have an appreciable influence on HRV; these have been associated with increases in blood pressure and sympathetic outflow (Fagius and Karhuvaara, 1989;#CITATION_TAG et al., 1998). However, papers only very rarely report that participants were asked to empty their bladder before experimental participation (Heathers, 2014).	n
CCT548	"One compromise solution is to measure a participant""s natural breathing rate, and use the derived frequency for respiratory pacing (e.g., Elstad, 2012). While this approach has utility during resting state registration, this procedure may inadvertently influence HRV during emotional or cognitive tasks as the participant has to consciously follow the pacing cue, in addition to paying attention to the experimental task -dual attention, in a number of contexts, significantly increases task difficulty (#CITATION_TAG, 1994). Zhang et al. (2010) argue that cardiorespiratory coupling during a cognitive task can be influenced either by activation of the motor cortex, which deceases cardiorespiratory coupling, or via increases in SNS activity from completing a cognitive task. However, here sympathetic outflow was indexed by normalized low frequency HRV -which is not straightforwardly related to SNS activity (e.g., Grassi and Esler, 1999;Moak et al., 2007;Goedhart et al., 2008;Billman, 2011Billman, , 2013a -so this latter claim requires further empirical support using indices that more directly index cardiac sympathetic outflow."	0	"One compromise solution is to measure a participant""s natural breathing rate, and use the derived frequency for respiratory pacing (e.g., Elstad, 2012). While this approach has utility during resting state registration, this procedure may inadvertently influence HRV during emotional or cognitive tasks as the participant has to consciously follow the pacing cue, in addition to paying attention to the experimental task -dual attention, in a number of contexts, significantly increases task difficulty (#CITATION_TAG, 1994). Zhang et al. (2010) argue that cardiorespiratory coupling during a cognitive task can be influenced either by activation of the motor cortex, which deceases cardiorespiratory coupling, or via increases in SNS activity from completing a cognitive task. However, here sympathetic outflow was indexed by normalized low frequency HRV -which is not straightforwardly related to SNS activity (e.g., Grassi and Esler, 1999;Moak et al., 2007;Goedhart et al., 2008;Billman, 2011Billman, , 2013a -so this latter claim requires further empirical support using indices that more directly index cardiac sympathetic outflow."	h
CCT549	"As detailed above, basic changes in respiration can have a significant impact on HRV. Pneumotachography is the gold standard for the monitoring of tidal volume, however, the use of a closed face-mask required to do so is cumbersome and impractical for most research in emotion and psychological science (e.g., faceto-face interactions). In lieu of this, the use of a strain gage to index the expansion of the chest can give sufficient informationmost importantly, a strain gage can identify gross deviations of typical cyclical respiration (e.g., sighs, coughs). Mirroring the importance of HR measures to reflect true sinus rhythm (as an ectopic beat does not represent ANS input to the SA node), ""true"" respiratory cycles must also be used to correctly draw inference on respiratory oscillations and coupling to HR. However, signals from strain gages do not necessarily have a linear relationship of circumference to signal (i.e., distension/signal output relationships may be different at different belt tensions) and that chest circumference is itself an indirect measure of the respiratory cycle (i.e., lung and chest wall volumes are not identical). In lieu of direct respiratory measures, established algorithms (Moody et al., 1985(Moody et al., , 1986) that have been successively improved (e.g., #CITATION_TAG et al., 2008;Langley et al., 2010) can also provide an appropriate surrogate measure of respiration from based on ECG signal morphology."	0	"In lieu of this, the use of a strain gage to index the expansion of the chest can give sufficient informationmost importantly, a strain gage can identify gross deviations of typical cyclical respiration (e.g., sighs, coughs). Mirroring the importance of HR measures to reflect true sinus rhythm (as an ectopic beat does not represent ANS input to the SA node), ""true"" respiratory cycles must also be used to correctly draw inference on respiratory oscillations and coupling to HR. However, signals from strain gages do not necessarily have a linear relationship of circumference to signal (i.e., distension/signal output relationships may be different at different belt tensions) and that chest circumference is itself an indirect measure of the respiratory cycle (i.e., lung and chest wall volumes are not identical). In lieu of direct respiratory measures, established algorithms (Moody et al., 1985(Moody et al., , 1986) that have been successively improved (e.g., #CITATION_TAG et al., 2008;Langley et al., 2010) can also provide an appropriate surrogate measure of respiration from based on ECG signal morphology."	e
CCT550	A number of external factors are usually controlled for in HRV research, including the intake of nicotine (Hayano et al., 1990;Sjoberg and Saint, 2011) and caffeine (Sondermeijer et al., 2002) preceding data collection. Cardioactive medication use, including some antidepressant classes (e.g., tricyclics; Kemp et al., 2010), some antipsychotic classes (e.g., clozapine; Cohen et al., 2001), benzodiazepines (Agelink et al., 2002), and antihypertensives (Schroeder et al., 2003) are also usually accounted for, although this may be somewhat difficult in practice when testing patient populations. Other factors that are usually accounted for include the time of day (Massin et al., 2000;van Eekelen et al., 2004), levels of habitual alcohol use (Quintana et al., 2013a,b), Woo et al. (1992). physical activity levels (Britton et al., 2007;Soares-Miranda et al., 2014), and age (#CITATION_TAG et al., 1986). Digestion of food and water are less commonly accounted for in HRV research, but both provoke a coordinated autonomic response. For instance, digesting food has been shown to reduce parasympathetic activity, even an hour after eating a 500 kcal meal (Lu et al., 1999). Even exposure to food-related cues elicits a similar response (Nederkoorn et al., 2000), suggesting a physiological response to the anticipation of a meal. Conversely, missing a meal (i.e., fasting) appears to have its own coordinated effects on HRV (Pivik et al., 2006), supporting the recommendation that participants consume a light meal approximately 2 h before the assessment of HRV (Tak et al., 2009). Water consumption has also been shown to increase HF-HRV in particular (Routledge et al., 2002), due to the vagal buffering response to the pressor effect provoked by hypo-osmotic fluids (Scott et al., 2001). Notably, this buffering response to the pressor effect is attenuated in older individuals (Jordan et al., 2000) and not observed in those with cardiac vagal denervation (Routledge et al., 2002). In addition, both bladder and gastric distension can also have an appreciable influence on HRV; these have been associated with increases in blood pressure and sympathetic outflow (Fagius and Karhuvaara, 1989;Rossi et al., 1998). However, papers only very rarely report that participants were asked to empty their bladder before experimental participation (Heathers, 2014).	0	A number of external factors are usually controlled for in HRV research, including the intake of nicotine (Hayano et al., 1990;Sjoberg and Saint, 2011) and caffeine (Sondermeijer et al., 2002) preceding data collection. Cardioactive medication use, including some antidepressant classes (e.g., tricyclics; Kemp et al., 2010), some antipsychotic classes (e.g., clozapine; Cohen et al., 2001), benzodiazepines (Agelink et al., 2002), and antihypertensives (Schroeder et al., 2003) are also usually accounted for, although this may be somewhat difficult in practice when testing patient populations. Other factors that are usually accounted for include the time of day (Massin et al., 2000;van Eekelen et al., 2004), levels of habitual alcohol use (Quintana et al., 2013a,b), Woo et al. (1992). physical activity levels (Britton et al., 2007;Soares-Miranda et al., 2014), and age (#CITATION_TAG et al., 1986). Digestion of food and water are less commonly accounted for in HRV research, but both provoke a coordinated autonomic response. For instance, digesting food has been shown to reduce parasympathetic activity, even an hour after eating a 500 kcal meal (Lu et al., 1999). Even exposure to food-related cues elicits a similar response (Nederkoorn et al., 2000), suggesting a physiological response to the anticipation of a meal.	s
CCT551	It should be mentioned here that while this paper focuses solely on issues of traditional methodological control, there are other domains in which significant improvements in the experimental environment surrounding HRV might be gained. Most crucially, signal analytic requirements often receive surprisingly little attention, and decisions about type of spectral analysis, windowing, and data cleaning are crucial (e.g., Berntson and Stowell, 1998) but are often under-reported. Likewise, recent interest in data uploading and retention (e.g., #CITATION_TAG et al., 2012) has received little systematic attention in cardiac psychophysiology so far, even though a) data retention is a American Psychological Association requirement (American psychological association [APA], 2001) and b) the ability to broadly access raw data is a potentially excellent control for the methodological and analytical issues outlined here, as well as a test bed for the development of future HRV metrics and meta-analysis.	0	It should be mentioned here that while this paper focuses solely on issues of traditional methodological control, there are other domains in which significant improvements in the experimental environment surrounding HRV might be gained. Most crucially, signal analytic requirements often receive surprisingly little attention, and decisions about type of spectral analysis, windowing, and data cleaning are crucial (e.g., Berntson and Stowell, 1998) but are often under-reported. Likewise, recent interest in data uploading and retention (e.g., #CITATION_TAG et al., 2012) has received little systematic attention in cardiac psychophysiology so far, even though a) data retention is a American Psychological Association requirement (American psychological association [APA], 2001) and b) the ability to broadly access raw data is a potentially excellent control for the methodological and analytical issues outlined here, as well as a test bed for the development of future HRV metrics and meta-analysis.	k
CCT552	The intracellular concentration of P is known to be influenced by the concentration of Prich ribosomes with their associated rRNA [2]. Increasing rRNA, coupled with increasing growth rates, have been shown to decrease the N:P ratio over a range of different organisms and biotopes [33]. Hillebrand et al. [34] found a similar trend of decreasing N:P ratio and Fig 6 . The photosynthetic quotient (PQ; mol O 2 produced per mol C fixed) at exponential and stationary growth phases (both N and P limited), and at the initial slope (Œ±*) and photosynthetic maximum (Pm*) of the PE curve. The horizontal line is the median, the box represents the 25-75% confidence interval, and the error bars the 10-90% confidence interval (n = 12 for exponential growth; n = 5 for N and P limitation). The data is presented in Table 1. doi:10.1371/journal.pone.0126308.g006 variability with increasing growth rate in phytoplankton, suggesting that fast-growing phytoplankton in general require more P, and also have a more confined N:P ratio compared with slow-growing phytoplankton. Recently, temperature was also shown to affect the concentration of ribosomes in phytoplankton; at a constant protein synthesis, relatively more ribosomes are needed at low temperature #CITATION_TAG. This is in line with the temperature effect that we observed, and the most plausible reason for the reduced C:P and N:P at low temperature and light.	4	pone. 0126308. g006 variability with increasing growth rate in phytoplankton, suggesting that fast-growing phytoplankton in general require more P, and also have a more confined N:P ratio compared with slow-growing phytoplankton. Recently, temperature was also shown to affect the concentration of ribosomes in phytoplankton; at a constant protein synthesis, relatively more ribosomes are needed at low temperature #CITATION_TAG. This is in line with the temperature effect that we observed, and the most plausible reason for the reduced C:P and N:P at low temperature and light.	 
CCT553	When modelling primary productivity, some of the key parameters in measurements of photosynthetic production are: the maximum light utilization coefficient (Œ± √É ), which is the initial slope, Œ±, of the photosynthesis-irradiance (PE) curve normalized to Chl a; the maximum photosynthetic rate (P m √É ); the irradiance where production equals consumption i.e. the compensation light intensity (E c ); and finally the light saturation parameter (E k ) #CITATION_TAG.	0	When modelling primary productivity, some of the key parameters in measurements of photosynthetic production are: the maximum light utilization coefficient (Œ± √É ), which is the initial slope, Œ±, of the photosynthesis-irradiance (PE) curve normalized to Chl a; the maximum photosynthetic rate (P m √É ); the irradiance where production equals consumption i.e. the compensation light intensity (E c ); and finally the light saturation parameter (E k ) #CITATION_TAG.	W
CCT554	Light and temperature have several well-known effects on primary production #CITATION_TAG. Under natural conditions with fluctuating light intensity there will be a continuous acclimation of light absorption and photosynthetic activity through the production of photosynthetic pigments and regulation of the energy channeled to the photochemical reaction centers. The light reactions are not directly dependent on temperature, but temperature affects enzymatic processes, membrane fluidity and intermolecular collision processes [42]. Light acclimation will affect photosynthesis under both limiting and saturating light conditions, whereas temperature will mostly affect photosynthesis at saturating light conditions [42]. As such, photosynthetic production will be optimized under all but the most limiting environmental conditions. The present experiments support these basic paradigms also for the cold-water diatom, despite (or more accurately: by means of) the observed variability in stoichiometry.	0	Light and temperature have several well-known effects on primary production #CITATION_TAG. Under natural conditions with fluctuating light intensity there will be a continuous acclimation of light absorption and photosynthetic activity through the production of photosynthetic pigments and regulation of the energy channeled to the photochemical reaction centers. The light reactions are not directly dependent on temperature, but temperature affects enzymatic processes, membrane fluidity and intermolecular collision processes [42]. Light acclimation will affect photosynthesis under both limiting and saturating light conditions, whereas temperature will mostly affect photosynthesis at saturating light conditions [42].	L
CCT555	Models of phytoplankton growth are important for understanding aquatic production and ecosystem-scale biogeochemistry. Abiotic variables such as light, temperature and nutrient availability are the most important aspects regulating productivity and growth in phytoplankton. The influence of these parameters on production is most often studied independently, whereas interaction effects such as the temperature dependent nature of light utilization for photosynthesis, may be expected #CITATION_TAG.	4	Models of phytoplankton growth are important for understanding aquatic production and ecosystem-scale biogeochemistry. Abiotic variables such as light, temperature and nutrient availability are the most important aspects regulating productivity and growth in phytoplankton. The influence of these parameters on production is most often studied independently, whereas interaction effects such as the temperature dependent nature of light utilization for photosynthesis, may be expected #CITATION_TAG.	e
CCT556	The interplay between environmental factors such as light, temperature and nutrient availability and the physiology of the cell determines the growth rate and stoichiometric composition of the major elements in algae. Traditionally factors such as the growth-limiting nutrient have been used to model nutrient uptake and growth [27], and recent advances have started to incorporate uptake-protein regulation into this equation [28][29]. The latter is an important step  as it incorporates the nutrient history of the primary producers, which is decisive in regulating the uptake rate determined by e.g. the number of uptake sites. The present data support the growing understanding of the interaction between fundamental abiotic parameters that should be included in growth models. Geider and La Roche #CITATION_TAG pointed out in their review on algal stoichiometry that relatively few studies examine the phenotypic flexibility in C:N:P during exponential growth and that more studies are needed in order to better understand the effect of temperature and light on these ratios. Under nutrient replete conditions the variability in the C:N:P ratio is normally larger between different species than between different environmental conditions such as variation in temperature [30]. Our data support this to some extent, as there was low variability in the C:N during active growth. However, C:P and N:P was twofold different between the lowest and highest value. The larger variability in C:P and N:P was caused by high P content relative to C and N at low light and temperature acclimation. Strong latitudinal patterns in the C:N:P ratio was recently described, and a lower than average ratio was associated with high latitudes [31]. Martiny et al. [31] suggested this lower C:N:P ratio to be caused by the largely diatom dominated communities present in cold water, but diatoms have also been associated with higher C:N:P ratio [32]. Our results here imply that there is a temperature effect, with lower C: N:P in low temperature and light.	0	Traditionally factors such as the growth-limiting nutrient have been used to model nutrient uptake and growth [27], and recent advances have started to incorporate uptake-protein regulation into this equation [28][29]. The latter is an important step  as it incorporates the nutrient history of the primary producers, which is decisive in regulating the uptake rate determined by e.g. the number of uptake sites. The present data support the growing understanding of the interaction between fundamental abiotic parameters that should be included in growth models. Geider and La Roche #CITATION_TAG pointed out in their review on algal stoichiometry that relatively few studies examine the phenotypic flexibility in C:N:P during exponential growth and that more studies are needed in order to better understand the effect of temperature and light on these ratios. Under nutrient replete conditions the variability in the C:N:P ratio is normally larger between different species than between different environmental conditions such as variation in temperature [30]. Our data support this to some extent, as there was low variability in the C:N during active growth. However, C:P and N:P was twofold different between the lowest and highest value.	e
CCT557	The interplay between environmental factors such as light, temperature and nutrient availability and the physiology of the cell determines the growth rate and stoichiometric composition of the major elements in algae. Traditionally factors such as the growth-limiting nutrient have been used to model nutrient uptake and growth [27], and recent advances have started to incorporate uptake-protein regulation into this equation [28][29]. The latter is an important step  as it incorporates the nutrient history of the primary producers, which is decisive in regulating the uptake rate determined by e.g. the number of uptake sites. The present data support the growing understanding of the interaction between fundamental abiotic parameters that should be included in growth models. Geider and La Roche [30] pointed out in their review on algal stoichiometry that relatively few studies examine the phenotypic flexibility in C:N:P during exponential growth and that more studies are needed in order to better understand the effect of temperature and light on these ratios. Under nutrient replete conditions the variability in the C:N:P ratio is normally larger between different species than between different environmental conditions such as variation in temperature [30]. Our data support this to some extent, as there was low variability in the C:N during active growth. However, C:P and N:P was twofold different between the lowest and highest value. The larger variability in C:P and N:P was caused by high P content relative to C and N at low light and temperature acclimation. Strong latitudinal patterns in the C:N:P ratio was recently described, and a lower than average ratio was associated with high latitudes #CITATION_TAG. Martiny et al. [31] suggested this lower C:N:P ratio to be caused by the largely diatom dominated communities present in cold water, but diatoms have also been associated with higher C:N:P ratio [32]. Our results here imply that there is a temperature effect, with lower C: N:P in low temperature and light.	4	Our data support this to some extent, as there was low variability in the C:N during active growth. However, C:P and N:P was twofold different between the lowest and highest value. The larger variability in C:P and N:P was caused by high P content relative to C and N at low light and temperature acclimation. Strong latitudinal patterns in the C:N:P ratio was recently described, and a lower than average ratio was associated with high latitudes #CITATION_TAG. Martiny et al. [31] suggested this lower C:N:P ratio to be caused by the largely diatom dominated communities present in cold water, but diatoms have also been associated with higher C:N:P ratio [32]. Our results here imply that there is a temperature effect, with lower C: N:P in low temperature and light.	t
CCT558	The interplay between environmental factors such as light, temperature and nutrient availability and the physiology of the cell determines the growth rate and stoichiometric composition of the major elements in algae. Traditionally factors such as the growth-limiting nutrient have been used to model nutrient uptake and growth [27], and recent advances have started to incorporate uptake-protein regulation into this equation [28][29]. The latter is an important step  as it incorporates the nutrient history of the primary producers, which is decisive in regulating the uptake rate determined by e.g. the number of uptake sites. The present data support the growing understanding of the interaction between fundamental abiotic parameters that should be included in growth models. Geider and La Roche [30] pointed out in their review on algal stoichiometry that relatively few studies examine the phenotypic flexibility in C:N:P during exponential growth and that more studies are needed in order to better understand the effect of temperature and light on these ratios. Under nutrient replete conditions the variability in the C:N:P ratio is normally larger between different species than between different environmental conditions such as variation in temperature [30]. Our data support this to some extent, as there was low variability in the C:N during active growth. However, C:P and N:P was twofold different between the lowest and highest value. The larger variability in C:P and N:P was caused by high P content relative to C and N at low light and temperature acclimation. Strong latitudinal patterns in the C:N:P ratio was recently described, and a lower than average ratio was associated with high latitudes [31]. Martiny et al. [31] suggested this lower C:N:P ratio to be caused by the largely diatom dominated communities present in cold water, but diatoms have also been associated with higher C:N:P ratio #CITATION_TAG. Our results here imply that there is a temperature effect, with lower C: N:P in low temperature and light.	2	However, C:P and N:P was twofold different between the lowest and highest value. The larger variability in C:P and N:P was caused by high P content relative to C and N at low light and temperature acclimation. Strong latitudinal patterns in the C:N:P ratio was recently described, and a lower than average ratio was associated with high latitudes [31]. Martiny et al. [31] suggested this lower C:N:P ratio to be caused by the largely diatom dominated communities present in cold water, but diatoms have also been associated with higher C:N:P ratio #CITATION_TAG. Our results here imply that there is a temperature effect, with lower C: N:P in low temperature and light.	 
CCT559	In this study, we present growth, element stoichiometry and primary production of a coldwater adapted, model organism, Chaetoceros wighamii; a common bloom forming diatom in the Baltic Sea #CITATION_TAG, subjected to a range of growth conditions around its known optimum. Our goal was to investigate potential interaction effects between light, temperature and nutrient limitation, and the results provide generically applicable productivity data for a cold-water diatom.	2	In this study, we present growth, element stoichiometry and primary production of a coldwater adapted, model organism, Chaetoceros wighamii; a common bloom forming diatom in the Baltic Sea #CITATION_TAG, subjected to a range of growth conditions around its known optimum. Our goal was to investigate potential interaction effects between light, temperature and nutrient limitation, and the results provide generically applicable productivity data for a cold-water diatom.	I
CCT560	We may expect climate change to disproportionally affect regions with strong seasonality in light availability and surface water temperature. Thus, it is important to improve biogeochemical models particularly in regions where seasonal primary production is coupled to low temperatures, such as seas and oceans at high latitudes. Most of the focus on interaction effects between different environmental variables stems from work on lakes [15]#CITATION_TAG. Coastal areas in arctic or subarctic regions will be subjected to many of the same changes, but relatively few studies have addressed interaction effects in these areas, in particular for cold water adapted phytoplankton species [16][17].	0	We may expect climate change to disproportionally affect regions with strong seasonality in light availability and surface water temperature. Thus, it is important to improve biogeochemical models particularly in regions where seasonal primary production is coupled to low temperatures, such as seas and oceans at high latitudes. Most of the focus on interaction effects between different environmental variables stems from work on lakes [15]#CITATION_TAG. Coastal areas in arctic or subarctic regions will be subjected to many of the same changes, but relatively few studies have addressed interaction effects in these areas, in particular for cold water adapted phytoplankton species [16][17].	s
CCT561	The photosynethic quotient (PQ) is given as the molar ratio of oxygen (in the form of O ) produced per C fixed by photosynthesis. The PQ is normally >1, indicating that a fraction of the reducing power created in the light reaction is used for other purposes than C fixation in the Calvin-Benson cycle, e.g. lipid or protein synthesis [12]. Furthermore, when the N source is nitrate that needs to be reduced, the PQ will be higher compared to a situation where ammonium is the N source [13]. Another process that will affect the PQ is photorespiration, which is a process consuming the O 2 produced during photosynthesis and thereby lowering the PQ #CITATION_TAG.	0	The photosynethic quotient (PQ) is given as the molar ratio of oxygen (in the form of O ) produced per C fixed by photosynthesis. The PQ is normally >1, indicating that a fraction of the reducing power created in the light reaction is used for other purposes than C fixation in the Calvin-Benson cycle, e.g. lipid or protein synthesis [12]. Furthermore, when the N source is nitrate that needs to be reduced, the PQ will be higher compared to a situation where ammonium is the N source [13]. Another process that will affect the PQ is photorespiration, which is a process consuming the O 2 produced during photosynthesis and thereby lowering the PQ #CITATION_TAG.	t
CCT562	The growth rate and photosynthetic properties (Œ± √É , P m √É , E c and E k ) we observed for C. wighamii were similar to published values [43], but expanded on these by including the interaction effect between light and temperature, and also including different nutrient limitation. Generally, the decreasing Œ± √É and P m √É and increasing E c and E k can be expected when the cells stated to experience nutrient stress and optimizing photosynthetic production becomes less important. An apparent paradox was the difference between N and P limitation, where P limitation seemingly affect Œ± √É and P m √É more than N limitation. Photosynthetic pigments contain N but no P, so intuitively this seems like a contradiction. However, both of these photosynthetic parameters were normalized to Chl a, which is the norm in the literature [11], and normalizing to POC instead yields an opposite result where Œ± and P m under N limitation are approximately half of that under P limitation. This highlight the importance of considering the biomass currency used to compare data. The most surprising finding was the low (<1) PQ values at nutrient and light limitation. For Pycnococcus provasolii it has been shown that the PQ was affected by both light acclimation and incubation light intensity #CITATION_TAG; where decreasing growth light decreased the PQ. The lowest PQ recorded by Iriarte [44] was 0.7, and this low value was suggested to be caused by an underestimation of O 2 production due to photorespiration. Photorespiration is a net loss process where O 2 replaces CO at the rubisco enzyme catalyzing the carbon fixation, resulting in consumption of 3 O 2 for every CO 2 produced [45]. Photorespiration may serve a function, such as a protective mechanism to avoid reactive oxygen species during photosynthesis [46], or in the assimilation of nitrate [47].	1	However, both of these photosynthetic parameters were normalized to Chl a, which is the norm in the literature [11], and normalizing to POC instead yields an opposite result where Œ± and P m under N limitation are approximately half of that under P limitation. This highlight the importance of considering the biomass currency used to compare data. The most surprising finding was the low (<1) PQ values at nutrient and light limitation. For Pycnococcus provasolii it has been shown that the PQ was affected by both light acclimation and incubation light intensity #CITATION_TAG; where decreasing growth light decreased the PQ. The lowest PQ recorded by Iriarte [44] was 0.7, and this low value was suggested to be caused by an underestimation of O 2 production due to photorespiration. Photorespiration is a net loss process where O 2 replaces CO at the rubisco enzyme catalyzing the carbon fixation, resulting in consumption of 3 O 2 for every CO 2 produced [45]. Photorespiration may serve a function, such as a protective mechanism to avoid reactive oxygen species during photosynthesis [46], or in the assimilation of nitrate [47].	n
CCT563	Once one or more nutrients are depleted, the stoichiometry has in general a much wider window of variability [2]. Typically, the ratio of C:N:P increase as C fixation continues for some time after cells have stopped dividing, which is supported by our observations. In particular diatoms are known to increase the C:N:P during stationary growth, and the extra carbon can have implications for the biogeochemical flux of carbon in the system [32]. The excess carbon can be stored as an energy reserve such as lipids [36]. Surplus N can be stored as protein, free amino acids or put into photosynthetic pigments [2,37], and P can be stored as polyphosphate #CITATION_TAG. During stationary growth, P limitation had the most pronounced effect on the N:P ratio, as opposed to N and Si limitation, suggesting that P content per biomass unit is less flexible than the N content in C. wighamii. This was also supported by increasing N:P during Si limitation. The much increased N:P at P and Si limitation suggests active uptake and storage of 2-4 fold the concentration of N during stationary growth phase, relative to P.	0	Typically, the ratio of C:N:P increase as C fixation continues for some time after cells have stopped dividing, which is supported by our observations. In particular diatoms are known to increase the C:N:P during stationary growth, and the extra carbon can have implications for the biogeochemical flux of carbon in the system [32]. The excess carbon can be stored as an energy reserve such as lipids [36]. Surplus N can be stored as protein, free amino acids or put into photosynthetic pigments [2,37], and P can be stored as polyphosphate #CITATION_TAG. During stationary growth, P limitation had the most pronounced effect on the N:P ratio, as opposed to N and Si limitation, suggesting that P content per biomass unit is less flexible than the N content in C. wighamii. This was also supported by increasing N:P during Si limitation. The much increased N:P at P and Si limitation suggests active uptake and storage of 2-4 fold the concentration of N during stationary growth phase, relative to P.	l
CCT564	Once one or more nutrients are depleted, the stoichiometry has in general a much wider window of variability [2]. Typically, the ratio of C:N:P increase as C fixation continues for some time after cells have stopped dividing, which is supported by our observations. In particular diatoms are known to increase the C:N:P during stationary growth, and the extra carbon can have implications for the biogeochemical flux of carbon in the system [32]. The excess carbon can be stored as an energy reserve such as lipids [36]. Surplus N can be stored as protein, free amino acids or put into photosynthetic pigments [2,#CITATION_TAG], and P can be stored as polyphosphate [38]. During stationary growth, P limitation had the most pronounced effect on the N:P ratio, as opposed to N and Si limitation, suggesting that P content per biomass unit is less flexible than the N content in C. wighamii. This was also supported by increasing N:P during Si limitation. The much increased N:P at P and Si limitation suggests active uptake and storage of 2-4 fold the concentration of N during stationary growth phase, relative to P.	0	Typically, the ratio of C:N:P increase as C fixation continues for some time after cells have stopped dividing, which is supported by our observations. In particular diatoms are known to increase the C:N:P during stationary growth, and the extra carbon can have implications for the biogeochemical flux of carbon in the system [32]. The excess carbon can be stored as an energy reserve such as lipids [36]. Surplus N can be stored as protein, free amino acids or put into photosynthetic pigments [2,#CITATION_TAG], and P can be stored as polyphosphate [38]. During stationary growth, P limitation had the most pronounced effect on the N:P ratio, as opposed to N and Si limitation, suggesting that P content per biomass unit is less flexible than the N content in C. wighamii. This was also supported by increasing N:P during Si limitation. The much increased N:P at P and Si limitation suggests active uptake and storage of 2-4 fold the concentration of N during stationary growth phase, relative to P.	l
CCT565	The interplay between environmental factors such as light, temperature and nutrient availability and the physiology of the cell determines the growth rate and stoichiometric composition of the major elements in algae. Traditionally factors such as the growth-limiting nutrient have been used to model nutrient uptake and growth #CITATION_TAG, and recent advances have started to incorporate uptake-protein regulation into this equation [28][29]. The latter is an important step  as it incorporates the nutrient history of the primary producers, which is decisive in regulating the uptake rate determined by e.g. the number of uptake sites. The present data support the growing understanding of the interaction between fundamental abiotic parameters that should be included in growth models. Geider and La Roche [30] pointed out in their review on algal stoichiometry that relatively few studies examine the phenotypic flexibility in C:N:P during exponential growth and that more studies are needed in order to better understand the effect of temperature and light on these ratios. Under nutrient replete conditions the variability in the C:N:P ratio is normally larger between different species than between different environmental conditions such as variation in temperature [30]. Our data support this to some extent, as there was low variability in the C:N during active growth. However, C:P and N:P was twofold different between the lowest and highest value. The larger variability in C:P and N:P was caused by high P content relative to C and N at low light and temperature acclimation. Strong latitudinal patterns in the C:N:P ratio was recently described, and a lower than average ratio was associated with high latitudes [31]. Martiny et al. [31] suggested this lower C:N:P ratio to be caused by the largely diatom dominated communities present in cold water, but diatoms have also been associated with higher C:N:P ratio [32]. Our results here imply that there is a temperature effect, with lower C: N:P in low temperature and light.	0	The interplay between environmental factors such as light, temperature and nutrient availability and the physiology of the cell determines the growth rate and stoichiometric composition of the major elements in algae. Traditionally factors such as the growth-limiting nutrient have been used to model nutrient uptake and growth #CITATION_TAG, and recent advances have started to incorporate uptake-protein regulation into this equation [28][29]. The latter is an important step  as it incorporates the nutrient history of the primary producers, which is decisive in regulating the uptake rate determined by e.g. the number of uptake sites. The present data support the growing understanding of the interaction between fundamental abiotic parameters that should be included in growth models. Geider and La Roche [30] pointed out in their review on algal stoichiometry that relatively few studies examine the phenotypic flexibility in C:N:P during exponential growth and that more studies are needed in order to better understand the effect of temperature and light on these ratios.	r
CCT566	Once one or more nutrients are depleted, the stoichiometry has in general a much wider window of variability [2]. Typically, the ratio of C:N:P increase as C fixation continues for some time after cells have stopped dividing, which is supported by our observations. In particular diatoms are known to increase the C:N:P during stationary growth, and the extra carbon can have implications for the biogeochemical flux of carbon in the system [32]. The excess carbon can be stored as an energy reserve such as lipids #CITATION_TAG. Surplus N can be stored as protein, free amino acids or put into photosynthetic pigments [2,37], and P can be stored as polyphosphate [38]. During stationary growth, P limitation had the most pronounced effect on the N:P ratio, as opposed to N and Si limitation, suggesting that P content per biomass unit is less flexible than the N content in C. wighamii. This was also supported by increasing N:P during Si limitation. The much increased N:P at P and Si limitation suggests active uptake and storage of 2-4 fold the concentration of N during stationary growth phase, relative to P.	0	Once one or more nutrients are depleted, the stoichiometry has in general a much wider window of variability [2]. Typically, the ratio of C:N:P increase as C fixation continues for some time after cells have stopped dividing, which is supported by our observations. In particular diatoms are known to increase the C:N:P during stationary growth, and the extra carbon can have implications for the biogeochemical flux of carbon in the system [32]. The excess carbon can be stored as an energy reserve such as lipids #CITATION_TAG. Surplus N can be stored as protein, free amino acids or put into photosynthetic pigments [2,37], and P can be stored as polyphosphate [38]. During stationary growth, P limitation had the most pronounced effect on the N:P ratio, as opposed to N and Si limitation, suggesting that P content per biomass unit is less flexible than the N content in C. wighamii. This was also supported by increasing N:P during Si limitation.	 
CCT567	The C:Chl a ratio was, as expected, strongly influenced by light acclimation, as the cells acclimate to low light conditions by increasing photosynthetic pigmentation #CITATION_TAG. The data suggests a second order temperature effect, with the effect of light acclimation becomes much greater at the lowest temperature. There is little evidence to suggest temperature effects on C: Chl a ratio [40], but similar results were found in the cold water diatom Skeletonema costatum which had higher variability in the Chl a content per cell at low temperatures [41]. During the stationary growth phase, the C:Chl a ratio was~4 fold higher during N limitation than during P or Si limitation, which can be attributed to the fact that Chl a contains N but not P or Si [2].	1	The C:Chl a ratio was, as expected, strongly influenced by light acclimation, as the cells acclimate to low light conditions by increasing photosynthetic pigmentation #CITATION_TAG. The data suggests a second order temperature effect, with the effect of light acclimation becomes much greater at the lowest temperature. There is little evidence to suggest temperature effects on C: Chl a ratio [40], but similar results were found in the cold water diatom Skeletonema costatum which had higher variability in the Chl a content per cell at low temperatures [41]. During the stationary growth phase, the C:Chl a ratio was~4 fold higher during N limitation than during P or Si limitation, which can be attributed to the fact that Chl a contains N but not P or Si [2].	T
CCT568	The intracellular concentration of P is known to be influenced by the concentration of Prich ribosomes with their associated rRNA [2]. Increasing rRNA, coupled with increasing growth rates, have been shown to decrease the N:P ratio over a range of different organisms and biotopes [33]. Hillebrand et al. #CITATION_TAG found a similar trend of decreasing N:P ratio and Fig 6 . The photosynthetic quotient (PQ; mol O 2 produced per mol C fixed) at exponential and stationary growth phases (both N and P limited), and at the initial slope (Œ±*) and photosynthetic maximum (Pm*) of the PE curve. The horizontal line is the median, the box represents the 25-75% confidence interval, and the error bars the 10-90% confidence interval (n = 12 for exponential growth; n = 5 for N and P limitation). The data is presented in Table 1. doi:10.1371/journal.pone.0126308.g006 variability with increasing growth rate in phytoplankton, suggesting that fast-growing phytoplankton in general require more P, and also have a more confined N:P ratio compared with slow-growing phytoplankton. Recently, temperature was also shown to affect the concentration of ribosomes in phytoplankton; at a constant protein synthesis, relatively more ribosomes are needed at low temperature [35]. This is in line with the temperature effect that we observed, and the most plausible reason for the reduced C:P and N:P at low temperature and light.	0	The intracellular concentration of P is known to be influenced by the concentration of Prich ribosomes with their associated rRNA [2]. Increasing rRNA, coupled with increasing growth rates, have been shown to decrease the N:P ratio over a range of different organisms and biotopes [33]. Hillebrand et al. #CITATION_TAG found a similar trend of decreasing N:P ratio and Fig 6 . The photosynthetic quotient (PQ; mol O 2 produced per mol C fixed) at exponential and stationary growth phases (both N and P limited), and at the initial slope (Œ±*) and photosynthetic maximum (Pm*) of the PE curve. The horizontal line is the median, the box represents the 25-75% confidence interval, and the error bars the 10-90% confidence interval (n = 12 for exponential growth; n = 5 for N and P limitation). The data is presented in Table 1. doi:10.1371/journal.	l
CCT569	The intracellular concentration of P is known to be influenced by the concentration of Prich ribosomes with their associated rRNA [2]. Increasing rRNA, coupled with increasing growth rates, have been shown to decrease the N:P ratio over a range of different organisms and biotopes #CITATION_TAG. Hillebrand et al. [34] found a similar trend of decreasing N:P ratio and Fig 6 . The photosynthetic quotient (PQ; mol O 2 produced per mol C fixed) at exponential and stationary growth phases (both N and P limited), and at the initial slope (Œ±*) and photosynthetic maximum (Pm*) of the PE curve. The horizontal line is the median, the box represents the 25-75% confidence interval, and the error bars the 10-90% confidence interval (n = 12 for exponential growth; n = 5 for N and P limitation). The data is presented in Table 1. doi:10.1371/journal.pone.0126308.g006 variability with increasing growth rate in phytoplankton, suggesting that fast-growing phytoplankton in general require more P, and also have a more confined N:P ratio compared with slow-growing phytoplankton. Recently, temperature was also shown to affect the concentration of ribosomes in phytoplankton; at a constant protein synthesis, relatively more ribosomes are needed at low temperature [35]. This is in line with the temperature effect that we observed, and the most plausible reason for the reduced C:P and N:P at low temperature and light.	0	The intracellular concentration of P is known to be influenced by the concentration of Prich ribosomes with their associated rRNA [2]. Increasing rRNA, coupled with increasing growth rates, have been shown to decrease the N:P ratio over a range of different organisms and biotopes #CITATION_TAG. Hillebrand et al. [34] found a similar trend of decreasing N:P ratio and Fig 6 . The photosynthetic quotient (PQ; mol O 2 produced per mol C fixed) at exponential and stationary growth phases (both N and P limited), and at the initial slope (Œ±*) and photosynthetic maximum (Pm*) of the PE curve. The horizontal line is the median, the box represents the 25-75% confidence interval, and the error bars the 10-90% confidence interval (n = 12 for exponential growth; n = 5 for N and P limitation). The data is presented in Table 1.	n
CCT570	The C:Chl a ratio was, as expected, strongly influenced by light acclimation, as the cells acclimate to low light conditions by increasing photosynthetic pigmentation [39]. The data suggests a second order temperature effect, with the effect of light acclimation becomes much greater at the lowest temperature. There is little evidence to suggest temperature effects on C: Chl a ratio [40], but similar results were found in the cold water diatom Skeletonema costatum which had higher variability in the Chl a content per cell at low temperatures #CITATION_TAG. During the stationary growth phase, the C:Chl a ratio was~4 fold higher during N limitation than during P or Si limitation, which can be attributed to the fact that Chl a contains N but not P or Si [2].	1	The C:Chl a ratio was, as expected, strongly influenced by light acclimation, as the cells acclimate to low light conditions by increasing photosynthetic pigmentation [39]. The data suggests a second order temperature effect, with the effect of light acclimation becomes much greater at the lowest temperature. There is little evidence to suggest temperature effects on C: Chl a ratio [40], but similar results were found in the cold water diatom Skeletonema costatum which had higher variability in the Chl a content per cell at low temperatures #CITATION_TAG. During the stationary growth phase, the C:Chl a ratio was~4 fold higher during N limitation than during P or Si limitation, which can be attributed to the fact that Chl a contains N but not P or Si [2].	e
CCT571	The growth rate and photosynthetic properties (Œ± √É , P m √É , E c and E k ) we observed for C. wighamii were similar to published values #CITATION_TAG, but expanded on these by including the interaction effect between light and temperature, and also including different nutrient limitation. Generally, the decreasing Œ± √É and P m √É and increasing E c and E k can be expected when the cells stated to experience nutrient stress and optimizing photosynthetic production becomes less important. An apparent paradox was the difference between N and P limitation, where P limitation seemingly affect Œ± √É and P m √É more than N limitation. Photosynthetic pigments contain N but no P, so intuitively this seems like a contradiction. However, both of these photosynthetic parameters were normalized to Chl a, which is the norm in the literature [11], and normalizing to POC instead yields an opposite result where Œ± and P m under N limitation are approximately half of that under P limitation. This highlight the importance of considering the biomass currency used to compare data. The most surprising finding was the low (<1) PQ values at nutrient and light limitation. For Pycnococcus provasolii it has been shown that the PQ was affected by both light acclimation and incubation light intensity [44]; where decreasing growth light decreased the PQ. The lowest PQ recorded by Iriarte [44] was 0.7, and this low value was suggested to be caused by an underestimation of O 2 production due to photorespiration. Photorespiration is a net loss process where O 2 replaces CO at the rubisco enzyme catalyzing the carbon fixation, resulting in consumption of 3 O 2 for every CO 2 produced [45]. Photorespiration may serve a function, such as a protective mechanism to avoid reactive oxygen species during photosynthesis [46], or in the assimilation of nitrate [47].	1	The growth rate and photosynthetic properties (Œ± √É , P m √É , E c and E k ) we observed for C. wighamii were similar to published values #CITATION_TAG, but expanded on these by including the interaction effect between light and temperature, and also including different nutrient limitation. Generally, the decreasing Œ± √É and P m √É and increasing E c and E k can be expected when the cells stated to experience nutrient stress and optimizing photosynthetic production becomes less important. An apparent paradox was the difference between N and P limitation, where P limitation seemingly affect Œ± √É and P m √É more than N limitation. Photosynthetic pigments contain N but no P, so intuitively this seems like a contradiction.	T
CCT572	The growth rate and photosynthetic properties (Œ± √É , P m √É , E c and E k ) we observed for C. wighamii were similar to published values [43], but expanded on these by including the interaction effect between light and temperature, and also including different nutrient limitation. Generally, the decreasing Œ± √É and P m √É and increasing E c and E k can be expected when the cells stated to experience nutrient stress and optimizing photosynthetic production becomes less important. An apparent paradox was the difference between N and P limitation, where P limitation seemingly affect Œ± √É and P m √É more than N limitation. Photosynthetic pigments contain N but no P, so intuitively this seems like a contradiction. However, both of these photosynthetic parameters were normalized to Chl a, which is the norm in the literature [11], and normalizing to POC instead yields an opposite result where Œ± and P m under N limitation are approximately half of that under P limitation. This highlight the importance of considering the biomass currency used to compare data. The most surprising finding was the low (<1) PQ values at nutrient and light limitation. For Pycnococcus provasolii it has been shown that the PQ was affected by both light acclimation and incubation light intensity [44]; where decreasing growth light decreased the PQ. The lowest PQ recorded by Iriarte [44] was 0.7, and this low value was suggested to be caused by an underestimation of O 2 production due to photorespiration. Photorespiration is a net loss process where O 2 replaces CO at the rubisco enzyme catalyzing the carbon fixation, resulting in consumption of 3 O 2 for every CO 2 produced #CITATION_TAG. Photorespiration may serve a function, such as a protective mechanism to avoid reactive oxygen species during photosynthesis [46], or in the assimilation of nitrate [47].	0	The most surprising finding was the low (<1) PQ values at nutrient and light limitation. For Pycnococcus provasolii it has been shown that the PQ was affected by both light acclimation and incubation light intensity [44]; where decreasing growth light decreased the PQ. The lowest PQ recorded by Iriarte [44] was 0.7, and this low value was suggested to be caused by an underestimation of O 2 production due to photorespiration. Photorespiration is a net loss process where O 2 replaces CO at the rubisco enzyme catalyzing the carbon fixation, resulting in consumption of 3 O 2 for every CO 2 produced #CITATION_TAG. Photorespiration may serve a function, such as a protective mechanism to avoid reactive oxygen species during photosynthesis [46], or in the assimilation of nitrate [47].	i
CCT573	The growth rate and photosynthetic properties (Œ± √É , P m √É , E c and E k ) we observed for C. wighamii were similar to published values [43], but expanded on these by including the interaction effect between light and temperature, and also including different nutrient limitation. Generally, the decreasing Œ± √É and P m √É and increasing E c and E k can be expected when the cells stated to experience nutrient stress and optimizing photosynthetic production becomes less important. An apparent paradox was the difference between N and P limitation, where P limitation seemingly affect Œ± √É and P m √É more than N limitation. Photosynthetic pigments contain N but no P, so intuitively this seems like a contradiction. However, both of these photosynthetic parameters were normalized to Chl a, which is the norm in the literature [11], and normalizing to POC instead yields an opposite result where Œ± and P m under N limitation are approximately half of that under P limitation. This highlight the importance of considering the biomass currency used to compare data. The most surprising finding was the low (<1) PQ values at nutrient and light limitation. For Pycnococcus provasolii it has been shown that the PQ was affected by both light acclimation and incubation light intensity [44]; where decreasing growth light decreased the PQ. The lowest PQ recorded by Iriarte [44] was 0.7, and this low value was suggested to be caused by an underestimation of O 2 production due to photorespiration. Photorespiration is a net loss process where O 2 replaces CO at the rubisco enzyme catalyzing the carbon fixation, resulting in consumption of 3 O 2 for every CO 2 produced [45]. Photorespiration may serve a function, such as a protective mechanism to avoid reactive oxygen species during photosynthesis #CITATION_TAG, or in the assimilation of nitrate [47].	0	For Pycnococcus provasolii it has been shown that the PQ was affected by both light acclimation and incubation light intensity [44]; where decreasing growth light decreased the PQ. The lowest PQ recorded by Iriarte [44] was 0.7, and this low value was suggested to be caused by an underestimation of O 2 production due to photorespiration. Photorespiration is a net loss process where O 2 replaces CO at the rubisco enzyme catalyzing the carbon fixation, resulting in consumption of 3 O 2 for every CO 2 produced [45]. Photorespiration may serve a function, such as a protective mechanism to avoid reactive oxygen species during photosynthesis #CITATION_TAG, or in the assimilation of nitrate [47].	r
CCT574	The interplay between environmental factors such as light, temperature and nutrient availability and the physiology of the cell determines the growth rate and stoichiometric composition of the major elements in algae. Traditionally factors such as the growth-limiting nutrient have been used to model nutrient uptake and growth [27], and recent advances have started to incorporate uptake-protein regulation into this equation [28]#CITATION_TAG. The latter is an important step  as it incorporates the nutrient history of the primary producers, which is decisive in regulating the uptake rate determined by e.g. the number of uptake sites. The present data support the growing understanding of the interaction between fundamental abiotic parameters that should be included in growth models. Geider and La Roche [30] pointed out in their review on algal stoichiometry that relatively few studies examine the phenotypic flexibility in C:N:P during exponential growth and that more studies are needed in order to better understand the effect of temperature and light on these ratios. Under nutrient replete conditions the variability in the C:N:P ratio is normally larger between different species than between different environmental conditions such as variation in temperature [30]. Our data support this to some extent, as there was low variability in the C:N during active growth. However, C:P and N:P was twofold different between the lowest and highest value. The larger variability in C:P and N:P was caused by high P content relative to C and N at low light and temperature acclimation. Strong latitudinal patterns in the C:N:P ratio was recently described, and a lower than average ratio was associated with high latitudes [31]. Martiny et al. [31] suggested this lower C:N:P ratio to be caused by the largely diatom dominated communities present in cold water, but diatoms have also been associated with higher C:N:P ratio [32]. Our results here imply that there is a temperature effect, with lower C: N:P in low temperature and light.	0	The interplay between environmental factors such as light, temperature and nutrient availability and the physiology of the cell determines the growth rate and stoichiometric composition of the major elements in algae. Traditionally factors such as the growth-limiting nutrient have been used to model nutrient uptake and growth [27], and recent advances have started to incorporate uptake-protein regulation into this equation [28]#CITATION_TAG. The latter is an important step  as it incorporates the nutrient history of the primary producers, which is decisive in regulating the uptake rate determined by e.g. the number of uptake sites. The present data support the growing understanding of the interaction between fundamental abiotic parameters that should be included in growth models. Geider and La Roche [30] pointed out in their review on algal stoichiometry that relatively few studies examine the phenotypic flexibility in C:N:P during exponential growth and that more studies are needed in order to better understand the effect of temperature and light on these ratios.	r
CCT575	The interplay between environmental factors such as light, temperature and nutrient availability and the physiology of the cell determines the growth rate and stoichiometric composition of the major elements in algae. Traditionally factors such as the growth-limiting nutrient have been used to model nutrient uptake and growth [27], and recent advances have started to incorporate uptake-protein regulation into this equation #CITATION_TAG[29]. The latter is an important step  as it incorporates the nutrient history of the primary producers, which is decisive in regulating the uptake rate determined by e.g. the number of uptake sites. The present data support the growing understanding of the interaction between fundamental abiotic parameters that should be included in growth models. Geider and La Roche [30] pointed out in their review on algal stoichiometry that relatively few studies examine the phenotypic flexibility in C:N:P during exponential growth and that more studies are needed in order to better understand the effect of temperature and light on these ratios. Under nutrient replete conditions the variability in the C:N:P ratio is normally larger between different species than between different environmental conditions such as variation in temperature [30]. Our data support this to some extent, as there was low variability in the C:N during active growth. However, C:P and N:P was twofold different between the lowest and highest value. The larger variability in C:P and N:P was caused by high P content relative to C and N at low light and temperature acclimation. Strong latitudinal patterns in the C:N:P ratio was recently described, and a lower than average ratio was associated with high latitudes [31]. Martiny et al. [31] suggested this lower C:N:P ratio to be caused by the largely diatom dominated communities present in cold water, but diatoms have also been associated with higher C:N:P ratio [32]. Our results here imply that there is a temperature effect, with lower C: N:P in low temperature and light.	0	The interplay between environmental factors such as light, temperature and nutrient availability and the physiology of the cell determines the growth rate and stoichiometric composition of the major elements in algae. Traditionally factors such as the growth-limiting nutrient have been used to model nutrient uptake and growth [27], and recent advances have started to incorporate uptake-protein regulation into this equation #CITATION_TAG[29]. The latter is an important step  as it incorporates the nutrient history of the primary producers, which is decisive in regulating the uptake rate determined by e.g. the number of uptake sites. The present data support the growing understanding of the interaction between fundamental abiotic parameters that should be included in growth models. Geider and La Roche [30] pointed out in their review on algal stoichiometry that relatively few studies examine the phenotypic flexibility in C:N:P during exponential growth and that more studies are needed in order to better understand the effect of temperature and light on these ratios.	r
CCT576	Carbon incorporation was determined using the 14 C isotope #CITATION_TAG. An activity of 0.73 kBq was added to 50 mL sample, which was subsequently distributed in scintillation vials (3 mL in each). After the incubation period (30 min), 200ŒºL 1M HCl was added, and the scintillation vials were left open for 2 days, after which 4 mL Hi Safe scintillation liquid was added [25]. Radioactivity of the samples was determined directly from the incubation vials using a liquid scintillation counter (PerkinElmer Inc., Wallac Winspectral 1414). The amount of total dissolved inorganic carbon (DIC) was measured with a high-temperature combustion IR carbon analyzer (Unicarbo, Electro Dynamo). Primary production was calculated from the uptake of 14 C knowing the total amount of added isotope and total DIC.	5	Carbon incorporation was determined using the 14 C isotope #CITATION_TAG. An activity of 0.73 kBq was added to 50 mL sample, which was subsequently distributed in scintillation vials (3 mL in each). After the incubation period (30 min), 200ŒºL 1M HCl was added, and the scintillation vials were left open for 2 days, after which 4 mL Hi Safe scintillation liquid was added [25]. Radioactivity of the samples was determined directly from the incubation vials using a liquid scintillation counter (PerkinElmer Inc., Wallac Winspectral 1414).	C
CCT577	The relationship between carbon and chlorophyll a (C:Chl a ratio) is central in modelling global carbon fluxes due to the Chl a retrieval capability from global ocean-color remote sensing. This ratio is highly dynamic, depending on environmental variables such as light and temperature [5], which should be taken into account when modeling ocean biochemical processes [6]. Light is the fundamental driver of carbon fixation in the ocean, and phytoplankton optimize primary production by regulating their photosynthetic pigments, i.e. photoacclimation. Most oceanic biogeochemical models include dynamic C:Chl a ratios with photoacclimation parameterization [1,[7][8], and it is important to understand interaction effects of several environmental parameters for improved parameterization [9]#CITATION_TAG.	0	The relationship between carbon and chlorophyll a (C:Chl a ratio) is central in modelling global carbon fluxes due to the Chl a retrieval capability from global ocean-color remote sensing. This ratio is highly dynamic, depending on environmental variables such as light and temperature [5], which should be taken into account when modeling ocean biochemical processes [6]. Light is the fundamental driver of carbon fixation in the ocean, and phytoplankton optimize primary production by regulating their photosynthetic pigments, i.e. photoacclimation. Most oceanic biogeochemical models include dynamic C:Chl a ratios with photoacclimation parameterization [1,[7][8], and it is important to understand interaction effects of several environmental parameters for improved parameterization [9]#CITATION_TAG.	t
CCT578	The Redfield C:N:P ratio of 106:16:1 is widely used as an average composition of these elements in phytoplankton [2]. However, different cellular components have specific stoichiometric fingerprints and growth rate will affect the ratio between different elements #CITATION_TAG. For example, there tend to be greater allocation of resources to P rich RNA during exponential growth (reducing the N:P ratio), and the N:P ratio has different optima for different growth conditions; the canonical N:P of 16 represents rather an average of a whole community than the optimum for individual species [4]. Nutrient limitation will typically move the stoichiometric ratio even further away from the Redfield ratio as the limiting nutrient is at a minimum and non-limiting nutrients are taken up and stored in excess [2].	2	The Redfield C:N:P ratio of 106:16:1 is widely used as an average composition of these elements in phytoplankton [2]. However, different cellular components have specific stoichiometric fingerprints and growth rate will affect the ratio between different elements #CITATION_TAG. For example, there tend to be greater allocation of resources to P rich RNA during exponential growth (reducing the N:P ratio), and the N:P ratio has different optima for different growth conditions; the canonical N:P of 16 represents rather an average of a whole community than the optimum for individual species [4]. Nutrient limitation will typically move the stoichiometric ratio even further away from the Redfield ratio as the limiting nutrient is at a minimum and non-limiting nutrients are taken up and stored in excess [2].	o
CCT579	The Redfield C:N:P ratio of 106:16:1 is widely used as an average composition of these elements in phytoplankton [2]. However, different cellular components have specific stoichiometric fingerprints and growth rate will affect the ratio between different elements [3]. For example, there tend to be greater allocation of resources to P rich RNA during exponential growth (reducing the N:P ratio), and the N:P ratio has different optima for different growth conditions; the canonical N:P of 16 represents rather an average of a whole community than the optimum for individual species #CITATION_TAG. Nutrient limitation will typically move the stoichiometric ratio even further away from the Redfield ratio as the limiting nutrient is at a minimum and non-limiting nutrients are taken up and stored in excess [2].	0	The Redfield C:N:P ratio of 106:16:1 is widely used as an average composition of these elements in phytoplankton [2]. However, different cellular components have specific stoichiometric fingerprints and growth rate will affect the ratio between different elements [3]. For example, there tend to be greater allocation of resources to P rich RNA during exponential growth (reducing the N:P ratio), and the N:P ratio has different optima for different growth conditions; the canonical N:P of 16 represents rather an average of a whole community than the optimum for individual species #CITATION_TAG. Nutrient limitation will typically move the stoichiometric ratio even further away from the Redfield ratio as the limiting nutrient is at a minimum and non-limiting nutrients are taken up and stored in excess [2].	r
CCT580	The relationship between carbon and chlorophyll a (C:Chl a ratio) is central in modelling global carbon fluxes due to the Chl a retrieval capability from global ocean-color remote sensing. This ratio is highly dynamic, depending on environmental variables such as light and temperature #CITATION_TAG, which should be taken into account when modeling ocean biochemical processes [6]. Light is the fundamental driver of carbon fixation in the ocean, and phytoplankton optimize primary production by regulating their photosynthetic pigments, i.e. photoacclimation. Most oceanic biogeochemical models include dynamic C:Chl a ratios with photoacclimation parameterization [1,[7][8], and it is important to understand interaction effects of several environmental parameters for improved parameterization [9][10].	0	The relationship between carbon and chlorophyll a (C:Chl a ratio) is central in modelling global carbon fluxes due to the Chl a retrieval capability from global ocean-color remote sensing. This ratio is highly dynamic, depending on environmental variables such as light and temperature #CITATION_TAG, which should be taken into account when modeling ocean biochemical processes [6]. Light is the fundamental driver of carbon fixation in the ocean, and phytoplankton optimize primary production by regulating their photosynthetic pigments, i.e. photoacclimation. Most oceanic biogeochemical models include dynamic C:Chl a ratios with photoacclimation parameterization [1,[7][8], and it is important to understand interaction effects of several environmental parameters for improved parameterization [9][10].	h
CCT581	The relationship between carbon and chlorophyll a (C:Chl a ratio) is central in modelling global carbon fluxes due to the Chl a retrieval capability from global ocean-color remote sensing. This ratio is highly dynamic, depending on environmental variables such as light and temperature [5], which should be taken into account when modeling ocean biochemical processes #CITATION_TAG. Light is the fundamental driver of carbon fixation in the ocean, and phytoplankton optimize primary production by regulating their photosynthetic pigments, i.e. photoacclimation. Most oceanic biogeochemical models include dynamic C:Chl a ratios with photoacclimation parameterization [1,[7][8], and it is important to understand interaction effects of several environmental parameters for improved parameterization [9][10].	0	The relationship between carbon and chlorophyll a (C:Chl a ratio) is central in modelling global carbon fluxes due to the Chl a retrieval capability from global ocean-color remote sensing. This ratio is highly dynamic, depending on environmental variables such as light and temperature [5], which should be taken into account when modeling ocean biochemical processes #CITATION_TAG. Light is the fundamental driver of carbon fixation in the ocean, and phytoplankton optimize primary production by regulating their photosynthetic pigments, i.e. photoacclimation. Most oceanic biogeochemical models include dynamic C:Chl a ratios with photoacclimation parameterization [1,[7][8], and it is important to understand interaction effects of several environmental parameters for improved parameterization [9][10].	h
CCT582	The relationship between carbon and chlorophyll a (C:Chl a ratio) is central in modelling global carbon fluxes due to the Chl a retrieval capability from global ocean-color remote sensing. This ratio is highly dynamic, depending on environmental variables such as light and temperature [5], which should be taken into account when modeling ocean biochemical processes [6]. Light is the fundamental driver of carbon fixation in the ocean, and phytoplankton optimize primary production by regulating their photosynthetic pigments, i.e. photoacclimation. Most oceanic biogeochemical models include dynamic C:Chl a ratios with photoacclimation parameterization [1,#CITATION_TAG][8], and it is important to understand interaction effects of several environmental parameters for improved parameterization [9][10].	0	The relationship between carbon and chlorophyll a (C:Chl a ratio) is central in modelling global carbon fluxes due to the Chl a retrieval capability from global ocean-color remote sensing. This ratio is highly dynamic, depending on environmental variables such as light and temperature [5], which should be taken into account when modeling ocean biochemical processes [6]. Light is the fundamental driver of carbon fixation in the ocean, and phytoplankton optimize primary production by regulating their photosynthetic pigments, i.e. photoacclimation. Most oceanic biogeochemical models include dynamic C:Chl a ratios with photoacclimation parameterization [1,#CITATION_TAG][8], and it is important to understand interaction effects of several environmental parameters for improved parameterization [9][10].	t
CCT583	The relationship between carbon and chlorophyll a (C:Chl a ratio) is central in modelling global carbon fluxes due to the Chl a retrieval capability from global ocean-color remote sensing. This ratio is highly dynamic, depending on environmental variables such as light and temperature [5], which should be taken into account when modeling ocean biochemical processes [6]. Light is the fundamental driver of carbon fixation in the ocean, and phytoplankton optimize primary production by regulating their photosynthetic pigments, i.e. photoacclimation. Most oceanic biogeochemical models include dynamic C:Chl a ratios with photoacclimation parameterization [1,[7]#CITATION_TAG, and it is important to understand interaction effects of several environmental parameters for improved parameterization [9][10].	0	The relationship between carbon and chlorophyll a (C:Chl a ratio) is central in modelling global carbon fluxes due to the Chl a retrieval capability from global ocean-color remote sensing. This ratio is highly dynamic, depending on environmental variables such as light and temperature [5], which should be taken into account when modeling ocean biochemical processes [6]. Light is the fundamental driver of carbon fixation in the ocean, and phytoplankton optimize primary production by regulating their photosynthetic pigments, i.e. photoacclimation. Most oceanic biogeochemical models include dynamic C:Chl a ratios with photoacclimation parameterization [1,[7]#CITATION_TAG, and it is important to understand interaction effects of several environmental parameters for improved parameterization [9][10].	t
CCT584	The relationship between carbon and chlorophyll a (C:Chl a ratio) is central in modelling global carbon fluxes due to the Chl a retrieval capability from global ocean-color remote sensing. This ratio is highly dynamic, depending on environmental variables such as light and temperature [5], which should be taken into account when modeling ocean biochemical processes [6]. Light is the fundamental driver of carbon fixation in the ocean, and phytoplankton optimize primary production by regulating their photosynthetic pigments, i.e. photoacclimation. Most oceanic biogeochemical models include dynamic C:Chl a ratios with photoacclimation parameterization [1,[7][8], and it is important to understand interaction effects of several environmental parameters for improved parameterization #CITATION_TAG[10].	0	The relationship between carbon and chlorophyll a (C:Chl a ratio) is central in modelling global carbon fluxes due to the Chl a retrieval capability from global ocean-color remote sensing. This ratio is highly dynamic, depending on environmental variables such as light and temperature [5], which should be taken into account when modeling ocean biochemical processes [6]. Light is the fundamental driver of carbon fixation in the ocean, and phytoplankton optimize primary production by regulating their photosynthetic pigments, i.e. photoacclimation. Most oceanic biogeochemical models include dynamic C:Chl a ratios with photoacclimation parameterization [1,[7][8], and it is important to understand interaction effects of several environmental parameters for improved parameterization #CITATION_TAG[10].	t
CCT585	Carbon incorporation was determined using the 14 C isotope [24]. An activity of 0.73 kBq was added to 50 mL sample, which was subsequently distributed in scintillation vials (3 mL in each). After the incubation period (30 min), 200ŒºL 1M HCl was added, and the scintillation vials were left open for 2 days, after which 4 mL Hi Safe scintillation liquid was added #CITATION_TAG. Radioactivity of the samples was determined directly from the incubation vials using a liquid scintillation counter (PerkinElmer Inc., Wallac Winspectral 1414). The amount of total dissolved inorganic carbon (DIC) was measured with a high-temperature combustion IR carbon analyzer (Unicarbo, Electro Dynamo). Primary production was calculated from the uptake of 14 C knowing the total amount of added isotope and total DIC.	5	Carbon incorporation was determined using the 14 C isotope [24]. An activity of 0.73 kBq was added to 50 mL sample, which was subsequently distributed in scintillation vials (3 mL in each). After the incubation period (30 min), 200ŒºL 1M HCl was added, and the scintillation vials were left open for 2 days, after which 4 mL Hi Safe scintillation liquid was added #CITATION_TAG. Radioactivity of the samples was determined directly from the incubation vials using a liquid scintillation counter (PerkinElmer Inc., Wallac Winspectral 1414). The amount of total dissolved inorganic carbon (DIC) was measured with a high-temperature combustion IR carbon analyzer (Unicarbo, Electro Dynamo). Primary production was calculated from the uptake of 14 C knowing the total amount of added isotope and total DIC.	t
CCT586	The photosynethic quotient (PQ) is given as the molar ratio of oxygen (in the form of O ) produced per C fixed by photosynthesis. The PQ is normally >1, indicating that a fraction of the reducing power created in the light reaction is used for other purposes than C fixation in the Calvin-Benson cycle, e.g. lipid or protein synthesis [12]. Furthermore, when the N source is nitrate that needs to be reduced, the PQ will be higher compared to a situation where ammonium is the N source #CITATION_TAG. Another process that will affect the PQ is photorespiration, which is a process consuming the O 2 produced during photosynthesis and thereby lowering the PQ [14].	5	The photosynethic quotient (PQ) is given as the molar ratio of oxygen (in the form of O ) produced per C fixed by photosynthesis. The PQ is normally >1, indicating that a fraction of the reducing power created in the light reaction is used for other purposes than C fixation in the Calvin-Benson cycle, e.g. lipid or protein synthesis [12]. Furthermore, when the N source is nitrate that needs to be reduced, the PQ will be higher compared to a situation where ammonium is the N source #CITATION_TAG. Another process that will affect the PQ is photorespiration, which is a process consuming the O 2 produced during photosynthesis and thereby lowering the PQ [14].	r
CCT587	We may expect climate change to disproportionally affect regions with strong seasonality in light availability and surface water temperature. Thus, it is important to improve biogeochemical models particularly in regions where seasonal primary production is coupled to low temperatures, such as seas and oceans at high latitudes. Most of the focus on interaction effects between different environmental variables stems from work on lakes [15][16]. Coastal areas in arctic or subarctic regions will be subjected to many of the same changes, but relatively few studies have addressed interaction effects in these areas, in particular for cold water adapted phytoplankton species [16]#CITATION_TAG.	0	We may expect climate change to disproportionally affect regions with strong seasonality in light availability and surface water temperature. Thus, it is important to improve biogeochemical models particularly in regions where seasonal primary production is coupled to low temperatures, such as seas and oceans at high latitudes. Most of the focus on interaction effects between different environmental variables stems from work on lakes [15][16]. Coastal areas in arctic or subarctic regions will be subjected to many of the same changes, but relatively few studies have addressed interaction effects in these areas, in particular for cold water adapted phytoplankton species [16]#CITATION_TAG.	s
CCT588	Chaetoceros wighamii was adopted from the culture collection of the Tv√§rminne Zoological Station (strain TVCWI) and cultured in T2 medium at 6 PSU, which is a modified f/2 medium #CITATION_TAG with N:Si:P nutrient ratios adjusted to 16:8:1, previously suggested to be close to optimal for this diatom [18]. The batch culture was grown in 2L polycarbonate flasks (filled to 1.5 L) and acclimated to different temperature (3, 7, 11 and 15¬∞C) and irradiance (20,40,130 and 450 Œºmol photons m -2 s -1 ) from daylight, fluorescent tubes (Philips TLD 965). Light was provided using a 16:8 hour light-dark cycle. The flasks were held in a temperature-regulated water bath and irradiance was adjusted with neutral density screens. The cultures were kept in suspension by bubbling with pre-filtered (0.2 Œºm) air. Growth was monitored daily by counting cells with a FlowCam (FluidImaging), which collects micrographs of individual cells passing through a flow cuvette. The growth rate was calculated from a linear fit to natural logarithm (ln) transformed cell numbers, and all the fits are presented in the supporting information (S1 Fig) . The first set of measurements of particulate organic carbon (POC), nitrogen (PON) and phosphorus (POP), chlorophyll a (Chl a) and photosynthesis-irradiance (PE) curves were obtained during exponential growth. The biomass during the exponential growth sampling was approximately 1000 Œºmol POC L -1 and 500 Œºg Chl a L -1 , which was approximately 10% of the maximum (in terms of POC) during the stationary growth phase.	5	Chaetoceros wighamii was adopted from the culture collection of the Tv√§rminne Zoological Station (strain TVCWI) and cultured in T2 medium at 6 PSU, which is a modified f/2 medium #CITATION_TAG with N:Si:P nutrient ratios adjusted to 16:8:1, previously suggested to be close to optimal for this diatom [18]. The batch culture was grown in 2L polycarbonate flasks (filled to 1.5 L) and acclimated to different temperature (3, 7, 11 and 15¬∞C) and irradiance (20,40,130 and 450 Œºmol photons m -2 s -1 ) from daylight, fluorescent tubes (Philips TLD 965). Light was provided using a 16:8 hour light-dark cycle. The flasks were held in a temperature-regulated water bath and irradiance was adjusted with neutral density screens.	C
CCT589	The growth rate and photosynthetic properties (Œ± √É , P m √É , E c and E k ) we observed for C. wighamii were similar to published values [43], but expanded on these by including the interaction effect between light and temperature, and also including different nutrient limitation. Generally, the decreasing Œ± √É and P m √É and increasing E c and E k can be expected when the cells stated to experience nutrient stress and optimizing photosynthetic production becomes less important. An apparent paradox was the difference between N and P limitation, where P limitation seemingly affect Œ± √É and P m √É more than N limitation. Photosynthetic pigments contain N but no P, so intuitively this seems like a contradiction. However, both of these photosynthetic parameters were normalized to Chl a, which is the norm in the literature [11], and normalizing to POC instead yields an opposite result where Œ± and P m under N limitation are approximately half of that under P limitation. This highlight the importance of considering the biomass currency used to compare data. The most surprising finding was the low (<1) PQ values at nutrient and light limitation. For Pycnococcus provasolii it has been shown that the PQ was affected by both light acclimation and incubation light intensity [44]; where decreasing growth light decreased the PQ. The lowest PQ recorded by Iriarte [44] was 0.7, and this low value was suggested to be caused by an underestimation of O 2 production due to photorespiration. Photorespiration is a net loss process where O 2 replaces CO at the rubisco enzyme catalyzing the carbon fixation, resulting in consumption of 3 O 2 for every CO 2 produced [45]. Photorespiration may serve a function, such as a protective mechanism to avoid reactive oxygen species during photosynthesis [46], or in the assimilation of nitrate #CITATION_TAG.	0	For Pycnococcus provasolii it has been shown that the PQ was affected by both light acclimation and incubation light intensity [44]; where decreasing growth light decreased the PQ. The lowest PQ recorded by Iriarte [44] was 0.7, and this low value was suggested to be caused by an underestimation of O 2 production due to photorespiration. Photorespiration is a net loss process where O 2 replaces CO at the rubisco enzyme catalyzing the carbon fixation, resulting in consumption of 3 O 2 for every CO 2 produced [45]. Photorespiration may serve a function, such as a protective mechanism to avoid reactive oxygen species during photosynthesis [46], or in the assimilation of nitrate #CITATION_TAG.	r
CCT590	"The finding of these studies (and many others) suggests to us that psychological well-being, including self-esteem, is influenced by numerous factors in a person s life and is in a particular state of flux during adolescence, when orthodontic treatment is commonly experienced. Shame and embarrassment about the appearance of the teeth is only a small part of these complex inter-relationships for most people. We believe, therefore, it is unrealistic to expect that major long term changes in psychological well-being could be demonstrated . [33] This has not been a surprising finding to others either. 34 Pitner cites the work of Diener and colleagues, who have studied the ability of people to adapt over time to new situations and extreme life events. 35,36 here is evidence that intensive and sometimes prolonged psychological interventions can improve psychological well-being 37 ; however we would be interested to know if this has been claimed for any dental or healthcare interventions, other than orthodontics. We undertook a brief search through the literature and were unable to find anything. This is not to imply that psychological well-being "" psychological make-up is an important mediating factor in determining how people respond to their circumstances and to new challenges. Orth and colleagues 38 found that better life outcomes were usually a consequence of, rather than a cause of high self-esteem. It has also been found that psychological factors might explain more about the impact of dental disorders upon individuals than their clinical symptoms [39][40][41]#CITATION_TAG[43] . In other words, with low self-esteem much more than a person with high self-esteem. This will help to explain why some people appear upset about relatively minor abnormalities, whilst others, with much more severe conditions, are not bothered. Further research needs to be undertaken in this area."	0	"We undertook a brief search through the literature and were unable to find anything. This is not to imply that psychological well-being "" psychological make-up is an important mediating factor in determining how people respond to their circumstances and to new challenges. Orth and colleagues 38 found that better life outcomes were usually a consequence of, rather than a cause of high self-esteem. It has also been found that psychological factors might explain more about the impact of dental disorders upon individuals than their clinical symptoms [39][40][41]#CITATION_TAG[43] . In other words, with low self-esteem much more than a person with high self-esteem. This will help to explain why some people appear upset about relatively minor abnormalities, whilst others, with much more severe conditions, are not bothered. Further research needs to be undertaken in this area."	l
CCT591	Fewer studies have reported evidence that correction of a malocclusion with orthodontic treatment leads to an improvement in OHQoL. Some studies, using a cross-sectional design, have found that individuals who have undergone orthodontic treatment had a better OHQoL than individuals who have not undergone orthodontic treatment. #CITATION_TAG,90,91 O her studies have found no difference in the OHQoL between treated and untreated groups. 92 her studies have found no difference in the OHQoL between treated and untreated groups. 92 ][95][96] Furthermore, a case controlled study also reported fewer physical, psychological and social impacts on daily performance associated with a malocclusion, in patients that had received Orthodontic treatment, compared to those who had not. 97 ][100] Marshman and colleagues 101 have expressed concern that generic measures of OHQoL might not fully capture the impact that malocclusion has suggested the development of a malocclusion specific measure of OHQoL for young people with malocclusion. The use and interpretation of data from generic and/or condition-specific measures of OHQoL continues to be the subject of much debate and research. 100	0	Fewer studies have reported evidence that correction of a malocclusion with orthodontic treatment leads to an improvement in OHQoL. Some studies, using a cross-sectional design, have found that individuals who have undergone orthodontic treatment had a better OHQoL than individuals who have not undergone orthodontic treatment. #CITATION_TAG,90,91 O her studies have found no difference in the OHQoL between treated and untreated groups. 92 her studies have found no difference in the OHQoL between treated and untreated groups. 92 ][95][96] Furthermore, a case controlled study also reported fewer physical, psychological and social impacts on daily performance associated with a malocclusion, in patients that had received Orthodontic treatment, compared to those who had not. 97 ][100] Marshman and colleagues 101 have expressed concern that generic measures of OHQoL might not fully capture the impact that malocclusion has suggested the development of a malocclusion specific measure of OHQoL for young people with malocclusion.	I
CCT592	Social well-being might be considered distinct from psychological well-being. Whereas psychological well-being reflects how content we are with ourselves, social well-being reveals how we interact with other people and with our community. 5][46] This perceived feeling of being unattractive and different to other people is made worse by the expression of supposed societal norms, through peer group pressure and images in the media. The awkwardness that young people feel about the appearance of their teeth leads to various coping strategies in social situations, including not showing their teeth when they smile, avoiding having their photograph taken and embarrassment when their photographs are shared through social media. It can also lead to approaches designed to hide their teeth, including placing their hand across their mouth when they smile. 46 e view of young people that others perceive them differently due to the appearance of their teeth has, to a certain extent, been confirmed by the work of Shaw. Using a technique of altering the arrangements of the teeth on standardised photographs of young people smiling, Shaw and colleagues showed that the appearance of teeth could influence the social judgements made by their peers about the person in the photograph #CITATION_TAG,48 ; however dental appearance did not affect the judgements made by teachers. The influence of dental appearance could, however, be surpassed by the overall attractiveness of the face. 47,48,50 T 2][53][54][55][56][57] Victims are particularly concerned when they are teased about the appearance of their teeth 51 and orthodontic treatment can help to alleviate this. 58 search is now focussed on ways of measuring the physical, functional, emotional and social impacts of conditions s daily life through the various concepts of quality of life, health and oral health-related quality of life.	0	The awkwardness that young people feel about the appearance of their teeth leads to various coping strategies in social situations, including not showing their teeth when they smile, avoiding having their photograph taken and embarrassment when their photographs are shared through social media. It can also lead to approaches designed to hide their teeth, including placing their hand across their mouth when they smile. 46 e view of young people that others perceive them differently due to the appearance of their teeth has, to a certain extent, been confirmed by the work of Shaw. Using a technique of altering the arrangements of the teeth on standardised photographs of young people smiling, Shaw and colleagues showed that the appearance of teeth could influence the social judgements made by their peers about the person in the photograph #CITATION_TAG,48 ; however dental appearance did not affect the judgements made by teachers. The influence of dental appearance could, however, be surpassed by the overall attractiveness of the face. 47,48,50 T 2][53][54][55][56][57] Victims are particularly concerned when they are teased about the appearance of their teeth 51 and orthodontic treatment can help to alleviate this. 58 search is now focussed on ways of measuring the physical, functional, emotional and social impacts of conditions s daily life through the various concepts of quality of life, health and oral health-related quality of life.	a
CCT593	Fewer studies have reported evidence that correction of a malocclusion with orthodontic treatment leads to an improvement in OHQoL. Some studies, using a cross-sectional design, have found that individuals who have undergone orthodontic treatment had a better OHQoL than individuals who have not undergone orthodontic treatment. 65,90,91 O her studies have found no difference in the OHQoL between treated and untreated groups. 92 ][95][96] Furthermore, a case controlled study also reported fewer physical, psychological and social impacts on daily performance associated with a malocclusion, in patients that had received Orthodontic treatment, compared to those who had not. 97 ][100] Marshman and colleagues #CITATION_TAG have expressed concern that generic measures of OHQoL might not fully capture the impact that malocclusion has suggested the development of a malocclusion specific measure of OHQoL for young people with malocclusion. The use and interpretation of data from generic and/or condition-specific measures of OHQoL continues to be the subject of much debate and research. 100	4	Some studies, using a cross-sectional design, have found that individuals who have undergone orthodontic treatment had a better OHQoL than individuals who have not undergone orthodontic treatment. 65,90,91 O her studies have found no difference in the OHQoL between treated and untreated groups. 92 ][95][96] Furthermore, a case controlled study also reported fewer physical, psychological and social impacts on daily performance associated with a malocclusion, in patients that had received Orthodontic treatment, compared to those who had not. 97 ][100] Marshman and colleagues #CITATION_TAG have expressed concern that generic measures of OHQoL might not fully capture the impact that malocclusion has suggested the development of a malocclusion specific measure of OHQoL for young people with malocclusion. The use and interpretation of data from generic and/or condition-specific measures of OHQoL continues to be the subject of much debate and research. 100	[
CCT594	"The finding of these studies (and many others) suggests to us that psychological well-being, including self-esteem, is influenced by numerous factors in a person s life and is in a particular state of flux during adolescence, when orthodontic treatment is commonly experienced. Shame and embarrassment about the appearance of the teeth is only a small part of these complex inter-relationships for most people. We believe, therefore, it is unrealistic to expect that major long term changes in psychological well-being could be demonstrated . [33] This has not been a surprising finding to others either. 34 Pitner cites the work of Diener and colleagues, who have studied the ability of people to adapt over time to new situations and extreme life events. 35,36 here is evidence that intensive and sometimes prolonged psychological interventions can improve psychological well-being 37 ; however we would be interested to know if this has been claimed for any dental or healthcare interventions, other than orthodontics. We undertook a brief search through the literature and were unable to find anything. This is not to imply that psychological well-being "" psychological make-up is an important mediating factor in determining how people respond to their circumstances and to new challenges. Orth and colleagues 38 found that better life outcomes were usually a consequence of, rather than a cause of high self-esteem. It has also been found that psychological factors might explain more about the impact of dental disorders upon individuals than their clinical symptoms #CITATION_TAG[40][41][42][43] . In other words, with low self-esteem much more than a person with high self-esteem. This will help to explain why some people appear upset about relatively minor abnormalities, whilst others, with much more severe conditions, are not bothered. Further research needs to be undertaken in this area."	0	"We undertook a brief search through the literature and were unable to find anything. This is not to imply that psychological well-being "" psychological make-up is an important mediating factor in determining how people respond to their circumstances and to new challenges. Orth and colleagues 38 found that better life outcomes were usually a consequence of, rather than a cause of high self-esteem. It has also been found that psychological factors might explain more about the impact of dental disorders upon individuals than their clinical symptoms #CITATION_TAG[40][41][42][43] . In other words, with low self-esteem much more than a person with high self-esteem. This will help to explain why some people appear upset about relatively minor abnormalities, whilst others, with much more severe conditions, are not bothered. Further research needs to be undertaken in this area."	l
CCT595	"The finding of these studies (and many others) suggests to us that psychological well-being, including self-esteem, is influenced by numerous factors in a person s life and is in a particular state of flux during adolescence, when orthodontic treatment is commonly experienced. Shame and embarrassment about the appearance of the teeth is only a small part of these complex inter-relationships for most people. We believe, therefore, it is unrealistic to expect that major long term changes in psychological well-being could be demonstrated . [33] This has not been a surprising finding to others either. 34 Pitner cites the work of Diener and colleagues, who have studied the ability of people to adapt over time to new situations and extreme life events. 35,36 here is evidence that intensive and sometimes prolonged psychological interventions can improve psychological well-being 37 ; however we would be interested to know if this has been claimed for any dental or healthcare interventions, other than orthodontics. We undertook a brief search through the literature and were unable to find anything. This is not to imply that psychological well-being "" psychological make-up is an important mediating factor in determining how people respond to their circumstances and to new challenges. Orth and colleagues 38 found that better life outcomes were usually a consequence of, rather than a cause of high self-esteem. It has also been found that psychological factors might explain more about the impact of dental disorders upon individuals than their clinical symptoms [39]#CITATION_TAG[41][42][43] . In other words, with low self-esteem much more than a person with high self-esteem. This will help to explain why some people appear upset about relatively minor abnormalities, whilst others, with much more severe conditions, are not bothered. Further research needs to be undertaken in this area."	0	"We undertook a brief search through the literature and were unable to find anything. This is not to imply that psychological well-being "" psychological make-up is an important mediating factor in determining how people respond to their circumstances and to new challenges. Orth and colleagues 38 found that better life outcomes were usually a consequence of, rather than a cause of high self-esteem. It has also been found that psychological factors might explain more about the impact of dental disorders upon individuals than their clinical symptoms [39]#CITATION_TAG[41][42][43] . In other words, with low self-esteem much more than a person with high self-esteem. This will help to explain why some people appear upset about relatively minor abnormalities, whilst others, with much more severe conditions, are not bothered. Further research needs to be undertaken in this area."	l
CCT596	"The finding of these studies (and many others) suggests to us that psychological well-being, including self-esteem, is influenced by numerous factors in a person s life and is in a particular state of flux during adolescence, when orthodontic treatment is commonly experienced. Shame and embarrassment about the appearance of the teeth is only a small part of these complex inter-relationships for most people. We believe, therefore, it is unrealistic to expect that major long term changes in psychological well-being could be demonstrated . [33] This has not been a surprising finding to others either. 34 Pitner cites the work of Diener and colleagues, who have studied the ability of people to adapt over time to new situations and extreme life events. 35,36 here is evidence that intensive and sometimes prolonged psychological interventions can improve psychological well-being 37 ; however we would be interested to know if this has been claimed for any dental or healthcare interventions, other than orthodontics. We undertook a brief search through the literature and were unable to find anything. This is not to imply that psychological well-being "" psychological make-up is an important mediating factor in determining how people respond to their circumstances and to new challenges. Orth and colleagues 38 found that better life outcomes were usually a consequence of, rather than a cause of high self-esteem. It has also been found that psychological factors might explain more about the impact of dental disorders upon individuals than their clinical symptoms [39][40]#CITATION_TAG[42][43] . In other words, with low self-esteem much more than a person with high self-esteem. This will help to explain why some people appear upset about relatively minor abnormalities, whilst others, with much more severe conditions, are not bothered. Further research needs to be undertaken in this area."	0	"We undertook a brief search through the literature and were unable to find anything. This is not to imply that psychological well-being "" psychological make-up is an important mediating factor in determining how people respond to their circumstances and to new challenges. Orth and colleagues 38 found that better life outcomes were usually a consequence of, rather than a cause of high self-esteem. It has also been found that psychological factors might explain more about the impact of dental disorders upon individuals than their clinical symptoms [39][40]#CITATION_TAG[42][43] . In other words, with low self-esteem much more than a person with high self-esteem. This will help to explain why some people appear upset about relatively minor abnormalities, whilst others, with much more severe conditions, are not bothered. Further research needs to be undertaken in this area."	l
CCT597	This has been found in non-clinical populations (mainly schoolchildren) [65]#CITATION_TAG[67][68][69][70][71][72][73][74] as well as young people referred for orthodontic treatment	0	This has been found in non-clinical populations (mainly schoolchildren) [65]#CITATION_TAG[67][68][69][70][71][72][73][74] as well as young people referred for orthodontic treatment	T
CCT598	This has been found in non-clinical populations (mainly schoolchildren) [65][66]#CITATION_TAG[68][69][70][71][72][73][74] as well as young people referred for orthodontic treatment	0	This has been found in non-clinical populations (mainly schoolchildren) [65][66]#CITATION_TAG[68][69][70][71][72][73][74] as well as young people referred for orthodontic treatment	T
CCT599	This has been found in non-clinical populations (mainly schoolchildren) [65][66][67]#CITATION_TAG[69][70][71][72][73][74] as well as young people referred for orthodontic treatment	0	This has been found in non-clinical populations (mainly schoolchildren) [65][66][67]#CITATION_TAG[69][70][71][72][73][74] as well as young people referred for orthodontic treatment	T
CCT600	This has been found in non-clinical populations (mainly schoolchildren) [65][66][67][68]#CITATION_TAG[70][71][72][73][74] as well as young people referred for orthodontic treatment	0	This has been found in non-clinical populations (mainly schoolchildren) [65][66][67][68]#CITATION_TAG[70][71][72][73][74] as well as young people referred for orthodontic treatment	T
CCT601	This has been found in non-clinical populations (mainly schoolchildren) [65][66][67][68][69]#CITATION_TAG[71][72][73][74] as well as young people referred for orthodontic treatment	0	This has been found in non-clinical populations (mainly schoolchildren) [65][66][67][68][69]#CITATION_TAG[71][72][73][74] as well as young people referred for orthodontic treatment	T
CCT602	This has been found in non-clinical populations (mainly schoolchildren) [65][66][67][68][69][70]#CITATION_TAG[72][73][74] as well as young people referred for orthodontic treatment	0	This has been found in non-clinical populations (mainly schoolchildren) [65][66][67][68][69][70]#CITATION_TAG[72][73][74] as well as young people referred for orthodontic treatment	T
CCT603	This has been found in non-clinical populations (mainly schoolchildren) [65][66][67][68][69][70][71]#CITATION_TAG[73][74] as well as young people referred for orthodontic treatment	0	This has been found in non-clinical populations (mainly schoolchildren) [65][66][67][68][69][70][71]#CITATION_TAG[73][74] as well as young people referred for orthodontic treatment	T
CCT604	This has been found in non-clinical populations (mainly schoolchildren) [65][66][67][68][69][70][71][72]#CITATION_TAG[74] as well as young people referred for orthodontic treatment	0	This has been found in non-clinical populations (mainly schoolchildren) [65][66][67][68][69][70][71][72]#CITATION_TAG[74] as well as young people referred for orthodontic treatment	T
CCT605	"The finding of these studies (and many others) suggests to us that psychological well-being, including self-esteem, is influenced by numerous factors in a person s life and is in a particular state of flux during adolescence, when orthodontic treatment is commonly experienced. Shame and embarrassment about the appearance of the teeth is only a small part of these complex inter-relationships for most people. We believe, therefore, it is unrealistic to expect that major long term changes in psychological well-being could be demonstrated . [33] This has not been a surprising finding to others either. 34 Pitner cites the work of Diener and colleagues, who have studied the ability of people to adapt over time to new situations and extreme life events. 35,36 here is evidence that intensive and sometimes prolonged psychological interventions can improve psychological well-being 37 ; however we would be interested to know if this has been claimed for any dental or healthcare interventions, other than orthodontics. We undertook a brief search through the literature and were unable to find anything. This is not to imply that psychological well-being "" psychological make-up is an important mediating factor in determining how people respond to their circumstances and to new challenges. Orth and colleagues #CITATION_TAG found that better life outcomes were usually a consequence of, rather than a cause of high self-esteem. It has also been found that psychological factors might explain more about the impact of dental disorders upon individuals than their clinical symptoms [39][40][41][42][43] . In other words, with low self-esteem much more than a person with high self-esteem. This will help to explain why some people appear upset about relatively minor abnormalities, whilst others, with much more severe conditions, are not bothered. Further research needs to be undertaken in this area."	0	"35,36 here is evidence that intensive and sometimes prolonged psychological interventions can improve psychological well-being 37 ; however we would be interested to know if this has been claimed for any dental or healthcare interventions, other than orthodontics. We undertook a brief search through the literature and were unable to find anything. This is not to imply that psychological well-being "" psychological make-up is an important mediating factor in determining how people respond to their circumstances and to new challenges. Orth and colleagues #CITATION_TAG found that better life outcomes were usually a consequence of, rather than a cause of high self-esteem. It has also been found that psychological factors might explain more about the impact of dental disorders upon individuals than their clinical symptoms [39][40][41][42][43] . In other words, with low self-esteem much more than a person with high self-esteem. This will help to explain why some people appear upset about relatively minor abnormalities, whilst others, with much more severe conditions, are not bothered. Further research needs to be undertaken in this area."	d
CCT606	"The finding of these studies (and many others) suggests to us that psychological well-being, including self-esteem, is influenced by numerous factors in a person s life and is in a particular state of flux during adolescence, when orthodontic treatment is commonly experienced. Shame and embarrassment about the appearance of the teeth is only a small part of these complex inter-relationships for most people. We believe, therefore, it is unrealistic to expect that major long term changes in psychological well-being could be demonstrated . [33] This has not been a surprising finding to others either. 34 [33] This has not been a surprising finding to others either. #CITATION_TAG Pitner cites the work of Diener and colleagues, who have studied the ability of people to adapt over time to new situations and extreme life events. 35,36 here is evidence that intensive and sometimes prolonged psychological interventions can improve psychological well-being 37 ; however we would be interested to know if this has been claimed for any dental or healthcare interventions, other than orthodontics. We undertook a brief search through the literature and were unable to find anything. This is not to imply that psychological well-being "" psychological make-up is an important mediating factor in determining how people respond to their circumstances and to new challenges. Orth and colleagues 38 found that better life outcomes were usually a consequence of, rather than a cause of high self-esteem. It has also been found that psychological factors might explain more about the impact of dental disorders upon individuals than their clinical symptoms [39][40][41][42][43] . In other words, with low self-esteem much more than a person with high self-esteem. This will help to explain why some people appear upset about relatively minor abnormalities, whilst others, with much more severe conditions, are not bothered. Further research needs to be undertaken in this area."	0	"Shame and embarrassment about the appearance of the teeth is only a small part of these complex inter-relationships for most people. We believe, therefore, it is unrealistic to expect that major long term changes in psychological well-being could be demonstrated . [33] This has not been a surprising finding to others either. 34 [33] This has not been a surprising finding to others either. #CITATION_TAG Pitner cites the work of Diener and colleagues, who have studied the ability of people to adapt over time to new situations and extreme life events. 35,36 here is evidence that intensive and sometimes prolonged psychological interventions can improve psychological well-being 37 ; however we would be interested to know if this has been claimed for any dental or healthcare interventions, other than orthodontics. We undertook a brief search through the literature and were unable to find anything. This is not to imply that psychological well-being "" psychological make-up is an important mediating factor in determining how people respond to their circumstances and to new challenges."	A
CCT607	Fewer studies have reported evidence that correction of a malocclusion with orthodontic treatment leads to an improvement in OHQoL. Some studies, using a cross-sectional design, have found that individuals who have undergone orthodontic treatment had a better OHQoL than individuals who have not undergone orthodontic treatment. 65,90,91 O her studies have found no difference in the OHQoL between treated and untreated groups. 92 ][95][96] Furthermore, a case controlled study also reported fewer physical, psychological and social impacts on daily performance associated with a malocclusion, in patients that had received Orthodontic treatment, compared to those who had not. 97 ]#CITATION_TAG Marshman and colleagues 101 have expressed concern that generic measures of OHQoL might not fully capture the impact that malocclusion has suggested the development of a malocclusion specific measure of OHQoL for young people with malocclusion. The use and interpretation of data from generic and/or condition-specific measures of OHQoL continues to be the subject of much debate and research. 100	0	Some studies, using a cross-sectional design, have found that individuals who have undergone orthodontic treatment had a better OHQoL than individuals who have not undergone orthodontic treatment. 65,90,91 O her studies have found no difference in the OHQoL between treated and untreated groups. 92 ][95][96] Furthermore, a case controlled study also reported fewer physical, psychological and social impacts on daily performance associated with a malocclusion, in patients that had received Orthodontic treatment, compared to those who had not. 97 ]#CITATION_TAG Marshman and colleagues 101 have expressed concern that generic measures of OHQoL might not fully capture the impact that malocclusion has suggested the development of a malocclusion specific measure of OHQoL for young people with malocclusion. The use and interpretation of data from generic and/or condition-specific measures of OHQoL continues to be the subject of much debate and research. 100	#
CCT608	[98]#CITATION_TAG[100] Marshman and colleagues 101 have expressed concern that generic measures of OHQoL might not fully capture the impact that malocclusion has suggested the development of a malocclusion specific measure of OHQoL for young people with malocclusion	0	[98]#CITATION_TAG[100] Marshman and colleagues 101 have expressed concern that generic measures of OHQoL might not fully capture the impact that malocclusion has suggested the development of a malocclusion specific measure of OHQoL for young people with malocclusion	[
CCT609	Fewer studies have reported evidence that correction of a malocclusion with orthodontic treatment leads to an improvement in OHQoL. Some studies, using a cross-sectional design, have found that individuals who have undergone orthodontic treatment had a better OHQoL than individuals who have not undergone orthodontic treatment. 65,90,91 O her studies have found no difference in the OHQoL between treated and untreated groups. 92 ][95][96] Furthermore, a case controlled study also reported fewer physical, psychological and social impacts on daily performance associated with a malocclusion, in patients that had received Orthodontic treatment, compared to those who had not. 97 #CITATION_TAG][100] Marshman and colleagues 101 have expressed concern that generic measures of OHQoL might not fully capture the impact that malocclusion has suggested the development of a malocclusion specific measure of OHQoL for young people with malocclusion. The use and interpretation of data from generic and/or condition-specific measures of OHQoL continues to be the subject of much debate and research. 100	0	Some studies, using a cross-sectional design, have found that individuals who have undergone orthodontic treatment had a better OHQoL than individuals who have not undergone orthodontic treatment. 65,90,91 O her studies have found no difference in the OHQoL between treated and untreated groups. 92 ][95][96] Furthermore, a case controlled study also reported fewer physical, psychological and social impacts on daily performance associated with a malocclusion, in patients that had received Orthodontic treatment, compared to those who had not. 97 #CITATION_TAG][100] Marshman and colleagues 101 have expressed concern that generic measures of OHQoL might not fully capture the impact that malocclusion has suggested the development of a malocclusion specific measure of OHQoL for young people with malocclusion. The use and interpretation of data from generic and/or condition-specific measures of OHQoL continues to be the subject of much debate and research. 100	C
CCT610	Recently, various studies have looked at the impact of malocclusion on OHQoL in children and adolescents of differing age groups. A number of studies focusing on pre-school children, often aged 5 years or below, failed to demonstrate an association between the presence of a malocclusion and OHQoL, 87,88 whilst other studies based on adolescents between the approximate ages of 11 to 15 years, have found the presence of a malocclusion to have a negative impact on OHQoL. #CITATION_TAG,89  arious factors may account for the disparity observed in the different age groups. arious factors may account for the disparity observed in the different age groups. Firstly, the presence of more severe forms of malocclusion, such as severe crowding or severe skeletal discrepancies causing an extreme overjet, often manifest in the mixed or permanent dentition, which may account for the negative impact that malocclusions have on OHQoL in such age groups. Secondly, the lack of impact that malocclusions have on OHQoL in pre-school children may be related to the lack of importance that such age groups give to aesthetics.	0	Recently, various studies have looked at the impact of malocclusion on OHQoL in children and adolescents of differing age groups. A number of studies focusing on pre-school children, often aged 5 years or below, failed to demonstrate an association between the presence of a malocclusion and OHQoL, 87,88 whilst other studies based on adolescents between the approximate ages of 11 to 15 years, have found the presence of a malocclusion to have a negative impact on OHQoL. #CITATION_TAG,89  arious factors may account for the disparity observed in the different age groups. arious factors may account for the disparity observed in the different age groups. Firstly, the presence of more severe forms of malocclusion, such as severe crowding or severe skeletal discrepancies causing an extreme overjet, often manifest in the mixed or permanent dentition, which may account for the negative impact that malocclusions have on OHQoL in such age groups. Secondly, the lack of impact that malocclusions have on OHQoL in pre-school children may be related to the lack of importance that such age groups give to aesthetics.	I
CCT611	It is worth clarifying the distinction between the terms scenario and pathway in the matrix architecture. We use the term scenario to describe a plausible, comprehensive, integrated and consistent description of how the future might unfold (#CITATION_TAG et al. 2000) while refraining from a concrete statement on probability. The term scenario specifically refers to integration of socio-economic, climate change, and climate change policy assumptions within the cells of the matrix. In contrast, the term pathway is used for the conditions describing the rows and columns of the matrix (e.g., the RCPs and SSPs). In other words, the term pathway emphasizes that these conditions are not comprehensive scenarios, but are focused on a specific component of the future (climate change or socio-economic circumstances). Only when combined can they provide the basis of an integrated scenario. The word pathway also emphasizes the time-dependent nature of the conditions.	0	It is worth clarifying the distinction between the terms scenario and pathway in the matrix architecture. We use the term scenario to describe a plausible, comprehensive, integrated and consistent description of how the future might unfold (#CITATION_TAG et al. 2000) while refraining from a concrete statement on probability. The term scenario specifically refers to integration of socio-economic, climate change, and climate change policy assumptions within the cells of the matrix. In contrast, the term pathway is used for the conditions describing the rows and columns of the matrix (e.g., the RCPs and SSPs). In other words, the term pathway emphasizes that these conditions are not comprehensive scenarios, but are focused on a specific component of the future (climate change or socio-economic circumstances).	e
CCT612	"In 2006, a process was started to develop a new set of global ""common"" scenarios (i.e. scenarios that are being developed to serve research needs across the relevant disciplines involved). The new scenarios were needed to address various issues such as the growing interest in mitigation scenarios, the need for more recent base year data and the specific data needs of state-of-the-art models (see also #CITATION_TAG and Yohe 2013). The roadmap for the new scenario process was described in Moss et al. (2010). The process includes three phases. As the first step, the IAM community 1 developed a set of concentration pathways (the Representative Concentration Pathways or RCPs) that were used by the ESM community to project the magnitude and extent of climate change (Taylor et al. 2012;Van Vuuren et al. 2011a). The emphasis in the second (current) phase, in parallel with the RCP-based climate projections, is to develop a set of new socioeconomic reference scenarios, with quantitative and qualitative elements, based on worlds with various levels of challenges to mitigation and adaptation. The current Special Issue forms part of this second phase. Moreover, new scenario storylines have been developed together with quantifications of associated population and income development which were reviewed by the research community in 2012. Articles describing these products are forthcoming (see . Finally, the socio-economic information, the RCPs and the associated climate change projections will be integrated in the third phase to develop scenarios for use by the climate change research community."	0	"In 2006, a process was started to develop a new set of global ""common"" scenarios (i.e. scenarios that are being developed to serve research needs across the relevant disciplines involved). The new scenarios were needed to address various issues such as the growing interest in mitigation scenarios, the need for more recent base year data and the specific data needs of state-of-the-art models (see also #CITATION_TAG and Yohe 2013). The roadmap for the new scenario process was described in Moss et al. (2010). The process includes three phases. As the first step, the IAM community 1 developed a set of concentration pathways (the Representative Concentration Pathways or RCPs) that were used by the ESM community to project the magnitude and extent of climate change (Taylor et al. 2012;Van Vuuren et al. 2011a)."	h
CCT613	"In 2006, a process was started to develop a new set of global ""common"" scenarios (i.e. scenarios that are being developed to serve research needs across the relevant disciplines involved). The new scenarios were needed to address various issues such as the growing interest in mitigation scenarios, the need for more recent base year data and the specific data needs of state-of-the-art models (see also Ebi and Yohe 2013). The roadmap for the new scenario process was described in Moss et al. (2010). The process includes three phases. As the first step, the IAM community 1 developed a set of concentration pathways (the Representative Concentration Pathways or RCPs) that were used by the ESM community to project the magnitude and extent of climate change (#CITATION_TAG et al. 2012;Van Vuuren et al. 2011a). The emphasis in the second (current) phase, in parallel with the RCP-based climate projections, is to develop a set of new socioeconomic reference scenarios, with quantitative and qualitative elements, based on worlds with various levels of challenges to mitigation and adaptation. The current Special Issue forms part of this second phase. Moreover, new scenario storylines have been developed together with quantifications of associated population and income development which were reviewed by the research community in 2012. Articles describing these products are forthcoming (see . Finally, the socio-economic information, the RCPs and the associated climate change projections will be integrated in the third phase to develop scenarios for use by the climate change research community."	0	The new scenarios were needed to address various issues such as the growing interest in mitigation scenarios, the need for more recent base year data and the specific data needs of state-of-the-art models (see also Ebi and Yohe 2013). The roadmap for the new scenario process was described in Moss et al. (2010). The process includes three phases. As the first step, the IAM community 1 developed a set of concentration pathways (the Representative Concentration Pathways or RCPs) that were used by the ESM community to project the magnitude and extent of climate change (#CITATION_TAG et al. 2012;Van Vuuren et al. 2011a). The emphasis in the second (current) phase, in parallel with the RCP-based climate projections, is to develop a set of new socioeconomic reference scenarios, with quantitative and qualitative elements, based on worlds with various levels of challenges to mitigation and adaptation. The current Special Issue forms part of this second phase. Moreover, new scenario storylines have been developed together with quantifications of associated population and income development which were reviewed by the research community in 2012.	h
CCT614	One important use of the matrix structure is as a heuristic tool, classifying typical published examples of combinations of factors that are crucial for adaptation and mitigation. By locating studies in different cells of the matrix, these studies can more readily be compared and evaluated. For example, let us assume that different studies have estimated the costs of mitigation policy for a wide range of different baselines. Such scenarios may include some with high technology development and global cooperation and others with slow technology development and little global cooperation. Classifying scenarios from the literature within the matrix might in that case allow researchers to account for these differences and thus compare scenarios with similar assumptions. Something similar was done in the IPCC Fig. 6 Illustrations of how the matrix architecture can be used to look into the cost and benefits of climate policy (indicated by the different colours). Different categories of climate policy costs and residual impacts are expected to vary across the cells of the matrix. The empty cell (dashed lines) illustrate that not all combinations of forcing levels and SSPs may be consistent. Colours in the left hand matrix illustrate how achievement of lower forcing levels imposes a greater mitigation cost for any given SSP, but that this cost also depends on the SSP being followed. Colours in the right hand matrix suggest how the costs of avoiding a certain amount of impact (not specified here) through adaptation, combined with the impact costs that remain, are greater under some SSPs than others and under higher levels of forcing. The use of the framework to explore mitigation and adaptation policies is further elaborated in Kriegler et al. (Submitted for publication in this special issue). The 3.7 W/m2 level has been added to illustrate that other levels of radiative forcing than the four RCPs may also be explored Fourth Assessment Report, when scenarios were classified on the basis of resemblance to one of the SRES scenarios when accounting for costs (Fisher et al. 2007). This also could be done for impacts or adaptation studies: the SSPs and the matrix can help classify studies in a common way and provide a framework for communication across various communities. Obviously, using the framework as a heuristic tool requires that criteria be established to determine whether a scenario aligns with a specific SSP and/or with different forcing levels. It is possible to establish quantitative criteria that define a space around an SSP, as was done for the harmonized scenarios in the SRES (Nakicenovic et al. 2000). In that sense, it is also useful to use the earlier published quantifications of scenarios (#CITATION_TAG et al. 2005;van Vuuren et al. 2012a) that identify scenario archetypes across assessments.	5	This also could be done for impacts or adaptation studies: the SSPs and the matrix can help classify studies in a common way and provide a framework for communication across various communities. Obviously, using the framework as a heuristic tool requires that criteria be established to determine whether a scenario aligns with a specific SSP and/or with different forcing levels. It is possible to establish quantitative criteria that define a space around an SSP, as was done for the harmonized scenarios in the SRES (Nakicenovic et al. 2000). In that sense, it is also useful to use the earlier published quantifications of scenarios (#CITATION_TAG et al. 2005;van Vuuren et al. 2012a) that identify scenario archetypes across assessments.	i
CCT615	"The vertical axis in the scenario framework is defined in terms of RCPs, i.e. the level of radiative forcing. There are large uncertainties surrounding model projections of future climate for a given level of radiative forcing, due to factors such as the inherent unpredictability of natural climatic variations, global climate sensitivity in response to anthropogenic forcing and regional patterns of climate response (#CITATION_TAG et al. 2007;Meehl et al. 2007; Tebaldi and Arblaster, Submitted for publication in this special issue; Van Vuuren et al. 2008). Regional projections of some climatic variables (such as precipitation and wind speed), which can be crucially important for impacts in certain sectors and systems, are even more uncertain than projections of others (such as air temperature). This is also true for the timing, pattern, frequency, duration, and intensity of weather events, which provides critical information for impacts assessments. Together, this implies that a specific climate model projection for a given RCP level might differ greatly from the projection from another climate model for the same forcing. This ""climate change"" uncertainty can be regarded as another axis of the framework (Fig. 3). It is important to address this uncertainty as much as possible by using a large range of ESM outputs (or pattern scaling results, see Tebaldi and Arblaster, Submitted for publication in this special issue). While analysts are increasingly applying multi-model ensemble climate projections in impact studies (e.g. Ara√∫jo and New, 2007;Diffenbaugh and Field, 2013), this is not always feasible. One way to handle the Fig. 2 The policy assumptions may vary within a SSP. Therefore, it can be defined as an additional axis within the framework. Shared policy reference assumptions (SPAs) to characterize the policy context are discussed in Kriegler et al. (Submitted for publication in this special issue). Examples of such SPAs are assumptions on mitigation policy (e.g. uniform carbon price versus detailed regulation) and adaptation policy (e.g. the level of international cooperation). Clearly, relationships exist between the SSP, the policy assumptions, and the forcing level climate uncertainty while limiting the number of IAV calculations might be by identifying expected ""best case"" and ""worst case"" scenarios for specific purposes. For instance, if changes in precipitation are known to be a key determinant of agricultural impacts in a region, it is possible to identify, for a specific forcing level, climate models projecting the highest and lowest level of precipitation change in that region. Such methods are commonly applied in IAVanalysis, although multiple criteria are normally applied in determining the final selection of representative climate scenarios to be used (IPCC-TGICA 2007;Wilby et al. 2009). Further guidelines on this would clearly be useful in application of the overall framework."	2	The vertical axis in the scenario framework is defined in terms of RCPs, i.e. the level of radiative forcing. There are large uncertainties surrounding model projections of future climate for a given level of radiative forcing, due to factors such as the inherent unpredictability of natural climatic variations, global climate sensitivity in response to anthropogenic forcing and regional patterns of climate response (#CITATION_TAG et al. 2007;Meehl et al. 2007; Tebaldi and Arblaster, Submitted for publication in this special issue; Van Vuuren et al. 2008). Regional projections of some climatic variables (such as precipitation and wind speed), which can be crucially important for impacts in certain sectors and systems, are even more uncertain than projections of others (such as air temperature). This is also true for the timing, pattern, frequency, duration, and intensity of weather events, which provides critical information for impacts assessments. Together, this implies that a specific climate model projection for a given RCP level might differ greatly from the projection from another climate model for the same forcing.	h
CCT616	"In 2006, a process was started to develop a new set of global ""common"" scenarios (i.e. scenarios that are being developed to serve research needs across the relevant disciplines involved). The new scenarios were needed to address various issues such as the growing interest in mitigation scenarios, the need for more recent base year data and the specific data needs of state-of-the-art models (see also Ebi and Yohe 2013). The roadmap for the new scenario process was described in #CITATION_TAG et al. (2010). The process includes three phases. As the first step, the IAM community 1 developed a set of concentration pathways (the Representative Concentration Pathways or RCPs) that were used by the ESM community to project the magnitude and extent of climate change (Taylor et al. 2012;Van Vuuren et al. 2011a). The emphasis in the second (current) phase, in parallel with the RCP-based climate projections, is to develop a set of new socioeconomic reference scenarios, with quantitative and qualitative elements, based on worlds with various levels of challenges to mitigation and adaptation. The current Special Issue forms part of this second phase. Moreover, new scenario storylines have been developed together with quantifications of associated population and income development which were reviewed by the research community in 2012. Articles describing these products are forthcoming (see . Finally, the socio-economic information, the RCPs and the associated climate change projections will be integrated in the third phase to develop scenarios for use by the climate change research community."	5	"In 2006, a process was started to develop a new set of global ""common"" scenarios (i.e. scenarios that are being developed to serve research needs across the relevant disciplines involved). The new scenarios were needed to address various issues such as the growing interest in mitigation scenarios, the need for more recent base year data and the specific data needs of state-of-the-art models (see also Ebi and Yohe 2013). The roadmap for the new scenario process was described in #CITATION_TAG et al. (2010). The process includes three phases. As the first step, the IAM community 1 developed a set of concentration pathways (the Representative Concentration Pathways or RCPs) that were used by the ESM community to project the magnitude and extent of climate change (Taylor et al. 2012;Van Vuuren et al. 2011a). The emphasis in the second (current) phase, in parallel with the RCP-based climate projections, is to develop a set of new socioeconomic reference scenarios, with quantitative and qualitative elements, based on worlds with various levels of challenges to mitigation and adaptation."	e
CCT617	One important use of the matrix structure is as a heuristic tool, classifying typical published examples of combinations of factors that are crucial for adaptation and mitigation. By locating studies in different cells of the matrix, these studies can more readily be compared and evaluated. For example, let us assume that different studies have estimated the costs of mitigation policy for a wide range of different baselines. Such scenarios may include some with high technology development and global cooperation and others with slow technology development and little global cooperation. Classifying scenarios from the literature within the matrix might in that case allow researchers to account for these differences and thus compare scenarios with similar assumptions. Something similar was done in the IPCC Fig. 6 Illustrations of how the matrix architecture can be used to look into the cost and benefits of climate policy (indicated by the different colours). Different categories of climate policy costs and residual impacts are expected to vary across the cells of the matrix. The empty cell (dashed lines) illustrate that not all combinations of forcing levels and SSPs may be consistent. Colours in the left hand matrix illustrate how achievement of lower forcing levels imposes a greater mitigation cost for any given SSP, but that this cost also depends on the SSP being followed. Colours in the right hand matrix suggest how the costs of avoiding a certain amount of impact (not specified here) through adaptation, combined with the impact costs that remain, are greater under some SSPs than others and under higher levels of forcing. The use of the framework to explore mitigation and adaptation policies is further elaborated in Kriegler et al. (Submitted for publication in this special issue). The 3.7 W/m2 level has been added to illustrate that other levels of radiative forcing than the four RCPs may also be explored Fourth Assessment Report, when scenarios were classified on the basis of resemblance to one of the SRES scenarios when accounting for costs (#CITATION_TAG et al. 2007). This also could be done for impacts or adaptation studies: the SSPs and the matrix can help classify studies in a common way and provide a framework for communication across various communities. Obviously, using the framework as a heuristic tool requires that criteria be established to determine whether a scenario aligns with a specific SSP and/or with different forcing levels. It is possible to establish quantitative criteria that define a space around an SSP, as was done for the harmonized scenarios in the SRES (Nakicenovic et al. 2000). In that sense, it is also useful to use the earlier published quantifications of scenarios (Raskin et al. 2005;van Vuuren et al. 2012a) that identify scenario archetypes across assessments.	0	Colours in the left hand matrix illustrate how achievement of lower forcing levels imposes a greater mitigation cost for any given SSP, but that this cost also depends on the SSP being followed. Colours in the right hand matrix suggest how the costs of avoiding a certain amount of impact (not specified here) through adaptation, combined with the impact costs that remain, are greater under some SSPs than others and under higher levels of forcing. The use of the framework to explore mitigation and adaptation policies is further elaborated in Kriegler et al. (Submitted for publication in this special issue). The 3.7 W/m2 level has been added to illustrate that other levels of radiative forcing than the four RCPs may also be explored Fourth Assessment Report, when scenarios were classified on the basis of resemblance to one of the SRES scenarios when accounting for costs (#CITATION_TAG et al. 2007). This also could be done for impacts or adaptation studies: the SSPs and the matrix can help classify studies in a common way and provide a framework for communication across various communities. Obviously, using the framework as a heuristic tool requires that criteria be established to determine whether a scenario aligns with a specific SSP and/or with different forcing levels. It is possible to establish quantitative criteria that define a space around an SSP, as was done for the harmonized scenarios in the SRES (Nakicenovic et al. 2000).	2
CCT618	"The vertical axis in the scenario framework is defined in terms of RCPs, i.e. the level of radiative forcing. There are large uncertainties surrounding model projections of future climate for a given level of radiative forcing, due to factors such as the inherent unpredictability of natural climatic variations, global climate sensitivity in response to anthropogenic forcing and regional patterns of climate response (Christensen et al. 2007;Meehl et al. 2007; Tebaldi and Arblaster, Submitted for publication in this special issue; Van Vuuren et al. 2008). Regional projections of some climatic variables (such as precipitation and wind speed), which can be crucially important for impacts in certain sectors and systems, are even more uncertain than projections of others (such as air temperature). This is also true for the timing, pattern, frequency, duration, and intensity of weather events, which provides critical information for impacts assessments. Together, this implies that a specific climate model projection for a given RCP level might differ greatly from the projection from another climate model for the same forcing. This ""climate change"" uncertainty can be regarded as another axis of the framework (Fig. 3). It is important to address this uncertainty as much as possible by using a large range of ESM outputs (or pattern scaling results, see Tebaldi and Arblaster, Submitted for publication in this special issue). While analysts are increasingly applying multi-model ensemble climate projections in impact studies (e.g. Ara√∫jo and New, 2007;Diffenbaugh and Field, 2013), this is not always feasible. One way to handle the Fig. 2 The policy assumptions may vary within a SSP. Therefore, it can be defined as an additional axis within the framework. Shared policy reference assumptions (SPAs) to characterize the policy context are discussed in Kriegler et al. (Submitted for publication in this special issue). Examples of such SPAs are assumptions on mitigation policy (e.g. uniform carbon price versus detailed regulation) and adaptation policy (e.g. the level of international cooperation). Clearly, relationships exist between the SSP, the policy assumptions, and the forcing level climate uncertainty while limiting the number of IAV calculations might be by identifying expected ""best case"" and ""worst case"" scenarios for specific purposes. For instance, if changes in precipitation are known to be a key determinant of agricultural impacts in a region, it is possible to identify, for a specific forcing level, climate models projecting the highest and lowest level of precipitation change in that region. Such methods are commonly applied in IAVanalysis, although multiple criteria are normally applied in determining the final selection of representative climate scenarios to be used (IPCC-TGICA 2007;#CITATION_TAG et al. 2009). Further guidelines on this would clearly be useful in application of the overall framework."	2	"Examples of such SPAs are assumptions on mitigation policy (e.g. uniform carbon price versus detailed regulation) and adaptation policy (e.g. the level of international cooperation). Clearly, relationships exist between the SSP, the policy assumptions, and the forcing level climate uncertainty while limiting the number of IAV calculations might be by identifying expected ""best case"" and ""worst case"" scenarios for specific purposes. For instance, if changes in precipitation are known to be a key determinant of agricultural impacts in a region, it is possible to identify, for a specific forcing level, climate models projecting the highest and lowest level of precipitation change in that region. Such methods are commonly applied in IAVanalysis, although multiple criteria are normally applied in determining the final selection of representative climate scenarios to be used (IPCC-TGICA 2007;#CITATION_TAG et al. 2009). Further guidelines on this would clearly be useful in application of the overall framework."	r
CCT619	We updated the systematic review by Neville et al. (33) by including 5 additional studies (Table 5) (191)(192)#CITATION_TAG(194)(195). In the review by Neville et al., the majority of identified studies reported little or no association between breastfeeding and weight change. Of those five studies, three studies were performed in low-and middle-income countries, one was performed in high-income country, and one was multicentre study (Brazil, Ghana, India, Norway, Oman, USA). In studies performed in low-and middle-income countries, we have not found any potential differential effect for breastfeeding and postpartum weight loss response as a function of countries being low to middle and high income. Two of the five additionally identified studies (194,195) reported a significant reduction in postpartum weight with breastfeeding. Sarkar and Taylor (191) in a cross-sectional study in Bangladesh revealed that body weight of mothers was negatively correlated with 1-12 and 13-24 months of lactation after controlling for height, education and food consumption. Stuebe et al. (192) showed that women who exclusively breastfed for greater than six months had the lowest BMI at 3 years postpartum as well as the lowest postpartum weight retention at 3 years compared with women who never exclusively breastfed. A multicentre study showed that lactation intensity and duration explained little variation in weight change patterns (193)(194)(195). Overall, the role of breastfeeding on postpartum weight change remains unclear.	5	We updated the systematic review by Neville et al. (33) by including 5 additional studies (Table 5) (191)(192)#CITATION_TAG(194)(195). In the review by Neville et al., the majority of identified studies reported little or no association between breastfeeding and weight change. Of those five studies, three studies were performed in low-and middle-income countries, one was performed in high-income country, and one was multicentre study (Brazil, Ghana, India, Norway, Oman, USA). In studies performed in low-and middle-income countries, we have not found any potential differential effect for breastfeeding and postpartum weight loss response as a function of countries being low to middle and high income.	W
CCT620	Breast milk is the natural first food for newborns. It provides all the energy and nutrients that an infant needs for the first six months of life, up to half or more during the second half of infancy and up to one-third during the second year of life (1,2). For mothers, breastfeeding has been reported to confer lower risk of breast and ovarian carcinoma (3,#CITATION_TAG), greater postpartum weight loss (5) and decreased blood pressure (6) compared with no breastfeeding. The World Health Organization (WHO) recommends exclusive breastfeeding in the first six months and continuation of breastfeeding for 2 years and beyond (1).	0	Breast milk is the natural first food for newborns. It provides all the energy and nutrients that an infant needs for the first six months of life, up to half or more during the second half of infancy and up to one-third during the second year of life (1,2). For mothers, breastfeeding has been reported to confer lower risk of breast and ovarian carcinoma (3,#CITATION_TAG), greater postpartum weight loss (5) and decreased blood pressure (6) compared with no breastfeeding. The World Health Organization (WHO) recommends exclusive breastfeeding in the first six months and continuation of breastfeeding for 2 years and beyond (1).	r
CCT621	Pooled results from 41 estimates (65,#CITATION_TAG, showed that mothers who ever breastfed their children had a 30% reduction in the risk of ovarian carcinoma, when compared with those who never breastfed (OR 0.70, 95% CI 0.64-0.77) (Tables 2 and A3; Fig. 3). (Tables 2 and A3; Fig. 3). The risk of ovarian carcinoma was 17% lower among women who had breastfed for less than six months when compared with those who did not breastfeed (OR 0.83, 95% CI 0.78-0.89). The risk of ovarian carcinoma among mothers who breastfed for 6months was 28% lower (OR 0.72, 95% CI 0.66-0.78; 19 In subgroup analysis, studies with sample sizes of more than 1500 showed a significant protection of 24% from NOTE: Weights are from random effects analysis Overall (I-squared = 71.9%, p = 0.000)   subsequent to the systemic review by Aune et al. in 2013 (31).	5	Pooled results from 41 estimates (65,#CITATION_TAG, showed that mothers who ever breastfed their children had a 30% reduction in the risk of ovarian carcinoma, when compared with those who never breastfed (OR 0.70, 95% CI 0.64-0.77) (Tables 2 and A3; Fig. 3). (Tables 2 and A3; Fig. 3). The risk of ovarian carcinoma was 17% lower among women who had breastfed for less than six months when compared with those who did not breastfeed (OR 0.83, 95% CI 0.78-0.89). The risk of ovarian carcinoma among mothers who breastfed for 6months was 28% lower (OR 0.72, 95% CI 0.66-0.78; 19 In subgroup analysis, studies with sample sizes of more than 1500 showed a significant protection of 24% from NOTE: Weights are from random effects analysis Overall (I-squared = 71.9%, p = 0.000)   subsequent to the systemic review by Aune et al. in 2013 (31).	P
CCT622	The goal of this paper is to try to fill these gaps. We first provide a thorough survey of the literature concerning several elicitation methods finding mixed results. In particular we focus on the unexplored HL task, finding that only twenty papers provide enough information to be included in the survey out of more than five hundreds studies that cite #CITATION_TAG and Laury (2002). This is due to the fact that the HL procedure is widely used as a companion task in experimental sessions in which the core treatments deal with other topics involving uncertainty. As a consequence, only a small fraction of contributions explicitly report about gender differences. We hence move beyond a simple meta-analysis to carry out a wide-range investigation based on the largest possible set of microdata, generated by directly asking for data the authors of all the 94 published HL replications.	2	The goal of this paper is to try to fill these gaps. We first provide a thorough survey of the literature concerning several elicitation methods finding mixed results. In particular we focus on the unexplored HL task, finding that only twenty papers provide enough information to be included in the survey out of more than five hundreds studies that cite #CITATION_TAG and Laury (2002). This is due to the fact that the HL procedure is widely used as a companion task in experimental sessions in which the core treatments deal with other topics involving uncertainty. As a consequence, only a small fraction of contributions explicitly report about gender differences. We hence move beyond a simple meta-analysis to carry out a wide-range investigation based on the largest possible set of microdata, generated by directly asking for data the authors of all the 94 published HL replications.	 
CCT623	Similar findings emerge with the Eckel and Grossman (2002) task, with sizable gender differences appearing both in the experiment presenting the task as well as in later replications (Arya et al., 2012;Ball et al., 2010;Crosetto and Filippin, 2013b;#CITATION_TAG et al., 2010;Eckel et al., 2009Eckel et al., , 2011Grossman and Eckel, 2009). Wik et al. (2004) find a gender gap among peasant households in Zambia. Cleave et al. (2010) find a gender gap in a wide sample but not in a subsample that participated to later experiments, but it is, to the best of our knowledge, the only exception.	4	Similar findings emerge with the Eckel and Grossman (2002) task, with sizable gender differences appearing both in the experiment presenting the task as well as in later replications (Arya et al., 2012;Ball et al., 2010;Crosetto and Filippin, 2013b;#CITATION_TAG et al., 2010;Eckel et al., 2009Eckel et al., , 2011Grossman and Eckel, 2009). Wik et al. (2004) find a gender gap among peasant households in Zambia. Cleave et al. (2010) find a gender gap in a wide sample but not in a subsample that participated to later experiments, but it is, to the best of our knowledge, the only exception.	S
CCT624	Similar findings emerge with the Eckel and Grossman (2002) task, with sizable gender differences appearing both in the experiment presenting the task as well as in later replications (Arya et al., 2012;Ball et al., 2010;#CITATION_TAG and Filippin, 2013b;Dave et al., 2010;Eckel et al., 2009Eckel et al., , 2011Grossman and Eckel, 2009). Wik et al. (2004) find a gender gap among peasant households in Zambia. Cleave et al. (2010) find a gender gap in a wide sample but not in a subsample that participated to later experiments, but it is, to the best of our knowledge, the only exception.	4	Similar findings emerge with the Eckel and Grossman (2002) task, with sizable gender differences appearing both in the experiment presenting the task as well as in later replications (Arya et al., 2012;Ball et al., 2010;#CITATION_TAG and Filippin, 2013b;Dave et al., 2010;Eckel et al., 2009Eckel et al., , 2011Grossman and Eckel, 2009). Wik et al. (2004) find a gender gap among peasant households in Zambia. Cleave et al. (2010) find a gender gap in a wide sample but not in a subsample that participated to later experiments, but it is, to the best of our knowledge, the only exception.	S
CCT625	Gender differences in risk preferences are often seen as a stylized fact in the economics and psychology literature. Most of the studies and meta-analyses find that women display a more prudent behavior than men when confronted with decisions under risk. In economics, for instance, surveys made by Eckel and Grossman (2008c) and Croson and Gneezy (2009) find mostly supporting evidence and investigate the robustness of this result along several dimensions, such as the characteristics of the subject pool, the strength of incentives, the gain vs. loss domain, the abstract vs. contextual framework. These surveys, though, are based on a relatively small sample of studies (16 and 10, respectively, 3 of which in common) given the variety of designs covered. As noted by #CITATION_TAG and Gneezy (2012), the differences in the methods used to measure the preferences can act as an additional source of heterogeneity. Consequently, Charness and Gneezy (2012) focus on a single elicitation method, the Investment Game, and find strong evidence that females are less willing to take risk. In psychology, Byrnes et al. (1999) provide a meta-analysis including 150 studies, using a broad definition of risk, from smoking to driving to gambling, and analyzing self-reported, incentivized, as well as observed choices. The study finds that males take more risks than females in most of the risk categories, even though the magnitude of the effect is usually small, seldom significant, and some studies find contrary evidence.	1	Most of the studies and meta-analyses find that women display a more prudent behavior than men when confronted with decisions under risk. In economics, for instance, surveys made by Eckel and Grossman (2008c) and Croson and Gneezy (2009) find mostly supporting evidence and investigate the robustness of this result along several dimensions, such as the characteristics of the subject pool, the strength of incentives, the gain vs. loss domain, the abstract vs. contextual framework. These surveys, though, are based on a relatively small sample of studies (16 and 10, respectively, 3 of which in common) given the variety of designs covered. As noted by #CITATION_TAG and Gneezy (2012), the differences in the methods used to measure the preferences can act as an additional source of heterogeneity. Consequently, Charness and Gneezy (2012) focus on a single elicitation method, the Investment Game, and find strong evidence that females are less willing to take risk. In psychology, Byrnes et al. (1999) provide a meta-analysis including 150 studies, using a broad definition of risk, from smoking to driving to gambling, and analyzing self-reported, incentivized, as well as observed choices. The study finds that males take more risks than females in most of the risk categories, even though the magnitude of the effect is usually small, seldom significant, and some studies find contrary evidence.	o
CCT626	Our results indicate that the frequency and the importance of gender differences reflect specific characteristics of the elicitation methods over and above true differences in the underlying (and latent) risk attitudes. Observing a gender gap not only depends on the task being contextual or not (#CITATION_TAG and Grossman, 2008a), on it having to do with risk or with uncertainty (Wieland and Sarin, 2012), or on the choices being incentivized, self-reported or observed (Byrnes et al., 1999). Even restricting the analysis to the narrow domain of incentivized lottery choice tasks currently used in experimental economics, gender differences depend on the details of the task. We single out two characteristics that jointly correlate with the likelihood of observing gender differences: a) the presence of a safe option within the choice set, and b) the use of lotteries with 50% ‚àí 50% fixed probabilities in tasks that generate the menu of lotteries changing the amounts at stake.	1	Our results indicate that the frequency and the importance of gender differences reflect specific characteristics of the elicitation methods over and above true differences in the underlying (and latent) risk attitudes. Observing a gender gap not only depends on the task being contextual or not (#CITATION_TAG and Grossman, 2008a), on it having to do with risk or with uncertainty (Wieland and Sarin, 2012), or on the choices being incentivized, self-reported or observed (Byrnes et al., 1999). Even restricting the analysis to the narrow domain of incentivized lottery choice tasks currently used in experimental economics, gender differences depend on the details of the task. We single out two characteristics that jointly correlate with the likelihood of observing gender differences: a) the presence of a safe option within the choice set, and b) the use of lotteries with 50% ‚àí 50% fixed probabilities in tasks that generate the menu of lotteries changing the amounts at stake.	b
CCT627	The overall frequency of inconsistent choices has already been summarized in Table 4. In Table 7 we provide a more detailed picture showing a breakdown by gender and type of inconsistency. The Table displays the number of inconsistent choices, overall and by gender, out of the total number that can be potentially observed. For instance, multiple switching cannot be observed in papers in which a single switching decision is imposed by design. Always choosing the safer (riskier) lottery is a dominated action only if there is a choice in which the good outcome has probability one (zero). 9 ultiple switching is the most common type of inconsistent behavior, observed about 14% of the times. Females are significantly more likely to be inconsistent (Fisher Exact test p < 0.001) and this at first glance seems to aim at numeracy as a possible explanation. These differences survive also in a multivariate framework in which other possible determinants  are included. In particular, presenting the lotteries in random order dramatically increases the fraction of inconsistencies. The number of choices in the price list also significantly increases inconsistencies, although to a much lower extent, while the presence of monetary incentives significantly reduces them. Inconsistent subjects make on average 5.15 safe choices, without significant gender differences (Mann Whitney test, p = 0.67). This number is lower than that of consistent subjects (5.63), and significantly so (Mann Whitney test, p < 0.001). At first glance this seems to suggest that inconsistent subjects tend to systematically bias downward the number of safe choices. However, a more careful interpretation suggests that inconsistent subjects simply tend to make choices that are closer to a random decision, which in the framework of the HL task coincides with choosing each option half of the times. This interpretation suggests that the positive correlation between risk aversion and IQ emphasized, among others, by #CITATION_TAG et al. (2010), could be an artifact of the format of the price list, as already argued by Andersson et al. (2013). Dominated choices (choosing always safe or always risky when certain outcomes exist) are much less frequent. Gender in this case does not help explaining the results, and neither do the other determinants, with the exception of incentives that also reduce the likelihood of making a safe choice when the good outcome is certain.	0	This number is lower than that of consistent subjects (5.63), and significantly so (Mann Whitney test, p < 0.001). At first glance this seems to suggest that inconsistent subjects tend to systematically bias downward the number of safe choices. However, a more careful interpretation suggests that inconsistent subjects simply tend to make choices that are closer to a random decision, which in the framework of the HL task coincides with choosing each option half of the times. This interpretation suggests that the positive correlation between risk aversion and IQ emphasized, among others, by #CITATION_TAG et al. (2010), could be an artifact of the format of the price list, as already argued by Andersson et al. (2013). Dominated choices (choosing always safe or always risky when certain outcomes exist) are much less frequent. Gender in this case does not help explaining the results, and neither do the other determinants, with the exception of incentives that also reduce the likelihood of making a safe choice when the good outcome is certain.	a
CCT628	"This paper examines the technical and persuasive rhetorical dimensions (#CITATION_TAG & Espeland, 1991) of a specific genealogy of calculation (Miller & Napier, 1993) ""local in both space and time"" (Carnegie & Napier, 1996, p.7). The institutional setting is the highly politicized early Queensland sugar industry and the time is the late 1800s. The calculative techniques are those employed by the Colonial Sugar Refining (CSR) Company at its Goondi sugar plantation and mill in north Queensland. The rhetoric is the economic argument used by CSR, both internally and externally, to rationalize its employment of indentured Pacific islanders. 1 nternally, the close attention paid to costs was a constant reminder to managers and employees that the continuation of the business, and their employment, depended on their ability to operate at a profit. This provided the justification for the employment of cheap islander labour. Externally, economic arguments for this practice were put forward to the government to argue for favourable legislation, to shareholders as a means of maintaining good dividends, and to the general public. They needed to be persuaded that the success of the fledgling sugar industry was vital to Queensland""s economic prosperity, and that this success hinged on a steady supply of cheap labour."	5	"This paper examines the technical and persuasive rhetorical dimensions (#CITATION_TAG & Espeland, 1991) of a specific genealogy of calculation (Miller & Napier, 1993) ""local in both space and time"" (Carnegie & Napier, 1996, p.7). The institutional setting is the highly politicized early Queensland sugar industry and the time is the late 1800s. The calculative techniques are those employed by the Colonial Sugar Refining (CSR) Company at its Goondi sugar plantation and mill in north Queensland. The rhetoric is the economic argument used by CSR, both internally and externally, to rationalize its employment of indentured Pacific islanders."	T
CCT629	"The recruiting of Pacific islanders began without official approval (Parnaby, 1964;Docker, 1970). Indeed, there was always a great deal of opposition to it, from the British Government, missionaries, the navy and many colonists (Morrison, 1888;Buxton, 1980;Irving, 1980). 5 Initially these objections appeared to be on the grounds that indentured labour was a form of kidnapping or slavery and that workers were mistreated (Morrison, 1888;Moore, 1974;#CITATION_TAG, Saunders & Cronin, 1975;Barker & Byford, 1988;The Call for Recognition, 1992;Moore, 1993;Andrew & Cook, 2000). However, over the next few decades, the reasons for such opposition became more complex and occasioned much more political lobbying and controversy, as public opinion moved against the islanders and their employment. This prejudice was fuelled by a political push to make Australia ""white"" (part of the Federation impetus), and by pressure from labour unions 6 to protect white labour from the competition occasioned by islanders, who received substantially lower wages. 7 pecific laws were created, first to permit the employment of islanders (Coolie Act (Queensland) 1862), then to protect them (Polynesian Labourers Act (Queensland) 1868), 8 to restrict them (Pacific Island Labourers Amendment Act (Queensland) 1884), and finally to deport them (Pacific Island Labourers"" Amendment Act (Queensland) 1885; Pacific Islanders Extension Act (Queensland) 1892; Pacific Island Labourers Act 1901). From 1868 to 1912, eight State and 13 Commonwealth Acts were passed on the issue (Gott, 1997). Where the British Government held that the Pacific islander labourers\"" rights should be equal with those of local labour, the Queensland Government saw Pacific islanders as ""a temporary and inferior labour supply without the rights of Europeans (Parnaby, 1964, p.153). Legislation thus enshrined racist attitudes, resulting in the eventual deportation of islanders by 1907 (The Call for Recognition, 1992, p.73)."	0	"The recruiting of Pacific islanders began without official approval (Parnaby, 1964;Docker, 1970). Indeed, there was always a great deal of opposition to it, from the British Government, missionaries, the navy and many colonists (Morrison, 1888;Buxton, 1980;Irving, 1980). 5 Initially these objections appeared to be on the grounds that indentured labour was a form of kidnapping or slavery and that workers were mistreated (Morrison, 1888;Moore, 1974;#CITATION_TAG, Saunders & Cronin, 1975;Barker & Byford, 1988;The Call for Recognition, 1992;Moore, 1993;Andrew & Cook, 2000). However, over the next few decades, the reasons for such opposition became more complex and occasioned much more political lobbying and controversy, as public opinion moved against the islanders and their employment. This prejudice was fuelled by a political push to make Australia ""white"" (part of the Federation impetus), and by pressure from labour unions 6 to protect white labour from the competition occasioned by islanders, who received substantially lower wages. 7 pecific laws were created, first to permit the employment of islanders (Coolie Act (Queensland) 1862), then to protect them (Polynesian Labourers Act (Queensland) 1868), 8 to restrict them (Pacific Island Labourers Amendment Act (Queensland) 1884), and finally to deport them (Pacific Island Labourers"" Amendment Act (Queensland) 1885; Pacific Islanders Extension Act (Queensland) 1892; Pacific Island Labourers Act 1901)."	I
CCT630	"The recruiting of Pacific islanders began without official approval (Parnaby, 1964;#CITATION_TAG, 1970). Indeed, there was always a great deal of opposition to it, from the British Government, missionaries, the navy and many colonists (Morrison, 1888;Buxton, 1980;Irving, 1980). 5 Initially these objections appeared to be on the grounds that indentured labour was a form of kidnapping or slavery and that workers were mistreated (Morrison, 1888;Moore, 1974;Evans, Saunders & Cronin, 1975;Barker & Byford, 1988;The Call for Recognition, 1992;Moore, 1993;Andrew & Cook, 2000). However, over the next few decades, the reasons for such opposition became more complex and occasioned much more political lobbying and controversy, as public opinion moved against the islanders and their employment. This prejudice was fuelled by a political push to make Australia ""white"" (part of the Federation impetus), and by pressure from labour unions 6 to protect white labour from the competition occasioned by islanders, who received substantially lower wages. 7 pecific laws were created, first to permit the employment of islanders (Coolie Act (Queensland) 1862), then to protect them (Polynesian Labourers Act (Queensland) 1868), 8 to restrict them (Pacific Island Labourers Amendment Act (Queensland) 1884), and finally to deport them (Pacific Island Labourers"" Amendment Act (Queensland) 1885; Pacific Islanders Extension Act (Queensland) 1892; Pacific Island Labourers Act 1901). From 1868 to 1912, eight State and 13 Commonwealth Acts were passed on the issue (Gott, 1997). Where the British Government held that the Pacific islander labourers\"" rights should be equal with those of local labour, the Queensland Government saw Pacific islanders as ""a temporary and inferior labour supply without the rights of Europeans (Parnaby, 1964, p.153). Legislation thus enshrined racist attitudes, resulting in the eventual deportation of islanders by 1907 (The Call for Recognition, 1992, p.73)."	0	The recruiting of Pacific islanders began without official approval (Parnaby, 1964;#CITATION_TAG, 1970). Indeed, there was always a great deal of opposition to it, from the British Government, missionaries, the navy and many colonists (Morrison, 1888;Buxton, 1980;Irving, 1980). 5 Initially these objections appeared to be on the grounds that indentured labour was a form of kidnapping or slavery and that workers were mistreated (Morrison, 1888;Moore, 1974;Evans, Saunders & Cronin, 1975;Barker & Byford, 1988;The Call for Recognition, 1992;Moore, 1993;Andrew & Cook, 2000). However, over the next few decades, the reasons for such opposition became more complex and occasioned much more political lobbying and controversy, as public opinion moved against the islanders and their employment.	T
CCT631	"The colony of Queensland separated from New South Wales in 1859 (Gott, 1997), and was then preoccupied with overcoming the lack of affordable, available and reliable labour to develop its coastal lands (Barker & Byford, 1988). Sugar production was agriculturally appropriate and, at the time, ""a good economic prospect"" 2 (#CITATION_TAG & Cook, 2000, p.1). With its British roots, and Britain""s dominating influence in the Pacific (Moore, 1993, p.183), Queensland adopted the plantation system as the dominant structure for its early sugar industry. Since Britain had abolished the slave trade, plantation owners turned to indentured labourers to meet their labour needs, recruiting Pacific islanders at their own expense and transporting them to Queensland. It is estimated that in the years 1863-1904, some 62,500 islanders were brought from more than 80 islands, to work on Queensland sugar plantations (The Call for Recognition, 1992, p.73). Since these islanders performed all the field work connected with the sugar industry, it is probable that without them, ""the initial enterprise should not have been forthcoming and ""very few of the old mills and plantations should have seen the light of day"" (NBAC/Z303, 1929). While they played a pivotal role in the success of Queensland""s sugar industry, little attention has been paid to the way they were accounted for by the sugar entrepreneurs, and for the role of accounting in justifying their employment."	0	"The colony of Queensland separated from New South Wales in 1859 (Gott, 1997), and was then preoccupied with overcoming the lack of affordable, available and reliable labour to develop its coastal lands (Barker & Byford, 1988). Sugar production was agriculturally appropriate and, at the time, ""a good economic prospect"" 2 (#CITATION_TAG & Cook, 2000, p.1). With its British roots, and Britain""s dominating influence in the Pacific (Moore, 1993, p.183), Queensland adopted the plantation system as the dominant structure for its early sugar industry. Since Britain had abolished the slave trade, plantation owners turned to indentured labourers to meet their labour needs, recruiting Pacific islanders at their own expense and transporting them to Queensland. It is estimated that in the years 1863-1904, some 62,500 islanders were brought from more than 80 islands, to work on Queensland sugar plantations (The Call for Recognition, 1992, p.73)."	u
CCT632	"This paper examines the technical and persuasive rhetorical dimensions (Carruthers & Espeland, 1991) of a specific genealogy of calculation (#CITATION_TAG & Napier, 1993) ""local in both space and time"" (Carnegie & Napier, 1996, p.7). The institutional setting is the highly politicized early Queensland sugar industry and the time is the late 1800s. The calculative techniques are those employed by the Colonial Sugar Refining (CSR) Company at its Goondi sugar plantation and mill in north Queensland. The rhetoric is the economic argument used by CSR, both internally and externally, to rationalize its employment of indentured Pacific islanders. 1 nternally, the close attention paid to costs was a constant reminder to managers and employees that the continuation of the business, and their employment, depended on their ability to operate at a profit. This provided the justification for the employment of cheap islander labour. Externally, economic arguments for this practice were put forward to the government to argue for favourable legislation, to shareholders as a means of maintaining good dividends, and to the general public. They needed to be persuaded that the success of the fledgling sugar industry was vital to Queensland""s economic prosperity, and that this success hinged on a steady supply of cheap labour."	5	"This paper examines the technical and persuasive rhetorical dimensions (Carruthers & Espeland, 1991) of a specific genealogy of calculation (#CITATION_TAG & Napier, 1993) ""local in both space and time"" (Carnegie & Napier, 1996, p.7). The institutional setting is the highly politicized early Queensland sugar industry and the time is the late 1800s. The calculative techniques are those employed by the Colonial Sugar Refining (CSR) Company at its Goondi sugar plantation and mill in north Queensland. The rhetoric is the economic argument used by CSR, both internally and externally, to rationalize its employment of indentured Pacific islanders."	T
CCT633	As we have argued in this chapter, a social-ecological dimension of urbanization has been neglected, resulting in a conceptual separation of the urban and the rural, and thus shaping our perceptions of the urbanization process itself and our policies and actions (cf. McGranahan et al. 2005 ;Grimm et al. 2008 ;Pickett et al. 2011 ;McDonald and Marcotullio 2011 ;Folke et al. 2011 ;Anderson and Elmqvist 2012 ;Wu 2013 ). Urbanization affects ecosystems both within and outside of urban areas, and as stated in Chaps. 1 and 21 , on a global scale urban land expansion will be much more rapid than urban population growth-in some places resulting in large, complex, urbanizing regions comprised of aggregations of interconnected cities and interspersed rural landscapes with multiple impacts, dependence and feedbacks (#CITATION_TAG et al. 2012a ;Seitzinger et al. 2012 ). Recently, new and promising conceptual frameworks based on analyses of urban land teleconnections have been proposed to further explore the multiple dependence and impacts of cities on distant places well beyond the urban hinterland (Seto et al. 2012a ); this holds promise to make many invisible social-ecological feedbacks and connections visible (Chap. 33 ). Many of the following chapters, including Chaps. 3 ,10 ,11 ,22 ,26 , and 27 will further explore this missing link-the urban social-ecological connections and their governance implications.	0	As we have argued in this chapter, a social-ecological dimension of urbanization has been neglected, resulting in a conceptual separation of the urban and the rural, and thus shaping our perceptions of the urbanization process itself and our policies and actions (cf. McGranahan et al. 2005 ;Grimm et al. 2008 ;Pickett et al. 2011 ;McDonald and Marcotullio 2011 ;Folke et al. 2011 ;Anderson and Elmqvist 2012 ;Wu 2013 ). Urbanization affects ecosystems both within and outside of urban areas, and as stated in Chaps. 1 and 21 , on a global scale urban land expansion will be much more rapid than urban population growth-in some places resulting in large, complex, urbanizing regions comprised of aggregations of interconnected cities and interspersed rural landscapes with multiple impacts, dependence and feedbacks (#CITATION_TAG et al. 2012a ;Seitzinger et al. 2012 ). Recently, new and promising conceptual frameworks based on analyses of urban land teleconnections have been proposed to further explore the multiple dependence and impacts of cities on distant places well beyond the urban hinterland (Seto et al. 2012a ); this holds promise to make many invisible social-ecological feedbacks and connections visible (Chap. 33 ). Many of the following chapters, including Chaps.	a
CCT634	History offers many lessons relevant to sustainability by exhibiting how humans and their societies have recognized and responded to challenges and opportunities of their natural environment (#CITATION_TAG 1999 ;Diamond 2005 ;Costanza et al. 2007a ;Sinclair et al. 2010 ). Three of the basic approaches to problem solving in antiquity were: (1) mobility of people to available resources, (2) ecosystem management to secure enhanced local growth of produce, and (3) increasing social complexity encoded in formal institutions that guided an expanding range of activities. These solution pathways were fundamental to the rise of early civilizations and are instrumental for integration in the design of sustainable cities in the future (Redman 2011 ).	0	History offers many lessons relevant to sustainability by exhibiting how humans and their societies have recognized and responded to challenges and opportunities of their natural environment (#CITATION_TAG 1999 ;Diamond 2005 ;Costanza et al. 2007a ;Sinclair et al. 2010 ). Three of the basic approaches to problem solving in antiquity were: (1) mobility of people to available resources, (2) ecosystem management to secure enhanced local growth of produce, and (3) increasing social complexity encoded in formal institutions that guided an expanding range of activities. These solution pathways were fundamental to the rise of early civilizations and are instrumental for integration in the design of sustainable cities in the future (Redman 2011 ).	H
CCT635	Not all of the green space in pre-industrial urban landscapes, however, was used to produce food. For example, open spaces have often been used as religious sites and as cemeteries. In many cities, particularly European, pleasure parks and pleasure gardens for purely recreational uses have also been present in cities since millennia, but these have mainly been the privilege of emperors, kings and other urban elites. In Stockholm, for instance, ordinary citizens were not allowed to enter such parks and gardens until the mid-1700s (#CITATION_TAG et al. 2005 ). The main social drivers that led to a shift toward public use of such green spaces were the rapid urbanization during the industrial revolution, in combination with emerging social values inspired by the Romantic Movement and the French Revolution (Barthel et al. 2005 ). However, clear delineations between urban and rural areas and use of urban green spaces for purely recreational purposes did not emerge until the nineteenth and twentieth centuries, and were reinforced by the development of a globalized economy, the fossil fuel energy regime, and technological innovations such as the steam engine and the railway (McNeill 2000 ;Barthel and Isendahl 2012 ;Barthel et al. 2013 ). Across Swedish cities, urban food production was ubiquitous until the development of the railway network, and the towns were in fact producing 50 % of their food consumption within their boundaries, and some were producing much more. For instance, in the mid-1700s, Uppsala produced more food than the city dwellers themselves consumed and the surplus was exported outside the city (Bj√∂rklund 2009 ). However, the mental models that developed among urban theorists in the beginning of the 1900s soon excluded the rural aspects of life in the city. One example is the Chicago School of urban sociology. Based in ecological theory (cf. Clements 1916 ) and using Chicago as a case study, the Chicago School of urban sociology emerged in the 1920s and 1930s to establish a modernist understanding of urban life as separate from rural life (McDonnell 2011 ). The idea of cities as separate entities essentially detached from their broader life-support systems (Wirth 1938 ) was strongly linked to major innovations in transportation technology as Chicago became an important hub in the U.S. railroad network in the 1850s, and food transportation over great distances became possible. Establishment as a railroad hub enabled Chicago to grow rapidly from a few thousand inhabitants in the 1850s to over two million in the early 1920s. Industrial-era technological innovation, cheap and effi cient travel, and economic growth (opening new markets, speeding up production cycles, and reducing the turnover time of capital) catered for the fi rst wave of space-time compression 1 (Harvey 1990 ). Hence, the modernist ideology underpinning the emergence of urban planning during the early decades of the 1900s distinctly separated local agricultures and other rural dimensions as obsolete in futuristic and normative understandings of the city as an autonomous social system (Barthel and Isendahl 2012 ).	0	Not all of the green space in pre-industrial urban landscapes, however, was used to produce food. For example, open spaces have often been used as religious sites and as cemeteries. In many cities, particularly European, pleasure parks and pleasure gardens for purely recreational uses have also been present in cities since millennia, but these have mainly been the privilege of emperors, kings and other urban elites. In Stockholm, for instance, ordinary citizens were not allowed to enter such parks and gardens until the mid-1700s (#CITATION_TAG et al. 2005 ). The main social drivers that led to a shift toward public use of such green spaces were the rapid urbanization during the industrial revolution, in combination with emerging social values inspired by the Romantic Movement and the French Revolution (Barthel et al. 2005 ). However, clear delineations between urban and rural areas and use of urban green spaces for purely recreational purposes did not emerge until the nineteenth and twentieth centuries, and were reinforced by the development of a globalized economy, the fossil fuel energy regime, and technological innovations such as the steam engine and the railway (McNeill 2000 ;Barthel and Isendahl 2012 ;Barthel et al. 2013 ). Across Swedish cities, urban food production was ubiquitous until the development of the railway network, and the towns were in fact producing 50 % of their food consumption within their boundaries, and some were producing much more.	S
CCT636	"A different type of sprawl characterized the layout of other ancient cities where residences were interspersed among agricultural plots in an extensive low-density continuum surrounding central institutional buildings and monuments. Scholars have identifi ed this settlement structure among the cities of the Khmer of early medieval Cambodia, the classic Maya of Central America, and some precolonial African societies (Evans et al. 2007 ;Scarborough et al. 2012 ;Simon 2008 ). The capital city of the Khmer, Angkor, is well known for its central temples and massive hydraulic works, but it was supported by a vast sprawl of residences, farm plots, local ponds, and an infrastructure that tied together roughly 1,000 km 2 of low density urbanism (Evans et al. 2007 ). Low density urbanism also characterized many of the major Mayan cities, such as Tikal in Guatemala and Caracol in Belize, where major constructions of temples, pyramids and palaces in a central location  were surrounded by a vast spread of housing complexes, agricultural plots, and an infrastructure of roads, causeways, and reservoirs tying them together (Scarborough et al. 2012 ). In both of these cases, agriculture within the broadly defi ned urban boundaries provided a major share of the city""s subsistence; this highlights the ancient roots of the modern revival of urban agriculture (#CITATION_TAG and Isendahl 2012 )."	5	"Scholars have identifi ed this settlement structure among the cities of the Khmer of early medieval Cambodia, the classic Maya of Central America, and some precolonial African societies (Evans et al. 2007 ;Scarborough et al. 2012 ;Simon 2008 ). The capital city of the Khmer, Angkor, is well known for its central temples and massive hydraulic works, but it was supported by a vast sprawl of residences, farm plots, local ponds, and an infrastructure that tied together roughly 1,000 km 2 of low density urbanism (Evans et al. 2007 ). Low density urbanism also characterized many of the major Mayan cities, such as Tikal in Guatemala and Caracol in Belize, where major constructions of temples, pyramids and palaces in a central location  were surrounded by a vast spread of housing complexes, agricultural plots, and an infrastructure of roads, causeways, and reservoirs tying them together (Scarborough et al. 2012 ). In both of these cases, agriculture within the broadly defi ned urban boundaries provided a major share of the city""s subsistence; this highlights the ancient roots of the modern revival of urban agriculture (#CITATION_TAG and Isendahl 2012 )."	o
CCT637	Ancient Mayan Cities . Cities in Meso-America traded a variety of food commodities both short-and long-distance (Dunning 2004 ;Isendahl 2006 ), but seasonally impassable rivers and energetically costly overland transports put a relatively high cost on trade and inhibited bulk-staple exchange (Isendahl 2006(#CITATION_TAG , 2012. Hence, much of the food consumed by the urban Maya Indians came from proximate lands (Isendahl 2006(Isendahl , 2012. For instance, large sectors of fertile soils inside the urban landscape were devoid of settlement constructions, but were used as city infi elds (Isendahl 2012 ). The management of these infi elds in Mayan cities was markedly different from the larger and stateowned farmstead gardens (Barthel and Isendahl 2012 ;Isendahl 2012 ), which were put under tremendous pressure when competition between city-states intensifi ed, a condition which at least partly contributed to the collapse of Mayan cities in the tenth century AD (Tainter 2011 ). The infi elds were used as household farmstead gardens, which concentrated agricultural knowledge and stewardship of the agricultural biodiversity that was the ultimate survival strategy for the populace (Ford and Emery 2008 ). Owing to residential proximity it was most carefully tended, and most carefully fertilized by the organic waste concentrated by city dwellers, and was used for plant breeding, experimentation, and for seed storage (Ford and Nigh 2009 ). The household farmstead garden held the key to a resilient fl ow of urban ecosystem services and provided food security for the population (Barthel and Isendahl 2012 ). Remnant urban ecosystems and the rich levels of biodiversity found in the urban Yucatan today are hence viewed to be the products of a millennia-long co-evolution in cultural landscapes (Ford and Emery 2008 ;Ford and Nigh 2009 ). Constantinople . Different in many respects from Mayan cities, Constantinople, the capital of the Roman cum Byzantine Empire from the fourth century AD until 1453, got its main source of staples of grain from the Nile Valley and was brought in by trading vessels averaging 40-50 tons each in capacity (Balicka-Witakowska 2010 ). Although these supply lines were subjected to the diffi cult winds of the eastern Mediterranean and the fl uctuations of Nile river dynamics, the most severe threats to food security were the sieges and blockades that distinctly cut food-and water-supply lines; these disruptions occurred on average every 65 years during the last 1,000 years (Barthel et al. 2010b ;Barthel and Isendahl 2012 ). The most diffi cult blockade on the food supply lines, at the end of the fourteenth century AD, lasted an astonishing 8 years, but it did not succeed in starving out the urban population (Ljungqvist et al. 2010 ). To accommodate growth and respond to food and water insecurities during such sieges, an additional wall (the Theodosian Wall) was erected 1.5 km westwards of and about a century after the fi rst (continued)	5	Ancient Mayan Cities . Cities in Meso-America traded a variety of food commodities both short-and long-distance (Dunning 2004 ;Isendahl 2006 ), but seasonally impassable rivers and energetically costly overland transports put a relatively high cost on trade and inhibited bulk-staple exchange (Isendahl 2006(#CITATION_TAG , 2012. Hence, much of the food consumed by the urban Maya Indians came from proximate lands (Isendahl 2006(Isendahl , 2012. For instance, large sectors of fertile soils inside the urban landscape were devoid of settlement constructions, but were used as city infi elds (Isendahl 2012 ). The management of these infi elds in Mayan cities was markedly different from the larger and stateowned farmstead gardens (Barthel and Isendahl 2012 ;Isendahl 2012 ), which were put under tremendous pressure when competition between city-states intensifi ed, a condition which at least partly contributed to the collapse of Mayan cities in the tenth century AD (Tainter 2011 ).	A
CCT638	Ancient Mayan Cities . Cities in Meso-America traded a variety of food commodities both short-and long-distance (Dunning 2004 ;Isendahl 2006 ), but seasonally impassable rivers and energetically costly overland transports put a relatively high cost on trade and inhibited bulk-staple exchange (Isendahl 2006(Isendahl , 2012. Hence, much of the food consumed by the urban Maya Indians came from proximate lands (Isendahl 2006(Isendahl , 2012. For instance, large sectors of fertile soils inside the urban landscape were devoid of settlement constructions, but were used as city infi elds (Isendahl 2012 ). The management of these infi elds in Mayan cities was markedly different from the larger and stateowned farmstead gardens (Barthel and Isendahl 2012 ;Isendahl 2012 ), which were put under tremendous pressure when competition between city-states intensifi ed, a condition which at least partly contributed to the collapse of Mayan cities in the tenth century AD (Tainter 2011 ). The infi elds were used as household farmstead gardens, which concentrated agricultural knowledge and stewardship of the agricultural biodiversity that was the ultimate survival strategy for the populace (#CITATION_TAG and Emery 2008 ). Owing to residential proximity it was most carefully tended, and most carefully fertilized by the organic waste concentrated by city dwellers, and was used for plant breeding, experimentation, and for seed storage (Ford and Nigh 2009 ). The household farmstead garden held the key to a resilient fl ow of urban ecosystem services and provided food security for the population (Barthel and Isendahl 2012 ). Remnant urban ecosystems and the rich levels of biodiversity found in the urban Yucatan today are hence viewed to be the products of a millennia-long co-evolution in cultural landscapes (Ford and Emery 2008 ;Ford and Nigh 2009 ). Constantinople . Different in many respects from Mayan cities, Constantinople, the capital of the Roman cum Byzantine Empire from the fourth century AD until 1453, got its main source of staples of grain from the Nile Valley and was brought in by trading vessels averaging 40-50 tons each in capacity (Balicka-Witakowska 2010 ). Although these supply lines were subjected to the diffi cult winds of the eastern Mediterranean and the fl uctuations of Nile river dynamics, the most severe threats to food security were the sieges and blockades that distinctly cut food-and water-supply lines; these disruptions occurred on average every 65 years during the last 1,000 years (Barthel et al. 2010b ;Barthel and Isendahl 2012 ). The most diffi cult blockade on the food supply lines, at the end of the fourteenth century AD, lasted an astonishing 8 years, but it did not succeed in starving out the urban population (Ljungqvist et al. 2010 ). To accommodate growth and respond to food and water insecurities during such sieges, an additional wall (the Theodosian Wall) was erected 1.5 km westwards of and about a century after the fi rst (continued)	0	Hence, much of the food consumed by the urban Maya Indians came from proximate lands (Isendahl 2006(Isendahl , 2012. For instance, large sectors of fertile soils inside the urban landscape were devoid of settlement constructions, but were used as city infi elds (Isendahl 2012 ). The management of these infi elds in Mayan cities was markedly different from the larger and stateowned farmstead gardens (Barthel and Isendahl 2012 ;Isendahl 2012 ), which were put under tremendous pressure when competition between city-states intensifi ed, a condition which at least partly contributed to the collapse of Mayan cities in the tenth century AD (Tainter 2011 ). The infi elds were used as household farmstead gardens, which concentrated agricultural knowledge and stewardship of the agricultural biodiversity that was the ultimate survival strategy for the populace (#CITATION_TAG and Emery 2008 ). Owing to residential proximity it was most carefully tended, and most carefully fertilized by the organic waste concentrated by city dwellers, and was used for plant breeding, experimentation, and for seed storage (Ford and Nigh 2009 ). The household farmstead garden held the key to a resilient fl ow of urban ecosystem services and provided food security for the population (Barthel and Isendahl 2012 ). Remnant urban ecosystems and the rich levels of biodiversity found in the urban Yucatan today are hence viewed to be the products of a millennia-long co-evolution in cultural landscapes (Ford and Emery 2008 ;Ford and Nigh 2009 ).	i
CCT639	Ancient Mayan Cities . Cities in Meso-America traded a variety of food commodities both short-and long-distance (Dunning 2004 ;Isendahl 2006 ), but seasonally impassable rivers and energetically costly overland transports put a relatively high cost on trade and inhibited bulk-staple exchange (Isendahl 2006(Isendahl , 2012. Hence, much of the food consumed by the urban Maya Indians came from proximate lands (Isendahl 2006(Isendahl , 2012. For instance, large sectors of fertile soils inside the urban landscape were devoid of settlement constructions, but were used as city infi elds (Isendahl 2012 ). The management of these infi elds in Mayan cities was markedly different from the larger and stateowned farmstead gardens (Barthel and Isendahl 2012 ;Isendahl 2012 ), which were put under tremendous pressure when competition between city-states intensifi ed, a condition which at least partly contributed to the collapse of Mayan cities in the tenth century AD (Tainter 2011 ). The infi elds were used as household farmstead gardens, which concentrated agricultural knowledge and stewardship of the agricultural biodiversity that was the ultimate survival strategy for the populace (Ford and Emery 2008 ). Owing to residential proximity it was most carefully tended, and most carefully fertilized by the organic waste concentrated by city dwellers, and was used for plant breeding, experimentation, and for seed storage (Ford and Nigh 2009 ). The household farmstead garden held the key to a resilient fl ow of urban ecosystem services and provided food security for the population (Barthel and Isendahl 2012 ). Remnant urban ecosystems and the rich levels of biodiversity found in the urban Yucatan today are hence viewed to be the products of a millennia-long co-evolution in cultural landscapes (Ford and Emery 2008 ;Ford and Nigh 2009 ). Constantinople . Different in many respects from Mayan cities, Constantinople, the capital of the Roman cum Byzantine Empire from the fourth century AD until 1453, got its main source of staples of grain from the Nile Valley and was brought in by trading vessels averaging 40-50 tons each in capacity (Balicka-Witakowska 2010 ). Although these supply lines were subjected to the diffi cult winds of the eastern Mediterranean and the fl uctuations of Nile river dynamics, the most severe threats to food security were the sieges and blockades that distinctly cut food-and water-supply lines; these disruptions occurred on average every 65 years during the last 1,000 years (Barthel et al. 2010b ;Barthel and Isendahl 2012 ). The most diffi cult blockade on the food supply lines, at the end of the fourteenth century AD, lasted an astonishing 8 years, but it did not succeed in starving out the urban population (#CITATION_TAG et al. 2010 ). To accommodate growth and respond to food and water insecurities during such sieges, an additional wall (the Theodosian Wall) was erected 1.5 km westwards of and about a century after the fi rst (continued)	0	Remnant urban ecosystems and the rich levels of biodiversity found in the urban Yucatan today are hence viewed to be the products of a millennia-long co-evolution in cultural landscapes (Ford and Emery 2008 ;Ford and Nigh 2009 ). Constantinople . Different in many respects from Mayan cities, Constantinople, the capital of the Roman cum Byzantine Empire from the fourth century AD until 1453, got its main source of staples of grain from the Nile Valley and was brought in by trading vessels averaging 40-50 tons each in capacity (Balicka-Witakowska 2010 ). Although these supply lines were subjected to the diffi cult winds of the eastern Mediterranean and the fl uctuations of Nile river dynamics, the most severe threats to food security were the sieges and blockades that distinctly cut food-and water-supply lines; these disruptions occurred on average every 65 years during the last 1,000 years (Barthel et al. 2010b ;Barthel and Isendahl 2012 ). The most diffi cult blockade on the food supply lines, at the end of the fourteenth century AD, lasted an astonishing 8 years, but it did not succeed in starving out the urban population (#CITATION_TAG et al. 2010 ). To accommodate growth and respond to food and water insecurities during such sieges, an additional wall (the Theodosian Wall) was erected 1.5 km westwards of and about a century after the fi rst (continued)	i
CCT640	"A different type of sprawl characterized the layout of other ancient cities where residences were interspersed among agricultural plots in an extensive low-density continuum surrounding central institutional buildings and monuments. Scholars have identifi ed this settlement structure among the cities of the Khmer of early medieval Cambodia, the classic Maya of Central America, and some precolonial African societies (#CITATION_TAG et al. 2007 ;Scarborough et al. 2012 ;Simon 2008 ). The capital city of the Khmer, Angkor, is well known for its central temples and massive hydraulic works, but it was supported by a vast sprawl of residences, farm plots, local ponds, and an infrastructure that tied together roughly 1,000 km 2 of low density urbanism (Evans et al. 2007 ). Low density urbanism also characterized many of the major Mayan cities, such as Tikal in Guatemala and Caracol in Belize, where major constructions of temples, pyramids and palaces in a central location  were surrounded by a vast spread of housing complexes, agricultural plots, and an infrastructure of roads, causeways, and reservoirs tying them together (Scarborough et al. 2012 ). In both of these cases, agriculture within the broadly defi ned urban boundaries provided a major share of the city""s subsistence; this highlights the ancient roots of the modern revival of urban agriculture (Barthel and Isendahl 2012 )."	0	"A different type of sprawl characterized the layout of other ancient cities where residences were interspersed among agricultural plots in an extensive low-density continuum surrounding central institutional buildings and monuments. Scholars have identifi ed this settlement structure among the cities of the Khmer of early medieval Cambodia, the classic Maya of Central America, and some precolonial African societies (#CITATION_TAG et al. 2007 ;Scarborough et al. 2012 ;Simon 2008 ). The capital city of the Khmer, Angkor, is well known for its central temples and massive hydraulic works, but it was supported by a vast sprawl of residences, farm plots, local ponds, and an infrastructure that tied together roughly 1,000 km 2 of low density urbanism (Evans et al. 2007 ). Low density urbanism also characterized many of the major Mayan cities, such as Tikal in Guatemala and Caracol in Belize, where major constructions of temples, pyramids and palaces in a central location  were surrounded by a vast spread of housing complexes, agricultural plots, and an infrastructure of roads, causeways, and reservoirs tying them together (Scarborough et al. 2012 ). In both of these cases, agriculture within the broadly defi ned urban boundaries provided a major share of the city""s subsistence; this highlights the ancient roots of the modern revival of urban agriculture (Barthel and Isendahl 2012 )."	c
CCT641	History offers many lessons relevant to sustainability by exhibiting how humans and their societies have recognized and responded to challenges and opportunities of their natural environment (Redman 1999 ;#CITATION_TAG 2005 ;Costanza et al. 2007a ;Sinclair et al. 2010 ). Three of the basic approaches to problem solving in antiquity were: (1) mobility of people to available resources, (2) ecosystem management to secure enhanced local growth of produce, and (3) increasing social complexity encoded in formal institutions that guided an expanding range of activities. These solution pathways were fundamental to the rise of early civilizations and are instrumental for integration in the design of sustainable cities in the future (Redman 2011 ).	0	History offers many lessons relevant to sustainability by exhibiting how humans and their societies have recognized and responded to challenges and opportunities of their natural environment (Redman 1999 ;#CITATION_TAG 2005 ;Costanza et al. 2007a ;Sinclair et al. 2010 ). Three of the basic approaches to problem solving in antiquity were: (1) mobility of people to available resources, (2) ecosystem management to secure enhanced local growth of produce, and (3) increasing social complexity encoded in formal institutions that guided an expanding range of activities. These solution pathways were fundamental to the rise of early civilizations and are instrumental for integration in the design of sustainable cities in the future (Redman 2011 ).	H
CCT642	"To achieve sustainability, we must incorporate natural capital (and the ecosystem goods and services that it provides) into our economic and social accounting and our systems of social choice. Ecosystem services are defi ned as, ""the direct and indirect benefi ts people obtain from ecosystems"" (#CITATION_TAG et al. 1997b ; Millennium Ecosystem Assessment 2005 ) (Chap. 11 ). These include provisioning services such as food, water and medicinal plants; regulating services such as air quality regulation, water purifi cation, regulation of fl oods, drought, and disease; supporting services such as soil formation and nutrient cycling; and cultural services such as recreational, scientifi c and spiritual benefi ts (Costanza et al. 1997b ;Daily 1997 ;de Groot et al. 2002de Groot et al. , 2010. People in cities benefi t from ecosystem services at a number of spatial and temporal scales (Chap. 11 ). Urban residents could not survive without these life support services and it is therefore necessary to take a comprehensive, integrated, multi-scale approach to what constitutes urban infrastructure and assets. It is not just the built capital of cities that we need to consider. It is the full spectrum of assets including social and natural capital at local, regional, national, and global scales."	0	"To achieve sustainability, we must incorporate natural capital (and the ecosystem goods and services that it provides) into our economic and social accounting and our systems of social choice. Ecosystem services are defi ned as, ""the direct and indirect benefi ts people obtain from ecosystems"" (#CITATION_TAG et al. 1997b ; Millennium Ecosystem Assessment 2005 ) (Chap. 11 ). These include provisioning services such as food, water and medicinal plants; regulating services such as air quality regulation, water purifi cation, regulation of fl oods, drought, and disease; supporting services such as soil formation and nutrient cycling; and cultural services such as recreational, scientifi c and spiritual benefi ts (Costanza et al. 1997b ;Daily 1997 ;de Groot et al. 2002de Groot et al. , 2010. People in cities benefi t from ecosystem services at a number of spatial and temporal scales (Chap."	c
CCT643	"During the previously described long stretch of history, societies and economies were not growing very quickly (Fig. 2.1 ). However, since the beginning of the industrial revolution, and especially after the start of the ""great acceleration"" following the end of WWII, there has been rapid economic expansion coupled with rapid urban growth-all driven by rapid expansion of fossil fuel use, especially oil (Costanza et al. 2007b ). Indeed, one of the hallmarks of contemporary urbanization is that urban areas are growing faster and larger than they did in the past as well in new geographic locations (Seto et al. 2012b ) (Chap. 21 ). Current mainstream concepts and models of the economy were developed in this period of rapid expansion as if the world we lived in had unlimited capacity for growth in the material economy. In this ""empty world"" context, built capital -the houses, roads, and factoriesthings that are concentrated in cities-was the limiting factor to improving human well-being. Natural capital -our ecological life support system-and social capitalour myriad relationships with each other-were viewed to be abundant (#CITATION_TAG et al. 1997a ). It made sense in this context not to worry too much about environmental and social ""externalities"" -effects that occurred outside the market-since they could be assumed to be relatively small and ultimately solvable. Instead, the focus was on the growth of the market economy, as measured by Gross Domestic Product (GDP), as a primary means to improve human welfare. The dominant thinking categorized the economy as only marketed goods and services and the goal of society was simply increasing the amount of these goods and services produced and consumed (Costanza et al. 1997a ). We now live in an interconnected global system that is relatively full of humans and their artifacts (Fig. 2.1 ) in what some are even calling a new geologic era-the ""Anthropocene"" (Crutzen 2002 ;Steffen et al. 2011 )-and have shifted into a human-dominated planet and into a new full-world context (Daly 2005 ). Some have also argued that we have already moved beyond the ""Anthropocene"" into the new urban era (Seto et al. 2010 ;Ljungqvist et al. 2010 ). Now we have to think differently about the relationship between humans and the rest of nature. If we seek ""improved human well-being and social equity, while signifi cantly reducing environmental risks and ecological scarcities,"" as the UN has recently proclaimed as the primary global goal (UNEP 2011 ), we will need a new vision of the economy and of cities and their relationship to the rest of the world that is better adapted to the new conditions we face. We will require a vision of the economy and urbanization that reintroduces the ecology of the urban. Material consumption and GDP are merely means to that end, not ends in themselves, and we need to better understand what really does contribute to sustainable human well-being (SHW), and recognize the substantial contributions of natural and social capital, which are now the limiting factors to improving SHW in many countries. We must be able to distinguish between real poverty in terms of low SHW and merely low monetary income."	0	"21 ). Current mainstream concepts and models of the economy were developed in this period of rapid expansion as if the world we lived in had unlimited capacity for growth in the material economy. In this ""empty world"" context, built capital -the houses, roads, and factoriesthings that are concentrated in cities-was the limiting factor to improving human well-being. Natural capital -our ecological life support system-and social capitalour myriad relationships with each other-were viewed to be abundant (#CITATION_TAG et al. 1997a ). It made sense in this context not to worry too much about environmental and social ""externalities"" -effects that occurred outside the market-since they could be assumed to be relatively small and ultimately solvable. Instead, the focus was on the growth of the market economy, as measured by Gross Domestic Product (GDP), as a primary means to improve human welfare. The dominant thinking categorized the economy as only marketed goods and services and the goal of society was simply increasing the amount of these goods and services produced and consumed (Costanza et al. 1997a )."	l
CCT644	"The landscape-productivity-human relationship evolved in villages and towns; this enabled the growth of large, diverse populations that would aggregate into what are now called cities. The cities of antiquity in Mesopotamia and other regions responded to the specifi c opportunities and constraints of their local social and ecological environment, yet general patterns emerged that share commonality with contemporary cities and may provide useful insights (#CITATION_TAG 2008 ;Smith 2012 ). The hallmarks of cities are: (a) a large population that (b) aggregates in a central location with (c) buildings and monuments that (d) represent institutions that organize and facilitate productivity. From the earliest times in Mesopotamia and in other regions, aggregations of people and their wealth have been threatened by military hostilities and they have repeatedly sought refuge behind strong defensive fortifi cations (Redman 1978 ). This has led to densely packed cities behind defensive walls, but at the same time growing rural to urban migration has led to settlements spreading outside the walls, a phenomenon that today one might call sprawl. This pattern of densely packed housing and central institutions within the walls, and residential settlement spreading far beyond the walls was frequent in the Near East, Asia, and Medieval Europe (Boone and Modarres 2006 ). In fact, Marco Polo reported that around the Mongol capital that would eventually become Beijing, ""There is a suburb outside each of the gates, which are 12 in number, and these suburbs are so great that they contain more people than the city itself"" (reported in ."	5	The landscape-productivity-human relationship evolved in villages and towns; this enabled the growth of large, diverse populations that would aggregate into what are now called cities. The cities of antiquity in Mesopotamia and other regions responded to the specifi c opportunities and constraints of their local social and ecological environment, yet general patterns emerged that share commonality with contemporary cities and may provide useful insights (#CITATION_TAG 2008 ;Smith 2012 ). The hallmarks of cities are: (a) a large population that (b) aggregates in a central location with (c) buildings and monuments that (d) represent institutions that organize and facilitate productivity. From the earliest times in Mesopotamia and in other regions, aggregations of people and their wealth have been threatened by military hostilities and they have repeatedly sought refuge behind strong defensive fortifi cations (Redman 1978 ). This has led to densely packed cities behind defensive walls, but at the same time growing rural to urban migration has led to settlements spreading outside the walls, a phenomenon that today one might call sprawl.	h
CCT645	Not all of the green space in pre-industrial urban landscapes, however, was used to produce food. For example, open spaces have often been used as religious sites and as cemeteries. In many cities, particularly European, pleasure parks and pleasure gardens for purely recreational uses have also been present in cities since millennia, but these have mainly been the privilege of emperors, kings and other urban elites. In Stockholm, for instance, ordinary citizens were not allowed to enter such parks and gardens until the mid-1700s (Barthel et al. 2005 ). The main social drivers that led to a shift toward public use of such green spaces were the rapid urbanization during the industrial revolution, in combination with emerging social values inspired by the Romantic Movement and the French Revolution (Barthel et al. 2005 ). However, clear delineations between urban and rural areas and use of urban green spaces for purely recreational purposes did not emerge until the nineteenth and twentieth centuries, and were reinforced by the development of a globalized economy, the fossil fuel energy regime, and technological innovations such as the steam engine and the railway (McNeill 2000 ;Barthel and Isendahl 2012 ;Barthel et al. 2013 ). Across Swedish cities, urban food production was ubiquitous until the development of the railway network, and the towns were in fact producing 50 % of their food consumption within their boundaries, and some were producing much more. For instance, in the mid-1700s, Uppsala produced more food than the city dwellers themselves consumed and the surplus was exported outside the city (Bj√∂rklund 2009 ). However, the mental models that developed among urban theorists in the beginning of the 1900s soon excluded the rural aspects of life in the city. One example is the Chicago School of urban sociology. Based in ecological theory (cf. Clements 1916 ) and using Chicago as a case study, the Chicago School of urban sociology emerged in the 1920s and 1930s to establish a modernist understanding of urban life as separate from rural life (McDonnell 2011 ). The idea of cities as separate entities essentially detached from their broader life-support systems (#CITATION_TAG 1938 ) was strongly linked to major innovations in transportation technology as Chicago became an important hub in the U.S. railroad network in the 1850s, and food transportation over great distances became possible. Establishment as a railroad hub enabled Chicago to grow rapidly from a few thousand inhabitants in the 1850s to over two million in the early 1920s. Industrial-era technological innovation, cheap and effi cient travel, and economic growth (opening new markets, speeding up production cycles, and reducing the turnover time of capital) catered for the fi rst wave of space-time compression 1 (Harvey 1990 ). Hence, the modernist ideology underpinning the emergence of urban planning during the early decades of the 1900s distinctly separated local agricultures and other rural dimensions as obsolete in futuristic and normative understandings of the city as an autonomous social system (Barthel and Isendahl 2012 ).	0	However, the mental models that developed among urban theorists in the beginning of the 1900s soon excluded the rural aspects of life in the city. One example is the Chicago School of urban sociology. Based in ecological theory (cf. Clements 1916 ) and using Chicago as a case study, the Chicago School of urban sociology emerged in the 1920s and 1930s to establish a modernist understanding of urban life as separate from rural life (McDonnell 2011 ). The idea of cities as separate entities essentially detached from their broader life-support systems (#CITATION_TAG 1938 ) was strongly linked to major innovations in transportation technology as Chicago became an important hub in the U.S. railroad network in the 1850s, and food transportation over great distances became possible. Establishment as a railroad hub enabled Chicago to grow rapidly from a few thousand inhabitants in the 1850s to over two million in the early 1920s. Industrial-era technological innovation, cheap and effi cient travel, and economic growth (opening new markets, speeding up production cycles, and reducing the turnover time of capital) catered for the fi rst wave of space-time compression 1 (Harvey 1990 ). Hence, the modernist ideology underpinning the emergence of urban planning during the early decades of the 1900s distinctly separated local agricultures and other rural dimensions as obsolete in futuristic and normative understandings of the city as an autonomous social system (Barthel and Isendahl 2012 ).	 
CCT646	Although there is great variation between different urban histories, large numbers of people aggregating into cities generally allowed for specialization of labor and other effi ciencies of scale. This often generated the outcome that a large proportion of urban people were no longer self-suffi cient in food production and hence, a greater proportion of people elsewhere in rural areas were be responsible for growing food for themselves, for the people in the city, and enough to monetarily offset the cost of transport and distribution. This put a tremendous burden on rural farming communities to produce much more than they would if solely working to supply enough for themselves. As the societal roles of the urban and rural populations grew increasingly different and complex, the objectives and understandings of these populations changed as well. Farmers experienced a shift away from traditional practices of the earlier village-farming era, in which they would have more intimately understood the landscape and productive systems and would have been inclined toward conservation practices wherein they balanced extractive activities with the regenerative capabilities of the land. The urban elite also experienced a shift away from traditional subsistence practices, and began to focus on the net produce they were able to extract from the countryside (or urban industries) and insisted on maximum production with little knowledge of, or concern for, the potential deleterious effects on the rural landscape (#CITATION_TAG and Adams 1958 ;Redman 1999 ). However, the disregard for local dynamics of ecological integrity was not simply the product of urban demand; rural land owners, and national and transnational agricultural businesses were also instrumental in the alienation of food production from the carrying capacity of land. The rise of population that the enhanced production of food facilitated was not accompanied by innovation in trans-locational governance or in governance regimes that integrated cities and their hinterlands. In an ideal hierarchical society, even though decision-making authority would be concentrated at the top, one could assume that knowledge would travel up the hierarchy, and that informed decisions and concern would be displayed by decisions that traveled down the hierarchy. This was, however, seldom the case, and rather the dominant pattern was of maximizing short-term returns with little concern for long-term consequences. In many instances, archaeological evidence attests to the intense environmental degradation in the regions around ancient cities, and one can see the impact of urban demand on the rural countryside continuing today (Diamond 2005 ;Redman 1999 ) (Fig. 2.2 ). In Chap s. 22 and 26 , we highlight the impact of the rising urban demand for food that is resulting in a competition for agricultural land; this competition is a global trend in land use that is largely unregulated.	0	This put a tremendous burden on rural farming communities to produce much more than they would if solely working to supply enough for themselves. As the societal roles of the urban and rural populations grew increasingly different and complex, the objectives and understandings of these populations changed as well. Farmers experienced a shift away from traditional practices of the earlier village-farming era, in which they would have more intimately understood the landscape and productive systems and would have been inclined toward conservation practices wherein they balanced extractive activities with the regenerative capabilities of the land. The urban elite also experienced a shift away from traditional subsistence practices, and began to focus on the net produce they were able to extract from the countryside (or urban industries) and insisted on maximum production with little knowledge of, or concern for, the potential deleterious effects on the rural landscape (#CITATION_TAG and Adams 1958 ;Redman 1999 ). However, the disregard for local dynamics of ecological integrity was not simply the product of urban demand; rural land owners, and national and transnational agricultural businesses were also instrumental in the alienation of food production from the carrying capacity of land. The rise of population that the enhanced production of food facilitated was not accompanied by innovation in trans-locational governance or in governance regimes that integrated cities and their hinterlands. In an ideal hierarchical society, even though decision-making authority would be concentrated at the top, one could assume that knowledge would travel up the hierarchy, and that informed decisions and concern would be displayed by decisions that traveled down the hierarchy.	r
CCT647	Urban green infrastructures, often rich in species, are, in most parts of the world, remnants of domesticated landscapes with a long-term history of land use. There are exceptions to this in regions that do not have a long-term history of agriculture, for example in parts of Oceania, South Africa and North America. It is in the cultural landscapes that biodiversity and ecosystem services are produced, and over which growing cities expand (#CITATION_TAG et al. 2009 ). Habitat legacies include long-lived species, meadows, gardens, ponds, agroforestry areas, satoyama systems, hedges, and	0	Urban green infrastructures, often rich in species, are, in most parts of the world, remnants of domesticated landscapes with a long-term history of land use. There are exceptions to this in regions that do not have a long-term history of agriculture, for example in parts of Oceania, South Africa and North America. It is in the cultural landscapes that biodiversity and ecosystem services are produced, and over which growing cities expand (#CITATION_TAG et al. 2009 ). Habitat legacies include long-lived species, meadows, gardens, ponds, agroforestry areas, satoyama systems, hedges, and	 
CCT648	"During the previously described long stretch of history, societies and economies were not growing very quickly (Fig. 2.1 ). However, since the beginning of the industrial revolution, and especially after the start of the ""great acceleration"" following the end of WWII, there has been rapid economic expansion coupled with rapid urban growth-all driven by rapid expansion of fossil fuel use, especially oil (Costanza et al. 2007b ). Indeed, one of the hallmarks of contemporary urbanization is that urban areas are growing faster and larger than they did in the past as well in new geographic locations (Seto et al. 2012b ) (Chap. 21 ). Current mainstream concepts and models of the economy were developed in this period of rapid expansion as if the world we lived in had unlimited capacity for growth in the material economy. In this ""empty world"" context, built capital -the houses, roads, and factoriesthings that are concentrated in cities-was the limiting factor to improving human well-being. Natural capital -our ecological life support system-and social capitalour myriad relationships with each other-were viewed to be abundant (Costanza et al. 1997a ). It made sense in this context not to worry too much about environmental and social ""externalities"" -effects that occurred outside the market-since they could be assumed to be relatively small and ultimately solvable. Instead, the focus was on the growth of the market economy, as measured by Gross Domestic Product (GDP), as a primary means to improve human welfare. The dominant thinking categorized the economy as only marketed goods and services and the goal of society was simply increasing the amount of these goods and services produced and consumed (Costanza et al. 1997a ). We now live in an interconnected global system that is relatively full of humans and their artifacts (Fig. 2.1 ) in what some are even calling a new geologic era-the ""Anthropocene"" (Crutzen 2002 ;#CITATION_TAG et al. 2011 )-and have shifted into a human-dominated planet and into a new full-world context (Daly 2005 ). Some have also argued that we have already moved beyond the ""Anthropocene"" into the new urban era (Seto et al. 2010 ;Ljungqvist et al. 2010 ). Now we have to think differently about the relationship between humans and the rest of nature. If we seek ""improved human well-being and social equity, while signifi cantly reducing environmental risks and ecological scarcities,"" as the UN has recently proclaimed as the primary global goal (UNEP 2011 ), we will need a new vision of the economy and of cities and their relationship to the rest of the world that is better adapted to the new conditions we face. We will require a vision of the economy and urbanization that reintroduces the ecology of the urban. Material consumption and GDP are merely means to that end, not ends in themselves, and we need to better understand what really does contribute to sustainable human well-being (SHW), and recognize the substantial contributions of natural and social capital, which are now the limiting factors to improving SHW in many countries. We must be able to distinguish between real poverty in terms of low SHW and merely low monetary income."	4	"It made sense in this context not to worry too much about environmental and social ""externalities"" -effects that occurred outside the market-since they could be assumed to be relatively small and ultimately solvable. Instead, the focus was on the growth of the market economy, as measured by Gross Domestic Product (GDP), as a primary means to improve human welfare. The dominant thinking categorized the economy as only marketed goods and services and the goal of society was simply increasing the amount of these goods and services produced and consumed (Costanza et al. 1997a ). We now live in an interconnected global system that is relatively full of humans and their artifacts (Fig. 2.1 ) in what some are even calling a new geologic era-the ""Anthropocene"" (Crutzen 2002 ;#CITATION_TAG et al. 2011 )-and have shifted into a human-dominated planet and into a new full-world context (Daly 2005 ). Some have also argued that we have already moved beyond the ""Anthropocene"" into the new urban era (Seto et al. 2010 ;Ljungqvist et al. 2010 ). Now we have to think differently about the relationship between humans and the rest of nature. If we seek ""improved human well-being and social equity, while signifi cantly reducing environmental risks and ecological scarcities,"" as the UN has recently proclaimed as the primary global goal (UNEP 2011 ), we will need a new vision of the economy and of cities and their relationship to the rest of the world that is better adapted to the new conditions we face."	e
CCT649	"The landscape-productivity-human relationship evolved in villages and towns; this enabled the growth of large, diverse populations that would aggregate into what are now called cities. The cities of antiquity in Mesopotamia and other regions responded to the specifi c opportunities and constraints of their local social and ecological environment, yet general patterns emerged that share commonality with contemporary cities and may provide useful insights (Simon 2008 ;#CITATION_TAG 2012 ). The hallmarks of cities are: (a) a large population that (b) aggregates in a central location with (c) buildings and monuments that (d) represent institutions that organize and facilitate productivity. From the earliest times in Mesopotamia and in other regions, aggregations of people and their wealth have been threatened by military hostilities and they have repeatedly sought refuge behind strong defensive fortifi cations (Redman 1978 ). This has led to densely packed cities behind defensive walls, but at the same time growing rural to urban migration has led to settlements spreading outside the walls, a phenomenon that today one might call sprawl. This pattern of densely packed housing and central institutions within the walls, and residential settlement spreading far beyond the walls was frequent in the Near East, Asia, and Medieval Europe (Boone and Modarres 2006 ). In fact, Marco Polo reported that around the Mongol capital that would eventually become Beijing, ""There is a suburb outside each of the gates, which are 12 in number, and these suburbs are so great that they contain more people than the city itself"" (reported in ."	0	The landscape-productivity-human relationship evolved in villages and towns; this enabled the growth of large, diverse populations that would aggregate into what are now called cities. The cities of antiquity in Mesopotamia and other regions responded to the specifi c opportunities and constraints of their local social and ecological environment, yet general patterns emerged that share commonality with contemporary cities and may provide useful insights (Simon 2008 ;#CITATION_TAG 2012 ). The hallmarks of cities are: (a) a large population that (b) aggregates in a central location with (c) buildings and monuments that (d) represent institutions that organize and facilitate productivity. From the earliest times in Mesopotamia and in other regions, aggregations of people and their wealth have been threatened by military hostilities and they have repeatedly sought refuge behind strong defensive fortifi cations (Redman 1978 ). This has led to densely packed cities behind defensive walls, but at the same time growing rural to urban migration has led to settlements spreading outside the walls, a phenomenon that today one might call sprawl.	h
CCT650	"Examining events and processes in the past often will provide useful insights into the origin of driving forces that impact cities today. However, the productive relationships that underlie the growth and success of cities may at the same time lead to relationships that are maladaptive, creating increased long term risks. For example, the concept of private property emerged to replace weak sense of ownership, lack of ownership, and/or the concept of community ownership. Farmers were increasingly able both to produce more food than their family required and they found ways to store this surplus for trade or for guarding against future bad harvests. However, one could only eat so much and a variety of factors limited the amount of food that could be effectively stored, including the ability of landlords and elites to appropriate some of the surplus through taxes. Hence the stimulus to produce a surplus remained limited in most farming villages. What changed this relationship, and is key to the growth of urban society, is the ability to transform locally produced surplus food into enduring prestige items associated with elevated status. This could only take place under a new social order that acknowledged classes with differential wealth, access to productive resources, power, and status. The promulgation of such a social order required an ideology (through religion, myth, constructed history, and/or law) that legitimized the existence of elite classes and the precious goods that helped to identify them. Of signifi cant importance was that along with the evolution of private property, surplus production, elite goods, and hierarchical class society, the inheritance for membership in these classes and ownership of precious goods became more often defi ned by family and clan rather than merit. Strength, agility, and intelligence certainly were important, but which family, clan, and class one was born into set the limits on one""s future potential in the age of early cities; to some extent, these constraints continue to operate today (Adams 1966 ;Prahalad 2005 ;#CITATION_TAG 1998 )."	0	"This could only take place under a new social order that acknowledged classes with differential wealth, access to productive resources, power, and status. The promulgation of such a social order required an ideology (through religion, myth, constructed history, and/or law) that legitimized the existence of elite classes and the precious goods that helped to identify them. Of signifi cant importance was that along with the evolution of private property, surplus production, elite goods, and hierarchical class society, the inheritance for membership in these classes and ownership of precious goods became more often defi ned by family and clan rather than merit. Strength, agility, and intelligence certainly were important, but which family, clan, and class one was born into set the limits on one""s future potential in the age of early cities; to some extent, these constraints continue to operate today (Adams 1966 ;Prahalad 2005 ;#CITATION_TAG 1998 )."	a
CCT651	Not all of the green space in pre-industrial urban landscapes, however, was used to produce food. For example, open spaces have often been used as religious sites and as cemeteries. In many cities, particularly European, pleasure parks and pleasure gardens for purely recreational uses have also been present in cities since millennia, but these have mainly been the privilege of emperors, kings and other urban elites. In Stockholm, for instance, ordinary citizens were not allowed to enter such parks and gardens until the mid-1700s (Barthel et al. 2005 ). The main social drivers that led to a shift toward public use of such green spaces were the rapid urbanization during the industrial revolution, in combination with emerging social values inspired by the Romantic Movement and the French Revolution (Barthel et al. 2005 ). However, clear delineations between urban and rural areas and use of urban green spaces for purely recreational purposes did not emerge until the nineteenth and twentieth centuries, and were reinforced by the development of a globalized economy, the fossil fuel energy regime, and technological innovations such as the steam engine and the railway (#CITATION_TAG 2000 ;Barthel and Isendahl 2012 ;Barthel et al. 2013 ). Across Swedish cities, urban food production was ubiquitous until the development of the railway network, and the towns were in fact producing 50 % of their food consumption within their boundaries, and some were producing much more. For instance, in the mid-1700s, Uppsala produced more food than the city dwellers themselves consumed and the surplus was exported outside the city (Bj√∂rklund 2009 ). However, the mental models that developed among urban theorists in the beginning of the 1900s soon excluded the rural aspects of life in the city. One example is the Chicago School of urban sociology. Based in ecological theory (cf. Clements 1916 ) and using Chicago as a case study, the Chicago School of urban sociology emerged in the 1920s and 1930s to establish a modernist understanding of urban life as separate from rural life (McDonnell 2011 ). The idea of cities as separate entities essentially detached from their broader life-support systems (Wirth 1938 ) was strongly linked to major innovations in transportation technology as Chicago became an important hub in the U.S. railroad network in the 1850s, and food transportation over great distances became possible. Establishment as a railroad hub enabled Chicago to grow rapidly from a few thousand inhabitants in the 1850s to over two million in the early 1920s. Industrial-era technological innovation, cheap and effi cient travel, and economic growth (opening new markets, speeding up production cycles, and reducing the turnover time of capital) catered for the fi rst wave of space-time compression 1 (Harvey 1990 ). Hence, the modernist ideology underpinning the emergence of urban planning during the early decades of the 1900s distinctly separated local agricultures and other rural dimensions as obsolete in futuristic and normative understandings of the city as an autonomous social system (Barthel and Isendahl 2012 ).	0	In many cities, particularly European, pleasure parks and pleasure gardens for purely recreational uses have also been present in cities since millennia, but these have mainly been the privilege of emperors, kings and other urban elites. In Stockholm, for instance, ordinary citizens were not allowed to enter such parks and gardens until the mid-1700s (Barthel et al. 2005 ). The main social drivers that led to a shift toward public use of such green spaces were the rapid urbanization during the industrial revolution, in combination with emerging social values inspired by the Romantic Movement and the French Revolution (Barthel et al. 2005 ). However, clear delineations between urban and rural areas and use of urban green spaces for purely recreational purposes did not emerge until the nineteenth and twentieth centuries, and were reinforced by the development of a globalized economy, the fossil fuel energy regime, and technological innovations such as the steam engine and the railway (#CITATION_TAG 2000 ;Barthel and Isendahl 2012 ;Barthel et al. 2013 ). Across Swedish cities, urban food production was ubiquitous until the development of the railway network, and the towns were in fact producing 50 % of their food consumption within their boundaries, and some were producing much more. For instance, in the mid-1700s, Uppsala produced more food than the city dwellers themselves consumed and the surplus was exported outside the city (Bj√∂rklund 2009 ). However, the mental models that developed among urban theorists in the beginning of the 1900s soon excluded the rural aspects of life in the city.	e
CCT652	"We can expect many ecosystem services to go almost unnoticed by the vast majority of people, especially when they are public, non-excludable services that never enter the private, excludable market. Conventional economic valuation presumes that people have well-formed preferences and enough information about trade-offs that they can adequately judge their ""willingness-to-pay. Since these assumptions do not hold for many ecosystem services (#CITATION_TAG et al. 1998 ) we must either:"	1	"We can expect many ecosystem services to go almost unnoticed by the vast majority of people, especially when they are public, non-excludable services that never enter the private, excludable market. Conventional economic valuation presumes that people have well-formed preferences and enough information about trade-offs that they can adequately judge their ""willingness-to-pay. Since these assumptions do not hold for many ecosystem services (#CITATION_TAG et al. 1998 ) we must either:"	n
CCT653	"Examining events and processes in the past often will provide useful insights into the origin of driving forces that impact cities today. However, the productive relationships that underlie the growth and success of cities may at the same time lead to relationships that are maladaptive, creating increased long term risks. For example, the concept of private property emerged to replace weak sense of ownership, lack of ownership, and/or the concept of community ownership. Farmers were increasingly able both to produce more food than their family required and they found ways to store this surplus for trade or for guarding against future bad harvests. However, one could only eat so much and a variety of factors limited the amount of food that could be effectively stored, including the ability of landlords and elites to appropriate some of the surplus through taxes. Hence the stimulus to produce a surplus remained limited in most farming villages. What changed this relationship, and is key to the growth of urban society, is the ability to transform locally produced surplus food into enduring prestige items associated with elevated status. This could only take place under a new social order that acknowledged classes with differential wealth, access to productive resources, power, and status. The promulgation of such a social order required an ideology (through religion, myth, constructed history, and/or law) that legitimized the existence of elite classes and the precious goods that helped to identify them. Of signifi cant importance was that along with the evolution of private property, surplus production, elite goods, and hierarchical class society, the inheritance for membership in these classes and ownership of precious goods became more often defi ned by family and clan rather than merit. Strength, agility, and intelligence certainly were important, but which family, clan, and class one was born into set the limits on one""s future potential in the age of early cities; to some extent, these constraints continue to operate today (Adams 1966 ;#CITATION_TAG 2005 ;Scott 1998 )."	0	"This could only take place under a new social order that acknowledged classes with differential wealth, access to productive resources, power, and status. The promulgation of such a social order required an ideology (through religion, myth, constructed history, and/or law) that legitimized the existence of elite classes and the precious goods that helped to identify them. Of signifi cant importance was that along with the evolution of private property, surplus production, elite goods, and hierarchical class society, the inheritance for membership in these classes and ownership of precious goods became more often defi ned by family and clan rather than merit. Strength, agility, and intelligence certainly were important, but which family, clan, and class one was born into set the limits on one""s future potential in the age of early cities; to some extent, these constraints continue to operate today (Adams 1966 ;#CITATION_TAG 2005 ;Scott 1998 )."	a
CCT654	"The landscape-productivity-human relationship evolved in villages and towns; this enabled the growth of large, diverse populations that would aggregate into what are now called cities. The cities of antiquity in Mesopotamia and other regions responded to the specifi c opportunities and constraints of their local social and ecological environment, yet general patterns emerged that share commonality with contemporary cities and may provide useful insights (Simon 2008 ;Smith 2012 ). The hallmarks of cities are: (a) a large population that (b) aggregates in a central location with (c) buildings and monuments that (d) represent institutions that organize and facilitate productivity. From the earliest times in Mesopotamia and in other regions, aggregations of people and their wealth have been threatened by military hostilities and they have repeatedly sought refuge behind strong defensive fortifi cations (#CITATION_TAG 1978 ). This has led to densely packed cities behind defensive walls, but at the same time growing rural to urban migration has led to settlements spreading outside the walls, a phenomenon that today one might call sprawl. This pattern of densely packed housing and central institutions within the walls, and residential settlement spreading far beyond the walls was frequent in the Near East, Asia, and Medieval Europe (Boone and Modarres 2006 ). In fact, Marco Polo reported that around the Mongol capital that would eventually become Beijing, ""There is a suburb outside each of the gates, which are 12 in number, and these suburbs are so great that they contain more people than the city itself"" (reported in ."	0	"The landscape-productivity-human relationship evolved in villages and towns; this enabled the growth of large, diverse populations that would aggregate into what are now called cities. The cities of antiquity in Mesopotamia and other regions responded to the specifi c opportunities and constraints of their local social and ecological environment, yet general patterns emerged that share commonality with contemporary cities and may provide useful insights (Simon 2008 ;Smith 2012 ). The hallmarks of cities are: (a) a large population that (b) aggregates in a central location with (c) buildings and monuments that (d) represent institutions that organize and facilitate productivity. From the earliest times in Mesopotamia and in other regions, aggregations of people and their wealth have been threatened by military hostilities and they have repeatedly sought refuge behind strong defensive fortifi cations (#CITATION_TAG 1978 ). This has led to densely packed cities behind defensive walls, but at the same time growing rural to urban migration has led to settlements spreading outside the walls, a phenomenon that today one might call sprawl. This pattern of densely packed housing and central institutions within the walls, and residential settlement spreading far beyond the walls was frequent in the Near East, Asia, and Medieval Europe (Boone and Modarres 2006 ). In fact, Marco Polo reported that around the Mongol capital that would eventually become Beijing, ""There is a suburb outside each of the gates, which are 12 in number, and these suburbs are so great that they contain more people than the city itself"" (reported in ."	m
CCT655	"During the previously described long stretch of history, societies and economies were not growing very quickly (Fig. 2.1 ). However, since the beginning of the industrial revolution, and especially after the start of the ""great acceleration"" following the end of WWII, there has been rapid economic expansion coupled with rapid urban growth-all driven by rapid expansion of fossil fuel use, especially oil (Costanza et al. 2007b ). Indeed, one of the hallmarks of contemporary urbanization is that urban areas are growing faster and larger than they did in the past as well in new geographic locations (#CITATION_TAG et al. 2012b ) (Chap. 21 ). Current mainstream concepts and models of the economy were developed in this period of rapid expansion as if the world we lived in had unlimited capacity for growth in the material economy. In this ""empty world"" context, built capital -the houses, roads, and factoriesthings that are concentrated in cities-was the limiting factor to improving human well-being. Natural capital -our ecological life support system-and social capitalour myriad relationships with each other-were viewed to be abundant (Costanza et al. 1997a ). It made sense in this context not to worry too much about environmental and social ""externalities"" -effects that occurred outside the market-since they could be assumed to be relatively small and ultimately solvable. Instead, the focus was on the growth of the market economy, as measured by Gross Domestic Product (GDP), as a primary means to improve human welfare. The dominant thinking categorized the economy as only marketed goods and services and the goal of society was simply increasing the amount of these goods and services produced and consumed (Costanza et al. 1997a ). We now live in an interconnected global system that is relatively full of humans and their artifacts (Fig. 2.1 ) in what some are even calling a new geologic era-the ""Anthropocene"" (Crutzen 2002 ;Steffen et al. 2011 )-and have shifted into a human-dominated planet and into a new full-world context (Daly 2005 ). Some have also argued that we have already moved beyond the ""Anthropocene"" into the new urban era (Seto et al. 2010 ;Ljungqvist et al. 2010 ). Now we have to think differently about the relationship between humans and the rest of nature. If we seek ""improved human well-being and social equity, while signifi cantly reducing environmental risks and ecological scarcities,"" as the UN has recently proclaimed as the primary global goal (UNEP 2011 ), we will need a new vision of the economy and of cities and their relationship to the rest of the world that is better adapted to the new conditions we face. We will require a vision of the economy and urbanization that reintroduces the ecology of the urban. Material consumption and GDP are merely means to that end, not ends in themselves, and we need to better understand what really does contribute to sustainable human well-being (SHW), and recognize the substantial contributions of natural and social capital, which are now the limiting factors to improving SHW in many countries. We must be able to distinguish between real poverty in terms of low SHW and merely low monetary income."	0	"During the previously described long stretch of history, societies and economies were not growing very quickly (Fig. 2.1 ). However, since the beginning of the industrial revolution, and especially after the start of the ""great acceleration"" following the end of WWII, there has been rapid economic expansion coupled with rapid urban growth-all driven by rapid expansion of fossil fuel use, especially oil (Costanza et al. 2007b ). Indeed, one of the hallmarks of contemporary urbanization is that urban areas are growing faster and larger than they did in the past as well in new geographic locations (#CITATION_TAG et al. 2012b ) (Chap. 21 ). Current mainstream concepts and models of the economy were developed in this period of rapid expansion as if the world we lived in had unlimited capacity for growth in the material economy. In this ""empty world"" context, built capital -the houses, roads, and factoriesthings that are concentrated in cities-was the limiting factor to improving human well-being."	d
CCT656	"During the previously described long stretch of history, societies and economies were not growing very quickly (Fig. 2.1 ). However, since the beginning of the industrial revolution, and especially after the start of the ""great acceleration"" following the end of WWII, there has been rapid economic expansion coupled with rapid urban growth-all driven by rapid expansion of fossil fuel use, especially oil (Costanza et al. 2007b ). Indeed, one of the hallmarks of contemporary urbanization is that urban areas are growing faster and larger than they did in the past as well in new geographic locations (Seto et al. 2012b ) (Chap. 21 ). Current mainstream concepts and models of the economy were developed in this period of rapid expansion as if the world we lived in had unlimited capacity for growth in the material economy. In this ""empty world"" context, built capital -the houses, roads, and factoriesthings that are concentrated in cities-was the limiting factor to improving human well-being. Natural capital -our ecological life support system-and social capitalour myriad relationships with each other-were viewed to be abundant (Costanza et al. 1997a ). It made sense in this context not to worry too much about environmental and social ""externalities"" -effects that occurred outside the market-since they could be assumed to be relatively small and ultimately solvable. Instead, the focus was on the growth of the market economy, as measured by Gross Domestic Product (GDP), as a primary means to improve human welfare. The dominant thinking categorized the economy as only marketed goods and services and the goal of society was simply increasing the amount of these goods and services produced and consumed (Costanza et al. 1997a ). We now live in an interconnected global system that is relatively full of humans and their artifacts (Fig. 2.1 ) in what some are even calling a new geologic era-the ""Anthropocene"" (Crutzen 2002 ;Steffen et al. 2011 )-and have shifted into a human-dominated planet and into a new full-world context (Daly 2005 ). Some have also argued that we have already moved beyond the ""Anthropocene"" into the new urban era (#CITATION_TAG et al. 2010 ;Ljungqvist et al. 2010 ). Now we have to think differently about the relationship between humans and the rest of nature. If we seek ""improved human well-being and social equity, while signifi cantly reducing environmental risks and ecological scarcities,"" as the UN has recently proclaimed as the primary global goal (UNEP 2011 ), we will need a new vision of the economy and of cities and their relationship to the rest of the world that is better adapted to the new conditions we face. We will require a vision of the economy and urbanization that reintroduces the ecology of the urban. Material consumption and GDP are merely means to that end, not ends in themselves, and we need to better understand what really does contribute to sustainable human well-being (SHW), and recognize the substantial contributions of natural and social capital, which are now the limiting factors to improving SHW in many countries. We must be able to distinguish between real poverty in terms of low SHW and merely low monetary income."	0	"Instead, the focus was on the growth of the market economy, as measured by Gross Domestic Product (GDP), as a primary means to improve human welfare. The dominant thinking categorized the economy as only marketed goods and services and the goal of society was simply increasing the amount of these goods and services produced and consumed (Costanza et al. 1997a ). We now live in an interconnected global system that is relatively full of humans and their artifacts (Fig. 2.1 ) in what some are even calling a new geologic era-the ""Anthropocene"" (Crutzen 2002 ;Steffen et al. 2011 )-and have shifted into a human-dominated planet and into a new full-world context (Daly 2005 ). Some have also argued that we have already moved beyond the ""Anthropocene"" into the new urban era (#CITATION_TAG et al. 2010 ;Ljungqvist et al. 2010 ). Now we have to think differently about the relationship between humans and the rest of nature. If we seek ""improved human well-being and social equity, while signifi cantly reducing environmental risks and ecological scarcities,"" as the UN has recently proclaimed as the primary global goal (UNEP 2011 ), we will need a new vision of the economy and of cities and their relationship to the rest of the world that is better adapted to the new conditions we face. We will require a vision of the economy and urbanization that reintroduces the ecology of the urban."	l
CCT657	"Examining events and processes in the past often will provide useful insights into the origin of driving forces that impact cities today. However, the productive relationships that underlie the growth and success of cities may at the same time lead to relationships that are maladaptive, creating increased long term risks. For example, the concept of private property emerged to replace weak sense of ownership, lack of ownership, and/or the concept of community ownership. Farmers were increasingly able both to produce more food than their family required and they found ways to store this surplus for trade or for guarding against future bad harvests. However, one could only eat so much and a variety of factors limited the amount of food that could be effectively stored, including the ability of landlords and elites to appropriate some of the surplus through taxes. Hence the stimulus to produce a surplus remained limited in most farming villages. What changed this relationship, and is key to the growth of urban society, is the ability to transform locally produced surplus food into enduring prestige items associated with elevated status. This could only take place under a new social order that acknowledged classes with differential wealth, access to productive resources, power, and status. The promulgation of such a social order required an ideology (through religion, myth, constructed history, and/or law) that legitimized the existence of elite classes and the precious goods that helped to identify them. Of signifi cant importance was that along with the evolution of private property, surplus production, elite goods, and hierarchical class society, the inheritance for membership in these classes and ownership of precious goods became more often defi ned by family and clan rather than merit. Strength, agility, and intelligence certainly were important, but which family, clan, and class one was born into set the limits on one""s future potential in the age of early cities; to some extent, these constraints continue to operate today (#CITATION_TAG 1966 ;Prahalad 2005 ;Scott 1998 )."	0	"This could only take place under a new social order that acknowledged classes with differential wealth, access to productive resources, power, and status. The promulgation of such a social order required an ideology (through religion, myth, constructed history, and/or law) that legitimized the existence of elite classes and the precious goods that helped to identify them. Of signifi cant importance was that along with the evolution of private property, surplus production, elite goods, and hierarchical class society, the inheritance for membership in these classes and ownership of precious goods became more often defi ned by family and clan rather than merit. Strength, agility, and intelligence certainly were important, but which family, clan, and class one was born into set the limits on one""s future potential in the age of early cities; to some extent, these constraints continue to operate today (#CITATION_TAG 1966 ;Prahalad 2005 ;Scott 1998 )."	a
CCT658	Stewardship of ecosystem services in metropolitan landscapes is thus dependent on the continuation of historically informed management practices. Current biodiversity and ecosystem services are conditioned by history, regional context and continuity (Foster et al. 2003 ). Continuity is carried by memory, as in memory of past environmental responses carried in the genes of organisms, in community compositions and in habitat legacies, as well as in people carrying social memory such as oral tradition, rituals, institutions and tools that guide management practices (#CITATION_TAG et al. 2010a ;Barthel and Isendahl 2012 ). Much of this memory has been lost, and there is a need to regain and produce new and relevant knowledge for management of urban socialecological systems (see Chaps. 27 and 30 ).	0	Stewardship of ecosystem services in metropolitan landscapes is thus dependent on the continuation of historically informed management practices. Current biodiversity and ecosystem services are conditioned by history, regional context and continuity (Foster et al. 2003 ). Continuity is carried by memory, as in memory of past environmental responses carried in the genes of organisms, in community compositions and in habitat legacies, as well as in people carrying social memory such as oral tradition, rituals, institutions and tools that guide management practices (#CITATION_TAG et al. 2010a ;Barthel and Isendahl 2012 ). Much of this memory has been lost, and there is a need to regain and produce new and relevant knowledge for management of urban socialecological systems (see Chaps. 27 and 30 ).	n
CCT659	Ancient Mayan Cities . Cities in Meso-America traded a variety of food commodities both short-and long-distance (Dunning 2004 ;Isendahl 2006 ), but seasonally impassable rivers and energetically costly overland transports put a relatively high cost on trade and inhibited bulk-staple exchange (Isendahl 2006(Isendahl , 2012. Hence, much of the food consumed by the urban Maya Indians came from proximate lands (Isendahl 2006(Isendahl , 2012. For instance, large sectors of fertile soils inside the urban landscape were devoid of settlement constructions, but were used as city infi elds (Isendahl 2012 ). The management of these infi elds in Mayan cities was markedly different from the larger and stateowned farmstead gardens (Barthel and Isendahl 2012 ;Isendahl 2012 ), which were put under tremendous pressure when competition between city-states intensifi ed, a condition which at least partly contributed to the collapse of Mayan cities in the tenth century AD (Tainter 2011 ). The infi elds were used as household farmstead gardens, which concentrated agricultural knowledge and stewardship of the agricultural biodiversity that was the ultimate survival strategy for the populace (Ford and Emery 2008 ). Owing to residential proximity it was most carefully tended, and most carefully fertilized by the organic waste concentrated by city dwellers, and was used for plant breeding, experimentation, and for seed storage (Ford and Nigh 2009 ). The household farmstead garden held the key to a resilient fl ow of urban ecosystem services and provided food security for the population (Barthel and Isendahl 2012 ). Remnant urban ecosystems and the rich levels of biodiversity found in the urban Yucatan today are hence viewed to be the products of a millennia-long co-evolution in cultural landscapes (Ford and Emery 2008 ;Ford and Nigh 2009 ). Constantinople . Different in many respects from Mayan cities, Constantinople, the capital of the Roman cum Byzantine Empire from the fourth century AD until 1453, got its main source of staples of grain from the Nile Valley and was brought in by trading vessels averaging 40-50 tons each in capacity (Balicka-Witakowska 2010 ). Although these supply lines were subjected to the diffi cult winds of the eastern Mediterranean and the fl uctuations of Nile river dynamics, the most severe threats to food security were the sieges and blockades that distinctly cut food-and water-supply lines; these disruptions occurred on average every 65 years during the last 1,000 years (Barthel et al. 2010b ;#CITATION_TAG and Isendahl 2012 ). The most diffi cult blockade on the food supply lines, at the end of the fourteenth century AD, lasted an astonishing 8 years, but it did not succeed in starving out the urban population (Ljungqvist et al. 2010 ). To accommodate growth and respond to food and water insecurities during such sieges, an additional wall (the Theodosian Wall) was erected 1.5 km westwards of and about a century after the fi rst (continued)	0	The household farmstead garden held the key to a resilient fl ow of urban ecosystem services and provided food security for the population (Barthel and Isendahl 2012 ). Remnant urban ecosystems and the rich levels of biodiversity found in the urban Yucatan today are hence viewed to be the products of a millennia-long co-evolution in cultural landscapes (Ford and Emery 2008 ;Ford and Nigh 2009 ). Constantinople . Different in many respects from Mayan cities, Constantinople, the capital of the Roman cum Byzantine Empire from the fourth century AD until 1453, got its main source of staples of grain from the Nile Valley and was brought in by trading vessels averaging 40-50 tons each in capacity (Balicka-Witakowska 2010 ). Although these supply lines were subjected to the diffi cult winds of the eastern Mediterranean and the fl uctuations of Nile river dynamics, the most severe threats to food security were the sieges and blockades that distinctly cut food-and water-supply lines; these disruptions occurred on average every 65 years during the last 1,000 years (Barthel et al. 2010b ;#CITATION_TAG and Isendahl 2012 ). The most diffi cult blockade on the food supply lines, at the end of the fourteenth century AD, lasted an astonishing 8 years, but it did not succeed in starving out the urban population (Ljungqvist et al. 2010 ). To accommodate growth and respond to food and water insecurities during such sieges, an additional wall (the Theodosian Wall) was erected 1.5 km westwards of and about a century after the fi rst (continued)	t
CCT660	Not all of the green space in pre-industrial urban landscapes, however, was used to produce food. For example, open spaces have often been used as religious sites and as cemeteries. In many cities, particularly European, pleasure parks and pleasure gardens for purely recreational uses have also been present in cities since millennia, but these have mainly been the privilege of emperors, kings and other urban elites. In Stockholm, for instance, ordinary citizens were not allowed to enter such parks and gardens until the mid-1700s (Barthel et al. 2005 ). The main social drivers that led to a shift toward public use of such green spaces were the rapid urbanization during the industrial revolution, in combination with emerging social values inspired by the Romantic Movement and the French Revolution (Barthel et al. 2005 ). However, clear delineations between urban and rural areas and use of urban green spaces for purely recreational purposes did not emerge until the nineteenth and twentieth centuries, and were reinforced by the development of a globalized economy, the fossil fuel energy regime, and technological innovations such as the steam engine and the railway (McNeill 2000 ;Barthel and Isendahl 2012 ;#CITATION_TAG et al. 2013 ). Across Swedish cities, urban food production was ubiquitous until the development of the railway network, and the towns were in fact producing 50 % of their food consumption within their boundaries, and some were producing much more. For instance, in the mid-1700s, Uppsala produced more food than the city dwellers themselves consumed and the surplus was exported outside the city (Bj√∂rklund 2009 ). However, the mental models that developed among urban theorists in the beginning of the 1900s soon excluded the rural aspects of life in the city. One example is the Chicago School of urban sociology. Based in ecological theory (cf. Clements 1916 ) and using Chicago as a case study, the Chicago School of urban sociology emerged in the 1920s and 1930s to establish a modernist understanding of urban life as separate from rural life (McDonnell 2011 ). The idea of cities as separate entities essentially detached from their broader life-support systems (Wirth 1938 ) was strongly linked to major innovations in transportation technology as Chicago became an important hub in the U.S. railroad network in the 1850s, and food transportation over great distances became possible. Establishment as a railroad hub enabled Chicago to grow rapidly from a few thousand inhabitants in the 1850s to over two million in the early 1920s. Industrial-era technological innovation, cheap and effi cient travel, and economic growth (opening new markets, speeding up production cycles, and reducing the turnover time of capital) catered for the fi rst wave of space-time compression 1 (Harvey 1990 ). Hence, the modernist ideology underpinning the emergence of urban planning during the early decades of the 1900s distinctly separated local agricultures and other rural dimensions as obsolete in futuristic and normative understandings of the city as an autonomous social system (Barthel and Isendahl 2012 ).	0	In many cities, particularly European, pleasure parks and pleasure gardens for purely recreational uses have also been present in cities since millennia, but these have mainly been the privilege of emperors, kings and other urban elites. In Stockholm, for instance, ordinary citizens were not allowed to enter such parks and gardens until the mid-1700s (Barthel et al. 2005 ). The main social drivers that led to a shift toward public use of such green spaces were the rapid urbanization during the industrial revolution, in combination with emerging social values inspired by the Romantic Movement and the French Revolution (Barthel et al. 2005 ). However, clear delineations between urban and rural areas and use of urban green spaces for purely recreational purposes did not emerge until the nineteenth and twentieth centuries, and were reinforced by the development of a globalized economy, the fossil fuel energy regime, and technological innovations such as the steam engine and the railway (McNeill 2000 ;Barthel and Isendahl 2012 ;#CITATION_TAG et al. 2013 ). Across Swedish cities, urban food production was ubiquitous until the development of the railway network, and the towns were in fact producing 50 % of their food consumption within their boundaries, and some were producing much more. For instance, in the mid-1700s, Uppsala produced more food than the city dwellers themselves consumed and the surplus was exported outside the city (Bj√∂rklund 2009 ). However, the mental models that developed among urban theorists in the beginning of the 1900s soon excluded the rural aspects of life in the city.	e
CCT661	"The landscape-productivity-human relationship evolved in villages and towns; this enabled the growth of large, diverse populations that would aggregate into what are now called cities. The cities of antiquity in Mesopotamia and other regions responded to the specifi c opportunities and constraints of their local social and ecological environment, yet general patterns emerged that share commonality with contemporary cities and may provide useful insights (Simon 2008 ;Smith 2012 ). The hallmarks of cities are: (a) a large population that (b) aggregates in a central location with (c) buildings and monuments that (d) represent institutions that organize and facilitate productivity. From the earliest times in Mesopotamia and in other regions, aggregations of people and their wealth have been threatened by military hostilities and they have repeatedly sought refuge behind strong defensive fortifi cations (Redman 1978 ). This has led to densely packed cities behind defensive walls, but at the same time growing rural to urban migration has led to settlements spreading outside the walls, a phenomenon that today one might call sprawl. This pattern of densely packed housing and central institutions within the walls, and residential settlement spreading far beyond the walls was frequent in the Near East, Asia, and Medieval Europe (#CITATION_TAG and Modarres 2006 ). In fact, Marco Polo reported that around the Mongol capital that would eventually become Beijing, ""There is a suburb outside each of the gates, which are 12 in number, and these suburbs are so great that they contain more people than the city itself"" (reported in ."	0	"The hallmarks of cities are: (a) a large population that (b) aggregates in a central location with (c) buildings and monuments that (d) represent institutions that organize and facilitate productivity. From the earliest times in Mesopotamia and in other regions, aggregations of people and their wealth have been threatened by military hostilities and they have repeatedly sought refuge behind strong defensive fortifi cations (Redman 1978 ). This has led to densely packed cities behind defensive walls, but at the same time growing rural to urban migration has led to settlements spreading outside the walls, a phenomenon that today one might call sprawl. This pattern of densely packed housing and central institutions within the walls, and residential settlement spreading far beyond the walls was frequent in the Near East, Asia, and Medieval Europe (#CITATION_TAG and Modarres 2006 ). In fact, Marco Polo reported that around the Mongol capital that would eventually become Beijing, ""There is a suburb outside each of the gates, which are 12 in number, and these suburbs are so great that they contain more people than the city itself"" (reported in ."	p
CCT662	A third approach to problem solving emerged, however, when larger populations required a transformation in the social order, which was largely achieved through innovations in social complexity. This is at the heart of what scholars call the Urban Revolution and it appears to have occurred fi rst in Mesopotamia (#CITATION_TAG 1950 ;Redman 1999 ). The formation of the fi rst cities and their linking together as one civilization on the Mesopotamian plain was relatively rapid, considering the scope of the social and technological changes involved. In about 5500 BC, only 2,000 years after the earliest known occupation of this region, cities emerged, and writing and other traits of urbanism such as monumental buildings and craft specialization had appeared. The rise of cities is not simply the growth of large collections of peoplerather, it involves communities that are far more diverse than their predecessors and more interdependent. Relative independence and self-suffi ciency characterized village farming communities, but it also limited their growth. Specialization in the production of various goods and complex exchange networks represented one way in which urban societies were able to grow. Cities were dependent on their hinterlands of surrounding towns and villages and developed ways to extract goods and services from their neighbors (see left panel in Fig. 2.2 ). It is clear that technological inventions such as effective irrigation agriculture, the manufacture and widespread exchange of goods, and the advance of science and mathematics were fundamental to the growth of cities. In turn, cities became and continue to be centers of innovation. Moreover, new inventions in the social realm, such as class-structured society, formalized systems of laws, and a hierarchical territorially-based government made cities possible and have continued to characterize their operation.	0	A third approach to problem solving emerged, however, when larger populations required a transformation in the social order, which was largely achieved through innovations in social complexity. This is at the heart of what scholars call the Urban Revolution and it appears to have occurred fi rst in Mesopotamia (#CITATION_TAG 1950 ;Redman 1999 ). The formation of the fi rst cities and their linking together as one civilization on the Mesopotamian plain was relatively rapid, considering the scope of the social and technological changes involved. In about 5500 BC, only 2,000 years after the earliest known occupation of this region, cities emerged, and writing and other traits of urbanism such as monumental buildings and craft specialization had appeared. The rise of cities is not simply the growth of large collections of peoplerather, it involves communities that are far more diverse than their predecessors and more interdependent.	h
CCT663	History offers many lessons relevant to sustainability by exhibiting how humans and their societies have recognized and responded to challenges and opportunities of their natural environment (Redman 1999 ;Diamond 2005 ;#CITATION_TAG et al. 2007a ;Sinclair et al. 2010 ). Three of the basic approaches to problem solving in antiquity were: (1) mobility of people to available resources, (2) ecosystem management to secure enhanced local growth of produce, and (3) increasing social complexity encoded in formal institutions that guided an expanding range of activities. These solution pathways were fundamental to the rise of early civilizations and are instrumental for integration in the design of sustainable cities in the future (Redman 2011 ).	0	History offers many lessons relevant to sustainability by exhibiting how humans and their societies have recognized and responded to challenges and opportunities of their natural environment (Redman 1999 ;Diamond 2005 ;#CITATION_TAG et al. 2007a ;Sinclair et al. 2010 ). Three of the basic approaches to problem solving in antiquity were: (1) mobility of people to available resources, (2) ecosystem management to secure enhanced local growth of produce, and (3) increasing social complexity encoded in formal institutions that guided an expanding range of activities. These solution pathways were fundamental to the rise of early civilizations and are instrumental for integration in the design of sustainable cities in the future (Redman 2011 ).	H
CCT664	"During the previously described long stretch of history, societies and economies were not growing very quickly (Fig. 2.1 ). However, since the beginning of the industrial revolution, and especially after the start of the ""great acceleration"" following the end of WWII, there has been rapid economic expansion coupled with rapid urban growth-all driven by rapid expansion of fossil fuel use, especially oil (Costanza et al. 2007b ). Indeed, one of the hallmarks of contemporary urbanization is that urban areas are growing faster and larger than they did in the past as well in new geographic locations (Seto et al. 2012b ) (Chap. 21 ). Current mainstream concepts and models of the economy were developed in this period of rapid expansion as if the world we lived in had unlimited capacity for growth in the material economy. In this ""empty world"" context, built capital -the houses, roads, and factoriesthings that are concentrated in cities-was the limiting factor to improving human well-being. Natural capital -our ecological life support system-and social capitalour myriad relationships with each other-were viewed to be abundant (Costanza et al. 1997a ). It made sense in this context not to worry too much about environmental and social ""externalities"" -effects that occurred outside the market-since they could be assumed to be relatively small and ultimately solvable. Instead, the focus was on the growth of the market economy, as measured by Gross Domestic Product (GDP), as a primary means to improve human welfare. The dominant thinking categorized the economy as only marketed goods and services and the goal of society was simply increasing the amount of these goods and services produced and consumed (Costanza et al. 1997a ). We now live in an interconnected global system that is relatively full of humans and their artifacts (Fig. 2.1 ) in what some are even calling a new geologic era-the ""Anthropocene"" (Crutzen 2002 ;Steffen et al. 2011 )-and have shifted into a human-dominated planet and into a new full-world context (#CITATION_TAG 2005 ). Some have also argued that we have already moved beyond the ""Anthropocene"" into the new urban era (Seto et al. 2010 ;Ljungqvist et al. 2010 ). Now we have to think differently about the relationship between humans and the rest of nature. If we seek ""improved human well-being and social equity, while signifi cantly reducing environmental risks and ecological scarcities,"" as the UN has recently proclaimed as the primary global goal (UNEP 2011 ), we will need a new vision of the economy and of cities and their relationship to the rest of the world that is better adapted to the new conditions we face. We will require a vision of the economy and urbanization that reintroduces the ecology of the urban. Material consumption and GDP are merely means to that end, not ends in themselves, and we need to better understand what really does contribute to sustainable human well-being (SHW), and recognize the substantial contributions of natural and social capital, which are now the limiting factors to improving SHW in many countries. We must be able to distinguish between real poverty in terms of low SHW and merely low monetary income."	0	"It made sense in this context not to worry too much about environmental and social ""externalities"" -effects that occurred outside the market-since they could be assumed to be relatively small and ultimately solvable. Instead, the focus was on the growth of the market economy, as measured by Gross Domestic Product (GDP), as a primary means to improve human welfare. The dominant thinking categorized the economy as only marketed goods and services and the goal of society was simply increasing the amount of these goods and services produced and consumed (Costanza et al. 1997a ). We now live in an interconnected global system that is relatively full of humans and their artifacts (Fig. 2.1 ) in what some are even calling a new geologic era-the ""Anthropocene"" (Crutzen 2002 ;Steffen et al. 2011 )-and have shifted into a human-dominated planet and into a new full-world context (#CITATION_TAG 2005 ). Some have also argued that we have already moved beyond the ""Anthropocene"" into the new urban era (Seto et al. 2010 ;Ljungqvist et al. 2010 ). Now we have to think differently about the relationship between humans and the rest of nature. If we seek ""improved human well-being and social equity, while signifi cantly reducing environmental risks and ecological scarcities,"" as the UN has recently proclaimed as the primary global goal (UNEP 2011 ), we will need a new vision of the economy and of cities and their relationship to the rest of the world that is better adapted to the new conditions we face."	e
CCT665	"During the previously described long stretch of history, societies and economies were not growing very quickly (Fig. 2.1 ). However, since the beginning of the industrial revolution, and especially after the start of the ""great acceleration"" following the end of WWII, there has been rapid economic expansion coupled with rapid urban growth-all driven by rapid expansion of fossil fuel use, especially oil (#CITATION_TAG et al. 2007b ). Indeed, one of the hallmarks of contemporary urbanization is that urban areas are growing faster and larger than they did in the past as well in new geographic locations (Seto et al. 2012b ) (Chap. 21 ). Current mainstream concepts and models of the economy were developed in this period of rapid expansion as if the world we lived in had unlimited capacity for growth in the material economy. In this ""empty world"" context, built capital -the houses, roads, and factoriesthings that are concentrated in cities-was the limiting factor to improving human well-being. Natural capital -our ecological life support system-and social capitalour myriad relationships with each other-were viewed to be abundant (Costanza et al. 1997a ). It made sense in this context not to worry too much about environmental and social ""externalities"" -effects that occurred outside the market-since they could be assumed to be relatively small and ultimately solvable. Instead, the focus was on the growth of the market economy, as measured by Gross Domestic Product (GDP), as a primary means to improve human welfare. The dominant thinking categorized the economy as only marketed goods and services and the goal of society was simply increasing the amount of these goods and services produced and consumed (Costanza et al. 1997a ). We now live in an interconnected global system that is relatively full of humans and their artifacts (Fig. 2.1 ) in what some are even calling a new geologic era-the ""Anthropocene"" (Crutzen 2002 ;Steffen et al. 2011 )-and have shifted into a human-dominated planet and into a new full-world context (Daly 2005 ). Some have also argued that we have already moved beyond the ""Anthropocene"" into the new urban era (Seto et al. 2010 ;Ljungqvist et al. 2010 ). Now we have to think differently about the relationship between humans and the rest of nature. If we seek ""improved human well-being and social equity, while signifi cantly reducing environmental risks and ecological scarcities,"" as the UN has recently proclaimed as the primary global goal (UNEP 2011 ), we will need a new vision of the economy and of cities and their relationship to the rest of the world that is better adapted to the new conditions we face. We will require a vision of the economy and urbanization that reintroduces the ecology of the urban. Material consumption and GDP are merely means to that end, not ends in themselves, and we need to better understand what really does contribute to sustainable human well-being (SHW), and recognize the substantial contributions of natural and social capital, which are now the limiting factors to improving SHW in many countries. We must be able to distinguish between real poverty in terms of low SHW and merely low monetary income."	0	"During the previously described long stretch of history, societies and economies were not growing very quickly (Fig. 2.1 ). However, since the beginning of the industrial revolution, and especially after the start of the ""great acceleration"" following the end of WWII, there has been rapid economic expansion coupled with rapid urban growth-all driven by rapid expansion of fossil fuel use, especially oil (#CITATION_TAG et al. 2007b ). Indeed, one of the hallmarks of contemporary urbanization is that urban areas are growing faster and larger than they did in the past as well in new geographic locations (Seto et al. 2012b ) (Chap. 21 ). Current mainstream concepts and models of the economy were developed in this period of rapid expansion as if the world we lived in had unlimited capacity for growth in the material economy."	o
CCT666	Ancient Mayan Cities . Cities in Meso-America traded a variety of food commodities both short-and long-distance (Dunning 2004 ;Isendahl 2006 ), but seasonally impassable rivers and energetically costly overland transports put a relatively high cost on trade and inhibited bulk-staple exchange (Isendahl 2006(Isendahl , 2012. Hence, much of the food consumed by the urban Maya Indians came from proximate lands (Isendahl 2006(Isendahl , 2012. For instance, large sectors of fertile soils inside the urban landscape were devoid of settlement constructions, but were used as city infi elds (Isendahl 2012 ). The management of these infi elds in Mayan cities was markedly different from the larger and stateowned farmstead gardens (Barthel and Isendahl 2012 ;Isendahl 2012 ), which were put under tremendous pressure when competition between city-states intensifi ed, a condition which at least partly contributed to the collapse of Mayan cities in the tenth century AD (Tainter 2011 ). The infi elds were used as household farmstead gardens, which concentrated agricultural knowledge and stewardship of the agricultural biodiversity that was the ultimate survival strategy for the populace (Ford and Emery 2008 ). Owing to residential proximity it was most carefully tended, and most carefully fertilized by the organic waste concentrated by city dwellers, and was used for plant breeding, experimentation, and for seed storage (Ford and Nigh 2009 ). The household farmstead garden held the key to a resilient fl ow of urban ecosystem services and provided food security for the population (Barthel and Isendahl 2012 ). Remnant urban ecosystems and the rich levels of biodiversity found in the urban Yucatan today are hence viewed to be the products of a millennia-long co-evolution in cultural landscapes (Ford and Emery 2008 ;#CITATION_TAG and Nigh 2009 ). Constantinople . Different in many respects from Mayan cities, Constantinople, the capital of the Roman cum Byzantine Empire from the fourth century AD until 1453, got its main source of staples of grain from the Nile Valley and was brought in by trading vessels averaging 40-50 tons each in capacity (Balicka-Witakowska 2010 ). Although these supply lines were subjected to the diffi cult winds of the eastern Mediterranean and the fl uctuations of Nile river dynamics, the most severe threats to food security were the sieges and blockades that distinctly cut food-and water-supply lines; these disruptions occurred on average every 65 years during the last 1,000 years (Barthel et al. 2010b ;Barthel and Isendahl 2012 ). The most diffi cult blockade on the food supply lines, at the end of the fourteenth century AD, lasted an astonishing 8 years, but it did not succeed in starving out the urban population (Ljungqvist et al. 2010 ). To accommodate growth and respond to food and water insecurities during such sieges, an additional wall (the Theodosian Wall) was erected 1.5 km westwards of and about a century after the fi rst (continued)	0	The infi elds were used as household farmstead gardens, which concentrated agricultural knowledge and stewardship of the agricultural biodiversity that was the ultimate survival strategy for the populace (Ford and Emery 2008 ). Owing to residential proximity it was most carefully tended, and most carefully fertilized by the organic waste concentrated by city dwellers, and was used for plant breeding, experimentation, and for seed storage (Ford and Nigh 2009 ). The household farmstead garden held the key to a resilient fl ow of urban ecosystem services and provided food security for the population (Barthel and Isendahl 2012 ). Remnant urban ecosystems and the rich levels of biodiversity found in the urban Yucatan today are hence viewed to be the products of a millennia-long co-evolution in cultural landscapes (Ford and Emery 2008 ;#CITATION_TAG and Nigh 2009 ). Constantinople . Different in many respects from Mayan cities, Constantinople, the capital of the Roman cum Byzantine Empire from the fourth century AD until 1453, got its main source of staples of grain from the Nile Valley and was brought in by trading vessels averaging 40-50 tons each in capacity (Balicka-Witakowska 2010 ). Although these supply lines were subjected to the diffi cult winds of the eastern Mediterranean and the fl uctuations of Nile river dynamics, the most severe threats to food security were the sieges and blockades that distinctly cut food-and water-supply lines; these disruptions occurred on average every 65 years during the last 1,000 years (Barthel et al. 2010b ;Barthel and Isendahl 2012 ). The most diffi cult blockade on the food supply lines, at the end of the fourteenth century AD, lasted an astonishing 8 years, but it did not succeed in starving out the urban population (Ljungqvist et al. 2010 ).	 
CCT667	Stewardship of ecosystem services in metropolitan landscapes is thus dependent on the continuation of historically informed management practices. Current biodiversity and ecosystem services are conditioned by history, regional context and continuity (#CITATION_TAG et al. 2003 ). Continuity is carried by memory, as in memory of past environmental responses carried in the genes of organisms, in community compositions and in habitat legacies, as well as in people carrying social memory such as oral tradition, rituals, institutions and tools that guide management practices (Barthel et al. 2010a ;Barthel and Isendahl 2012 ). Much of this memory has been lost, and there is a need to regain and produce new and relevant knowledge for management of urban socialecological systems (see Chaps. 27 and 30 ).	0	Stewardship of ecosystem services in metropolitan landscapes is thus dependent on the continuation of historically informed management practices. Current biodiversity and ecosystem services are conditioned by history, regional context and continuity (#CITATION_TAG et al. 2003 ). Continuity is carried by memory, as in memory of past environmental responses carried in the genes of organisms, in community compositions and in habitat legacies, as well as in people carrying social memory such as oral tradition, rituals, institutions and tools that guide management practices (Barthel et al. 2010a ;Barthel and Isendahl 2012 ). Much of this memory has been lost, and there is a need to regain and produce new and relevant knowledge for management of urban socialecological systems (see Chaps. 27 and 30 ).	u
CCT668	"Realizability semantics are of paramount importance in the study of intuitionistic theories. They were first proposed by Kleene [17] in 1945. Friedman [12] showed metamathematical results for intuitionistic set theories by extending a notion of realizability developed by Kreisel and Troelstra [21]. A realizability-notion akin to Kleene""s slash [18,19] was extended to various intuitionistic set theories by Myhill [27,#CITATION_TAG], whereby he also drew on work by Moschovakis [24]. We use IZF to denote intuitionistic Zermelo-Fraenkel set theory formulated with Collection. [27] showed that intuitionistic ZF with Replacement instead of Collection (dubbed IZF R henceforth) has the DP, NEP, and EP. [28] proved that his constructive set theory CST enjoys the DP and the NEP, and that the theory without the axioms of countable and dependent choice, CST ‚àí , also has the EP."	0	"Realizability semantics are of paramount importance in the study of intuitionistic theories. They were first proposed by Kleene [17] in 1945. Friedman [12] showed metamathematical results for intuitionistic set theories by extending a notion of realizability developed by Kreisel and Troelstra [21]. A realizability-notion akin to Kleene""s slash [18,19] was extended to various intuitionistic set theories by Myhill [27,#CITATION_TAG], whereby he also drew on work by Moschovakis [24]. We use IZF to denote intuitionistic Zermelo-Fraenkel set theory formulated with Collection. [27] showed that intuitionistic ZF with Replacement instead of Collection (dubbed IZF R henceforth) has the DP, NEP, and EP. [28] proved that his constructive set theory CST enjoys the DP and the NEP, and that the theory without the axioms of countable and dependent choice, CST ‚àí , also has the EP."	e
CCT669	"It was left open in [28] whether the full existence property holds in the presence of relativized dependent choice, RDC. Friedman and ≈†ƒçedrov [15] then established that IZF R + RDC satisfies the EP also. Several systems of set theory for the constructive mathematical practice were propounded by Friedman in [14]. The metamathematical properties of these theories and several others as well were subsequently investigated by Beeson [5,6]. In particular, Beeson showed that IZF has the DP and NEP. He used a combination of Kreisel-Troelstra realizability and Kleene""s [17][18][19][20] q-realizability. However, while Myhill and Friedman developed realizability directly for extensional set theories, Beeson engineered his realizability for non-extensional set theories and obtained results for the extensional set theories of [14] only via an interpretation in their non-extensional counterparts. This detour had the disadvantage that in many cases (where the theory does not have full Separation or Powerset) the DP and NEP for the corresponding extensional set theory T -ext could only be established for a restricted class of formulae. In [33,36,#CITATION_TAG] the author of the present paper developed a different machinery for showing the DP and the NEP (and several other properties) directly for extensional set theories. [36] introduced a self-validating semantics for constructive Zermelo-Fraenkel set theory, CZF, that combines realizability for extensional set theory and truth. In [37] this method was used to establish the DP and NEP for CZF and IZF augmented by familiar choice principles, i.e., any combination of the principles of Countable Choice, Relativized Dependent Choices and the Presentation Axiom (cf. [32]). Also Markov""s principle may be added. So far we have not addressed the question whether the EP holds for IZF and CZF. Partial results were obtained in [35,Theorems 8.3,8.4] to the effect that CZF augmented via a strong form of the axiom of choice, the Œ†Œ£ axiom of choice, has the EP for a very large collection of formulae. It was shown by Friedman and ≈†ƒçedrov that the EP fails for IZF, intuitionistic Zermelo-Fraenkel set theory formulated with Collection. As IZF R possesses the EP, Collection is clearly implicated in this failure. Beeson in [6, IX.1] posed the following question:"	4	"He used a combination of Kreisel-Troelstra realizability and Kleene""s [17][18][19][20] q-realizability. However, while Myhill and Friedman developed realizability directly for extensional set theories, Beeson engineered his realizability for non-extensional set theories and obtained results for the extensional set theories of [14] only via an interpretation in their non-extensional counterparts. This detour had the disadvantage that in many cases (where the theory does not have full Separation or Powerset) the DP and NEP for the corresponding extensional set theory T -ext could only be established for a restricted class of formulae. In [33,36,#CITATION_TAG] the author of the present paper developed a different machinery for showing the DP and the NEP (and several other properties) directly for extensional set theories. [36] introduced a self-validating semantics for constructive Zermelo-Fraenkel set theory, CZF, that combines realizability for extensional set theory and truth. In [37] this method was used to establish the DP and NEP for CZF and IZF augmented by familiar choice principles, i.e., any combination of the principles of Countable Choice, Relativized Dependent Choices and the Presentation Axiom (cf. [32]). Also Markov""s principle may be added."	6
CCT670	"It was left open in [28] whether the full existence property holds in the presence of relativized dependent choice, RDC. Friedman and ≈†ƒçedrov [15] then established that IZF R + RDC satisfies the EP also. Several systems of set theory for the constructive mathematical practice were propounded by Friedman in [14]. The metamathematical properties of these theories and several others as well were subsequently investigated by Beeson [5,6]. In particular, Beeson showed that IZF has the DP and NEP. He used a combination of Kreisel-Troelstra realizability and Kleene""s [17][18][19][20] q-realizability. However, while Myhill and Friedman developed realizability directly for extensional set theories, Beeson engineered his realizability for non-extensional set theories and obtained results for the extensional set theories of [14] only via an interpretation in their non-extensional counterparts. This detour had the disadvantage that in many cases (where the theory does not have full Separation or Powerset) the DP and NEP for the corresponding extensional set theory T -ext could only be established for a restricted class of formulae. In [33,#CITATION_TAG,37] the author of the present paper developed a different machinery for showing the DP and the NEP (and several other properties) directly for extensional set theories. [36] introduced a self-validating semantics for constructive Zermelo-Fraenkel set theory, CZF, that combines realizability for extensional set theory and truth. In [37] this method was used to establish the DP and NEP for CZF and IZF augmented by familiar choice principles, i.e., any combination of the principles of Countable Choice, Relativized Dependent Choices and the Presentation Axiom (cf. [32]). Also Markov""s principle may be added. So far we have not addressed the question whether the EP holds for IZF and CZF. Partial results were obtained in [35,Theorems 8.3,8.4] to the effect that CZF augmented via a strong form of the axiom of choice, the Œ†Œ£ axiom of choice, has the EP for a very large collection of formulae. It was shown by Friedman and ≈†ƒçedrov that the EP fails for IZF, intuitionistic Zermelo-Fraenkel set theory formulated with Collection. As IZF R possesses the EP, Collection is clearly implicated in this failure. Beeson in [6, IX.1] posed the following question:"	4	"He used a combination of Kreisel-Troelstra realizability and Kleene""s [17][18][19][20] q-realizability. However, while Myhill and Friedman developed realizability directly for extensional set theories, Beeson engineered his realizability for non-extensional set theories and obtained results for the extensional set theories of [14] only via an interpretation in their non-extensional counterparts. This detour had the disadvantage that in many cases (where the theory does not have full Separation or Powerset) the DP and NEP for the corresponding extensional set theory T -ext could only be established for a restricted class of formulae. In [33,#CITATION_TAG,37] the author of the present paper developed a different machinery for showing the DP and the NEP (and several other properties) directly for extensional set theories. [36] introduced a self-validating semantics for constructive Zermelo-Fraenkel set theory, CZF, that combines realizability for extensional set theory and truth. In [37] this method was used to establish the DP and NEP for CZF and IZF augmented by familiar choice principles, i.e., any combination of the principles of Countable Choice, Relativized Dependent Choices and the Presentation Axiom (cf. [32]). Also Markov""s principle may be added."	C
CCT671	"Realizability semantics are of paramount importance in the study of intuitionistic theories. They were first proposed by Kleene [17] in 1945. Friedman [12] showed metamathematical results for intuitionistic set theories by extending a notion of realizability developed by Kreisel and Troelstra [21]. A realizability-notion akin to Kleene""s slash [#CITATION_TAG,19] was extended to various intuitionistic set theories by Myhill [27,28], whereby he also drew on work by Moschovakis [24]. We use IZF to denote intuitionistic Zermelo-Fraenkel set theory formulated with Collection. [27] showed that intuitionistic ZF with Replacement instead of Collection (dubbed IZF R henceforth) has the DP, NEP, and EP. [28] proved that his constructive set theory CST enjoys the DP and the NEP, and that the theory without the axioms of countable and dependent choice, CST ‚àí , also has the EP."	0	"Realizability semantics are of paramount importance in the study of intuitionistic theories. They were first proposed by Kleene [17] in 1945. Friedman [12] showed metamathematical results for intuitionistic set theories by extending a notion of realizability developed by Kreisel and Troelstra [21]. A realizability-notion akin to Kleene""s slash [#CITATION_TAG,19] was extended to various intuitionistic set theories by Myhill [27,28], whereby he also drew on work by Moschovakis [24]. We use IZF to denote intuitionistic Zermelo-Fraenkel set theory formulated with Collection. [27] showed that intuitionistic ZF with Replacement instead of Collection (dubbed IZF R henceforth) has the DP, NEP, and EP. [28] proved that his constructive set theory CST enjoys the DP and the NEP, and that the theory without the axioms of countable and dependent choice, CST ‚àí , also has the EP."	e
CCT672	"Realizability semantics are of paramount importance in the study of intuitionistic theories. They were first proposed by Kleene #CITATION_TAG in 1945. Friedman [12] showed metamathematical results for intuitionistic set theories by extending a notion of realizability developed by Kreisel and Troelstra [21]. A realizability-notion akin to Kleene""s slash [18,19] was extended to various intuitionistic set theories by Myhill [27,28], whereby he also drew on work by Moschovakis [24]. We use IZF to denote intuitionistic Zermelo-Fraenkel set theory formulated with Collection. [27] showed that intuitionistic ZF with Replacement instead of Collection (dubbed IZF R henceforth) has the DP, NEP, and EP. [28] proved that his constructive set theory CST enjoys the DP and the NEP, and that the theory without the axioms of countable and dependent choice, CST ‚àí , also has the EP."	0	"Realizability semantics are of paramount importance in the study of intuitionistic theories. They were first proposed by Kleene #CITATION_TAG in 1945. Friedman [12] showed metamathematical results for intuitionistic set theories by extending a notion of realizability developed by Kreisel and Troelstra [21]. A realizability-notion akin to Kleene""s slash [18,19] was extended to various intuitionistic set theories by Myhill [27,28], whereby he also drew on work by Moschovakis [24]. We use IZF to denote intuitionistic Zermelo-Fraenkel set theory formulated with Collection."	h
CCT673	"Realizability semantics are of paramount importance in the study of intuitionistic theories. They were first proposed by Kleene [17] in 1945. Friedman [12] showed metamathematical results for intuitionistic set theories by extending a notion of realizability developed by Kreisel and Troelstra [21]. A realizability-notion akin to Kleene""s slash [18,19] was extended to various intuitionistic set theories by Myhill [#CITATION_TAG,28], whereby he also drew on work by Moschovakis [24]. We use IZF to denote intuitionistic Zermelo-Fraenkel set theory formulated with Collection. [27] showed that intuitionistic ZF with Replacement instead of Collection (dubbed IZF R henceforth) has the DP, NEP, and EP. [28] proved that his constructive set theory CST enjoys the DP and the NEP, and that the theory without the axioms of countable and dependent choice, CST ‚àí , also has the EP."	0	"Realizability semantics are of paramount importance in the study of intuitionistic theories. They were first proposed by Kleene [17] in 1945. Friedman [12] showed metamathematical results for intuitionistic set theories by extending a notion of realizability developed by Kreisel and Troelstra [21]. A realizability-notion akin to Kleene""s slash [18,19] was extended to various intuitionistic set theories by Myhill [#CITATION_TAG,28], whereby he also drew on work by Moschovakis [24]. We use IZF to denote intuitionistic Zermelo-Fraenkel set theory formulated with Collection. [27] showed that intuitionistic ZF with Replacement instead of Collection (dubbed IZF R henceforth) has the DP, NEP, and EP. [28] proved that his constructive set theory CST enjoys the DP and the NEP, and that the theory without the axioms of countable and dependent choice, CST ‚àí , also has the EP."	e
CCT674	"It was left open in [28] whether the full existence property holds in the presence of relativized dependent choice, RDC. Friedman and ≈†ƒçedrov [15] then established that IZF R + RDC satisfies the EP also. Several systems of set theory for the constructive mathematical practice were propounded by Friedman in #CITATION_TAG. The metamathematical properties of these theories and several others as well were subsequently investigated by Beeson [5,6]. In particular, Beeson showed that IZF has the DP and NEP. He used a combination of Kreisel-Troelstra realizability and Kleene""s [17][18][19][20] q-realizability. However, while Myhill and Friedman developed realizability directly for extensional set theories, Beeson engineered his realizability for non-extensional set theories and obtained results for the extensional set theories of [14] only via an interpretation in their non-extensional counterparts. This detour had the disadvantage that in many cases (where the theory does not have full Separation or Powerset) the DP and NEP for the corresponding extensional set theory T -ext could only be established for a restricted class of formulae. In [33,36,37] the author of the present paper developed a different machinery for showing the DP and the NEP (and several other properties) directly for extensional set theories. [36] introduced a self-validating semantics for constructive Zermelo-Fraenkel set theory, CZF, that combines realizability for extensional set theory and truth. In [37] this method was used to establish the DP and NEP for CZF and IZF augmented by familiar choice principles, i.e., any combination of the principles of Countable Choice, Relativized Dependent Choices and the Presentation Axiom (cf. [32]). Also Markov""s principle may be added. So far we have not addressed the question whether the EP holds for IZF and CZF. Partial results were obtained in [35,Theorems 8.3,8.4] to the effect that CZF augmented via a strong form of the axiom of choice, the Œ†Œ£ axiom of choice, has the EP for a very large collection of formulae. It was shown by Friedman and ≈†ƒçedrov that the EP fails for IZF, intuitionistic Zermelo-Fraenkel set theory formulated with Collection. As IZF R possesses the EP, Collection is clearly implicated in this failure. Beeson in [6, IX.1] posed the following question:"	0	"It was left open in [28] whether the full existence property holds in the presence of relativized dependent choice, RDC. Friedman and ≈†ƒçedrov [15] then established that IZF R + RDC satisfies the EP also. Several systems of set theory for the constructive mathematical practice were propounded by Friedman in #CITATION_TAG. The metamathematical properties of these theories and several others as well were subsequently investigated by Beeson [5,6]. In particular, Beeson showed that IZF has the DP and NEP. He used a combination of Kreisel-Troelstra realizability and Kleene""s [17][18][19][20] q-realizability."	v
CCT675	We shall introduce two extended notions of E-computability, christened E exp -computability and E ‚Ñò -computability, rendering the functions exp(a, b) = a b and P (x) = {u | u ‚äÜ x} computable, respectively (where a b denotes the set of all functions from a to b). Indices for these functions will supply suitable for realizability interpretations of CZF E and CZF P , respectively. E ‚Ñò -computability is closely related to power recursion, where the power set operation is regarded to be an initial function. The latter notion has been studied by Moschovakis [25] and Moss #CITATION_TAG. to Definition 2.9. We thereby arrive at an inductively defined class E ‚Ñò .	0	We shall introduce two extended notions of E-computability, christened E exp -computability and E ‚Ñò -computability, rendering the functions exp(a, b) = a b and P (x) = {u | u ‚äÜ x} computable, respectively (where a b denotes the set of all functions from a to b). Indices for these functions will supply suitable for realizability interpretations of CZF E and CZF P , respectively. E ‚Ñò -computability is closely related to power recursion, where the power set operation is regarded to be an initial function. The latter notion has been studied by Moschovakis [25] and Moss #CITATION_TAG. to Definition 2.9. We thereby arrive at an inductively defined class E ‚Ñò .	 
CCT676	"Realizability semantics are a crucial tool in the study of intuitionistic theories. We introduce a form of realizability based on general set recursive functions where a realizer for an existential statement provides a set of witnesses for the existential quantifier rather than a single witness. Realizability based on indices of general set recursive functions was introduced in [34] and employed to prove, inter alia, metamathematical properties for CZF augmented by strong forms of the axiom of choice in [35,Theorems 8.3,8.4]. There are points of contact with a notion of realizability used by Tharp [42] who employed (indices of) Œ£ 1 definable partial (class) functions as realizers, though there are important differences, too, as Tharp works in a classical context and assumes a definable search operation on the universe which basically amounts to working under the hypothesis V = L. Moreover, there are connections with Lifschitz"" realizability [22] where a realizer for an existential arithmetical statement provides a finite co-recursive set of witnesses (see [#CITATION_TAG,8] for extensions to analysis and set theory). Another important type of semantics or interpretation for intuitionistic systems is functional interpretation. The Diller-Nahm interpretation [9] also employs sets of witnesses to interpret existential quantifiers. It has been extended to set theories by Burr, Diller and Schulte [7,10,41]. Burr [7, Corollary 5.12] and Diller [10, Proposition 4.4] prove weak forms of term existence property for a higher type versions of CZF ‚àí . Interestingly, Diller conjectures ([10] Conjectures 4.8,4.9) that the term existence property fails for higher type versions of CZF ‚àí . By contrast, in this paper it shown that CZF ‚àí does have the existence property (Corollary 6.1)."	1	"Realizability semantics are a crucial tool in the study of intuitionistic theories. We introduce a form of realizability based on general set recursive functions where a realizer for an existential statement provides a set of witnesses for the existential quantifier rather than a single witness. Realizability based on indices of general set recursive functions was introduced in [34] and employed to prove, inter alia, metamathematical properties for CZF augmented by strong forms of the axiom of choice in [35,Theorems 8.3,8.4]. There are points of contact with a notion of realizability used by Tharp [42] who employed (indices of) Œ£ 1 definable partial (class) functions as realizers, though there are important differences, too, as Tharp works in a classical context and assumes a definable search operation on the universe which basically amounts to working under the hypothesis V = L. Moreover, there are connections with Lifschitz"" realizability [22] where a realizer for an existential arithmetical statement provides a finite co-recursive set of witnesses (see [#CITATION_TAG,8] for extensions to analysis and set theory). Another important type of semantics or interpretation for intuitionistic systems is functional interpretation. The Diller-Nahm interpretation [9] also employs sets of witnesses to interpret existential quantifiers. It has been extended to set theories by Burr, Diller and Schulte [7,10,41]."	r
CCT677	"where a and x are sets. Here we use Kleene""s curly bracket notation to convey that a is viewed as encoding the programme of some kind of Turing machine which takes a set input x to produce a result {a}(x). In generalized recursion theory this is known as E-recursion or set recursion (see, e.g., #CITATION_TAG or [40, Ch.X]). One point of deviation from the standard notion of E-computability though is that we will take the constant function with value œâ as an initial function. There is a lot of leeway in setting up E-recursion. The particular schemes we use are especially germane to our situation. Very likely there is a lot of redundancy but any attempts at being economical would not have any benefits for the purposes of this paper. Our construction will provide a specific set-theoretic model for the elementary theory of operations and numbers EON (see, e.g., [6,VI.2], or the theory APP as described in [43,Ch.9,Sect.3]). We utilize encoding of finite sequences of sets by the usual pairing function ‚ü® , ‚ü© with ‚ü®x, y‚ü© = {{x}, {x, y}}, letting ‚ü®x‚ü© = x and ‚ü®x 1 , . . . , x n , x n+1 ‚ü© = ‚ü®‚ü®x 1 , . . . , x n ‚ü©, x n+1 ‚ü©. We use functions () 0 and () 1 to retrieve the left and right components, respectively, of an ordered pair a = ‚ü®x, y‚ü©, i.e., (a) 0 = x and (a) 1 = y."	0	"where a and x are sets. Here we use Kleene""s curly bracket notation to convey that a is viewed as encoding the programme of some kind of Turing machine which takes a set input x to produce a result {a}(x). In generalized recursion theory this is known as E-recursion or set recursion (see, e.g., #CITATION_TAG or [40, Ch. X]). One point of deviation from the standard notion of E-computability though is that we will take the constant function with value œâ as an initial function. There is a lot of leeway in setting up E-recursion."	 
CCT678	A class X is said to be -closed if A  X implies a  X for every pair a, A  .Theorem 2.7 (IKP) For any  inductive definition  there is a smallest -closed class I(); moreover, I() is a  class as well.Proof : [2, Theorem 11.4] and #CITATION_TAG	0	A class X is said to be -closed if A  X implies a  X for every pair a, A  .Theorem 2.7 (IKP) For any  inductive definition  there is a smallest -closed class I(); moreover, I() is a  class as well. Proof : [2, Theorem 11.4] and #CITATION_TAG	r
CCT679	To show this we use a much more elaborate technology than realizability. It is possible to carry out an ordinal analysis of IKP just as for KP as in #CITATION_TAG. It involves a term structure built from the backbone of an ordinal representation system that mimics the constructible hierarchy. For every theorem Œ£ theorem of IKP of the form ‚àÉxA(x) one can effectively determine an ordinal Œ± from the representation system (which is smaller than the Bachmann-Howard ordinal) and an infinitary cut-free derivation D Œ± 0 ‚àÉ xA(x). Since this is a derivation in infinitary intuitionistic logic one obtains from the proof an explicit term t in the term structure and a proof D ‚Ä≤ Œ± 0 A (t). The canonical interpretation of t in the constructible hierarchy as defined in [31, 3.5 Soundness Theorem] then provides the explicit witness for ‚àÉxA(x). As the entire reasoning can be carried out in IKP this entails that IKP has the EP for Œ£ formulae. Corollary 6.1. CZF ‚àí has the EP.	0	To show this we use a much more elaborate technology than realizability. It is possible to carry out an ordinal analysis of IKP just as for KP as in #CITATION_TAG. It involves a term structure built from the backbone of an ordinal representation system that mimics the constructible hierarchy. For every theorem Œ£ theorem of IKP of the form ‚àÉxA(x) one can effectively determine an ordinal Œ± from the representation system (which is smaller than the Bachmann-Howard ordinal) and an infinitary cut-free derivation D Œ± 0 ‚àÉ xA(x). Since this is a derivation in infinitary intuitionistic logic one obtains from the proof an explicit term t in the term structure and a proof D ‚Ä≤ Œ± 0 A (t).	t
CCT680	"It was left open in [28] whether the full existence property holds in the presence of relativized dependent choice, RDC. Friedman and ≈†ƒçedrov [15] then established that IZF R + RDC satisfies the EP also. Several systems of set theory for the constructive mathematical practice were propounded by Friedman in [14]. The metamathematical properties of these theories and several others as well were subsequently investigated by Beeson [5,6]. In particular, Beeson showed that IZF has the DP and NEP. He used a combination of Kreisel-Troelstra realizability and Kleene""s [17][18][19][20] q-realizability. However, while Myhill and Friedman developed realizability directly for extensional set theories, Beeson engineered his realizability for non-extensional set theories and obtained results for the extensional set theories of [14] only via an interpretation in their non-extensional counterparts. This detour had the disadvantage that in many cases (where the theory does not have full Separation or Powerset) the DP and NEP for the corresponding extensional set theory T -ext could only be established for a restricted class of formulae. In [#CITATION_TAG,36,37] the author of the present paper developed a different machinery for showing the DP and the NEP (and several other properties) directly for extensional set theories. [36] introduced a self-validating semantics for constructive Zermelo-Fraenkel set theory, CZF, that combines realizability for extensional set theory and truth. In [37] this method was used to establish the DP and NEP for CZF and IZF augmented by familiar choice principles, i.e., any combination of the principles of Countable Choice, Relativized Dependent Choices and the Presentation Axiom (cf. [32]). Also Markov""s principle may be added. So far we have not addressed the question whether the EP holds for IZF and CZF. Partial results were obtained in [35,Theorems 8.3,8.4] to the effect that CZF augmented via a strong form of the axiom of choice, the Œ†Œ£ axiom of choice, has the EP for a very large collection of formulae. It was shown by Friedman and ≈†ƒçedrov that the EP fails for IZF, intuitionistic Zermelo-Fraenkel set theory formulated with Collection. As IZF R possesses the EP, Collection is clearly implicated in this failure. Beeson in [6, IX.1] posed the following question:"	0	"He used a combination of Kreisel-Troelstra realizability and Kleene""s [17][18][19][20] q-realizability. However, while Myhill and Friedman developed realizability directly for extensional set theories, Beeson engineered his realizability for non-extensional set theories and obtained results for the extensional set theories of [14] only via an interpretation in their non-extensional counterparts. This detour had the disadvantage that in many cases (where the theory does not have full Separation or Powerset) the DP and NEP for the corresponding extensional set theory T -ext could only be established for a restricted class of formulae. In [#CITATION_TAG,36,37] the author of the present paper developed a different machinery for showing the DP and the NEP (and several other properties) directly for extensional set theories. [36] introduced a self-validating semantics for constructive Zermelo-Fraenkel set theory, CZF, that combines realizability for extensional set theory and truth. In [37] this method was used to establish the DP and NEP for CZF and IZF augmented by familiar choice principles, i.e., any combination of the principles of Countable Choice, Relativized Dependent Choices and the Presentation Axiom (cf. [32]). Also Markov""s principle may be added."	A
CCT681	"Realizability semantics are a crucial tool in the study of intuitionistic theories. We introduce a form of realizability based on general set recursive functions where a realizer for an existential statement provides a set of witnesses for the existential quantifier rather than a single witness. Realizability based on indices of general set recursive functions was introduced in #CITATION_TAG and employed to prove, inter alia, metamathematical properties for CZF augmented by strong forms of the axiom of choice in [35,Theorems 8.3,8.4]. There are points of contact with a notion of realizability used by Tharp [42] who employed (indices of) Œ£ 1 definable partial (class) functions as realizers, though there are important differences, too, as Tharp works in a classical context and assumes a definable search operation on the universe which basically amounts to working under the hypothesis V = L. Moreover, there are connections with Lifschitz"" realizability [22] where a realizer for an existential arithmetical statement provides a finite co-recursive set of witnesses (see [30,8] for extensions to analysis and set theory). Another important type of semantics or interpretation for intuitionistic systems is functional interpretation. The Diller-Nahm interpretation [9] also employs sets of witnesses to interpret existential quantifiers. It has been extended to set theories by Burr, Diller and Schulte [7,10,41]. Burr [7, Corollary 5.12] and Diller [10, Proposition 4.4] prove weak forms of term existence property for a higher type versions of CZF ‚àí . Interestingly, Diller conjectures ([10] Conjectures 4.8,4.9) that the term existence property fails for higher type versions of CZF ‚àí . By contrast, in this paper it shown that CZF ‚àí does have the existence property (Corollary 6.1)."	0	"Realizability semantics are a crucial tool in the study of intuitionistic theories. We introduce a form of realizability based on general set recursive functions where a realizer for an existential statement provides a set of witnesses for the existential quantifier rather than a single witness. Realizability based on indices of general set recursive functions was introduced in #CITATION_TAG and employed to prove, inter alia, metamathematical properties for CZF augmented by strong forms of the axiom of choice in [35,Theorems 8.3,8.4]. There are points of contact with a notion of realizability used by Tharp [42] who employed (indices of) Œ£ 1 definable partial (class) functions as realizers, though there are important differences, too, as Tharp works in a classical context and assumes a definable search operation on the universe which basically amounts to working under the hypothesis V = L. Moreover, there are connections with Lifschitz"" realizability [22] where a realizer for an existential arithmetical statement provides a finite co-recursive set of witnesses (see [30,8] for extensions to analysis and set theory). Another important type of semantics or interpretation for intuitionistic systems is functional interpretation. The Diller-Nahm interpretation [9] also employs sets of witnesses to interpret existential quantifiers."	a
CCT682	We define a relation a wt B between sets and set-theoretic formulae. a ‚Ä¢ f wt B will be an abbreviation for ‚àÉx[a ‚Ä¢ f ‚âÉ x ‚àß x wt B]. a wt A iff A holds true, whenever A is an atomic formula Remark 3.2. The above notion of realizability stripped of its truth component was employed in #CITATION_TAG to obtain prooftheoretic results relating intuitionistic and classical set theories. Proof. This is immediate by induction on the complexity of B. Lemma 3.4. Let ‚Éó x = x 1 , . . . , x r and ‚Éó a = a 1 , . . . , a r . To each formula A(‚Éó x) of set theory (with all free variables among ‚Éó x) we can effectively assign (a code of) an E-recursive partial function œá A such that the following hold:	0	We define a relation a wt B between sets and set-theoretic formulae. a ‚Ä¢ f wt B will be an abbreviation for ‚àÉx[a ‚Ä¢ f ‚âÉ x ‚àß x wt B]. a wt A iff A holds true, whenever A is an atomic formula Remark 3.2. The above notion of realizability stripped of its truth component was employed in #CITATION_TAG to obtain prooftheoretic results relating intuitionistic and classical set theories. Proof. This is immediate by induction on the complexity of B. Lemma 3.4. Let ‚Éó x = x 1 , . . . , x r and ‚Éó a = a 1 , . . . , a r . To each formula A(‚Éó x) of set theory (with all free variables among ‚Éó x) we can effectively assign (a code of) an E-recursive partial function œá A such that the following hold:	 
CCT683	"Realizability semantics are a crucial tool in the study of intuitionistic theories. We introduce a form of realizability based on general set recursive functions where a realizer for an existential statement provides a set of witnesses for the existential quantifier rather than a single witness. Realizability based on indices of general set recursive functions was introduced in [34] and employed to prove, inter alia, metamathematical properties for CZF augmented by strong forms of the axiom of choice in [35,Theorems 8.3,8.4]. There are points of contact with a notion of realizability used by Tharp #CITATION_TAG who employed (indices of) Œ£ 1 definable partial (class) functions as realizers, though there are important differences, too, as Tharp works in a classical context and assumes a definable search operation on the universe which basically amounts to working under the hypothesis V = L. Moreover, there are connections with Lifschitz"" realizability [22] where a realizer for an existential arithmetical statement provides a finite co-recursive set of witnesses (see [30,8] for extensions to analysis and set theory). Another important type of semantics or interpretation for intuitionistic systems is functional interpretation. The Diller-Nahm interpretation [9] also employs sets of witnesses to interpret existential quantifiers. It has been extended to set theories by Burr, Diller and Schulte [7,10,41]. Burr [7, Corollary 5.12] and Diller [10, Proposition 4.4] prove weak forms of term existence property for a higher type versions of CZF ‚àí . Interestingly, Diller conjectures ([10] Conjectures 4.8,4.9) that the term existence property fails for higher type versions of CZF ‚àí . By contrast, in this paper it shown that CZF ‚àí does have the existence property (Corollary 6.1)."	5	"Realizability semantics are a crucial tool in the study of intuitionistic theories. We introduce a form of realizability based on general set recursive functions where a realizer for an existential statement provides a set of witnesses for the existential quantifier rather than a single witness. Realizability based on indices of general set recursive functions was introduced in [34] and employed to prove, inter alia, metamathematical properties for CZF augmented by strong forms of the axiom of choice in [35,Theorems 8.3,8.4]. There are points of contact with a notion of realizability used by Tharp #CITATION_TAG who employed (indices of) Œ£ 1 definable partial (class) functions as realizers, though there are important differences, too, as Tharp works in a classical context and assumes a definable search operation on the universe which basically amounts to working under the hypothesis V = L. Moreover, there are connections with Lifschitz"" realizability [22] where a realizer for an existential arithmetical statement provides a finite co-recursive set of witnesses (see [30,8] for extensions to analysis and set theory). Another important type of semantics or interpretation for intuitionistic systems is functional interpretation. The Diller-Nahm interpretation [9] also employs sets of witnesses to interpret existential quantifiers. It has been extended to set theories by Burr, Diller and Schulte [7,10,41]."	r
CCT684	"Realizability semantics are a crucial tool in the study of intuitionistic theories. We introduce a form of realizability based on general set recursive functions where a realizer for an existential statement provides a set of witnesses for the existential quantifier rather than a single witness. Realizability based on indices of general set recursive functions was introduced in [34] and employed to prove, inter alia, metamathematical properties for CZF augmented by strong forms of the axiom of choice in [35,Theorems 8.3,8.4]. There are points of contact with a notion of realizability used by Tharp [42] who employed (indices of) Œ£ 1 definable partial (class) functions as realizers, though there are important differences, too, as Tharp works in a classical context and assumes a definable search operation on the universe which basically amounts to working under the hypothesis V = L. Moreover, there are connections with Lifschitz"" realizability #CITATION_TAG where a realizer for an existential arithmetical statement provides a finite co-recursive set of witnesses (see [30,8] for extensions to analysis and set theory). Another important type of semantics or interpretation for intuitionistic systems is functional interpretation. The Diller-Nahm interpretation [9] also employs sets of witnesses to interpret existential quantifiers. It has been extended to set theories by Burr, Diller and Schulte [7,10,41]. Burr [7, Corollary 5.12] and Diller [10, Proposition 4.4] prove weak forms of term existence property for a higher type versions of CZF ‚àí . Interestingly, Diller conjectures ([10] Conjectures 4.8,4.9) that the term existence property fails for higher type versions of CZF ‚àí . By contrast, in this paper it shown that CZF ‚àí does have the existence property (Corollary 6.1)."	1	"Realizability semantics are a crucial tool in the study of intuitionistic theories. We introduce a form of realizability based on general set recursive functions where a realizer for an existential statement provides a set of witnesses for the existential quantifier rather than a single witness. Realizability based on indices of general set recursive functions was introduced in [34] and employed to prove, inter alia, metamathematical properties for CZF augmented by strong forms of the axiom of choice in [35,Theorems 8.3,8.4]. There are points of contact with a notion of realizability used by Tharp [42] who employed (indices of) Œ£ 1 definable partial (class) functions as realizers, though there are important differences, too, as Tharp works in a classical context and assumes a definable search operation on the universe which basically amounts to working under the hypothesis V = L. Moreover, there are connections with Lifschitz"" realizability #CITATION_TAG where a realizer for an existential arithmetical statement provides a finite co-recursive set of witnesses (see [30,8] for extensions to analysis and set theory). Another important type of semantics or interpretation for intuitionistic systems is functional interpretation. The Diller-Nahm interpretation [9] also employs sets of witnesses to interpret existential quantifiers. It has been extended to set theories by Burr, Diller and Schulte [7,10,41]."	r
CCT685	"Realizability semantics are a crucial tool in the study of intuitionistic theories. We introduce a form of realizability based on general set recursive functions where a realizer for an existential statement provides a set of witnesses for the existential quantifier rather than a single witness. Realizability based on indices of general set recursive functions was introduced in [34] and employed to prove, inter alia, metamathematical properties for CZF augmented by strong forms of the axiom of choice in [35,Theorems 8.3,8.4]. There are points of contact with a notion of realizability used by Tharp [42] who employed (indices of) Œ£ 1 definable partial (class) functions as realizers, though there are important differences, too, as Tharp works in a classical context and assumes a definable search operation on the universe which basically amounts to working under the hypothesis V = L. Moreover, there are connections with Lifschitz"" realizability [22] where a realizer for an existential arithmetical statement provides a finite co-recursive set of witnesses (see [30,8] for extensions to analysis and set theory). Another important type of semantics or interpretation for intuitionistic systems is functional interpretation. The Diller-Nahm interpretation #CITATION_TAG also employs sets of witnesses to interpret existential quantifiers. It has been extended to set theories by Burr, Diller and Schulte [7,10,41]. Burr [7, Corollary 5.12] and Diller [10, Proposition 4.4] prove weak forms of term existence property for a higher type versions of CZF ‚àí . Interestingly, Diller conjectures ([10] Conjectures 4.8,4.9) that the term existence property fails for higher type versions of CZF ‚àí . By contrast, in this paper it shown that CZF ‚àí does have the existence property (Corollary 6.1)."	0	"Realizability based on indices of general set recursive functions was introduced in [34] and employed to prove, inter alia, metamathematical properties for CZF augmented by strong forms of the axiom of choice in [35,Theorems 8.3,8.4]. There are points of contact with a notion of realizability used by Tharp [42] who employed (indices of) Œ£ 1 definable partial (class) functions as realizers, though there are important differences, too, as Tharp works in a classical context and assumes a definable search operation on the universe which basically amounts to working under the hypothesis V = L. Moreover, there are connections with Lifschitz"" realizability [22] where a realizer for an existential arithmetical statement provides a finite co-recursive set of witnesses (see [30,8] for extensions to analysis and set theory). Another important type of semantics or interpretation for intuitionistic systems is functional interpretation. The Diller-Nahm interpretation #CITATION_TAG also employs sets of witnesses to interpret existential quantifiers. It has been extended to set theories by Burr, Diller and Schulte [7,10,41]. Burr [7, Corollary 5.12] and Diller [10, Proposition 4.4] prove weak forms of term existence property for a higher type versions of CZF ‚àí . Interestingly, Diller conjectures ([10] Conjectures 4.8,4.9) that the term existence property fails for higher type versions of CZF ‚àí . By contrast, in this paper it shown that CZF ‚àí does have the existence property (Corollary 6.1)."	i
CCT686	"It was left open in [28] whether the full existence property holds in the presence of relativized dependent choice, RDC. Friedman and ≈†ƒçedrov [15] then established that IZF R + RDC satisfies the EP also. Several systems of set theory for the constructive mathematical practice were propounded by Friedman in [14]. The metamathematical properties of these theories and several others as well were subsequently investigated by Beeson [#CITATION_TAG,6]. In particular, Beeson showed that IZF has the DP and NEP. He used a combination of Kreisel-Troelstra realizability and Kleene""s [17][18][19][20] q-realizability. However, while Myhill and Friedman developed realizability directly for extensional set theories, Beeson engineered his realizability for non-extensional set theories and obtained results for the extensional set theories of [14] only via an interpretation in their non-extensional counterparts. This detour had the disadvantage that in many cases (where the theory does not have full Separation or Powerset) the DP and NEP for the corresponding extensional set theory T -ext could only be established for a restricted class of formulae. In [33,36,37] the author of the present paper developed a different machinery for showing the DP and the NEP (and several other properties) directly for extensional set theories. [36] introduced a self-validating semantics for constructive Zermelo-Fraenkel set theory, CZF, that combines realizability for extensional set theory and truth. In [37] this method was used to establish the DP and NEP for CZF and IZF augmented by familiar choice principles, i.e., any combination of the principles of Countable Choice, Relativized Dependent Choices and the Presentation Axiom (cf. [32]). Also Markov""s principle may be added. So far we have not addressed the question whether the EP holds for IZF and CZF. Partial results were obtained in [35,Theorems 8.3,8.4] to the effect that CZF augmented via a strong form of the axiom of choice, the Œ†Œ£ axiom of choice, has the EP for a very large collection of formulae. It was shown by Friedman and ≈†ƒçedrov that the EP fails for IZF, intuitionistic Zermelo-Fraenkel set theory formulated with Collection. As IZF R possesses the EP, Collection is clearly implicated in this failure. Beeson in [6, IX.1] posed the following question:"	0	"It was left open in [28] whether the full existence property holds in the presence of relativized dependent choice, RDC. Friedman and ≈†ƒçedrov [15] then established that IZF R + RDC satisfies the EP also. Several systems of set theory for the constructive mathematical practice were propounded by Friedman in [14]. The metamathematical properties of these theories and several others as well were subsequently investigated by Beeson [#CITATION_TAG,6]. In particular, Beeson showed that IZF has the DP and NEP. He used a combination of Kreisel-Troelstra realizability and Kleene""s [17][18][19][20] q-realizability. However, while Myhill and Friedman developed realizability directly for extensional set theories, Beeson engineered his realizability for non-extensional set theories and obtained results for the extensional set theories of [14] only via an interpretation in their non-extensional counterparts."	 
CCT687	"Realizability semantics are of paramount importance in the study of intuitionistic theories. They were first proposed by Kleene [17] in 1945. Friedman [12] showed metamathematical results for intuitionistic set theories by extending a notion of realizability developed by Kreisel and Troelstra #CITATION_TAG. A realizability-notion akin to Kleene""s slash [18,19] was extended to various intuitionistic set theories by Myhill [27,28], whereby he also drew on work by Moschovakis [24]. We use IZF to denote intuitionistic Zermelo-Fraenkel set theory formulated with Collection. [27] showed that intuitionistic ZF with Replacement instead of Collection (dubbed IZF R henceforth) has the DP, NEP, and EP. [28] proved that his constructive set theory CST enjoys the DP and the NEP, and that the theory without the axioms of countable and dependent choice, CST ‚àí , also has the EP."	0	"Realizability semantics are of paramount importance in the study of intuitionistic theories. They were first proposed by Kleene [17] in 1945. Friedman [12] showed metamathematical results for intuitionistic set theories by extending a notion of realizability developed by Kreisel and Troelstra #CITATION_TAG. A realizability-notion akin to Kleene""s slash [18,19] was extended to various intuitionistic set theories by Myhill [27,28], whereby he also drew on work by Moschovakis [24]. We use IZF to denote intuitionistic Zermelo-Fraenkel set theory formulated with Collection. [27] showed that intuitionistic ZF with Replacement instead of Collection (dubbed IZF R henceforth) has the DP, NEP, and EP."	i
CCT688	"Realizability semantics are of paramount importance in the study of intuitionistic theories. They were first proposed by Kleene [17] in 1945. Friedman #CITATION_TAG showed metamathematical results for intuitionistic set theories by extending a notion of realizability developed by Kreisel and Troelstra [21]. A realizability-notion akin to Kleene""s slash [18,19] was extended to various intuitionistic set theories by Myhill [27,28], whereby he also drew on work by Moschovakis [24]. We use IZF to denote intuitionistic Zermelo-Fraenkel set theory formulated with Collection. [27] showed that intuitionistic ZF with Replacement instead of Collection (dubbed IZF R henceforth) has the DP, NEP, and EP. [28] proved that his constructive set theory CST enjoys the DP and the NEP, and that the theory without the axioms of countable and dependent choice, CST ‚àí , also has the EP."	0	"Realizability semantics are of paramount importance in the study of intuitionistic theories. They were first proposed by Kleene [17] in 1945. Friedman #CITATION_TAG showed metamathematical results for intuitionistic set theories by extending a notion of realizability developed by Kreisel and Troelstra [21]. A realizability-notion akin to Kleene""s slash [18,19] was extended to various intuitionistic set theories by Myhill [27,28], whereby he also drew on work by Moschovakis [24]. We use IZF to denote intuitionistic Zermelo-Fraenkel set theory formulated with Collection. [27] showed that intuitionistic ZF with Replacement instead of Collection (dubbed IZF R henceforth) has the DP, NEP, and EP."	i
CCT689	"It was left open in [28] whether the full existence property holds in the presence of relativized dependent choice, RDC. Friedman and ≈†ƒçedrov [15] then established that IZF R + RDC satisfies the EP also. Several systems of set theory for the constructive mathematical practice were propounded by Friedman in [14]. The metamathematical properties of these theories and several others as well were subsequently investigated by Beeson [5,6]. In particular, Beeson showed that IZF has the DP and NEP. He used a combination of Kreisel-Troelstra realizability and Kleene""s [17][18][19]#CITATION_TAG q-realizability. However, while Myhill and Friedman developed realizability directly for extensional set theories, Beeson engineered his realizability for non-extensional set theories and obtained results for the extensional set theories of [14] only via an interpretation in their non-extensional counterparts. This detour had the disadvantage that in many cases (where the theory does not have full Separation or Powerset) the DP and NEP for the corresponding extensional set theory T -ext could only be established for a restricted class of formulae. In [33,36,37] the author of the present paper developed a different machinery for showing the DP and the NEP (and several other properties) directly for extensional set theories. [36] introduced a self-validating semantics for constructive Zermelo-Fraenkel set theory, CZF, that combines realizability for extensional set theory and truth. In [37] this method was used to establish the DP and NEP for CZF and IZF augmented by familiar choice principles, i.e., any combination of the principles of Countable Choice, Relativized Dependent Choices and the Presentation Axiom (cf. [32]). Also Markov""s principle may be added. So far we have not addressed the question whether the EP holds for IZF and CZF. Partial results were obtained in [35,Theorems 8.3,8.4] to the effect that CZF augmented via a strong form of the axiom of choice, the Œ†Œ£ axiom of choice, has the EP for a very large collection of formulae. It was shown by Friedman and ≈†ƒçedrov that the EP fails for IZF, intuitionistic Zermelo-Fraenkel set theory formulated with Collection. As IZF R possesses the EP, Collection is clearly implicated in this failure. Beeson in [6, IX.1] posed the following question:"	0	"Several systems of set theory for the constructive mathematical practice were propounded by Friedman in [14]. The metamathematical properties of these theories and several others as well were subsequently investigated by Beeson [5,6]. In particular, Beeson showed that IZF has the DP and NEP. He used a combination of Kreisel-Troelstra realizability and Kleene""s [17][18][19]#CITATION_TAG q-realizability. However, while Myhill and Friedman developed realizability directly for extensional set theories, Beeson engineered his realizability for non-extensional set theories and obtained results for the extensional set theories of [14] only via an interpretation in their non-extensional counterparts. This detour had the disadvantage that in many cases (where the theory does not have full Separation or Powerset) the DP and NEP for the corresponding extensional set theory T -ext could only be established for a restricted class of formulae. In [33,36,37] the author of the present paper developed a different machinery for showing the DP and the NEP (and several other properties) directly for extensional set theories."	e
CCT690	Fungicides have different modes of action and can be both broad range or target a specific group of fungi [15] and the fungicide type and use vary for different crops. Previous studies examining fungicide effects on non-target fungi in the wheat phyllosphere using culture-dependent methods have shown that fungicides with different modes of action have differing effects on individual fungal taxa [7][8][9]#CITATION_TAG[17][18]. Some of the biases of culturedependent methods can be overcome using DNA-based methods. Recently, high-throughput sequencing technologies have revolutionized the study of microbial diversity in the phyllosphere. Consequently, knowledge on bacterial phyllosphere communities on agricultural crops is growing, but less is known about fungi [19]. So far, fungicide effects on fungal communities in the phyllosphere has only been investigated to a limited extent using DNA-based fingerprinting methods [20,21] and high-throughput sequencing [22], but none of these studies focused on cereals.	2	Fungicides have different modes of action and can be both broad range or target a specific group of fungi [15] and the fungicide type and use vary for different crops. Previous studies examining fungicide effects on non-target fungi in the wheat phyllosphere using culture-dependent methods have shown that fungicides with different modes of action have differing effects on individual fungal taxa [7][8][9]#CITATION_TAG[17][18]. Some of the biases of culturedependent methods can be overcome using DNA-based methods. Recently, high-throughput sequencing technologies have revolutionized the study of microbial diversity in the phyllosphere. Consequently, knowledge on bacterial phyllosphere communities on agricultural crops is growing, but less is known about fungi [19].	r
CCT691	Wheat is one of the most important crops worldwide and the wheat-associated fungal community was one of the first phyllosphere communities to be studied #CITATION_TAG. The wheat phyllosphere has been found to contain many basidiomycete yeasts such as Cryptococcus spp.  Sporobolomyces roseus and filamentous saprotrophs, e.g. Cladosporium spp.  Alternaria spp.  Epicoccum spp.  and plant pathogens [5][6][7][8]. Fungi can be present both as epiphytes and endophytes on wheat leaves. This is reflected in the different sets of fungi retrieved when washed leaf pieces are cultured compared with leaf wash liquid [9]. The main components of the fungal wheat leaf community differ in studies conducted at different sites and at different times and the mechanisms that lie behind the dynamics of fungal communities in the phyllosphere of agricultural crops are not well understood.	0	Wheat is one of the most important crops worldwide and the wheat-associated fungal community was one of the first phyllosphere communities to be studied #CITATION_TAG. The wheat phyllosphere has been found to contain many basidiomycete yeasts such as Cryptococcus spp. Sporobolomyces roseus and filamentous saprotrophs, e.g. Cladosporium spp. Alternaria spp.	W
CCT692	Wheat is one of the most important crops worldwide and the wheat-associated fungal community was one of the first phyllosphere communities to be studied [5]. The wheat phyllosphere has been found to contain many basidiomycete yeasts such as Cryptococcus spp.  Sporobolomyces roseus and filamentous saprotrophs, e.g. Cladosporium spp.  Alternaria spp.  Epicoccum spp.  and plant pathogens [5][6][7][8]. Fungi can be present both as epiphytes and endophytes on wheat leaves. This is reflected in the different sets of fungi retrieved when washed leaf pieces are cultured compared with leaf wash liquid #CITATION_TAG. The main components of the fungal wheat leaf community differ in studies conducted at different sites and at different times and the mechanisms that lie behind the dynamics of fungal communities in the phyllosphere of agricultural crops are not well understood.	0	Epicoccum spp. and plant pathogens [5][6][7][8]. Fungi can be present both as epiphytes and endophytes on wheat leaves. This is reflected in the different sets of fungi retrieved when washed leaf pieces are cultured compared with leaf wash liquid #CITATION_TAG. The main components of the fungal wheat leaf community differ in studies conducted at different sites and at different times and the mechanisms that lie behind the dynamics of fungal communities in the phyllosphere of agricultural crops are not well understood.	 
CCT693	The ITS2 region was amplified on a 2720 Thermal Cycler (Life Technologies, CA, USA) using the forward primer fITS7 (GTGARTCATCGAATCTTTG; #CITATION_TAG and the reverse primer ITS4 (TCCTCCGCTTATTGATATGC; [26]. The length of the ITS2 is variable among fungi, ranging between ,122 and 245 bp [25]. The ITS4 primer was tagged with an 8 bp barcode. PCR was run in 50-ml reactions with 0.8 ng/ml template, 200 mM of each nucleotide, 2.75 mM MgCl 2 , forward primer at 500 nM, tagged primer at 300 nM and 0.02 U/ml polymerase (DreamTaq Green, Thermo Scientific, MA, USA) in PCR buffer. PCR conditions were 5 min at 94uC, 30-32 cycles of [30 s at 94uC, 30 s at 57uC, 30 s at 72uC] and 7 min at 72uC. The number of cycles was adapted for each sample to give weak to moderately strong bands on the agarose gel with approximately the same strength for all samples to avoid oversaturation and distortion of the PCR pool. To determine the number of cycles necessary for each sample, test runs were conducted with non-barcoded primers starting at 25 PCR cycles before samples were run with the barcoded primers.	5	The ITS2 region was amplified on a 2720 Thermal Cycler (Life Technologies, CA, USA) using the forward primer fITS7 (GTGARTCATCGAATCTTTG; #CITATION_TAG and the reverse primer ITS4 (TCCTCCGCTTATTGATATGC; [26]. The length of the ITS2 is variable among fungi, ranging between ,122 and 245 bp [25]. The ITS4 primer was tagged with an 8 bp barcode. PCR was run in 50-ml reactions with 0.8 ng/ml template, 200 mM of each nucleotide, 2.75 mM MgCl 2 , forward primer at 500 nM, tagged primer at 300 nM and 0.02 U/ml polymerase (DreamTaq Green, Thermo Scientific, MA, USA) in PCR buffer.	T
CCT694	Fungicides have different modes of action and can be both broad range or target a specific group of fungi [15] and the fungicide type and use vary for different crops. Previous studies examining fungicide effects on non-target fungi in the wheat phyllosphere using culture-dependent methods have shown that fungicides with different modes of action have differing effects on individual fungal taxa [7][8][9][16][17]#CITATION_TAG. Some of the biases of culturedependent methods can be overcome using DNA-based methods. Recently, high-throughput sequencing technologies have revolutionized the study of microbial diversity in the phyllosphere. Consequently, knowledge on bacterial phyllosphere communities on agricultural crops is growing, but less is known about fungi [19]. So far, fungicide effects on fungal communities in the phyllosphere has only been investigated to a limited extent using DNA-based fingerprinting methods [20,21] and high-throughput sequencing [22], but none of these studies focused on cereals.	2	Fungicides have different modes of action and can be both broad range or target a specific group of fungi [15] and the fungicide type and use vary for different crops. Previous studies examining fungicide effects on non-target fungi in the wheat phyllosphere using culture-dependent methods have shown that fungicides with different modes of action have differing effects on individual fungal taxa [7][8][9][16][17]#CITATION_TAG. Some of the biases of culturedependent methods can be overcome using DNA-based methods. Recently, high-throughput sequencing technologies have revolutionized the study of microbial diversity in the phyllosphere. Consequently, knowledge on bacterial phyllosphere communities on agricultural crops is growing, but less is known about fungi [19].	r
CCT695	Fungicides have different modes of action and can be both broad range or target a specific group of fungi [15] and the fungicide type and use vary for different crops. Previous studies examining fungicide effects on non-target fungi in the wheat phyllosphere using culture-dependent methods have shown that fungicides with different modes of action have differing effects on individual fungal taxa [7][8][9][16]#CITATION_TAG[18]. Some of the biases of culturedependent methods can be overcome using DNA-based methods. Recently, high-throughput sequencing technologies have revolutionized the study of microbial diversity in the phyllosphere. Consequently, knowledge on bacterial phyllosphere communities on agricultural crops is growing, but less is known about fungi [19]. So far, fungicide effects on fungal communities in the phyllosphere has only been investigated to a limited extent using DNA-based fingerprinting methods [20,21] and high-throughput sequencing [22], but none of these studies focused on cereals.	2	Fungicides have different modes of action and can be both broad range or target a specific group of fungi [15] and the fungicide type and use vary for different crops. Previous studies examining fungicide effects on non-target fungi in the wheat phyllosphere using culture-dependent methods have shown that fungicides with different modes of action have differing effects on individual fungal taxa [7][8][9][16]#CITATION_TAG[18]. Some of the biases of culturedependent methods can be overcome using DNA-based methods. Recently, high-throughput sequencing technologies have revolutionized the study of microbial diversity in the phyllosphere. Consequently, knowledge on bacterial phyllosphere communities on agricultural crops is growing, but less is known about fungi [19].	r
CCT696	OTU_0_Sporobolomyces_roseus (p,0.001) was relatively more abundant in the Southern area and it was the largest community member in that area, while OTU_3_Dioszegia_fristingensis was the most abundant species in the Northern area (Fig. 7). Both of these species produce pigments and ballistospores, two characters considered to be a sign of adaptation to the phyllosphere [48]. Several studies have reported Sporobolomyces roseus as very common on wheat leaves [5,7]. In contrast, Blixt et al. [6] only found a small proportion of this species in their study, but they selectively collected leaves diseased with Phaeospharia nodorum. Dioszegia fristingensis was described relatively recently in Germany [58], and has been reported from China #CITATION_TAG. It has been suggested that a group of Dioszegia, including D. fristingensis, is restricted to colder climates [58].	0	Both of these species produce pigments and ballistospores, two characters considered to be a sign of adaptation to the phyllosphere [48]. Several studies have reported Sporobolomyces roseus as very common on wheat leaves [5,7]. In contrast, Blixt et al. [6] only found a small proportion of this species in their study, but they selectively collected leaves diseased with Phaeospharia nodorum. Dioszegia fristingensis was described relatively recently in Germany [58], and has been reported from China #CITATION_TAG. It has been suggested that a group of Dioszegia, including D. fristingensis, is restricted to colder climates [58].	z
CCT697	Sampling of wheat fields was carried out in two important agricultural production areas of Sweden, a Northern sampling area located in the region of V√§ sterg√∂tland and a Southern sampling area in the Sk√•ne region (Fig. 1). The Southern area is characterised by a milder and drier climate. The two areas also differ in agricultural management, for example in terms of cropping sequence #CITATION_TAG, the choice of wheat variety and fungicides are used more frequently in the Southern area [24]. The average winter wheat yield is about 2000 kg/ha higher in the Southern area [23]. At the time of sampling, fields in the Northern area had reached anthesis, while in the Southern area the developmental stage ranged from anthesis to the early dough ripening stage (Table 1).	0	Sampling of wheat fields was carried out in two important agricultural production areas of Sweden, a Northern sampling area located in the region of V√§ sterg√∂tland and a Southern sampling area in the Sk√•ne region (Fig. 1). The Southern area is characterised by a milder and drier climate. The two areas also differ in agricultural management, for example in terms of cropping sequence #CITATION_TAG, the choice of wheat variety and fungicides are used more frequently in the Southern area [24]. The average winter wheat yield is about 2000 kg/ha higher in the Southern area [23]. At the time of sampling, fields in the Northern area had reached anthesis, while in the Southern area the developmental stage ranged from anthesis to the early dough ripening stage (Table 1).	e
CCT698	The phyllosphere, defined as the total above-ground parts of plants, provides a habitat for many microorganisms #CITATION_TAG. Phyllosphere microorganisms, including fungi, have been shown to perform important ecological functions and can be both beneficial and harmful to their host plant [2]. In agricultural crops, some phyllosphere fungi are important pathogens, while others have antagonistic properties [3] or can influence the physiology of the plant [4]. Understanding the influence of agricultural practices on phyllosphere fungal communities is important in order to create the best conditions for crop development.	0	The phyllosphere, defined as the total above-ground parts of plants, provides a habitat for many microorganisms #CITATION_TAG. Phyllosphere microorganisms, including fungi, have been shown to perform important ecological functions and can be both beneficial and harmful to their host plant [2]. In agricultural crops, some phyllosphere fungi are important pathogens, while others have antagonistic properties [3] or can influence the physiology of the plant [4]. Understanding the influence of agricultural practices on phyllosphere fungal communities is important in order to create the best conditions for crop development.	T
CCT699	Fungicides have different modes of action and can be both broad range or target a specific group of fungi #CITATION_TAG and the fungicide type and use vary for different crops. Previous studies examining fungicide effects on non-target fungi in the wheat phyllosphere using culture-dependent methods have shown that fungicides with different modes of action have differing effects on individual fungal taxa [7][8][9][16][17][18]. Some of the biases of culturedependent methods can be overcome using DNA-based methods. Recently, high-throughput sequencing technologies have revolutionized the study of microbial diversity in the phyllosphere. Consequently, knowledge on bacterial phyllosphere communities on agricultural crops is growing, but less is known about fungi [19]. So far, fungicide effects on fungal communities in the phyllosphere has only been investigated to a limited extent using DNA-based fingerprinting methods [20,21] and high-throughput sequencing [22], but none of these studies focused on cereals.	0	Fungicides have different modes of action and can be both broad range or target a specific group of fungi #CITATION_TAG and the fungicide type and use vary for different crops. Previous studies examining fungicide effects on non-target fungi in the wheat phyllosphere using culture-dependent methods have shown that fungicides with different modes of action have differing effects on individual fungal taxa [7][8][9][16][17][18]. Some of the biases of culturedependent methods can be overcome using DNA-based methods. Recently, high-throughput sequencing technologies have revolutionized the study of microbial diversity in the phyllosphere.	F
CCT700	"The fungicide sensitivity of phyllosphere fungi has mostly been investigated with fungicides that are no longer used or have been prohibited in Sweden, except for some sterol biosynthesis inhibitors (SBI). SBI fungicides have been shown to have no or    Species hypothesis accession codes in the UNITE 1 database version are indicated when available. Functional assignment as ""pathogen"" is only used for taxa known to be pathogenic on wheat. a moderate effect on the ""pink"" and ""white"" phyllosphere yeasts, with a somewhat stronger effect on ""white"" yeasts [16]. Aureobasidium pullulans is reported to be sensitive to propiconazole [16] and prochloraz [17,18] and these two fungicides and other SBI fungicides have been used in almost all the fields in this study (Table S1). The ascomycete A. pullulans is one of the most common inhabitants of the phyllosphere of many crops [48] and is also present in many other habitats [49]. Aureobasidium pullulans is known to be antagonistic towards necrotrophic pathogens, e.g. grey mould in strawberries [50] and powdery mildew in durum wheat [51]. The mechanism of the antagonism is hypothesised to be competition for nutrients #CITATION_TAG. Some strains of A. pullulans also produce a type of antibiotic called aureobasidins [53]. The antagonistic potential of biological control agents is frequently strain-specific, depending on the mechanism of antagonism. From the sequence data, we cannot make inferences about the antagonistic capacity of an OTU. Hence, it is unknown whether the reduction in the relative abundance of A. pullulans in fungicide-treated leaves has an impact on the antagonistic capacity of the fungal community. Several OTUs were identified as common wheat pathogens in the dataset: OTU_14_Mycosphaerella_graminicola, OTU_13_ Blumeria_graminis, OTU_1_Puccinia_striiformis, OTU_47_ Phaeosphaeria_nodorum (Parastagonospora nodorum), OTU_20_ Monographella_spp and OTU_224_Pyrenophora_tritici-repentis. Surprisingly, there was no significant effect of fungicide treatment on the relative abundance of any of these OTUs. On the contrary, there was a tendency for higher variability in the relative abundance of M. graminicola and B. graminis in treated samples (Fig. 6), and the share of B. graminis (the only member of Erysiphales) was larger in treated samples (Fig. 3). On the other hand, P. striiformis tended to dominate the fungal community in untreated samples and was nearly absent from the fungicidetreated samples from the same fields, only being present in two fields in the Southern area (Fig. 3). Fungicide resistance in common pathogens is an increasing problem and could be an explanation for the high variability in the relative abundance of the pathogens observed here. Resistance to strobilurines in M. graminicola and even more so in B. graminis is widespread in the Nordic and Baltic countries. In addition, resistance to demethylation inhibitor fungicides is increasing in both pathogens [10]. 454 sequencing is a semi-quantitative method only allowing quantification of the relative abundance of different OTUs [25]. Thus, we were unable to determine whether the fungicide treatment had an effect on absolute abundance of the pathogens."	0	Aureobasidium pullulans is reported to be sensitive to propiconazole [16] and prochloraz [17,18] and these two fungicides and other SBI fungicides have been used in almost all the fields in this study (Table S1). The ascomycete A. pullulans is one of the most common inhabitants of the phyllosphere of many crops [48] and is also present in many other habitats [49]. Aureobasidium pullulans is known to be antagonistic towards necrotrophic pathogens, e.g. grey mould in strawberries [50] and powdery mildew in durum wheat [51]. The mechanism of the antagonism is hypothesised to be competition for nutrients #CITATION_TAG. Some strains of A. pullulans also produce a type of antibiotic called aureobasidins [53]. The antagonistic potential of biological control agents is frequently strain-specific, depending on the mechanism of antagonism. From the sequence data, we cannot make inferences about the antagonistic capacity of an OTU.	h
CCT701	The community composition at the order level was significantly different for fungicide-treated and untreated samples (Fig. 3). The proportion of Leucosporidiales (p,0.05) and Dothideales (p, 0.05) was lower in fungicide-treated samples than in the control samples. This was reflected at the species level, where univariate tests showed that the relative abundance of three OTUs: OTU_6_Dioszegia_sp (p,0.05), OTU_28_Aureobasidium_pullu-lans_a (p,0.05) and OTU_25_Leucosporidium_golubevii (p, 0.05), was lower in fungicide-treated leaves than control leaves. OTU_6_Dioszegia_sp was similar to the ITS sequences of both D. crocea and D. aurantiaca. These species have been isolated from both the phyllosphere [43] and the rhizosphere of different plants [44,#CITATION_TAG]. Leucosporidium golubevii is a yeast discovered in freshwater [46], and has been reported from the phyllosphere of balsam poplar [47]. In addition, the relative abundance of OTU_16_Phaeosphaeria_juncophila (p,0.01) was higher in fungicide-treated leaves (Fig. 6). Phaeosphaeria juncophila was first isolated from the rush Juncus articulatus, but little is known about its ecology.	0	The proportion of Leucosporidiales (p,0.05) and Dothideales (p, 0.05) was lower in fungicide-treated samples than in the control samples. This was reflected at the species level, where univariate tests showed that the relative abundance of three OTUs: OTU_6_Dioszegia_sp (p,0.05), OTU_28_Aureobasidium_pullu-lans_a (p,0.05) and OTU_25_Leucosporidium_golubevii (p, 0.05), was lower in fungicide-treated leaves than control leaves. OTU_6_Dioszegia_sp was similar to the ITS sequences of both D. crocea and D. aurantiaca. These species have been isolated from both the phyllosphere [43] and the rhizosphere of different plants [44,#CITATION_TAG]. Leucosporidium golubevii is a yeast discovered in freshwater [46], and has been reported from the phyllosphere of balsam poplar [47]. In addition, the relative abundance of OTU_16_Phaeosphaeria_juncophila (p,0.01) was higher in fungicide-treated leaves (Fig. 6). Phaeosphaeria juncophila was first isolated from the rush Juncus articulatus, but little is known about its ecology.	e
CCT702	The community composition at the order level was significantly different for fungicide-treated and untreated samples (Fig. 3). The proportion of Leucosporidiales (p,0.05) and Dothideales (p, 0.05) was lower in fungicide-treated samples than in the control samples. This was reflected at the species level, where univariate tests showed that the relative abundance of three OTUs: OTU_6_Dioszegia_sp (p,0.05), OTU_28_Aureobasidium_pullu-lans_a (p,0.05) and OTU_25_Leucosporidium_golubevii (p, 0.05), was lower in fungicide-treated leaves than control leaves. OTU_6_Dioszegia_sp was similar to the ITS sequences of both D. crocea and D. aurantiaca. These species have been isolated from both the phyllosphere [43] and the rhizosphere of different plants [#CITATION_TAG,45]. Leucosporidium golubevii is a yeast discovered in freshwater [46], and has been reported from the phyllosphere of balsam poplar [47]. In addition, the relative abundance of OTU_16_Phaeosphaeria_juncophila (p,0.01) was higher in fungicide-treated leaves (Fig. 6). Phaeosphaeria juncophila was first isolated from the rush Juncus articulatus, but little is known about its ecology.	0	The proportion of Leucosporidiales (p,0.05) and Dothideales (p, 0.05) was lower in fungicide-treated samples than in the control samples. This was reflected at the species level, where univariate tests showed that the relative abundance of three OTUs: OTU_6_Dioszegia_sp (p,0.05), OTU_28_Aureobasidium_pullu-lans_a (p,0.05) and OTU_25_Leucosporidium_golubevii (p, 0.05), was lower in fungicide-treated leaves than control leaves. OTU_6_Dioszegia_sp was similar to the ITS sequences of both D. crocea and D. aurantiaca. These species have been isolated from both the phyllosphere [43] and the rhizosphere of different plants [#CITATION_TAG,45]. Leucosporidium golubevii is a yeast discovered in freshwater [46], and has been reported from the phyllosphere of balsam poplar [47]. In addition, the relative abundance of OTU_16_Phaeosphaeria_juncophila (p,0.01) was higher in fungicide-treated leaves (Fig. 6). Phaeosphaeria juncophila was first isolated from the rush Juncus articulatus, but little is known about its ecology.	e
CCT703	The community composition at the order level was significantly different for fungicide-treated and untreated samples (Fig. 3). The proportion of Leucosporidiales (p,0.05) and Dothideales (p, 0.05) was lower in fungicide-treated samples than in the control samples. This was reflected at the species level, where univariate tests showed that the relative abundance of three OTUs: OTU_6_Dioszegia_sp (p,0.05), OTU_28_Aureobasidium_pullu-lans_a (p,0.05) and OTU_25_Leucosporidium_golubevii (p, 0.05), was lower in fungicide-treated leaves than control leaves. OTU_6_Dioszegia_sp was similar to the ITS sequences of both D. crocea and D. aurantiaca. These species have been isolated from both the phyllosphere [43] and the rhizosphere of different plants [44,45]. Leucosporidium golubevii is a yeast discovered in freshwater [46], and has been reported from the phyllosphere of balsam poplar #CITATION_TAG. In addition, the relative abundance of OTU_16_Phaeosphaeria_juncophila (p,0.01) was higher in fungicide-treated leaves (Fig. 6). Phaeosphaeria juncophila was first isolated from the rush Juncus articulatus, but little is known about its ecology.	1	This was reflected at the species level, where univariate tests showed that the relative abundance of three OTUs: OTU_6_Dioszegia_sp (p,0.05), OTU_28_Aureobasidium_pullu-lans_a (p,0.05) and OTU_25_Leucosporidium_golubevii (p, 0.05), was lower in fungicide-treated leaves than control leaves. OTU_6_Dioszegia_sp was similar to the ITS sequences of both D. crocea and D. aurantiaca. These species have been isolated from both the phyllosphere [43] and the rhizosphere of different plants [44,45]. Leucosporidium golubevii is a yeast discovered in freshwater [46], and has been reported from the phyllosphere of balsam poplar #CITATION_TAG. In addition, the relative abundance of OTU_16_Phaeosphaeria_juncophila (p,0.01) was higher in fungicide-treated leaves (Fig. 6). Phaeosphaeria juncophila was first isolated from the rush Juncus articulatus, but little is known about its ecology.	s
CCT704	The phyllosphere, defined as the total above-ground parts of plants, provides a habitat for many microorganisms [1]. Phyllosphere microorganisms, including fungi, have been shown to perform important ecological functions and can be both beneficial and harmful to their host plant [2]. In agricultural crops, some phyllosphere fungi are important pathogens, while others have antagonistic properties [3] or can influence the physiology of the plant #CITATION_TAG. Understanding the influence of agricultural practices on phyllosphere fungal communities is important in order to create the best conditions for crop development.	0	The phyllosphere, defined as the total above-ground parts of plants, provides a habitat for many microorganisms [1]. Phyllosphere microorganisms, including fungi, have been shown to perform important ecological functions and can be both beneficial and harmful to their host plant [2]. In agricultural crops, some phyllosphere fungi are important pathogens, while others have antagonistic properties [3] or can influence the physiology of the plant #CITATION_TAG. Understanding the influence of agricultural practices on phyllosphere fungal communities is important in order to create the best conditions for crop development.	 
CCT705	"The fungicide sensitivity of phyllosphere fungi has mostly been investigated with fungicides that are no longer used or have been prohibited in Sweden, except for some sterol biosynthesis inhibitors (SBI). SBI fungicides have been shown to have no or    Species hypothesis accession codes in the UNITE 1 database version are indicated when available. Functional assignment as ""pathogen"" is only used for taxa known to be pathogenic on wheat. a moderate effect on the ""pink"" and ""white"" phyllosphere yeasts, with a somewhat stronger effect on ""white"" yeasts [16]. Aureobasidium pullulans is reported to be sensitive to propiconazole [16] and prochloraz [17,18] and these two fungicides and other SBI fungicides have been used in almost all the fields in this study (Table S1). The ascomycete A. pullulans is one of the most common inhabitants of the phyllosphere of many crops [48] and is also present in many other habitats #CITATION_TAG. Aureobasidium pullulans is known to be antagonistic towards necrotrophic pathogens, e.g. grey mould in strawberries [50] and powdery mildew in durum wheat [51]. The mechanism of the antagonism is hypothesised to be competition for nutrients [52]. Some strains of A. pullulans also produce a type of antibiotic called aureobasidins [53]. The antagonistic potential of biological control agents is frequently strain-specific, depending on the mechanism of antagonism. From the sequence data, we cannot make inferences about the antagonistic capacity of an OTU. Hence, it is unknown whether the reduction in the relative abundance of A. pullulans in fungicide-treated leaves has an impact on the antagonistic capacity of the fungal community. Several OTUs were identified as common wheat pathogens in the dataset: OTU_14_Mycosphaerella_graminicola, OTU_13_ Blumeria_graminis, OTU_1_Puccinia_striiformis, OTU_47_ Phaeosphaeria_nodorum (Parastagonospora nodorum), OTU_20_ Monographella_spp and OTU_224_Pyrenophora_tritici-repentis. Surprisingly, there was no significant effect of fungicide treatment on the relative abundance of any of these OTUs. On the contrary, there was a tendency for higher variability in the relative abundance of M. graminicola and B. graminis in treated samples (Fig. 6), and the share of B. graminis (the only member of Erysiphales) was larger in treated samples (Fig. 3). On the other hand, P. striiformis tended to dominate the fungal community in untreated samples and was nearly absent from the fungicidetreated samples from the same fields, only being present in two fields in the Southern area (Fig. 3). Fungicide resistance in common pathogens is an increasing problem and could be an explanation for the high variability in the relative abundance of the pathogens observed here. Resistance to strobilurines in M. graminicola and even more so in B. graminis is widespread in the Nordic and Baltic countries. In addition, resistance to demethylation inhibitor fungicides is increasing in both pathogens [10]. 454 sequencing is a semi-quantitative method only allowing quantification of the relative abundance of different OTUs [25]. Thus, we were unable to determine whether the fungicide treatment had an effect on absolute abundance of the pathogens."	0	"Functional assignment as ""pathogen"" is only used for taxa known to be pathogenic on wheat. a moderate effect on the ""pink"" and ""white"" phyllosphere yeasts, with a somewhat stronger effect on ""white"" yeasts [16]. Aureobasidium pullulans is reported to be sensitive to propiconazole [16] and prochloraz [17,18] and these two fungicides and other SBI fungicides have been used in almost all the fields in this study (Table S1). The ascomycete A. pullulans is one of the most common inhabitants of the phyllosphere of many crops [48] and is also present in many other habitats #CITATION_TAG. Aureobasidium pullulans is known to be antagonistic towards necrotrophic pathogens, e.g. grey mould in strawberries [50] and powdery mildew in durum wheat [51]. The mechanism of the antagonism is hypothesised to be competition for nutrients [52]. Some strains of A. pullulans also produce a type of antibiotic called aureobasidins [53]."	s
CCT706	"It is widely acknowledged that the use of stories supports the development of literacy in the context of learning English as a first language (Short, 2012). The desire to read and write, for example, can be nurtured by the storyteller""s ways of animating stories; and the students"" reading comprehension and skills in retelling and writing stories can be enhanced through the exposure to the structure of a story and its repetitive elements. In a similar vein, it has been argued that story genres are considered some of the most suitable for students learning a second language because of their emphasis on action and events, their strong tradition of oral, embodied performance, and their concern with common themes (#CITATION_TAG, 2012;Pennington, 2009;Tsou, Wang, & Tzeng, 2006)."	1	"It is widely acknowledged that the use of stories supports the development of literacy in the context of learning English as a first language (Short, 2012). The desire to read and write, for example, can be nurtured by the storyteller""s ways of animating stories; and the students"" reading comprehension and skills in retelling and writing stories can be enhanced through the exposure to the structure of a story and its repetitive elements. In a similar vein, it has been argued that story genres are considered some of the most suitable for students learning a second language because of their emphasis on action and events, their strong tradition of oral, embodied performance, and their concern with common themes (#CITATION_TAG, 2012;Pennington, 2009;Tsou, Wang, & Tzeng, 2006)."	 
CCT707	"However, it seems that there are a few studies investigating this issue in the context of teaching and learning English as a foreign language (e.g. Lee, 2012;Megawati & Anugerahwati, 2012). Given the different learning situations, such as limited time allocated to English lessons, large class size, students"" low motivation, and form-focused exams (#CITATION_TAG & Goh, 2014;Ramon-Plo & Pilarmur-Duenas, 2014), the use of stories in EFL learning contexts accordingly needs modifications. This research addresses this issue. Understanding how EFL learners"" writing narrative texts before and after their engagement with story-based lessons would inform how to more effectively enact teaching strategies in EFL language classrooms. This paper is a part of a larger study that explored how EFL secondary school teachers in Indonesia enhance their students"" English narrative writing through a professional learning program based on genre theory and Systemic Functional Linguistics (hereafter SFL). The professional doi: dx.doi.org/10.17509/ijal.v6i2.4870 learning program focused on a pedagogical intervention that incorporates oral story sharing activities into the English literacy program. The intervention was framed within Rose and Martin""s (2012) Reading to Learn (R2L) pedagogy. Within this framework, the professional learning program was conducted extensively through two consecutive workshops and eight sessions of classroom practices. While the workshops aimed to extend the teachers"" linguistic subject knowledge and their pedagogical content, the classroom practices aimed to explore learning experiences designed by these teachers resulting from the professional learning. This paper will address the classroom practices. In particular it examines the ways the teachers use storying as a pedagogical approach to developing students"" English oral competences in order to inform narrative text writing. It will also briefly present the preliminary findings from the students"" written texts to show the impacts of the redesigned pedagogy."	0	"However, it seems that there are a few studies investigating this issue in the context of teaching and learning English as a foreign language (e.g. Lee, 2012;Megawati & Anugerahwati, 2012). Given the different learning situations, such as limited time allocated to English lessons, large class size, students"" low motivation, and form-focused exams (#CITATION_TAG & Goh, 2014;Ramon-Plo & Pilarmur-Duenas, 2014), the use of stories in EFL learning contexts accordingly needs modifications. This research addresses this issue. Understanding how EFL learners"" writing narrative texts before and after their engagement with story-based lessons would inform how to more effectively enact teaching strategies in EFL language classrooms. This paper is a part of a larger study that explored how EFL secondary school teachers in Indonesia enhance their students"" English narrative writing through a professional learning program based on genre theory and Systemic Functional Linguistics (hereafter SFL)."	i
CCT708	"However, it seems that there are a few studies investigating this issue in the context of teaching and learning English as a foreign language (e.g. Lee, 2012;Megawati & Anugerahwati, 2012). Given the different learning situations, such as limited time allocated to English lessons, large class size, students"" low motivation, and form-focused exams (Chen & Goh, 2014;Ramon-Plo & Pilarmur-Duenas, 2014), the use of stories in EFL learning contexts accordingly needs modifications. This research addresses this issue. Understanding how EFL learners"" writing narrative texts before and after their engagement with story-based lessons would inform how to more effectively enact teaching strategies in EFL language classrooms. This paper is a part of a larger study that explored how EFL secondary school teachers in Indonesia enhance their students"" English narrative writing through a professional learning program based on genre theory and Systemic Functional Linguistics (hereafter SFL). The professional doi: dx.doi.org/10.17509/ijal.v6i2.4870 learning program focused on a pedagogical intervention that incorporates oral story sharing activities into the English literacy program. The intervention was framed within #CITATION_TAG and Martin""s (2012) Reading to Learn (R2L) pedagogy. Within this framework, the professional learning program was conducted extensively through two consecutive workshops and eight sessions of classroom practices. While the workshops aimed to extend the teachers"" linguistic subject knowledge and their pedagogical content, the classroom practices aimed to explore learning experiences designed by these teachers resulting from the professional learning. This paper will address the classroom practices. In particular it examines the ways the teachers use storying as a pedagogical approach to developing students"" English oral competences in order to inform narrative text writing. It will also briefly present the preliminary findings from the students"" written texts to show the impacts of the redesigned pedagogy."	5	"The professional doi: dx. doi.org/10.17509/ijal. v6i2.4870 learning program focused on a pedagogical intervention that incorporates oral story sharing activities into the English literacy program. The intervention was framed within #CITATION_TAG and Martin""s (2012) Reading to Learn (R2L) pedagogy. Within this framework, the professional learning program was conducted extensively through two consecutive workshops and eight sessions of classroom practices. While the workshops aimed to extend the teachers"" linguistic subject knowledge and their pedagogical content, the classroom practices aimed to explore learning experiences designed by these teachers resulting from the professional learning. This paper will address the classroom practices."	r
CCT709	"It is widely acknowledged that the use of stories supports the development of literacy in the context of learning English as a first language (Short, 2012). The desire to read and write, for example, can be nurtured by the storyteller""s ways of animating stories; and the students"" reading comprehension and skills in retelling and writing stories can be enhanced through the exposure to the structure of a story and its repetitive elements. In a similar vein, it has been argued that story genres are considered some of the most suitable for students learning a second language because of their emphasis on action and events, their strong tradition of oral, embodied performance, and their concern with common themes (Lee, 2012;Pennington, 2009;#CITATION_TAG, Wang, & Tzeng, 2006)."	1	"It is widely acknowledged that the use of stories supports the development of literacy in the context of learning English as a first language (Short, 2012). The desire to read and write, for example, can be nurtured by the storyteller""s ways of animating stories; and the students"" reading comprehension and skills in retelling and writing stories can be enhanced through the exposure to the structure of a story and its repetitive elements. In a similar vein, it has been argued that story genres are considered some of the most suitable for students learning a second language because of their emphasis on action and events, their strong tradition of oral, embodied performance, and their concern with common themes (Lee, 2012;Pennington, 2009;#CITATION_TAG, Wang, & Tzeng, 2006)."	 
CCT710	"The nature of the present study was action-oriented fieldwork attempting to investigate the development of EFL students"" writing English stories. The actionoriented approach was deployed for this study because of twofold objectives. First, as part of a broader project, this phase functioned as a research site in which I observed the development of the teacher participants"" knowledge and its enactment in the classroom. As such, the research was not initiated by a problem that was wholly ""owned"" by teachers (Hall, Leat, Wall, Higgins, & Edwards, 2006). In this phase the teacher participants implemented their two cycles of action-oriented project by drawing on the principles of Action Research that include plan, act and observe, and reflect (#CITATION_TAG, McTaggart, & Nixon, 2014). Following this, the next aim is to gauge to what extent the project impacted on the students"" learning outcomes. In this respect, I collaboratively worked with the teacher participants in designing and executing the learning experiences for the students throughout the iteration of action research cycle (Bruce, Flynn, & Sheley, 2011)."	5	"The actionoriented approach was deployed for this study because of twofold objectives. First, as part of a broader project, this phase functioned as a research site in which I observed the development of the teacher participants"" knowledge and its enactment in the classroom. As such, the research was not initiated by a problem that was wholly ""owned"" by teachers (Hall, Leat, Wall, Higgins, & Edwards, 2006). In this phase the teacher participants implemented their two cycles of action-oriented project by drawing on the principles of Action Research that include plan, act and observe, and reflect (#CITATION_TAG, McTaggart, & Nixon, 2014). Following this, the next aim is to gauge to what extent the project impacted on the students"" learning outcomes. In this respect, I collaboratively worked with the teacher participants in designing and executing the learning experiences for the students throughout the iteration of action research cycle (Bruce, Flynn, & Sheley, 2011)."	h
CCT711	"A number of studies have examined the effectiveness of EFL practice in supporting students"" ability to communicate in English (e.g. Chen and Goh, 2014;Ramon Plo and Pilarmur-Deunas, 2014). Studies of teachers"" perceptions of English language teaching methods and their actual in-class behaviour indicate commonly perceived factors that pose challenges to the implementation of an EFL curriculum. Goh (2014), Ramon Plo andPilarmur-Deunas ( 2014) and Nguyen (2011) who surveyed EFL teachers in China, Spain, and Vietnam respectively, reported that those challenging factors include lack of class time, examoriented lessons, and learners"" reluctance to participate in communicative activities. Because of the limited time for English in a crowded curriculum, form-focused language learning has come into favour, with less emphasis placed on communicative-based activities. This contradicts studies by #CITATION_TAG (2013) in Bangladesh and Asafeh, Khwaile, and Alshbou (2012) in Jordan that report many EFL learners preferred to have more communicative activities to practice their English, although they showed positive attitudes to traditional activities such as drilling of grammar rules and vocabulary. EFL learners were also reported to be aware that drilling, sentence exercises, and grammar explanations would be useful for them to prepare for their exams. Overall, these perception studies have contributed to the recognition of the established traditions of teacher-fronted, form-focused and exam-oriented lessons."	1	"Studies of teachers"" perceptions of English language teaching methods and their actual in-class behaviour indicate commonly perceived factors that pose challenges to the implementation of an EFL curriculum. Goh (2014), Ramon Plo andPilarmur-Deunas ( 2014) and Nguyen (2011) who surveyed EFL teachers in China, Spain, and Vietnam respectively, reported that those challenging factors include lack of class time, examoriented lessons, and learners"" reluctance to participate in communicative activities. Because of the limited time for English in a crowded curriculum, form-focused language learning has come into favour, with less emphasis placed on communicative-based activities. This contradicts studies by #CITATION_TAG (2013) in Bangladesh and Asafeh, Khwaile, and Alshbou (2012) in Jordan that report many EFL learners preferred to have more communicative activities to practice their English, although they showed positive attitudes to traditional activities such as drilling of grammar rules and vocabulary. EFL learners were also reported to be aware that drilling, sentence exercises, and grammar explanations would be useful for them to prepare for their exams. Overall, these perception studies have contributed to the recognition of the established traditions of teacher-fronted, form-focused and exam-oriented lessons."	 
CCT712	"A good deal of useful work for stories has been done with genre pedagogy in particular Martin and Plum""s (1997) description of narrative genre. In the SFL tradition, narratives are not the only genre identified within the story family. There are variations in stories which constitute narrative along with recount, anecdote, exemplum, and observations (#CITATION_TAG & Rose, 2008). Each of the story genres has similar stages but serves different social purposes. For example, narratives are to entertain, recount to share experience, anecdote to share a reaction, exemplums to share moral judgments, and observations to share a personal response to things or events. The stages commonly identified in these genres are started optionally with an Orientation stage introducing an expectant activity and a Coda at the end of the story. The variations that differentiate these stories are present depending on the unfolding stages that disrupt an expectant activity and types of responses to this disruption. The stages in narratives, as the focus of the study, will be further discussed below."	5	"A good deal of useful work for stories has been done with genre pedagogy in particular Martin and Plum""s (1997) description of narrative genre. In the SFL tradition, narratives are not the only genre identified within the story family. There are variations in stories which constitute narrative along with recount, anecdote, exemplum, and observations (#CITATION_TAG & Rose, 2008). Each of the story genres has similar stages but serves different social purposes. For example, narratives are to entertain, recount to share experience, anecdote to share a reaction, exemplums to share moral judgments, and observations to share a personal response to things or events. The stages commonly identified in these genres are started optionally with an Orientation stage introducing an expectant activity and a Coda at the end of the story."	e
CCT713	"Figure 2 Action-oriented research cycles-adapted from Kemmis, McTaggart, & Nixon (2014) During the fieldwork, my position as a researcher was in a continuum that changed over time from an onlooker to a participant observer, or vice versa (Creswell, 2013;Greene, 2014;Widodo, 2015). I observed how the teacher participants translated and enacted the instructional strategies introduced in the workshop into learning experiences relevant to their students"" situation (#CITATION_TAG & Berry, 2012). Cognizant of implementing an alternative model posing a considerable threat (Kubanyiova, 2006), I lent myself to the participants as teacher mentor (Widodo, 2015) and co-teacher (Bruce, Flynn, & Sheley, 2011) who provided specific input or support whenever needed (Van Driel & Berry, 2012). This meant at times I had to respond to the teacher participants"" queries or teach a certain point of the lesson and therefore it was difficult for me as an observer to capture all important events in the class. To anticipate this, apart from the researcher""s reflective journal and video recording, discussions with the teacher participants were done immediately after the lessons to note important events that might influence the design for the following lessons."	5	"Figure 2 Action-oriented research cycles-adapted from Kemmis, McTaggart, & Nixon (2014) During the fieldwork, my position as a researcher was in a continuum that changed over time from an onlooker to a participant observer, or vice versa (Creswell, 2013;Greene, 2014;Widodo, 2015). I observed how the teacher participants translated and enacted the instructional strategies introduced in the workshop into learning experiences relevant to their students"" situation (#CITATION_TAG & Berry, 2012). Cognizant of implementing an alternative model posing a considerable threat (Kubanyiova, 2006), I lent myself to the participants as teacher mentor (Widodo, 2015) and co-teacher (Bruce, Flynn, & Sheley, 2011) who provided specific input or support whenever needed (Van Driel & Berry, 2012). This meant at times I had to respond to the teacher participants"" queries or teach a certain point of the lesson and therefore it was difficult for me as an observer to capture all important events in the class. To anticipate this, apart from the researcher""s reflective journal and video recording, discussions with the teacher participants were done immediately after the lessons to note important events that might influence the design for the following lessons."	 
CCT714	"The study involved a secondary school in Bandung, West Java, Indonesia and two English language teachers as part of the research team. In recruiting the participants of the study, purposeful sampling was undertaken to ensure that the selected participants provided sufficient data illuminating the aims of the study (#CITATION_TAG, 2013). The selection was guided by the research objectives that highlight Oral story sharing the value of using stories in language classroom. These objectives are in line with the 2013 English Curriculum that mandates the teaching of narrative texts. As this text type was introduced in year 8 (students aged 13-14), two English teachers teaching in that level were invited to participate. Based on the agreement with the school authority, one of the teachers"" classes consisting of 42 students was selected as part of this study."	5	The study involved a secondary school in Bandung, West Java, Indonesia and two English language teachers as part of the research team. In recruiting the participants of the study, purposeful sampling was undertaken to ensure that the selected participants provided sufficient data illuminating the aims of the study (#CITATION_TAG, 2013). The selection was guided by the research objectives that highlight Oral story sharing the value of using stories in language classroom. These objectives are in line with the 2013 English Curriculum that mandates the teaching of narrative texts. As this text type was introduced in year 8 (students aged 13-14), two English teachers teaching in that level were invited to participate.	n
CCT715	"The nature of the present study was action-oriented fieldwork attempting to investigate the development of EFL students"" writing English stories. The actionoriented approach was deployed for this study because of twofold objectives. First, as part of a broader project, this phase functioned as a research site in which I observed the development of the teacher participants"" knowledge and its enactment in the classroom. As such, the research was not initiated by a problem that was wholly ""owned"" by teachers (Hall, Leat, Wall, Higgins, & Edwards, 2006). In this phase the teacher participants implemented their two cycles of action-oriented project by drawing on the principles of Action Research that include plan, act and observe, and reflect (Kemmis, McTaggart, & Nixon, 2014). Following this, the next aim is to gauge to what extent the project impacted on the students"" learning outcomes. In this respect, I collaboratively worked with the teacher participants in designing and executing the learning experiences for the students throughout the iteration of action research cycle (#CITATION_TAG, Flynn, & Sheley, 2011)."	5	"As such, the research was not initiated by a problem that was wholly ""owned"" by teachers (Hall, Leat, Wall, Higgins, & Edwards, 2006). In this phase the teacher participants implemented their two cycles of action-oriented project by drawing on the principles of Action Research that include plan, act and observe, and reflect (Kemmis, McTaggart, & Nixon, 2014). Following this, the next aim is to gauge to what extent the project impacted on the students"" learning outcomes. In this respect, I collaboratively worked with the teacher participants in designing and executing the learning experiences for the students throughout the iteration of action research cycle (#CITATION_TAG, Flynn, & Sheley, 2011)."	s
CCT716	"A number of studies have examined the effectiveness of EFL practice in supporting students"" ability to communicate in English (e.g. Chen and Goh, 2014;Ramon Plo and Pilarmur-Deunas, 2014). Studies of teachers"" perceptions of English language teaching methods and their actual in-class behaviour indicate commonly perceived factors that pose challenges to the implementation of an EFL curriculum. Goh (2014), Ramon Plo andPilarmur-Deunas ( 2014) and Nguyen (2011) who surveyed EFL teachers in China, Spain, and Vietnam respectively, reported that those challenging factors include lack of class time, examoriented lessons, and learners"" reluctance to participate in communicative activities. Because of the limited time for English in a crowded curriculum, form-focused language learning has come into favour, with less emphasis placed on communicative-based activities. This contradicts studies by Shrestha (2013) in Bangladesh and #CITATION_TAG, Khwaile, and Alshbou (2012) in Jordan that report many EFL learners preferred to have more communicative activities to practice their English, although they showed positive attitudes to traditional activities such as drilling of grammar rules and vocabulary. EFL learners were also reported to be aware that drilling, sentence exercises, and grammar explanations would be useful for them to prepare for their exams. Overall, these perception studies have contributed to the recognition of the established traditions of teacher-fronted, form-focused and exam-oriented lessons."	1	"Studies of teachers"" perceptions of English language teaching methods and their actual in-class behaviour indicate commonly perceived factors that pose challenges to the implementation of an EFL curriculum. Goh (2014), Ramon Plo andPilarmur-Deunas ( 2014) and Nguyen (2011) who surveyed EFL teachers in China, Spain, and Vietnam respectively, reported that those challenging factors include lack of class time, examoriented lessons, and learners"" reluctance to participate in communicative activities. Because of the limited time for English in a crowded curriculum, form-focused language learning has come into favour, with less emphasis placed on communicative-based activities. This contradicts studies by Shrestha (2013) in Bangladesh and #CITATION_TAG, Khwaile, and Alshbou (2012) in Jordan that report many EFL learners preferred to have more communicative activities to practice their English, although they showed positive attitudes to traditional activities such as drilling of grammar rules and vocabulary. EFL learners were also reported to be aware that drilling, sentence exercises, and grammar explanations would be useful for them to prepare for their exams. Overall, these perception studies have contributed to the recognition of the established traditions of teacher-fronted, form-focused and exam-oriented lessons."	 
CCT717	Story is a rich resource for literacy and provides abundant linguistic resources for students to learn a foreign language. Engaging interactively with stories allows EFL teachers and students not only to extend their language proficiency but also to develop emotional involvement with the target language (#CITATION_TAG, 2006). To engage EFL learners cognitively and affectively with story, it is argued that careful selection of story content should be made by focusing not only on linguistic resources but also on elements that might catch the interest of the students such as interesting characters, a clear plot and ending (Pinter, 2006). As such, through storying, EFL learners experience greater opportunity to develop their linguistic resources as well as a deeper understanding of the culture and people of the target language represented in the story.	4	Story is a rich resource for literacy and provides abundant linguistic resources for students to learn a foreign language. Engaging interactively with stories allows EFL teachers and students not only to extend their language proficiency but also to develop emotional involvement with the target language (#CITATION_TAG, 2006). To engage EFL learners cognitively and affectively with story, it is argued that careful selection of story content should be made by focusing not only on linguistic resources but also on elements that might catch the interest of the students such as interesting characters, a clear plot and ending (Pinter, 2006). As such, through storying, EFL learners experience greater opportunity to develop their linguistic resources as well as a deeper understanding of the culture and people of the target language represented in the story.	n
CCT718	Several hybrid systems, which combine two or more CI techniques, have also been proposed for TSF, such as Evolutionary ANN (EANN) [4]. Most EANNs use the standard Genetic Algorithm (GA). More recently, the Estimation Distribution Algorithm (EDA) was proposed [13]. Such algorithm uses exploitation and exploration properties to find a good solution. In #CITATION_TAG, EDA was used as the search engine of an EANN, outperforming a GA based EANN. Following this result, in this paper we propose a novel Evolutionary SVM (ESVM) approach based on the EDA engine, in order to automatically select the best SVM multi-step ahead forecasting model. Moreover, we also compare ESVM with the EANN proposed in [16] and the popular ARIMA methodology.	2	Most EANNs use the standard Genetic Algorithm (GA). More recently, the Estimation Distribution Algorithm (EDA) was proposed [13]. Such algorithm uses exploitation and exploration properties to find a good solution. In #CITATION_TAG, EDA was used as the search engine of an EANN, outperforming a GA based EANN. Following this result, in this paper we propose a novel Evolutionary SVM (ESVM) approach based on the EDA engine, in order to automatically select the best SVM multi-step ahead forecasting model. Moreover, we also compare ESVM with the EANN proposed in [16] and the popular ARIMA methodology.	C
CCT719	When designing a SVM, there are three crucial issues it should be taken into account: the type of SVM to use, the selection of the kernel function and tuning the parameters associated with the two previous selections. Since TSF is a particular regression case, for the SVM type and kernel, we selected the popular Œµ-insensitive loss function (known as Œµ-SVR) and Gaussian kernel combination, as implemented in the LIBSVM tool #CITATION_TAG. In SVM regression [17], the input y = (y t‚àíkI , . . . , y t‚àík2 , y t‚àík1 ), for a SVM with I inputs, is transformed into a high m-dimensional feature space, by using a nonlinear mapping (œÜ) that does not need to be explicitly known but that depends of a kernel function. Then, the SVM algorithm finds the best linear separating hyperplane, tolerating a small error (Œµ) when fitting the data, in the feature space:	0	When designing a SVM, there are three crucial issues it should be taken into account: the type of SVM to use, the selection of the kernel function and tuning the parameters associated with the two previous selections. Since TSF is a particular regression case, for the SVM type and kernel, we selected the popular Œµ-insensitive loss function (known as Œµ-SVR) and Gaussian kernel combination, as implemented in the LIBSVM tool #CITATION_TAG. In SVM regression [17], the input y = (y t‚àíkI , . . . , y t‚àík2 , y t‚àík1 ), for a SVM with I inputs, is transformed into a high m-dimensional feature space, by using a nonlinear mapping (œÜ) that does not need to be explicitly known but that depends of a kernel function. Then, the SVM algorithm finds the best linear separating hyperplane, tolerating a small error (Œµ) when fitting the data, in the feature space:	i
CCT720	When applying these CI methods to TSF, variable and model selection are critical issues. A sliding time window is often used to create a set of training examples from the series. A small time window will provide insufficient information, while using a large number of time lags will increase the probability of having irrelevant inputs. Thus, variable selection is useful to discard irrelevant time lags, leading to simpler models that are easier to interpret and that usually give better performances [#CITATION_TAG,9,6]. On the other hand, CI models such as ANN and SVM have hyperparameters that need to be adjusted (e.g., number of ANN hidden nodes or kernel parameter) [8]. Complex models may overfit the data, losing the capability to generalize, while a model that is too simple will present limited learning capabilities.	2	When applying these CI methods to TSF, variable and model selection are critical issues. A sliding time window is often used to create a set of training examples from the series. A small time window will provide insufficient information, while using a large number of time lags will increase the probability of having irrelevant inputs. Thus, variable selection is useful to discard irrelevant time lags, leading to simpler models that are easier to interpret and that usually give better performances [#CITATION_TAG,9,6]. On the other hand, CI models such as ANN and SVM have hyperparameters that need to be adjusted (e.g., number of ANN hidden nodes or kernel parameter) [8]. Complex models may overfit the data, losing the capability to generalize, while a model that is too simple will present limited learning capabilities.	s
CCT721	Several Operational Research TSF methods have been proposed, such as Holt-Winters (in the sixties) or the ARIMA methodology [14] (in the seventies). More recently, several Computational Intelligence (CI) methods have been applied to TSF, such as Artificial Neural Networks (ANN) [12,6], and Support Vector Machines (SVM) [15,9,#CITATION_TAG]. CI models such as ANNs and SVMs are natural solutions for TSF, since they are more flexible (i.e., no a priori restriction is imposed) when compared with classical TSF models, presenting nonlinear learning capabilities. When compared with ANN, SVM presents theoretical advantages, such as the absence of local minima in the learning phase.	2	Several Operational Research TSF methods have been proposed, such as Holt-Winters (in the sixties) or the ARIMA methodology [14] (in the seventies). More recently, several Computational Intelligence (CI) methods have been applied to TSF, such as Artificial Neural Networks (ANN) [12,6], and Support Vector Machines (SVM) [15,9,#CITATION_TAG]. CI models such as ANNs and SVMs are natural solutions for TSF, since they are more flexible (i.e., no a priori restriction is imposed) when compared with classical TSF models, presenting nonlinear learning capabilities. When compared with ANN, SVM presents theoretical advantages, such as the absence of local minima in the learning phase.	o
CCT722	Forecasting the future using past data is an important tool to reduce uncertainty and support both individual and organization decision making. In particular, multi-step ahead predictions (e.g., issued several months in advance) are useful to aid tactical decisions, such as planning production resources or evaluating alternative economic strategies [2]. The field of Time Series Forecasting (TSF) deals with the prediction of a given phenomenon (e.g., umbrella sales) based on the past patterns of the same event. TSF has become increasingly used in distinct areas such as Agriculture, Finance, Production or Sales #CITATION_TAG.	4	Forecasting the future using past data is an important tool to reduce uncertainty and support both individual and organization decision making. In particular, multi-step ahead predictions (e.g., issued several months in advance) are useful to aid tactical decisions, such as planning production resources or evaluating alternative economic strategies [2]. The field of Time Series Forecasting (TSF) deals with the prediction of a given phenomenon (e.g., umbrella sales) based on the past patterns of the same event. TSF has become increasingly used in distinct areas such as Agriculture, Finance, Production or Sales #CITATION_TAG.	 
CCT723	Several hybrid systems, which combine two or more CI techniques, have also been proposed for TSF, such as Evolutionary ANN (EANN) [4]. Most EANNs use the standard Genetic Algorithm (GA). More recently, the Estimation Distribution Algorithm (EDA) was proposed #CITATION_TAG. Such algorithm uses exploitation and exploration properties to find a good solution. In [16], EDA was used as the search engine of an EANN, outperforming a GA based EANN. Following this result, in this paper we propose a novel Evolutionary SVM (ESVM) approach based on the EDA engine, in order to automatically select the best SVM multi-step ahead forecasting model. Moreover, we also compare ESVM with the EANN proposed in [16] and the popular ARIMA methodology.	5	Several hybrid systems, which combine two or more CI techniques, have also been proposed for TSF, such as Evolutionary ANN (EANN) [4]. Most EANNs use the standard Genetic Algorithm (GA). More recently, the Estimation Distribution Algorithm (EDA) was proposed #CITATION_TAG. Such algorithm uses exploitation and exploration properties to find a good solution. In [16], EDA was used as the search engine of an EANN, outperforming a GA based EANN. Following this result, in this paper we propose a novel Evolutionary SVM (ESVM) approach based on the EDA engine, in order to automatically select the best SVM multi-step ahead forecasting model.	r
CCT724	The Symmetric Mean Absolute Percentage Error (SMAPE) is given by #CITATION_TAG:	5	The Symmetric Mean Absolute Percentage Error (SMAPE) is given by #CITATION_TAG:	T
CCT725	Forecasting the future using past data is an important tool to reduce uncertainty and support both individual and organization decision making. In particular, multi-step ahead predictions (e.g., issued several months in advance) are useful to aid tactical decisions, such as planning production resources or evaluating alternative economic strategies #CITATION_TAG. The field of Time Series Forecasting (TSF) deals with the prediction of a given phenomenon (e.g., umbrella sales) based on the past patterns of the same event. TSF has become increasingly used in distinct areas such as Agriculture, Finance, Production or Sales [14].	4	Forecasting the future using past data is an important tool to reduce uncertainty and support both individual and organization decision making. In particular, multi-step ahead predictions (e.g., issued several months in advance) are useful to aid tactical decisions, such as planning production resources or evaluating alternative economic strategies #CITATION_TAG. The field of Time Series Forecasting (TSF) deals with the prediction of a given phenomenon (e.g., umbrella sales) based on the past patterns of the same event. TSF has become increasingly used in distinct areas such as Agriculture, Finance, Production or Sales [14].	n
CCT726	When applying these CI methods to TSF, variable and model selection are critical issues. A sliding time window is often used to create a set of training examples from the series. A small time window will provide insufficient information, while using a large number of time lags will increase the probability of having irrelevant inputs. Thus, variable selection is useful to discard irrelevant time lags, leading to simpler models that are easier to interpret and that usually give better performances [4,9,6]. On the other hand, CI models such as ANN and SVM have hyperparameters that need to be adjusted (e.g., number of ANN hidden nodes or kernel parameter) #CITATION_TAG. Complex models may overfit the data, losing the capability to generalize, while a model that is too simple will present limited learning capabilities.	0	A sliding time window is often used to create a set of training examples from the series. A small time window will provide insufficient information, while using a large number of time lags will increase the probability of having irrelevant inputs. Thus, variable selection is useful to discard irrelevant time lags, leading to simpler models that are easier to interpret and that usually give better performances [4,9,6]. On the other hand, CI models such as ANN and SVM have hyperparameters that need to be adjusted (e.g., number of ANN hidden nodes or kernel parameter) #CITATION_TAG. Complex models may overfit the data, losing the capability to generalize, while a model that is too simple will present limited learning capabilities.	h
CCT727	For the comparison, we have chosen the EANN presented in [16], which is similar to ESVM except that is uses a multilayer perceptron trained with the RPROP algorithm, as implemented using the SNNS tool [18]. EANN optimizes the number of inputs (I ‚àà {1, ..., 100}) and hidden nodes (from 0 to 99) and the RPROP parameters (Œî 0 ‚àà {1, 0.01, 0.001, . . ., 10 ‚àí9 } and Œî max ‚àà {0, 1, ..., 99}). Both the ESVM and EANN experiments were conducted using code written in the C language by the authors. As the stopping criterion, we used a maximum of 100 generations for ESVM and EANN. For a baseline comparison, we have also chosen the ARIMA methodology, as computed by the ForecastPro c tool #CITATION_TAG. The rationale is to use a popular benchmark that can easily be compared and that does not require expert model selection capabilities from the user. The obtained results are shown in Table 2 (SMAPE errors and best SVM models). An analysis to tables shows that the proposed ESVM provides interesting forecasts when compared with EANN and ARIMA. Each forecasting approach is the best option for two series. Yet, ESVM provides the lowest average and median (over all series, last two rows) results. The left of Fig. 1 plots the evolution of the best fitness values for ESVM (left), showing a fast convergence of the EDA algorithm for all series. For demonstration purposes, the right of Fig. 1 plots the ESVM forecasts for Quebec, showing a good fit.	5	, 99}). Both the ESVM and EANN experiments were conducted using code written in the C language by the authors. As the stopping criterion, we used a maximum of 100 generations for ESVM and EANN. For a baseline comparison, we have also chosen the ARIMA methodology, as computed by the ForecastPro c tool #CITATION_TAG. The rationale is to use a popular benchmark that can easily be compared and that does not require expert model selection capabilities from the user. The obtained results are shown in Table 2 (SMAPE errors and best SVM models). An analysis to tables shows that the proposed ESVM provides interesting forecasts when compared with EANN and ARIMA.	b
CCT728	"We selected a total of six time series, with different characteristics and from distinct domains (Table 1). Five series were selected from the well-known Hyndman""s time series data library repository [10]. These are named Passengers, Temperature, Dow-Jones, Quebec and Abraham12. We also adopt the Mackey-Glass series, which is a common nonlinear benchmark. It should be noted that these six times series were also adopted by the NN3 and NN5 forecasting competitions #CITATION_TAG. Except for Mackey-Glass, all datasets are from real-world domains and such data can be affected by external issues (e.g., strikes), which make them interesting datasets and more difficult to predict."	4	"Five series were selected from the well-known Hyndman""s time series data library repository [10]. These are named Passengers, Temperature, Dow-Jones, Quebec and Abraham12. We also adopt the Mackey-Glass series, which is a common nonlinear benchmark. It should be noted that these six times series were also adopted by the NN3 and NN5 forecasting competitions #CITATION_TAG. Except for Mackey-Glass, all datasets are from real-world domains and such data can be affected by external issues (e.g., strikes), which make them interesting datasets and more difficult to predict."	h
CCT729	For the comparison, we have chosen the EANN presented in [16], which is similar to ESVM except that is uses a multilayer perceptron trained with the RPROP algorithm, as implemented using the SNNS tool #CITATION_TAG. EANN optimizes the number of inputs (I ‚àà {1, ..., 100}) and hidden nodes (from 0 to 99) and the RPROP parameters (Œî 0 ‚àà {1, 0.01, 0.001, . . ., 10 ‚àí9 } and Œî max ‚àà {0, 1, ..., 99}). Both the ESVM and EANN experiments were conducted using code written in the C language by the authors. As the stopping criterion, we used a maximum of 100 generations for ESVM and EANN. For a baseline comparison, we have also chosen the ARIMA methodology, as computed by the ForecastPro c tool [7]. The rationale is to use a popular benchmark that can easily be compared and that does not require expert model selection capabilities from the user. The obtained results are shown in Table 2 (SMAPE errors and best SVM models). An analysis to tables shows that the proposed ESVM provides interesting forecasts when compared with EANN and ARIMA. Each forecasting approach is the best option for two series. Yet, ESVM provides the lowest average and median (over all series, last two rows) results. The left of Fig. 1 plots the evolution of the best fitness values for ESVM (left), showing a fast convergence of the EDA algorithm for all series. For demonstration purposes, the right of Fig. 1 plots the ESVM forecasts for Quebec, showing a good fit.	5	For the comparison, we have chosen the EANN presented in [16], which is similar to ESVM except that is uses a multilayer perceptron trained with the RPROP algorithm, as implemented using the SNNS tool #CITATION_TAG. EANN optimizes the number of inputs (I ‚àà {1, ... , 100}) and hidden nodes (from 0 to 99) and the RPROP parameters (Œî 0 ‚àà {1, 0.01, 0.001, . . ., 10 ‚àí9 } and Œî max ‚àà {0, 1, ... , 99}).	F
CCT730	"A considerable treatment literature has been published on bulimia nervosa (BN) [1,2], which is marked by a chronic and relapse-ridden course, can result into serious medical complications, and is associated with severe comorbid psychopathology and functional impairment [3,4]. The bulk of this literature has focused on the use of cognitive-behavioural therapy (CBT), which is widely considered as the treatment of choice for BN [1,2,5]. The theory [6] that underpins and guides CBT [7] is primarily concerned with the psychopathological processes that account for the persistence of the disorder. This theory assumes a dysfunctional system for evaluating self-worth [6], whereby self-worth is largely or even exclusively defined in terms of shape and weight and related control [8]. This over-evaluation of shape and weight (OSW) can then lead to dietary restraint, which often includes the adoption of rigid dietary rules about eating and food [6][7][8][9][10]. Due to the psychological and physiological effects of dietary restraint, when these inflexible dietary rules, which are extremely difficult to maintain, are broken, all attempts to control eating are abandoned and a binge occurs [6]. Although several randomised controlled trials have shown that CBT is more effective than a wide range of alternative treatments [1,2,5,11], amongst BN treatment completers, only 40-50 % have a full and lasting response [12]#CITATION_TAG[14]. The developers of the original CB theory argued that four additional factors might account for the persistence of dysfunctional cognitions (OSW) and eating-disordered behaviours in some patients that present obstacles for change: (a) interpersonal problems; (b) core low selfesteem; (c) clinical perfectionism; and (d) mood intolerance [12,13]. Accordingly, they reformulated the original CB theory into an enhanced version by encapsulating these factors that considered being ""trans-diagnostic"" as well [13]. According to the enhanced CB version (CB-E) [13], the difficulties in establishing and/or maintaining interpersonal relationships may directly precipitate episodes of binge eating, affect all of the other maintenance factors and/or amplify OSW [12,15]. The pervasive low self-esteem that often persists after recovery [16] is thought to lead to attempts to control shape and weight and similarly contribute to negative affect [13,17]. Despite adverse consequences, when clinical perfectionism or over-evaluation of striving for and achieving personally demanding standards [18] is present, it might encourage increased striving to achieve unrealistic high standards in the valued domain of shape and weight and foster dietary restraint [13,[18][19][20]. The final maintenance factor of mood intolerance (i.e. inability to appropriately cope with adverse affective states followed by dysfunctional impulsive behaviours) [13] is believed to directly affect and maintain binge eating [12,17,[21][22][23][24]. The CB-E approach is consistent with research that documented two subtypes of patients with BN and binge eating disorder (BED) based on purely dietary restraint (i.e. approximately 60-70 % of samples) versus dietarynegative affect (i.e. approximately 30-40 % of samples) dimensions [25,26]."	0	"This theory assumes a dysfunctional system for evaluating self-worth [6], whereby self-worth is largely or even exclusively defined in terms of shape and weight and related control [8]. This over-evaluation of shape and weight (OSW) can then lead to dietary restraint, which often includes the adoption of rigid dietary rules about eating and food [6][7][8][9][10]. Due to the psychological and physiological effects of dietary restraint, when these inflexible dietary rules, which are extremely difficult to maintain, are broken, all attempts to control eating are abandoned and a binge occurs [6]. Although several randomised controlled trials have shown that CBT is more effective than a wide range of alternative treatments [1,2,5,11], amongst BN treatment completers, only 40-50 % have a full and lasting response [12]#CITATION_TAG[14]. The developers of the original CB theory argued that four additional factors might account for the persistence of dysfunctional cognitions (OSW) and eating-disordered behaviours in some patients that present obstacles for change: (a) interpersonal problems; (b) core low selfesteem; (c) clinical perfectionism; and (d) mood intolerance [12,13]. Accordingly, they reformulated the original CB theory into an enhanced version by encapsulating these factors that considered being ""trans-diagnostic"" as well [13]. According to the enhanced CB version (CB-E) [13], the difficulties in establishing and/or maintaining interpersonal relationships may directly precipitate episodes of binge eating, affect all of the other maintenance factors and/or amplify OSW [12,15]."	g
CCT731	"The current study aimed at extending research in this area by testing and comparing the original and CB-E models in a large clinical sample seeking treatment for bulimic-type EDs, which include BN and its variants [bulimic-type ED not otherwise specified (EDNOS), i.e. EDs ""clinically significant but not meeting full DSM-IV diagnostic criteria for BN, or needing additional study, such as BED] [29]. It was expected that even though both theoretical models (Fig. 1) would provide a good fit to the observed data, the CB-E maintenance model would account for a greater proportion of the variance in dietary restraint and binge eating (i.e. the hallmark behaviour of all bulimic-type EDs) [13,29]. Evaluating whether the strength of the conceptual relationships of both CB maintenance models is similar or different across diagnostic groups and formally testing the significance of the mediation or indirect effects embedded within the CB models (Fig. 1) in each diagnostic group were additional aims of the study. It is worth of note that prior the completion of the study, the APA Task Force made several changes to ED diagnoses in the DSM-5 [30] in order to reduce the preponderance of the DSM-IV [31] Anorexic and bulimictype EDNOS category [29,32] that formed the most common ED among those seeking treatment [33]. Regarding bulimic-type EDNOS, in addition to making BED a formal diagnosis, DSM-5 [30] revised the behavioural criteria (i.e. the threshold for frequency and duration), eliminated the diagnostic subtypes for BN, and changed the EDNOS designation to Other Specified Feeding or ED; Online Resource 1 summarizes the diagnostic criteria for bulimic-type EDs from the fourth to the fifth editions. As a consequence, all cases initially diagnosed as BN and bulimic-type EDNOS using the DSM-IV [31] criteria were re-categorized using the new DSM-5 criteria [30]. All analyses conducted to evaluate our hypothesis (Fig. 1) and potential differences across groups were based on DSM-5 diagnosis of BN, BED, and bulimic-type EDNOS 1 ; for simplicity, this last term was used in the current manuscript to refer to bulimic-type diagnoses that fell into the Other Specified Feeding or ED group. Re-categorizing diagnoses also allowed us to evaluate the degree to which the use of DSM-5 criteria [30] decreased the proportion of DSM-IV [31] bulimic-type EDNOS cases. This is also a novel contribution to the current literature given that prior research using the same [34] or a similar [3,35] procedure focused on community samples rather than on clinical treatment seeking samples. 1 It is should be noted that, although both CB models posit that binge eating may encourage in some individuals compensatory behaviours aimed at counteracting the effects of binge eating on weight [6,13] for details, in the current manuscript we focused on binge eating and did not incorporate compensatory behaviours neither in the form of purging nor in the form of non-purging for three main reasons: (1) the scheme distinguishing purging and non-purging BN subtypes has been eliminated from DSM-5 (Online Resource 1); (2) the DSM-5 BN and BED diagnoses are distinguished by the presence versus absence of recurrent inappropriate compensatory behaviours (Online Resource 1); and (3) the necessary prerequisite of the advanced statistical procedure (see ""Statistical Analyses"") used for evaluating if the strength of the conceptual relationships of both CB maintenance models (Fig. 1) is similar or different across DSM-5 BN, BED, and bulimic-type EDNOS (that includes also sub-threshold BED cases) is that the model under investigation should contain the same number of latent variables, each of which includes the same number of measured/observed variables for all groups of interest #CITATION_TAG."	0	"All analyses conducted to evaluate our hypothesis (Fig. 1) and potential differences across groups were based on DSM-5 diagnosis of BN, BED, and bulimic-type EDNOS 1 ; for simplicity, this last term was used in the current manuscript to refer to bulimic-type diagnoses that fell into the Other Specified Feeding or ED group. Re-categorizing diagnoses also allowed us to evaluate the degree to which the use of DSM-5 criteria [30] decreased the proportion of DSM-IV [31] bulimic-type EDNOS cases. This is also a novel contribution to the current literature given that prior research using the same [34] or a similar [3,35] procedure focused on community samples rather than on clinical treatment seeking samples. 1 It is should be noted that, although both CB models posit that binge eating may encourage in some individuals compensatory behaviours aimed at counteracting the effects of binge eating on weight [6,13] for details, in the current manuscript we focused on binge eating and did not incorporate compensatory behaviours neither in the form of purging nor in the form of non-purging for three main reasons: (1) the scheme distinguishing purging and non-purging BN subtypes has been eliminated from DSM-5 (Online Resource 1); (2) the DSM-5 BN and BED diagnoses are distinguished by the presence versus absence of recurrent inappropriate compensatory behaviours (Online Resource 1); and (3) the necessary prerequisite of the advanced statistical procedure (see ""Statistical Analyses"") used for evaluating if the strength of the conceptual relationships of both CB maintenance models (Fig. 1) is similar or different across DSM-5 BN, BED, and bulimic-type EDNOS (that includes also sub-threshold BED cases) is that the model under investigation should contain the same number of latent variables, each of which includes the same number of measured/observed variables for all groups of interest #CITATION_TAG."	h
CCT732	"A considerable treatment literature has been published on bulimia nervosa (BN) [1,2], which is marked by a chronic and relapse-ridden course, can result into serious medical complications, and is associated with severe comorbid psychopathology and functional impairment [3,4]. The bulk of this literature has focused on the use of cognitive-behavioural therapy (CBT), which is widely considered as the treatment of choice for BN [1,2,5]. The theory [6] that underpins and guides CBT [7] is primarily concerned with the psychopathological processes that account for the persistence of the disorder. This theory assumes a dysfunctional system for evaluating self-worth [6], whereby self-worth is largely or even exclusively defined in terms of shape and weight and related control [8]. This over-evaluation of shape and weight (OSW) can then lead to dietary restraint, which often includes the adoption of rigid dietary rules about eating and food [6][7][8][9][10]. Due to the psychological and physiological effects of dietary restraint, when these inflexible dietary rules, which are extremely difficult to maintain, are broken, all attempts to control eating are abandoned and a binge occurs [6]. Although several randomised controlled trials have shown that CBT is more effective than a wide range of alternative treatments [1,2,5,11], amongst BN treatment completers, only 40-50 % have a full and lasting response #CITATION_TAG[13][14]. The developers of the original CB theory argued that four additional factors might account for the persistence of dysfunctional cognitions (OSW) and eating-disordered behaviours in some patients that present obstacles for change: (a) interpersonal problems; (b) core low selfesteem; (c) clinical perfectionism; and (d) mood intolerance [12,13]. Accordingly, they reformulated the original CB theory into an enhanced version by encapsulating these factors that considered being ""trans-diagnostic"" as well [13]. According to the enhanced CB version (CB-E) [13], the difficulties in establishing and/or maintaining interpersonal relationships may directly precipitate episodes of binge eating, affect all of the other maintenance factors and/or amplify OSW [12,15]. The pervasive low self-esteem that often persists after recovery [16] is thought to lead to attempts to control shape and weight and similarly contribute to negative affect [13,17]. Despite adverse consequences, when clinical perfectionism or over-evaluation of striving for and achieving personally demanding standards [18] is present, it might encourage increased striving to achieve unrealistic high standards in the valued domain of shape and weight and foster dietary restraint [13,[18][19][20]. The final maintenance factor of mood intolerance (i.e. inability to appropriately cope with adverse affective states followed by dysfunctional impulsive behaviours) [13] is believed to directly affect and maintain binge eating [12,17,[21][22][23][24]. The CB-E approach is consistent with research that documented two subtypes of patients with BN and binge eating disorder (BED) based on purely dietary restraint (i.e. approximately 60-70 % of samples) versus dietarynegative affect (i.e. approximately 30-40 % of samples) dimensions [25,26]."	1	"This theory assumes a dysfunctional system for evaluating self-worth [6], whereby self-worth is largely or even exclusively defined in terms of shape and weight and related control [8]. This over-evaluation of shape and weight (OSW) can then lead to dietary restraint, which often includes the adoption of rigid dietary rules about eating and food [6][7][8][9][10]. Due to the psychological and physiological effects of dietary restraint, when these inflexible dietary rules, which are extremely difficult to maintain, are broken, all attempts to control eating are abandoned and a binge occurs [6]. Although several randomised controlled trials have shown that CBT is more effective than a wide range of alternative treatments [1,2,5,11], amongst BN treatment completers, only 40-50 % have a full and lasting response #CITATION_TAG[13][14]. The developers of the original CB theory argued that four additional factors might account for the persistence of dysfunctional cognitions (OSW) and eating-disordered behaviours in some patients that present obstacles for change: (a) interpersonal problems; (b) core low selfesteem; (c) clinical perfectionism; and (d) mood intolerance [12,13]. Accordingly, they reformulated the original CB theory into an enhanced version by encapsulating these factors that considered being ""trans-diagnostic"" as well [13]. According to the enhanced CB version (CB-E) [13], the difficulties in establishing and/or maintaining interpersonal relationships may directly precipitate episodes of binge eating, affect all of the other maintenance factors and/or amplify OSW [12,15]."	g
CCT733	"A considerable treatment literature has been published on bulimia nervosa (BN) [1,2], which is marked by a chronic and relapse-ridden course, can result into serious medical complications, and is associated with severe comorbid psychopathology and functional impairment [3,4]. The bulk of this literature has focused on the use of cognitive-behavioural therapy (CBT), which is widely considered as the treatment of choice for BN [1,2,5]. The theory [6] that underpins and guides CBT [7] is primarily concerned with the psychopathological processes that account for the persistence of the disorder. This theory assumes a dysfunctional system for evaluating self-worth [6], whereby self-worth is largely or even exclusively defined in terms of shape and weight and related control [8]. This over-evaluation of shape and weight (OSW) can then lead to dietary restraint, which often includes the adoption of rigid dietary rules about eating and food [6][7][8][9][10]. Due to the psychological and physiological effects of dietary restraint, when these inflexible dietary rules, which are extremely difficult to maintain, are broken, all attempts to control eating are abandoned and a binge occurs [6]. Although several randomised controlled trials have shown that CBT is more effective than a wide range of alternative treatments [1,2,5,11], amongst BN treatment completers, only 40-50 % have a full and lasting response [12][13][14]. The developers of the original CB theory argued that four additional factors might account for the persistence of dysfunctional cognitions (OSW) and eating-disordered behaviours in some patients that present obstacles for change: (a) interpersonal problems; (b) core low selfesteem; (c) clinical perfectionism; and (d) mood intolerance [12,13]. Accordingly, they reformulated the original CB theory into an enhanced version by encapsulating these factors that considered being ""trans-diagnostic"" as well [13]. According to the enhanced CB version (CB-E) [13], the difficulties in establishing and/or maintaining interpersonal relationships may directly precipitate episodes of binge eating, affect all of the other maintenance factors and/or amplify OSW [12,15]. The pervasive low self-esteem that often persists after recovery [16] is thought to lead to attempts to control shape and weight and similarly contribute to negative affect [13,#CITATION_TAG]. Despite adverse consequences, when clinical perfectionism or over-evaluation of striving for and achieving personally demanding standards [18] is present, it might encourage increased striving to achieve unrealistic high standards in the valued domain of shape and weight and foster dietary restraint [13,[18][19][20]. The final maintenance factor of mood intolerance (i.e. inability to appropriately cope with adverse affective states followed by dysfunctional impulsive behaviours) [13] is believed to directly affect and maintain binge eating [12,17,[21][22][23][24]. The CB-E approach is consistent with research that documented two subtypes of patients with BN and binge eating disorder (BED) based on purely dietary restraint (i.e. approximately 60-70 % of samples) versus dietarynegative affect (i.e. approximately 30-40 % of samples) dimensions [25,26]."	1	"The developers of the original CB theory argued that four additional factors might account for the persistence of dysfunctional cognitions (OSW) and eating-disordered behaviours in some patients that present obstacles for change: (a) interpersonal problems; (b) core low selfesteem; (c) clinical perfectionism; and (d) mood intolerance [12,13]. Accordingly, they reformulated the original CB theory into an enhanced version by encapsulating these factors that considered being ""trans-diagnostic"" as well [13]. According to the enhanced CB version (CB-E) [13], the difficulties in establishing and/or maintaining interpersonal relationships may directly precipitate episodes of binge eating, affect all of the other maintenance factors and/or amplify OSW [12,15]. The pervasive low self-esteem that often persists after recovery [16] is thought to lead to attempts to control shape and weight and similarly contribute to negative affect [13,#CITATION_TAG]. Despite adverse consequences, when clinical perfectionism or over-evaluation of striving for and achieving personally demanding standards [18] is present, it might encourage increased striving to achieve unrealistic high standards in the valued domain of shape and weight and foster dietary restraint [13,[18][19][20]. The final maintenance factor of mood intolerance (i.e. inability to appropriately cope with adverse affective states followed by dysfunctional impulsive behaviours) [13] is believed to directly affect and maintain binge eating [12,17,[21][22][23][24]. The CB-E approach is consistent with research that documented two subtypes of patients with BN and binge eating disorder (BED) based on purely dietary restraint (i.e. approximately 60-70 % of samples) versus dietarynegative affect (i.e. approximately 30-40 % of samples) dimensions [25,26]."	i
CCT734	"A considerable treatment literature has been published on bulimia nervosa (BN) [1,2], which is marked by a chronic and relapse-ridden course, can result into serious medical complications, and is associated with severe comorbid psychopathology and functional impairment [3,4]. The bulk of this literature has focused on the use of cognitive-behavioural therapy (CBT), which is widely considered as the treatment of choice for BN [1,2,5]. The theory #CITATION_TAG that underpins and guides CBT [7] is primarily concerned with the psychopathological processes that account for the persistence of the disorder. This theory assumes a dysfunctional system for evaluating self-worth [6], whereby self-worth is largely or even exclusively defined in terms of shape and weight and related control [8]. This over-evaluation of shape and weight (OSW) can then lead to dietary restraint, which often includes the adoption of rigid dietary rules about eating and food [6][7][8][9][10]. Due to the psychological and physiological effects of dietary restraint, when these inflexible dietary rules, which are extremely difficult to maintain, are broken, all attempts to control eating are abandoned and a binge occurs [6]. Although several randomised controlled trials have shown that CBT is more effective than a wide range of alternative treatments [1,2,5,11], amongst BN treatment completers, only 40-50 % have a full and lasting response [12][13][14]. The developers of the original CB theory argued that four additional factors might account for the persistence of dysfunctional cognitions (OSW) and eating-disordered behaviours in some patients that present obstacles for change: (a) interpersonal problems; (b) core low selfesteem; (c) clinical perfectionism; and (d) mood intolerance [12,13]. Accordingly, they reformulated the original CB theory into an enhanced version by encapsulating these factors that considered being ""trans-diagnostic"" as well [13]. According to the enhanced CB version (CB-E) [13], the difficulties in establishing and/or maintaining interpersonal relationships may directly precipitate episodes of binge eating, affect all of the other maintenance factors and/or amplify OSW [12,15]. The pervasive low self-esteem that often persists after recovery [16] is thought to lead to attempts to control shape and weight and similarly contribute to negative affect [13,17]. Despite adverse consequences, when clinical perfectionism or over-evaluation of striving for and achieving personally demanding standards [18] is present, it might encourage increased striving to achieve unrealistic high standards in the valued domain of shape and weight and foster dietary restraint [13,[18][19][20]. The final maintenance factor of mood intolerance (i.e. inability to appropriately cope with adverse affective states followed by dysfunctional impulsive behaviours) [13] is believed to directly affect and maintain binge eating [12,17,[21][22][23][24]. The CB-E approach is consistent with research that documented two subtypes of patients with BN and binge eating disorder (BED) based on purely dietary restraint (i.e. approximately 60-70 % of samples) versus dietarynegative affect (i.e. approximately 30-40 % of samples) dimensions [25,26]."	5	A considerable treatment literature has been published on bulimia nervosa (BN) [1,2], which is marked by a chronic and relapse-ridden course, can result into serious medical complications, and is associated with severe comorbid psychopathology and functional impairment [3,4]. The bulk of this literature has focused on the use of cognitive-behavioural therapy (CBT), which is widely considered as the treatment of choice for BN [1,2,5]. The theory #CITATION_TAG that underpins and guides CBT [7] is primarily concerned with the psychopathological processes that account for the persistence of the disorder. This theory assumes a dysfunctional system for evaluating self-worth [6], whereby self-worth is largely or even exclusively defined in terms of shape and weight and related control [8]. This over-evaluation of shape and weight (OSW) can then lead to dietary restraint, which often includes the adoption of rigid dietary rules about eating and food [6][7][8][9][10]. Due to the psychological and physiological effects of dietary restraint, when these inflexible dietary rules, which are extremely difficult to maintain, are broken, all attempts to control eating are abandoned and a binge occurs [6].	e
CCT735	"A considerable treatment literature has been published on bulimia nervosa (BN) [1,2], which is marked by a chronic and relapse-ridden course, can result into serious medical complications, and is associated with severe comorbid psychopathology and functional impairment [3,4]. The bulk of this literature has focused on the use of cognitive-behavioural therapy (CBT), which is widely considered as the treatment of choice for BN [1,2,5]. The theory [6] that underpins and guides CBT #CITATION_TAG is primarily concerned with the psychopathological processes that account for the persistence of the disorder. This theory assumes a dysfunctional system for evaluating self-worth [6], whereby self-worth is largely or even exclusively defined in terms of shape and weight and related control [8]. This over-evaluation of shape and weight (OSW) can then lead to dietary restraint, which often includes the adoption of rigid dietary rules about eating and food [6][7][8][9][10]. Due to the psychological and physiological effects of dietary restraint, when these inflexible dietary rules, which are extremely difficult to maintain, are broken, all attempts to control eating are abandoned and a binge occurs [6]. Although several randomised controlled trials have shown that CBT is more effective than a wide range of alternative treatments [1,2,5,11], amongst BN treatment completers, only 40-50 % have a full and lasting response [12][13][14]. The developers of the original CB theory argued that four additional factors might account for the persistence of dysfunctional cognitions (OSW) and eating-disordered behaviours in some patients that present obstacles for change: (a) interpersonal problems; (b) core low selfesteem; (c) clinical perfectionism; and (d) mood intolerance [12,13]. Accordingly, they reformulated the original CB theory into an enhanced version by encapsulating these factors that considered being ""trans-diagnostic"" as well [13]. According to the enhanced CB version (CB-E) [13], the difficulties in establishing and/or maintaining interpersonal relationships may directly precipitate episodes of binge eating, affect all of the other maintenance factors and/or amplify OSW [12,15]. The pervasive low self-esteem that often persists after recovery [16] is thought to lead to attempts to control shape and weight and similarly contribute to negative affect [13,17]. Despite adverse consequences, when clinical perfectionism or over-evaluation of striving for and achieving personally demanding standards [18] is present, it might encourage increased striving to achieve unrealistic high standards in the valued domain of shape and weight and foster dietary restraint [13,[18][19][20]. The final maintenance factor of mood intolerance (i.e. inability to appropriately cope with adverse affective states followed by dysfunctional impulsive behaviours) [13] is believed to directly affect and maintain binge eating [12,17,[21][22][23][24]. The CB-E approach is consistent with research that documented two subtypes of patients with BN and binge eating disorder (BED) based on purely dietary restraint (i.e. approximately 60-70 % of samples) versus dietarynegative affect (i.e. approximately 30-40 % of samples) dimensions [25,26]."	5	A considerable treatment literature has been published on bulimia nervosa (BN) [1,2], which is marked by a chronic and relapse-ridden course, can result into serious medical complications, and is associated with severe comorbid psychopathology and functional impairment [3,4]. The bulk of this literature has focused on the use of cognitive-behavioural therapy (CBT), which is widely considered as the treatment of choice for BN [1,2,5]. The theory [6] that underpins and guides CBT #CITATION_TAG is primarily concerned with the psychopathological processes that account for the persistence of the disorder. This theory assumes a dysfunctional system for evaluating self-worth [6], whereby self-worth is largely or even exclusively defined in terms of shape and weight and related control [8]. This over-evaluation of shape and weight (OSW) can then lead to dietary restraint, which often includes the adoption of rigid dietary rules about eating and food [6][7][8][9][10]. Due to the psychological and physiological effects of dietary restraint, when these inflexible dietary rules, which are extremely difficult to maintain, are broken, all attempts to control eating are abandoned and a binge occurs [6].	e
CCT736	"A considerable treatment literature has been published on bulimia nervosa (BN) [1,2], which is marked by a chronic and relapse-ridden course, can result into serious medical complications, and is associated with severe comorbid psychopathology and functional impairment [3,4]. The bulk of this literature has focused on the use of cognitive-behavioural therapy (CBT), which is widely considered as the treatment of choice for BN [1,2,5]. The theory [6] that underpins and guides CBT [7] is primarily concerned with the psychopathological processes that account for the persistence of the disorder. This theory assumes a dysfunctional system for evaluating self-worth [6], whereby self-worth is largely or even exclusively defined in terms of shape and weight and related control [8]. This over-evaluation of shape and weight (OSW) can then lead to dietary restraint, which often includes the adoption of rigid dietary rules about eating and food [6][7][8][9][10]. Due to the psychological and physiological effects of dietary restraint, when these inflexible dietary rules, which are extremely difficult to maintain, are broken, all attempts to control eating are abandoned and a binge occurs [6]. Although several randomised controlled trials have shown that CBT is more effective than a wide range of alternative treatments [1,2,5,11], amongst BN treatment completers, only 40-50 % have a full and lasting response [12][13][14]. The developers of the original CB theory argued that four additional factors might account for the persistence of dysfunctional cognitions (OSW) and eating-disordered behaviours in some patients that present obstacles for change: (a) interpersonal problems; (b) core low selfesteem; (c) clinical perfectionism; and (d) mood intolerance [12,13]. Accordingly, they reformulated the original CB theory into an enhanced version by encapsulating these factors that considered being ""trans-diagnostic"" as well [13]. According to the enhanced CB version (CB-E) [13], the difficulties in establishing and/or maintaining interpersonal relationships may directly precipitate episodes of binge eating, affect all of the other maintenance factors and/or amplify OSW [12,15]. The pervasive low self-esteem that often persists after recovery [16] is thought to lead to attempts to control shape and weight and similarly contribute to negative affect [13,17]. Despite adverse consequences, when clinical perfectionism or over-evaluation of striving for and achieving personally demanding standards [18] is present, it might encourage increased striving to achieve unrealistic high standards in the valued domain of shape and weight and foster dietary restraint [13,[18][19][20]. The final maintenance factor of mood intolerance (i.e. inability to appropriately cope with adverse affective states followed by dysfunctional impulsive behaviours) [13] is believed to directly affect and maintain binge eating [12,17,[21][22][23]#CITATION_TAG. The CB-E approach is consistent with research that documented two subtypes of patients with BN and binge eating disorder (BED) based on purely dietary restraint (i.e. approximately 60-70 % of samples) versus dietarynegative affect (i.e. approximately 30-40 % of samples) dimensions [25,26]."	4	According to the enhanced CB version (CB-E) [13], the difficulties in establishing and/or maintaining interpersonal relationships may directly precipitate episodes of binge eating, affect all of the other maintenance factors and/or amplify OSW [12,15]. The pervasive low self-esteem that often persists after recovery [16] is thought to lead to attempts to control shape and weight and similarly contribute to negative affect [13,17]. Despite adverse consequences, when clinical perfectionism or over-evaluation of striving for and achieving personally demanding standards [18] is present, it might encourage increased striving to achieve unrealistic high standards in the valued domain of shape and weight and foster dietary restraint [13,[18][19][20]. The final maintenance factor of mood intolerance (i.e. inability to appropriately cope with adverse affective states followed by dysfunctional impulsive behaviours) [13] is believed to directly affect and maintain binge eating [12,17,[21][22][23]#CITATION_TAG. The CB-E approach is consistent with research that documented two subtypes of patients with BN and binge eating disorder (BED) based on purely dietary restraint (i.e. approximately 60-70 % of samples) versus dietarynegative affect (i.e. approximately 30-40 % of samples) dimensions [25,26].	i
CCT737	"After re-categorizing all DSM-IV cases using DSM-5 diagnostic criteria, differences in demographic and clinical variables between diagnostic groups were assessed by means of ANOVA or œá 2 test, as appropriate, followed by post hoc pairwise comparisons with Bonferroni correction if needed [46]. The appropriate measures of effect size for continuous (partial Œ∑ 2 ) or categorical variables (Cramer"" s œï) were calculated. Cut-off conventions for partial Œ∑ 2 are as follows: small (.01-.09), medium (.10-.24), and large (‚â•.25) [46]. Cut-off conventions for Cramer"" s œï (with df = 2) are as follows: small (.07-.20), medium (.21-.34), and large (‚â•.35) [46]. There were no missing data. Latent variable structural equation modelling (SEM) was used to examine both hypothesized CB models, depicted in Fig. 1. It involves estimation of (a) a measurement model and (b) a structural m o d e l w h i l e a c c o u n t i n g f o r m e a s u r e m e n t error [39]. The measurement model tests the proposed measurement of study constructs by estimating factor loadings between observed/measured variables and underlying latent variables (Online Resource 3), using confirmatory factor analysis. The structural model retains the components of the measurement model and tests the specified structural relationships between latent variables (i.e. the directional paths; Fig. 1); BMI and depression severity (i.e. BDI score) were covariates in each structural model and specified to predict each of the latent variables [39] in an attempt to reduce their effects on the relationships between the latent variables under investigation [17,#CITATION_TAG]. 5 EM analyses were performed in Mplus version 6.12 [49] with a maximum likelihood approach (as pre-analysis of the data did not reveal any evidence for univariate and multivariate non-normality). EM analyses were performed in Mplus version 6.12 [49] with a maximum likelihood approach (as pre-analysis of the data did not reveal any evidence for univariate and multivariate non-normality). Criteria for good measurement and structural model fit were as follows: Comparative Fit Index and Tucker-Lewis Index values ‚â•.95, standardized root-mean-square residual values ‚â§.08, and root-mean-square error of approximation values ‚â§.06 [39,49]. The Chi-square statistic (œá 2 ) is also reported. To obtain the most parsimonious and accurate representation of the data, we planned to trim non-significant structural paths and to add paths not originally specified (trimmed/revised model) but that impacted the fit of the model to the data based on the modification indices values (MIs > 5.0) provided by Mplus [39,49]; the trimmed/ revised models were re-examined for good fit, and the initial (hypothesized) and trimmed/revised (nested) models were compared using the Chi-square difference test (‚àÜœá 2 ) [39]. Because the original and CB-E structural models were not nested models (i.e. hierarchically related to one other in the sense that their parameter sets are subsets of one another), it was not possible to use the ‚àÜœá 2 to statistically compare model fit, and therefore, we compared the predictive utility of each CB model by examining the percentage of variance accounted for in dietary restraint and binge eating by each model, as recommended [24,39]."	0	Latent variable structural equation modelling (SEM) was used to examine both hypothesized CB models, depicted in Fig. 1. It involves estimation of (a) a measurement model and (b) a structural m o d e l w h i l e a c c o u n t i n g f o r m e a s u r e m e n t error [39]. The measurement model tests the proposed measurement of study constructs by estimating factor loadings between observed/measured variables and underlying latent variables (Online Resource 3), using confirmatory factor analysis. The structural model retains the components of the measurement model and tests the specified structural relationships between latent variables (i.e. the directional paths; Fig. 1); BMI and depression severity (i.e. BDI score) were covariates in each structural model and specified to predict each of the latent variables [39] in an attempt to reduce their effects on the relationships between the latent variables under investigation [17,#CITATION_TAG]. 5 EM analyses were performed in Mplus version 6.12 [49] with a maximum likelihood approach (as pre-analysis of the data did not reveal any evidence for univariate and multivariate non-normality). EM analyses were performed in Mplus version 6.12 [49] with a maximum likelihood approach (as pre-analysis of the data did not reveal any evidence for univariate and multivariate non-normality). Criteria for good measurement and structural model fit were as follows: Comparative Fit Index and Tucker-Lewis Index values ‚â•.	e
CCT738	"A considerable treatment literature has been published on bulimia nervosa (BN) [1,2], which is marked by a chronic and relapse-ridden course, can result into serious medical complications, and is associated with severe comorbid psychopathology and functional impairment [3,4]. The bulk of this literature has focused on the use of cognitive-behavioural therapy (CBT), which is widely considered as the treatment of choice for BN [1,2,5]. The theory [6] that underpins and guides CBT [7] is primarily concerned with the psychopathological processes that account for the persistence of the disorder. This theory assumes a dysfunctional system for evaluating self-worth [6], whereby self-worth is largely or even exclusively defined in terms of shape and weight and related control [8]. This over-evaluation of shape and weight (OSW) can then lead to dietary restraint, which often includes the adoption of rigid dietary rules about eating and food [6][7][8][9][10]. Due to the psychological and physiological effects of dietary restraint, when these inflexible dietary rules, which are extremely difficult to maintain, are broken, all attempts to control eating are abandoned and a binge occurs [6]. Although several randomised controlled trials have shown that CBT is more effective than a wide range of alternative treatments [1,2,5,11], amongst BN treatment completers, only 40-50 % have a full and lasting response [12][13][14]. The developers of the original CB theory argued that four additional factors might account for the persistence of dysfunctional cognitions (OSW) and eating-disordered behaviours in some patients that present obstacles for change: (a) interpersonal problems; (b) core low selfesteem; (c) clinical perfectionism; and (d) mood intolerance [12,13]. Accordingly, they reformulated the original CB theory into an enhanced version by encapsulating these factors that considered being ""trans-diagnostic"" as well [13]. According to the enhanced CB version (CB-E) [13], the difficulties in establishing and/or maintaining interpersonal relationships may directly precipitate episodes of binge eating, affect all of the other maintenance factors and/or amplify OSW [12,#CITATION_TAG]. The pervasive low self-esteem that often persists after recovery [16] is thought to lead to attempts to control shape and weight and similarly contribute to negative affect [13,17]. Despite adverse consequences, when clinical perfectionism or over-evaluation of striving for and achieving personally demanding standards [18] is present, it might encourage increased striving to achieve unrealistic high standards in the valued domain of shape and weight and foster dietary restraint [13,[18][19][20]. The final maintenance factor of mood intolerance (i.e. inability to appropriately cope with adverse affective states followed by dysfunctional impulsive behaviours) [13] is believed to directly affect and maintain binge eating [12,17,[21][22][23][24]. The CB-E approach is consistent with research that documented two subtypes of patients with BN and binge eating disorder (BED) based on purely dietary restraint (i.e. approximately 60-70 % of samples) versus dietarynegative affect (i.e. approximately 30-40 % of samples) dimensions [25,26]."	2	"Although several randomised controlled trials have shown that CBT is more effective than a wide range of alternative treatments [1,2,5,11], amongst BN treatment completers, only 40-50 % have a full and lasting response [12][13][14]. The developers of the original CB theory argued that four additional factors might account for the persistence of dysfunctional cognitions (OSW) and eating-disordered behaviours in some patients that present obstacles for change: (a) interpersonal problems; (b) core low selfesteem; (c) clinical perfectionism; and (d) mood intolerance [12,13]. Accordingly, they reformulated the original CB theory into an enhanced version by encapsulating these factors that considered being ""trans-diagnostic"" as well [13]. According to the enhanced CB version (CB-E) [13], the difficulties in establishing and/or maintaining interpersonal relationships may directly precipitate episodes of binge eating, affect all of the other maintenance factors and/or amplify OSW [12,#CITATION_TAG]. The pervasive low self-esteem that often persists after recovery [16] is thought to lead to attempts to control shape and weight and similarly contribute to negative affect [13,17]. Despite adverse consequences, when clinical perfectionism or over-evaluation of striving for and achieving personally demanding standards [18] is present, it might encourage increased striving to achieve unrealistic high standards in the valued domain of shape and weight and foster dietary restraint [13,[18][19][20]. The final maintenance factor of mood intolerance (i.e. inability to appropriately cope with adverse affective states followed by dysfunctional impulsive behaviours) [13] is believed to directly affect and maintain binge eating [12,17,[21][22][23][24]."	 
CCT739	"A considerable treatment literature has been published on bulimia nervosa (BN) [1,2], which is marked by a chronic and relapse-ridden course, can result into serious medical complications, and is associated with severe comorbid psychopathology and functional impairment [3,4]. The bulk of this literature has focused on the use of cognitive-behavioural therapy (CBT), which is widely considered as the treatment of choice for BN [1,2,5]. The theory [6] that underpins and guides CBT [7] is primarily concerned with the psychopathological processes that account for the persistence of the disorder. This theory assumes a dysfunctional system for evaluating self-worth [6], whereby self-worth is largely or even exclusively defined in terms of shape and weight and related control [8]. This over-evaluation of shape and weight (OSW) can then lead to dietary restraint, which often includes the adoption of rigid dietary rules about eating and food [6][7][8][9][10]. Due to the psychological and physiological effects of dietary restraint, when these inflexible dietary rules, which are extremely difficult to maintain, are broken, all attempts to control eating are abandoned and a binge occurs [6]. Although several randomised controlled trials have shown that CBT is more effective than a wide range of alternative treatments [1,2,5,11], amongst BN treatment completers, only 40-50 % have a full and lasting response [12][13][14]. The developers of the original CB theory argued that four additional factors might account for the persistence of dysfunctional cognitions (OSW) and eating-disordered behaviours in some patients that present obstacles for change: (a) interpersonal problems; (b) core low selfesteem; (c) clinical perfectionism; and (d) mood intolerance [12,13]. Accordingly, they reformulated the original CB theory into an enhanced version by encapsulating these factors that considered being ""trans-diagnostic"" as well [13]. According to the enhanced CB version (CB-E) [13], the difficulties in establishing and/or maintaining interpersonal relationships may directly precipitate episodes of binge eating, affect all of the other maintenance factors and/or amplify OSW [12,15]. The pervasive low self-esteem that often persists after recovery [16] is thought to lead to attempts to control shape and weight and similarly contribute to negative affect [13,17]. Despite adverse consequences, when clinical perfectionism or over-evaluation of striving for and achieving personally demanding standards [18] is present, it might encourage increased striving to achieve unrealistic high standards in the valued domain of shape and weight and foster dietary restraint [13,[18][19][20]. The final maintenance factor of mood intolerance (i.e. inability to appropriately cope with adverse affective states followed by dysfunctional impulsive behaviours) [13] is believed to directly affect and maintain binge eating [12,17,[21][22]#CITATION_TAG[24]. The CB-E approach is consistent with research that documented two subtypes of patients with BN and binge eating disorder (BED) based on purely dietary restraint (i.e. approximately 60-70 % of samples) versus dietarynegative affect (i.e. approximately 30-40 % of samples) dimensions [25,26]."	4	According to the enhanced CB version (CB-E) [13], the difficulties in establishing and/or maintaining interpersonal relationships may directly precipitate episodes of binge eating, affect all of the other maintenance factors and/or amplify OSW [12,15]. The pervasive low self-esteem that often persists after recovery [16] is thought to lead to attempts to control shape and weight and similarly contribute to negative affect [13,17]. Despite adverse consequences, when clinical perfectionism or over-evaluation of striving for and achieving personally demanding standards [18] is present, it might encourage increased striving to achieve unrealistic high standards in the valued domain of shape and weight and foster dietary restraint [13,[18][19][20]. The final maintenance factor of mood intolerance (i.e. inability to appropriately cope with adverse affective states followed by dysfunctional impulsive behaviours) [13] is believed to directly affect and maintain binge eating [12,17,[21][22]#CITATION_TAG[24]. The CB-E approach is consistent with research that documented two subtypes of patients with BN and binge eating disorder (BED) based on purely dietary restraint (i.e. approximately 60-70 % of samples) versus dietarynegative affect (i.e. approximately 30-40 % of samples) dimensions [25,26].	i
CCT740	"A considerable treatment literature has been published on bulimia nervosa (BN) [1,#CITATION_TAG], which is marked by a chronic and relapse-ridden course, can result into serious medical complications, and is associated with severe comorbid psychopathology and functional impairment [3,4]. The bulk of this literature has focused on the use of cognitive-behavioural therapy (CBT), which is widely considered as the treatment of choice for BN [1,2,5]. The theory [6] that underpins and guides CBT [7] is primarily concerned with the psychopathological processes that account for the persistence of the disorder. This theory assumes a dysfunctional system for evaluating self-worth [6], whereby self-worth is largely or even exclusively defined in terms of shape and weight and related control [8]. This over-evaluation of shape and weight (OSW) can then lead to dietary restraint, which often includes the adoption of rigid dietary rules about eating and food [6][7][8][9][10]. Due to the psychological and physiological effects of dietary restraint, when these inflexible dietary rules, which are extremely difficult to maintain, are broken, all attempts to control eating are abandoned and a binge occurs [6]. Although several randomised controlled trials have shown that CBT is more effective than a wide range of alternative treatments [1,2,5,11], amongst BN treatment completers, only 40-50 % have a full and lasting response [12][13][14]. The developers of the original CB theory argued that four additional factors might account for the persistence of dysfunctional cognitions (OSW) and eating-disordered behaviours in some patients that present obstacles for change: (a) interpersonal problems; (b) core low selfesteem; (c) clinical perfectionism; and (d) mood intolerance [12,13]. Accordingly, they reformulated the original CB theory into an enhanced version by encapsulating these factors that considered being ""trans-diagnostic"" as well [13]. According to the enhanced CB version (CB-E) [13], the difficulties in establishing and/or maintaining interpersonal relationships may directly precipitate episodes of binge eating, affect all of the other maintenance factors and/or amplify OSW [12,15]. The pervasive low self-esteem that often persists after recovery [16] is thought to lead to attempts to control shape and weight and similarly contribute to negative affect [13,17]. Despite adverse consequences, when clinical perfectionism or over-evaluation of striving for and achieving personally demanding standards [18] is present, it might encourage increased striving to achieve unrealistic high standards in the valued domain of shape and weight and foster dietary restraint [13,[18][19][20]. The final maintenance factor of mood intolerance (i.e. inability to appropriately cope with adverse affective states followed by dysfunctional impulsive behaviours) [13] is believed to directly affect and maintain binge eating [12,17,[21][22][23][24]. The CB-E approach is consistent with research that documented two subtypes of patients with BN and binge eating disorder (BED) based on purely dietary restraint (i.e. approximately 60-70 % of samples) versus dietarynegative affect (i.e. approximately 30-40 % of samples) dimensions [25,26]."	0	A considerable treatment literature has been published on bulimia nervosa (BN) [1,#CITATION_TAG], which is marked by a chronic and relapse-ridden course, can result into serious medical complications, and is associated with severe comorbid psychopathology and functional impairment [3,4]. The bulk of this literature has focused on the use of cognitive-behavioural therapy (CBT), which is widely considered as the treatment of choice for BN [1,2,5]. The theory [6] that underpins and guides CBT [7] is primarily concerned with the psychopathological processes that account for the persistence of the disorder. This theory assumes a dysfunctional system for evaluating self-worth [6], whereby self-worth is largely or even exclusively defined in terms of shape and weight and related control [8].	A
CCT741	"A considerable treatment literature has been published on bulimia nervosa (BN) [1,2], which is marked by a chronic and relapse-ridden course, can result into serious medical complications, and is associated with severe comorbid psychopathology and functional impairment [3,4]. The bulk of this literature has focused on the use of cognitive-behavioural therapy (CBT), which is widely considered as the treatment of choice for BN [1,2,5]. The theory [6] that underpins and guides CBT [7] is primarily concerned with the psychopathological processes that account for the persistence of the disorder. This theory assumes a dysfunctional system for evaluating self-worth [6], whereby self-worth is largely or even exclusively defined in terms of shape and weight and related control [8]. This over-evaluation of shape and weight (OSW) can then lead to dietary restraint, which often includes the adoption of rigid dietary rules about eating and food [6][7][8][9][10]. Due to the psychological and physiological effects of dietary restraint, when these inflexible dietary rules, which are extremely difficult to maintain, are broken, all attempts to control eating are abandoned and a binge occurs [6]. Although several randomised controlled trials have shown that CBT is more effective than a wide range of alternative treatments [1,2,5,11], amongst BN treatment completers, only 40-50 % have a full and lasting response [12][13][14]. The developers of the original CB theory argued that four additional factors might account for the persistence of dysfunctional cognitions (OSW) and eating-disordered behaviours in some patients that present obstacles for change: (a) interpersonal problems; (b) core low selfesteem; (c) clinical perfectionism; and (d) mood intolerance [12,13]. Accordingly, they reformulated the original CB theory into an enhanced version by encapsulating these factors that considered being ""trans-diagnostic"" as well [13]. According to the enhanced CB version (CB-E) [13], the difficulties in establishing and/or maintaining interpersonal relationships may directly precipitate episodes of binge eating, affect all of the other maintenance factors and/or amplify OSW [12,15]. The pervasive low self-esteem that often persists after recovery [16] is thought to lead to attempts to control shape and weight and similarly contribute to negative affect [13,17]. Despite adverse consequences, when clinical perfectionism or over-evaluation of striving for and achieving personally demanding standards [18] is present, it might encourage increased striving to achieve unrealistic high standards in the valued domain of shape and weight and foster dietary restraint [13,[18][19][20]. The final maintenance factor of mood intolerance (i.e. inability to appropriately cope with adverse affective states followed by dysfunctional impulsive behaviours) [13] is believed to directly affect and maintain binge eating [12,17,[21]#CITATION_TAG[23][24]. The CB-E approach is consistent with research that documented two subtypes of patients with BN and binge eating disorder (BED) based on purely dietary restraint (i.e. approximately 60-70 % of samples) versus dietarynegative affect (i.e. approximately 30-40 % of samples) dimensions [25,26]."	2	According to the enhanced CB version (CB-E) [13], the difficulties in establishing and/or maintaining interpersonal relationships may directly precipitate episodes of binge eating, affect all of the other maintenance factors and/or amplify OSW [12,15]. The pervasive low self-esteem that often persists after recovery [16] is thought to lead to attempts to control shape and weight and similarly contribute to negative affect [13,17]. Despite adverse consequences, when clinical perfectionism or over-evaluation of striving for and achieving personally demanding standards [18] is present, it might encourage increased striving to achieve unrealistic high standards in the valued domain of shape and weight and foster dietary restraint [13,[18][19][20]. The final maintenance factor of mood intolerance (i.e. inability to appropriately cope with adverse affective states followed by dysfunctional impulsive behaviours) [13] is believed to directly affect and maintain binge eating [12,17,[21]#CITATION_TAG[23][24]. The CB-E approach is consistent with research that documented two subtypes of patients with BN and binge eating disorder (BED) based on purely dietary restraint (i.e. approximately 60-70 % of samples) versus dietarynegative affect (i.e. approximately 30-40 % of samples) dimensions [25,26].	i
CCT742	"One of several changes to ED diagnoses that the APA Task Force made in DSM-5 [30] to decrease the preponderance of the EDNOS category [29,32] was the recognition of BED as a formal ED. When the DSM-5 criteria were applied to the current sample, the proportion of bulimictype EDNOS cases identified based on DSM-IV [31] criteria was reduced by 29.6 %; this reduction was due primarily to the reclassification of individuals into the BED diagnostic category. In sharp contrast to other ED diagnoses, the DSM-5 diagnosis of BED [30] does not include a criterion pertaining to body image, probably because of the belief that shape and weight concerns may simply reflect the (over)weight problems of BED patients #CITATION_TAG. However, research indicated that individuals with BED consistently described themselves as fatter than healthy controls matched for BMI, and their shape and weight concerns decrease as binge eating frequency decreases, even when BMI does not change [70]. The notion that body image concerns might be a clinical feature of BED is further supported by emerging research indicating that: (a) BED patients, as compared to normal-weight, overweight, and obese controls, have significantly greater shape and weight concerns, as well as greater eating-related psychopathology and psychological problems, including greater levels of depression and lower core self-esteem [71]; (b) greater body image concerns are predictors of poorer post-treatment outcomes, regardless of the specific type of treatment for BED [72], [70]; (c) BED patients report greater levels of shape and weight concerns than non-eating-disordered psychiatric controls [71]. The current study also provides evidence that shape and weight concerns are relevant in BED as in the other bulimic-type ED diagnostic groups (Table 2), as the differences across DSM-5 diagnostic groups, were minimal and not significant. 8 Based on the emerging empirical evidence summarized above and because the absence of a feature reflecting a disturbance in body image for the BED diagnosis casts this ED merely as a behavioural overeating construct, scholars have suggested the routine assessment of shape and weight concerns during clinical practice, as well as the incorporation of body image disturbance in the diagnostic scheme for BED in future DSM revisions, either as an individual criterion or as a diagnostic specifier (i.e. a sub-category within a diagnosis that assists with treatment matching and/or prediction of treatment outcome) [70,71]. Although much research is still needed, a similar change would be consistent with a """"trans-diagnostic"""" view of EDs [13], in which body image disturbance would be a core diagnostic feature of all EDs."	4	One of several changes to ED diagnoses that the APA Task Force made in DSM-5 [30] to decrease the preponderance of the EDNOS category [29,32] was the recognition of BED as a formal ED. When the DSM-5 criteria were applied to the current sample, the proportion of bulimictype EDNOS cases identified based on DSM-IV [31] criteria was reduced by 29.6 %; this reduction was due primarily to the reclassification of individuals into the BED diagnostic category. In sharp contrast to other ED diagnoses, the DSM-5 diagnosis of BED [30] does not include a criterion pertaining to body image, probably because of the belief that shape and weight concerns may simply reflect the (over)weight problems of BED patients #CITATION_TAG. However, research indicated that individuals with BED consistently described themselves as fatter than healthy controls matched for BMI, and their shape and weight concerns decrease as binge eating frequency decreases, even when BMI does not change [70]. The notion that body image concerns might be a clinical feature of BED is further supported by emerging research indicating that: (a) BED patients, as compared to normal-weight, overweight, and obese controls, have significantly greater shape and weight concerns, as well as greater eating-related psychopathology and psychological problems, including greater levels of depression and lower core self-esteem [71]; (b) greater body image concerns are predictors of poorer post-treatment outcomes, regardless of the specific type of treatment for BED [72], [70]; (c) BED patients report greater levels of shape and weight concerns than non-eating-disordered psychiatric controls [71]. The current study also provides evidence that shape and weight concerns are relevant in BED as in the other bulimic-type ED diagnostic groups (Table 2), as the differences across DSM-5 diagnostic groups, were minimal and not significant.	 
CCT743	Participants were drawn from a sample of 893 individuals consecutively referred to, and assessed for treatment of an ED, at five medium-large sized specialized care centres for EDs in Northern, Central, and Southern Italy between February 2011 and June 2013. Though a portion of this data set has already been used to evaluate the role of attachment in DSM-IV EDs [36], there is no overlap between those results and those presented here. In the current study, participants, who met DSM-IV diagnostic criteria for BN (n = 275) or bulimic-type EDNOS (n = 404), were included. Exclusion criteria comprised concurrent treatment for eating and weight-related disturbances, severe psychiatric conditions (psychosis) and intellectual disabilities, and insufficient knowledge of Italian. The flowchart of study participants is available in Online Resource 2. DSM-IV [31] ED and lifetime Axis I psychiatric disorder diagnoses were based on the Structured Clinical Interview for DSM-IV Axis I Disorders (SCID-I/P) [37]. The ED diagnoses were confirmed by findings from the Eating Disorder Examination-Interview-12.0D (EDE) #CITATION_TAG, administered to assess dietary restraint and frequency of binge eating episodes as well (see measures section). At each participating centre, clinicians with experience and training in assessing and treating EDs carried out the diagnostic procedures. Approximately 22 % of the SCID-I/Ps and 20 % of the EDEs conducted were audio-recorded and rated by a blinded clinician to establish inter-rater reliability (Œ∫), which was as follows: between .95 and 1.0 for lifetime and current (i.e. EDs) Axis I disorders; and 1.0 for diagnoses of EDs assessed by the means of EDE. All cases initially diagnosed as BN and bulimic-type EDNOS using the DSM-IV [31] criteria were re-categorized with the new DSM-5 criteria [30] on the basis of information from the interview records [34]. 2	0	Exclusion criteria comprised concurrent treatment for eating and weight-related disturbances, severe psychiatric conditions (psychosis) and intellectual disabilities, and insufficient knowledge of Italian. The flowchart of study participants is available in Online Resource 2. DSM-IV [31] ED and lifetime Axis I psychiatric disorder diagnoses were based on the Structured Clinical Interview for DSM-IV Axis I Disorders (SCID-I/P) [37]. The ED diagnoses were confirmed by findings from the Eating Disorder Examination-Interview-12.0D (EDE) #CITATION_TAG, administered to assess dietary restraint and frequency of binge eating episodes as well (see measures section). At each participating centre, clinicians with experience and training in assessing and treating EDs carried out the diagnostic procedures. Approximately 22 % of the SCID-I/Ps and 20 % of the EDEs conducted were audio-recorded and rated by a blinded clinician to establish inter-rater reliability (Œ∫), which was as follows: between .95 and 1.0 for lifetime and current (i.e. EDs) Axis I disorders; and 1.0 for diagnoses of EDs assessed by the means of EDE. All cases initially diagnosed as BN and bulimic-type EDNOS using the DSM-IV [31] criteria were re-categorized with the new DSM-5 criteria [30] on the basis of information from the interview records [34].	 
CCT744	Apart from body image concerns, the preliminary evidence that all diagnostic groups report comparable scores in all measures used to assess the four maintaining factors (incorporated in the CB-E model) supports the suggestion that intrapersonal problems, core low self-esteem, clinical perfectionism, and mood intolerance are related to all bulimic-type EDs without differences at the diagnostic level [13,15,17,36]. On the other hand, differences between BED and the other bulimic-type ED diagnostic groups were also observed (Table 2). Prior research comparing individuals with provisional DSM-IV BED to either DSM-IV BN purging or non-purging subtypes found significant differences in both current (age, BMI, and dietary restraint at the time of the assessment) and age-historical variables (age of onset) #CITATION_TAG[74][75]. The same pattern was observed in this study using DSM-5 criteria, although the magnitude of the differences was less prominent, and the mean of some of the variables measured at the time of the assessment is higher (i.e. dietary restraint), or lower (i.e. BMI) that one might generally expect for the BED group [73]. Nevertheless, the variability of both current and agehistorical variables within BED population is well documented [73,74], and mean values of both dietary restraint and BMI for BED cases are quite close to those observed in other clinical studies [76,77], [73]. Since the mean age of our BED participants at the time of assessment is consistent with that reported in several Italian studies [76,78], but lower than that of American studies (ranging from 38 to 48 years) [73], the possibility that Italians with BED are less tolerant of their overweight condition [78,79] and thus seek treatment more often than their US counterparts should not be ruled out. However, future studies are needed to corroborate this hypothesis.	1	Apart from body image concerns, the preliminary evidence that all diagnostic groups report comparable scores in all measures used to assess the four maintaining factors (incorporated in the CB-E model) supports the suggestion that intrapersonal problems, core low self-esteem, clinical perfectionism, and mood intolerance are related to all bulimic-type EDs without differences at the diagnostic level [13,15,17,36]. On the other hand, differences between BED and the other bulimic-type ED diagnostic groups were also observed (Table 2). Prior research comparing individuals with provisional DSM-IV BED to either DSM-IV BN purging or non-purging subtypes found significant differences in both current (age, BMI, and dietary restraint at the time of the assessment) and age-historical variables (age of onset) #CITATION_TAG[74][75]. The same pattern was observed in this study using DSM-5 criteria, although the magnitude of the differences was less prominent, and the mean of some of the variables measured at the time of the assessment is higher (i.e. dietary restraint), or lower (i.e. BMI) that one might generally expect for the BED group [73]. Nevertheless, the variability of both current and agehistorical variables within BED population is well documented [73,74], and mean values of both dietary restraint and BMI for BED cases are quite close to those observed in other clinical studies [76,77], [73]. Since the mean age of our BED participants at the time of assessment is consistent with that reported in several Italian studies [76,78], but lower than that of American studies (ranging from 38 to 48 years) [73], the possibility that Italians with BED are less tolerant of their overweight condition [78,79] and thus seek treatment more often than their US counterparts should not be ruled out.	i
CCT745	"While clinical perfectionism was the only maintaining variable directly linked to dietary restraint, interpersonal problems and mood intolerance were directly linked to binge eating, emphasizing the direct key role that both factors may have in its occurrence [11,21,22,44,48,52,53]. The positive and significant relationships between mood intolerance and binge eating are in accordance with CB-E model, which postulate that binge eating has a regulatory function and occur in an attempt to reduce the negative affective states [13]. However, in the current study, there was no direct relationship between dietary restraint and binge eating. This finding, as well as the evidence that interventions for binge eating that do not focus on reducing OSW and/or dietary restraint (i.e. interpersonal therapy, dialectical-behaviour therapy) decrease binge eating relative to assessment-only control conditions [1,2,11,54,55], seems incompatible with the theoretical assertion of both CB models, i.e. OSW affects binging indirectly through increasing the likelihood of dietary restraint [6,13]. Although there is evidence that initial dietary restraint levels predict future onset of binge eating among asymptomatic individuals [24,56,#CITATION_TAG], as in this study, prior research using clinical interviews or ecological momentary assessment failed to support the dietary restraint-binge eating relationship among bulimic-type ED patients [9,[58][59][60]. Although, the impact of dietary restraint on binge eating deserves further elucidation, the direct paths from interpersonal problems and mood intolerance to binge eating lend some credence to scholars"" suggestion that factors other than restraint may play a more critical role in the maintenance of binge eating among clinical samples [21,47,48,54,55], and highlight the importance of their inclusion in the CB-E theory, assessment, and target [12,13,21,23,28]. Moreover, the present study indicated that the dietary restraint-binge eating relationship is fully mediated and explained by mood intolerance. Although this indirect effect was unexpected, it appears consistent with findings from studies indicating that dietary manipulations that transiently deplete tryptophan levels (and consequently 5-HT synthesis in the brain) contribute to dysphoric mood in bulimic-type ED subjects [61,62], increasing the likelihood that an individual might binge eat to relieve dysphoria [21,22,48,60,61]. Furthermore, based on the results of neurobiological, molecular-genetic, and brain-imaging studies, Steiger and colleagues [63] postulated that factors affecting 5-HT functional activity may indirectly influence susceptibility to binge eating by heightening affective instability. Abnormal 5-HT status in subjects with bulimictype EDs may represents the cumulative effects of chronic dietary restraint [64][65][66], an inherited disposition, the consequence of exposure to intense developmental stressors, and traumatic experiences, and/or their combination [63]. Thus, a better understanding of the underlying serotonergic susceptibilities may explain heterogeneous clinical manifestations within the bulimic-type ED population and help clinicians to select the most appropriate treatment [63]. For instance, people with bulimic-type EDs whose variations in 5-HT status are mainly secondary consequences of dietary attempts may have relatively focal treatment needs (i.e. eating-symptom-focused therapies, such as the original version of CBT). However, different clinical pictures need to be considered. bulimic-type ED patients may benefit from more elaborate forms of interventions, such as the CBT-E [7,12,13,27], in case of more severe 5-HT abnormalities [63], and particularly if they are at least partly linked to affective instability mediated by 5-HT functioning or severe developmental disruptions that can affect both 5-HT functioning and affective instability [63]. Apart from the biological perceptive, cognitive factors may also play a central role in understanding the nature of the association between dietary restraint and binge eating. For instance, according to the abstinence violation effect (AVE) model, the inevitable violation of strict and inflexible dietary rules is thought to activate all-or-none thinking (e.g. perfect restraint vs. complete failure) [67]. This ""dichotomous"" thinking style, which is common among people who binge eat and addressed within CBT and CBT-E [7,13], is believed to heighten negative mood and disinhibit attempts to control what one eats [47,67]. Support for the AVE has been observed among binge-eaters [68,69]. Furthermore, longitudinal investigations amongst asymptomatic individuals revealed that the emotional distress caused by repeated perceived dietary failures increases mood deflection, which in turn results in increase binge eating [48,57]."	4	"The positive and significant relationships between mood intolerance and binge eating are in accordance with CB-E model, which postulate that binge eating has a regulatory function and occur in an attempt to reduce the negative affective states [13]. However, in the current study, there was no direct relationship between dietary restraint and binge eating. This finding, as well as the evidence that interventions for binge eating that do not focus on reducing OSW and/or dietary restraint (i.e. interpersonal therapy, dialectical-behaviour therapy) decrease binge eating relative to assessment-only control conditions [1,2,11,54,55], seems incompatible with the theoretical assertion of both CB models, i.e. OSW affects binging indirectly through increasing the likelihood of dietary restraint [6,13]. Although there is evidence that initial dietary restraint levels predict future onset of binge eating among asymptomatic individuals [24,56,#CITATION_TAG], as in this study, prior research using clinical interviews or ecological momentary assessment failed to support the dietary restraint-binge eating relationship among bulimic-type ED patients [9,[58][59][60]. Although, the impact of dietary restraint on binge eating deserves further elucidation, the direct paths from interpersonal problems and mood intolerance to binge eating lend some credence to scholars"" suggestion that factors other than restraint may play a more critical role in the maintenance of binge eating among clinical samples [21,47,48,54,55], and highlight the importance of their inclusion in the CB-E theory, assessment, and target [12,13,21,23,28]. Moreover, the present study indicated that the dietary restraint-binge eating relationship is fully mediated and explained by mood intolerance. Although this indirect effect was unexpected, it appears consistent with findings from studies indicating that dietary manipulations that transiently deplete tryptophan levels (and consequently 5-HT synthesis in the brain) contribute to dysphoric mood in bulimic-type ED subjects [61,62], increasing the likelihood that an individual might binge eat to relieve dysphoria [21,22,48,60,61]."	o
CCT746	"The current study aimed at extending research in this area by testing and comparing the original and CB-E models in a large clinical sample seeking treatment for bulimic-type EDs, which include BN and its variants [bulimic-type ED not otherwise specified (EDNOS), i.e. EDs ""clinically significant but not meeting full DSM-IV diagnostic criteria for BN, or needing additional study, such as BED] #CITATION_TAG. It was expected that even though both theoretical models (Fig. 1) would provide a good fit to the observed data, the CB-E maintenance model would account for a greater proportion of the variance in dietary restraint and binge eating (i.e. the hallmark behaviour of all bulimic-type EDs) [13,29]. Evaluating whether the strength of the conceptual relationships of both CB maintenance models is similar or different across diagnostic groups and formally testing the significance of the mediation or indirect effects embedded within the CB models (Fig. 1) in each diagnostic group were additional aims of the study. It is worth of note that prior the completion of the study, the APA Task Force made several changes to ED diagnoses in the DSM-5 [30] in order to reduce the preponderance of the DSM-IV [31] Anorexic and bulimictype EDNOS category [29,32] that formed the most common ED among those seeking treatment [33]. Regarding bulimic-type EDNOS, in addition to making BED a formal diagnosis, DSM-5 [30] revised the behavioural criteria (i.e. the threshold for frequency and duration), eliminated the diagnostic subtypes for BN, and changed the EDNOS designation to Other Specified Feeding or ED; Online Resource 1 summarizes the diagnostic criteria for bulimic-type EDs from the fourth to the fifth editions. As a consequence, all cases initially diagnosed as BN and bulimic-type EDNOS using the DSM-IV [31] criteria were re-categorized using the new DSM-5 criteria [30]. All analyses conducted to evaluate our hypothesis (Fig. 1) and potential differences across groups were based on DSM-5 diagnosis of BN, BED, and bulimic-type EDNOS 1 ; for simplicity, this last term was used in the current manuscript to refer to bulimic-type diagnoses that fell into the Other Specified Feeding or ED group. Re-categorizing diagnoses also allowed us to evaluate the degree to which the use of DSM-5 criteria [30] decreased the proportion of DSM-IV [31] bulimic-type EDNOS cases. This is also a novel contribution to the current literature given that prior research using the same [34] or a similar [3,35] procedure focused on community samples rather than on clinical treatment seeking samples. 1 It is should be noted that, although both CB models posit that binge eating may encourage in some individuals compensatory behaviours aimed at counteracting the effects of binge eating on weight [6,13] for details, in the current manuscript we focused on binge eating and did not incorporate compensatory behaviours neither in the form of purging nor in the form of non-purging for three main reasons: (1) the scheme distinguishing purging and non-purging BN subtypes has been eliminated from DSM-5 (Online Resource 1); (2) the DSM-5 BN and BED diagnoses are distinguished by the presence versus absence of recurrent inappropriate compensatory behaviours (Online Resource 1); and (3) the necessary prerequisite of the advanced statistical procedure (see ""Statistical Analyses"") used for evaluating if the strength of the conceptual relationships of both CB maintenance models (Fig. 1) is similar or different across DSM-5 BN, BED, and bulimic-type EDNOS (that includes also sub-threshold BED cases) is that the model under investigation should contain the same number of latent variables, each of which includes the same number of measured/observed variables for all groups of interest [39]."	5	"The current study aimed at extending research in this area by testing and comparing the original and CB-E models in a large clinical sample seeking treatment for bulimic-type EDs, which include BN and its variants [bulimic-type ED not otherwise specified (EDNOS), i.e. EDs ""clinically significant but not meeting full DSM-IV diagnostic criteria for BN, or needing additional study, such as BED] #CITATION_TAG. It was expected that even though both theoretical models (Fig. 1) would provide a good fit to the observed data, the CB-E maintenance model would account for a greater proportion of the variance in dietary restraint and binge eating (i.e. the hallmark behaviour of all bulimic-type EDs) [13,29]. Evaluating whether the strength of the conceptual relationships of both CB maintenance models is similar or different across diagnostic groups and formally testing the significance of the mediation or indirect effects embedded within the CB models (Fig. 1) in each diagnostic group were additional aims of the study. It is worth of note that prior the completion of the study, the APA Task Force made several changes to ED diagnoses in the DSM-5 [30] in order to reduce the preponderance of the DSM-IV [31] Anorexic and bulimictype EDNOS category [29,32] that formed the most common ED among those seeking treatment [33]."	T
CCT747	"While clinical perfectionism was the only maintaining variable directly linked to dietary restraint, interpersonal problems and mood intolerance were directly linked to binge eating, emphasizing the direct key role that both factors may have in its occurrence [11,21,22,44,48,52,53]. The positive and significant relationships between mood intolerance and binge eating are in accordance with CB-E model, which postulate that binge eating has a regulatory function and occur in an attempt to reduce the negative affective states [13]. However, in the current study, there was no direct relationship between dietary restraint and binge eating. This finding, as well as the evidence that interventions for binge eating that do not focus on reducing OSW and/or dietary restraint (i.e. interpersonal therapy, dialectical-behaviour therapy) decrease binge eating relative to assessment-only control conditions [1,2,11,54,55], seems incompatible with the theoretical assertion of both CB models, i.e. OSW affects binging indirectly through increasing the likelihood of dietary restraint [6,13]. Although there is evidence that initial dietary restraint levels predict future onset of binge eating among asymptomatic individuals [24,56,57], as in this study, prior research using clinical interviews or ecological momentary assessment failed to support the dietary restraint-binge eating relationship among bulimic-type ED patients [9,[58][59][60]. Although, the impact of dietary restraint on binge eating deserves further elucidation, the direct paths from interpersonal problems and mood intolerance to binge eating lend some credence to scholars"" suggestion that factors other than restraint may play a more critical role in the maintenance of binge eating among clinical samples [21,47,48,54,55], and highlight the importance of their inclusion in the CB-E theory, assessment, and target [12,13,21,23,28]. Moreover, the present study indicated that the dietary restraint-binge eating relationship is fully mediated and explained by mood intolerance. Although this indirect effect was unexpected, it appears consistent with findings from studies indicating that dietary manipulations that transiently deplete tryptophan levels (and consequently 5-HT synthesis in the brain) contribute to dysphoric mood in bulimic-type ED subjects [61,62], increasing the likelihood that an individual might binge eat to relieve dysphoria [21,22,48,60,61]. Furthermore, based on the results of neurobiological, molecular-genetic, and brain-imaging studies, Steiger and colleagues #CITATION_TAG postulated that factors affecting 5-HT functional activity may indirectly influence susceptibility to binge eating by heightening affective instability. Abnormal 5-HT status in subjects with bulimictype EDs may represents the cumulative effects of chronic dietary restraint [64][65][66], an inherited disposition, the consequence of exposure to intense developmental stressors, and traumatic experiences, and/or their combination [63]. Thus, a better understanding of the underlying serotonergic susceptibilities may explain heterogeneous clinical manifestations within the bulimic-type ED population and help clinicians to select the most appropriate treatment [63]. For instance, people with bulimic-type EDs whose variations in 5-HT status are mainly secondary consequences of dietary attempts may have relatively focal treatment needs (i.e. eating-symptom-focused therapies, such as the original version of CBT). However, different clinical pictures need to be considered. bulimic-type ED patients may benefit from more elaborate forms of interventions, such as the CBT-E [7,12,13,27], in case of more severe 5-HT abnormalities [63], and particularly if they are at least partly linked to affective instability mediated by 5-HT functioning or severe developmental disruptions that can affect both 5-HT functioning and affective instability [63]. Apart from the biological perceptive, cognitive factors may also play a central role in understanding the nature of the association between dietary restraint and binge eating. For instance, according to the abstinence violation effect (AVE) model, the inevitable violation of strict and inflexible dietary rules is thought to activate all-or-none thinking (e.g. perfect restraint vs. complete failure) [67]. This ""dichotomous"" thinking style, which is common among people who binge eat and addressed within CBT and CBT-E [7,13], is believed to heighten negative mood and disinhibit attempts to control what one eats [47,67]. Support for the AVE has been observed among binge-eaters [68,69]. Furthermore, longitudinal investigations amongst asymptomatic individuals revealed that the emotional distress caused by repeated perceived dietary failures increases mood deflection, which in turn results in increase binge eating [48,57]."	3	"Although, the impact of dietary restraint on binge eating deserves further elucidation, the direct paths from interpersonal problems and mood intolerance to binge eating lend some credence to scholars"" suggestion that factors other than restraint may play a more critical role in the maintenance of binge eating among clinical samples [21,47,48,54,55], and highlight the importance of their inclusion in the CB-E theory, assessment, and target [12,13,21,23,28]. Moreover, the present study indicated that the dietary restraint-binge eating relationship is fully mediated and explained by mood intolerance. Although this indirect effect was unexpected, it appears consistent with findings from studies indicating that dietary manipulations that transiently deplete tryptophan levels (and consequently 5-HT synthesis in the brain) contribute to dysphoric mood in bulimic-type ED subjects [61,62], increasing the likelihood that an individual might binge eat to relieve dysphoria [21,22,48,60,61]. Furthermore, based on the results of neurobiological, molecular-genetic, and brain-imaging studies, Steiger and colleagues #CITATION_TAG postulated that factors affecting 5-HT functional activity may indirectly influence susceptibility to binge eating by heightening affective instability. Abnormal 5-HT status in subjects with bulimictype EDs may represents the cumulative effects of chronic dietary restraint [64][65][66], an inherited disposition, the consequence of exposure to intense developmental stressors, and traumatic experiences, and/or their combination [63]. Thus, a better understanding of the underlying serotonergic susceptibilities may explain heterogeneous clinical manifestations within the bulimic-type ED population and help clinicians to select the most appropriate treatment [63]. For instance, people with bulimic-type EDs whose variations in 5-HT status are mainly secondary consequences of dietary attempts may have relatively focal treatment needs (i.e. eating-symptom-focused therapies, such as the original version of CBT)."	o
CCT748	"A considerable treatment literature has been published on bulimia nervosa (BN) [#CITATION_TAG,2], which is marked by a chronic and relapse-ridden course, can result into serious medical complications, and is associated with severe comorbid psychopathology and functional impairment [3,4]. The bulk of this literature has focused on the use of cognitive-behavioural therapy (CBT), which is widely considered as the treatment of choice for BN [1,2,5]. The theory [6] that underpins and guides CBT [7] is primarily concerned with the psychopathological processes that account for the persistence of the disorder. This theory assumes a dysfunctional system for evaluating self-worth [6], whereby self-worth is largely or even exclusively defined in terms of shape and weight and related control [8]. This over-evaluation of shape and weight (OSW) can then lead to dietary restraint, which often includes the adoption of rigid dietary rules about eating and food [6][7][8][9][10]. Due to the psychological and physiological effects of dietary restraint, when these inflexible dietary rules, which are extremely difficult to maintain, are broken, all attempts to control eating are abandoned and a binge occurs [6]. Although several randomised controlled trials have shown that CBT is more effective than a wide range of alternative treatments [1,2,5,11], amongst BN treatment completers, only 40-50 % have a full and lasting response [12][13][14]. The developers of the original CB theory argued that four additional factors might account for the persistence of dysfunctional cognitions (OSW) and eating-disordered behaviours in some patients that present obstacles for change: (a) interpersonal problems; (b) core low selfesteem; (c) clinical perfectionism; and (d) mood intolerance [12,13]. Accordingly, they reformulated the original CB theory into an enhanced version by encapsulating these factors that considered being ""trans-diagnostic"" as well [13]. According to the enhanced CB version (CB-E) [13], the difficulties in establishing and/or maintaining interpersonal relationships may directly precipitate episodes of binge eating, affect all of the other maintenance factors and/or amplify OSW [12,15]. The pervasive low self-esteem that often persists after recovery [16] is thought to lead to attempts to control shape and weight and similarly contribute to negative affect [13,17]. Despite adverse consequences, when clinical perfectionism or over-evaluation of striving for and achieving personally demanding standards [18] is present, it might encourage increased striving to achieve unrealistic high standards in the valued domain of shape and weight and foster dietary restraint [13,[18][19][20]. The final maintenance factor of mood intolerance (i.e. inability to appropriately cope with adverse affective states followed by dysfunctional impulsive behaviours) [13] is believed to directly affect and maintain binge eating [12,17,[21][22][23][24]. The CB-E approach is consistent with research that documented two subtypes of patients with BN and binge eating disorder (BED) based on purely dietary restraint (i.e. approximately 60-70 % of samples) versus dietarynegative affect (i.e. approximately 30-40 % of samples) dimensions [25,26]."	4	A considerable treatment literature has been published on bulimia nervosa (BN) [#CITATION_TAG,2], which is marked by a chronic and relapse-ridden course, can result into serious medical complications, and is associated with severe comorbid psychopathology and functional impairment [3,4]. The bulk of this literature has focused on the use of cognitive-behavioural therapy (CBT), which is widely considered as the treatment of choice for BN [1,2,5]. The theory [6] that underpins and guides CBT [7] is primarily concerned with the psychopathological processes that account for the persistence of the disorder. This theory assumes a dysfunctional system for evaluating self-worth [6], whereby self-worth is largely or even exclusively defined in terms of shape and weight and related control [8].	A
CCT749	"A considerable treatment literature has been published on bulimia nervosa (BN) [1,2], which is marked by a chronic and relapse-ridden course, can result into serious medical complications, and is associated with severe comorbid psychopathology and functional impairment [3,4]. The bulk of this literature has focused on the use of cognitive-behavioural therapy (CBT), which is widely considered as the treatment of choice for BN [1,2,5]. The theory [6] that underpins and guides CBT [7] is primarily concerned with the psychopathological processes that account for the persistence of the disorder. This theory assumes a dysfunctional system for evaluating self-worth [6], whereby self-worth is largely or even exclusively defined in terms of shape and weight and related control [8]. This over-evaluation of shape and weight (OSW) can then lead to dietary restraint, which often includes the adoption of rigid dietary rules about eating and food [6][7][8][9][10]. Due to the psychological and physiological effects of dietary restraint, when these inflexible dietary rules, which are extremely difficult to maintain, are broken, all attempts to control eating are abandoned and a binge occurs [6]. Although several randomised controlled trials have shown that CBT is more effective than a wide range of alternative treatments [1,2,5,11], amongst BN treatment completers, only 40-50 % have a full and lasting response [12][13][14]. The developers of the original CB theory argued that four additional factors might account for the persistence of dysfunctional cognitions (OSW) and eating-disordered behaviours in some patients that present obstacles for change: (a) interpersonal problems; (b) core low selfesteem; (c) clinical perfectionism; and (d) mood intolerance [12,13]. Accordingly, they reformulated the original CB theory into an enhanced version by encapsulating these factors that considered being ""trans-diagnostic"" as well [13]. According to the enhanced CB version (CB-E) [13], the difficulties in establishing and/or maintaining interpersonal relationships may directly precipitate episodes of binge eating, affect all of the other maintenance factors and/or amplify OSW [12,15]. The pervasive low self-esteem that often persists after recovery [16] is thought to lead to attempts to control shape and weight and similarly contribute to negative affect [13,17]. Despite adverse consequences, when clinical perfectionism or over-evaluation of striving for and achieving personally demanding standards [18] is present, it might encourage increased striving to achieve unrealistic high standards in the valued domain of shape and weight and foster dietary restraint [13,[18][19][20]. The final maintenance factor of mood intolerance (i.e. inability to appropriately cope with adverse affective states followed by dysfunctional impulsive behaviours) [13] is believed to directly affect and maintain binge eating [12,17,#CITATION_TAG[22][23][24]. The CB-E approach is consistent with research that documented two subtypes of patients with BN and binge eating disorder (BED) based on purely dietary restraint (i.e. approximately 60-70 % of samples) versus dietarynegative affect (i.e. approximately 30-40 % of samples) dimensions [25,26]."	2	According to the enhanced CB version (CB-E) [13], the difficulties in establishing and/or maintaining interpersonal relationships may directly precipitate episodes of binge eating, affect all of the other maintenance factors and/or amplify OSW [12,15]. The pervasive low self-esteem that often persists after recovery [16] is thought to lead to attempts to control shape and weight and similarly contribute to negative affect [13,17]. Despite adverse consequences, when clinical perfectionism or over-evaluation of striving for and achieving personally demanding standards [18] is present, it might encourage increased striving to achieve unrealistic high standards in the valued domain of shape and weight and foster dietary restraint [13,[18][19][20]. The final maintenance factor of mood intolerance (i.e. inability to appropriately cope with adverse affective states followed by dysfunctional impulsive behaviours) [13] is believed to directly affect and maintain binge eating [12,17,#CITATION_TAG[22][23][24]. The CB-E approach is consistent with research that documented two subtypes of patients with BN and binge eating disorder (BED) based on purely dietary restraint (i.e. approximately 60-70 % of samples) versus dietarynegative affect (i.e. approximately 30-40 % of samples) dimensions [25,26].	i
CCT750	"A considerable treatment literature has been published on bulimia nervosa (BN) [1,2], which is marked by a chronic and relapse-ridden course, can result into serious medical complications, and is associated with severe comorbid psychopathology and functional impairment [3,4]. The bulk of this literature has focused on the use of cognitive-behavioural therapy (CBT), which is widely considered as the treatment of choice for BN [1,2,5]. The theory [6] that underpins and guides CBT [7] is primarily concerned with the psychopathological processes that account for the persistence of the disorder. This theory assumes a dysfunctional system for evaluating self-worth [6], whereby self-worth is largely or even exclusively defined in terms of shape and weight and related control [8]. This over-evaluation of shape and weight (OSW) can then lead to dietary restraint, which often includes the adoption of rigid dietary rules about eating and food [6][7][8][9][10]. Due to the psychological and physiological effects of dietary restraint, when these inflexible dietary rules, which are extremely difficult to maintain, are broken, all attempts to control eating are abandoned and a binge occurs [6]. Although several randomised controlled trials have shown that CBT is more effective than a wide range of alternative treatments [1,2,5,#CITATION_TAG], amongst BN treatment completers, only 40-50 % have a full and lasting response [12][13][14]. The developers of the original CB theory argued that four additional factors might account for the persistence of dysfunctional cognitions (OSW) and eating-disordered behaviours in some patients that present obstacles for change: (a) interpersonal problems; (b) core low selfesteem; (c) clinical perfectionism; and (d) mood intolerance [12,13]. Accordingly, they reformulated the original CB theory into an enhanced version by encapsulating these factors that considered being ""trans-diagnostic"" as well [13]. According to the enhanced CB version (CB-E) [13], the difficulties in establishing and/or maintaining interpersonal relationships may directly precipitate episodes of binge eating, affect all of the other maintenance factors and/or amplify OSW [12,15]. The pervasive low self-esteem that often persists after recovery [16] is thought to lead to attempts to control shape and weight and similarly contribute to negative affect [13,17]. Despite adverse consequences, when clinical perfectionism or over-evaluation of striving for and achieving personally demanding standards [18] is present, it might encourage increased striving to achieve unrealistic high standards in the valued domain of shape and weight and foster dietary restraint [13,[18][19][20]. The final maintenance factor of mood intolerance (i.e. inability to appropriately cope with adverse affective states followed by dysfunctional impulsive behaviours) [13] is believed to directly affect and maintain binge eating [12,17,[21][22][23][24]. The CB-E approach is consistent with research that documented two subtypes of patients with BN and binge eating disorder (BED) based on purely dietary restraint (i.e. approximately 60-70 % of samples) versus dietarynegative affect (i.e. approximately 30-40 % of samples) dimensions [25,26]."	1	"This theory assumes a dysfunctional system for evaluating self-worth [6], whereby self-worth is largely or even exclusively defined in terms of shape and weight and related control [8]. This over-evaluation of shape and weight (OSW) can then lead to dietary restraint, which often includes the adoption of rigid dietary rules about eating and food [6][7][8][9][10]. Due to the psychological and physiological effects of dietary restraint, when these inflexible dietary rules, which are extremely difficult to maintain, are broken, all attempts to control eating are abandoned and a binge occurs [6]. Although several randomised controlled trials have shown that CBT is more effective than a wide range of alternative treatments [1,2,5,#CITATION_TAG], amongst BN treatment completers, only 40-50 % have a full and lasting response [12][13][14]. The developers of the original CB theory argued that four additional factors might account for the persistence of dysfunctional cognitions (OSW) and eating-disordered behaviours in some patients that present obstacles for change: (a) interpersonal problems; (b) core low selfesteem; (c) clinical perfectionism; and (d) mood intolerance [12,13]. Accordingly, they reformulated the original CB theory into an enhanced version by encapsulating these factors that considered being ""trans-diagnostic"" as well [13]. According to the enhanced CB version (CB-E) [13], the difficulties in establishing and/or maintaining interpersonal relationships may directly precipitate episodes of binge eating, affect all of the other maintenance factors and/or amplify OSW [12,15]."	g
CCT751	"A considerable treatment literature has been published on bulimia nervosa (BN) [1,2], which is marked by a chronic and relapse-ridden course, can result into serious medical complications, and is associated with severe comorbid psychopathology and functional impairment [#CITATION_TAG,4]. The bulk of this literature has focused on the use of cognitive-behavioural therapy (CBT), which is widely considered as the treatment of choice for BN [1,2,5]. The theory [6] that underpins and guides CBT [7] is primarily concerned with the psychopathological processes that account for the persistence of the disorder. This theory assumes a dysfunctional system for evaluating self-worth [6], whereby self-worth is largely or even exclusively defined in terms of shape and weight and related control [8]. This over-evaluation of shape and weight (OSW) can then lead to dietary restraint, which often includes the adoption of rigid dietary rules about eating and food [6][7][8][9][10]. Due to the psychological and physiological effects of dietary restraint, when these inflexible dietary rules, which are extremely difficult to maintain, are broken, all attempts to control eating are abandoned and a binge occurs [6]. Although several randomised controlled trials have shown that CBT is more effective than a wide range of alternative treatments [1,2,5,11], amongst BN treatment completers, only 40-50 % have a full and lasting response [12][13][14]. The developers of the original CB theory argued that four additional factors might account for the persistence of dysfunctional cognitions (OSW) and eating-disordered behaviours in some patients that present obstacles for change: (a) interpersonal problems; (b) core low selfesteem; (c) clinical perfectionism; and (d) mood intolerance [12,13]. Accordingly, they reformulated the original CB theory into an enhanced version by encapsulating these factors that considered being ""trans-diagnostic"" as well [13]. According to the enhanced CB version (CB-E) [13], the difficulties in establishing and/or maintaining interpersonal relationships may directly precipitate episodes of binge eating, affect all of the other maintenance factors and/or amplify OSW [12,15]. The pervasive low self-esteem that often persists after recovery [16] is thought to lead to attempts to control shape and weight and similarly contribute to negative affect [13,17]. Despite adverse consequences, when clinical perfectionism or over-evaluation of striving for and achieving personally demanding standards [18] is present, it might encourage increased striving to achieve unrealistic high standards in the valued domain of shape and weight and foster dietary restraint [13,[18][19][20]. The final maintenance factor of mood intolerance (i.e. inability to appropriately cope with adverse affective states followed by dysfunctional impulsive behaviours) [13] is believed to directly affect and maintain binge eating [12,17,[21][22][23][24]. The CB-E approach is consistent with research that documented two subtypes of patients with BN and binge eating disorder (BED) based on purely dietary restraint (i.e. approximately 60-70 % of samples) versus dietarynegative affect (i.e. approximately 30-40 % of samples) dimensions [25,26]."	4	A considerable treatment literature has been published on bulimia nervosa (BN) [1,2], which is marked by a chronic and relapse-ridden course, can result into serious medical complications, and is associated with severe comorbid psychopathology and functional impairment [#CITATION_TAG,4]. The bulk of this literature has focused on the use of cognitive-behavioural therapy (CBT), which is widely considered as the treatment of choice for BN [1,2,5]. The theory [6] that underpins and guides CBT [7] is primarily concerned with the psychopathological processes that account for the persistence of the disorder. This theory assumes a dysfunctional system for evaluating self-worth [6], whereby self-worth is largely or even exclusively defined in terms of shape and weight and related control [8].	A
CCT752	After testing the proposed measurement and structural CB (i.e. enhanced and original) models in the entire diagnostically mixed sample, participants (N = 679) were grouped according to DSM-5 diagnosis, and multi-group SEM analyses were performed to determine whether the factor loadings and structural paths values differed or were similar across diagnostic groups (i.e. to investigate measurement and structural invariance). Measurement and structural invariance is supported if the strength of the factor loadings and the path estimates is equivalent across groups, respectively. To test for invariance, constrained (i.e. measurement or structural parameters were fixed to be equal for the groups) and unconstrained (i.e. parameters were allowed to vary; nested) models were compared using the ‚àÜœá 2 [39]; a non-significant ‚àÜœá 2 indicates that model parameters are invariant across DSM-5 diagnostic groups. Finally, as testing the significance of the mediation or indirect effects using bootstrap procedure has been recommended #CITATION_TAG, Mplus [49] was specified to (a) create 5,000 bootstrap samples from the data set by random sampling with replacement and (b) generate indirect effects and bias-corrected confidence intervals (95 % CIs) around the indirect effects when analysing the (final) structural models (Fig. 2). If the 95 % CI does not include zero, the indirect effect is statistically significant at .05 [50]. The type of mediation (partial or full) for each DSM-5 diagnostic group was determined by whether or not there was a significant direct path in (final) structural models (Fig. 2). If there was not a significant direct path, then full mediation occurred [39,49,50]. 1, the proportion of bulimictype EDNOS cases identified based on DSM-IV criteria dropped from 59.5 to 29.9 % (related samples Wilcoxon signed rank test, p < 0.001) when DSM-5 criteria were used. Among the initial 404 DSM-IV bulimic-type EDNOS cases, six were reclassified as BN, and 195 as BED. The socio-demographic and clinical characteristics and differences between DSM-5 bulimic-type ED groups are summarized in Table 2.	0	After testing the proposed measurement and structural CB (i.e. enhanced and original) models in the entire diagnostically mixed sample, participants (N = 679) were grouped according to DSM-5 diagnosis, and multi-group SEM analyses were performed to determine whether the factor loadings and structural paths values differed or were similar across diagnostic groups (i.e. to investigate measurement and structural invariance). Measurement and structural invariance is supported if the strength of the factor loadings and the path estimates is equivalent across groups, respectively. To test for invariance, constrained (i.e. measurement or structural parameters were fixed to be equal for the groups) and unconstrained (i.e. parameters were allowed to vary; nested) models were compared using the ‚àÜœá 2 [39]; a non-significant ‚àÜœá 2 indicates that model parameters are invariant across DSM-5 diagnostic groups. Finally, as testing the significance of the mediation or indirect effects using bootstrap procedure has been recommended #CITATION_TAG, Mplus [49] was specified to (a) create 5,000 bootstrap samples from the data set by random sampling with replacement and (b) generate indirect effects and bias-corrected confidence intervals (95 % CIs) around the indirect effects when analysing the (final) structural models (Fig. 2). If the 95 % CI does not include zero, the indirect effect is statistically significant at .05 [50]. The type of mediation (partial or full) for each DSM-5 diagnostic group was determined by whether or not there was a significant direct path in (final) structural models (Fig. 2). If there was not a significant direct path, then full mediation occurred [39,49,50].	a
CCT753	"A considerable treatment literature has been published on bulimia nervosa (BN) [1,2], which is marked by a chronic and relapse-ridden course, can result into serious medical complications, and is associated with severe comorbid psychopathology and functional impairment [3,4]. The bulk of this literature has focused on the use of cognitive-behavioural therapy (CBT), which is widely considered as the treatment of choice for BN [1,2,#CITATION_TAG]. The theory [6] that underpins and guides CBT [7] is primarily concerned with the psychopathological processes that account for the persistence of the disorder. This theory assumes a dysfunctional system for evaluating self-worth [6], whereby self-worth is largely or even exclusively defined in terms of shape and weight and related control [8]. This over-evaluation of shape and weight (OSW) can then lead to dietary restraint, which often includes the adoption of rigid dietary rules about eating and food [6][7][8][9][10]. Due to the psychological and physiological effects of dietary restraint, when these inflexible dietary rules, which are extremely difficult to maintain, are broken, all attempts to control eating are abandoned and a binge occurs [6]. Although several randomised controlled trials have shown that CBT is more effective than a wide range of alternative treatments [1,2,5,11], amongst BN treatment completers, only 40-50 % have a full and lasting response [12][13][14]. The developers of the original CB theory argued that four additional factors might account for the persistence of dysfunctional cognitions (OSW) and eating-disordered behaviours in some patients that present obstacles for change: (a) interpersonal problems; (b) core low selfesteem; (c) clinical perfectionism; and (d) mood intolerance [12,13]. Accordingly, they reformulated the original CB theory into an enhanced version by encapsulating these factors that considered being ""trans-diagnostic"" as well [13]. According to the enhanced CB version (CB-E) [13], the difficulties in establishing and/or maintaining interpersonal relationships may directly precipitate episodes of binge eating, affect all of the other maintenance factors and/or amplify OSW [12,15]. The pervasive low self-esteem that often persists after recovery [16] is thought to lead to attempts to control shape and weight and similarly contribute to negative affect [13,17]. Despite adverse consequences, when clinical perfectionism or over-evaluation of striving for and achieving personally demanding standards [18] is present, it might encourage increased striving to achieve unrealistic high standards in the valued domain of shape and weight and foster dietary restraint [13,[18][19][20]. The final maintenance factor of mood intolerance (i.e. inability to appropriately cope with adverse affective states followed by dysfunctional impulsive behaviours) [13] is believed to directly affect and maintain binge eating [12,17,[21][22][23][24]. The CB-E approach is consistent with research that documented two subtypes of patients with BN and binge eating disorder (BED) based on purely dietary restraint (i.e. approximately 60-70 % of samples) versus dietarynegative affect (i.e. approximately 30-40 % of samples) dimensions [25,26]."	0	A considerable treatment literature has been published on bulimia nervosa (BN) [1,2], which is marked by a chronic and relapse-ridden course, can result into serious medical complications, and is associated with severe comorbid psychopathology and functional impairment [3,4]. The bulk of this literature has focused on the use of cognitive-behavioural therapy (CBT), which is widely considered as the treatment of choice for BN [1,2,#CITATION_TAG]. The theory [6] that underpins and guides CBT [7] is primarily concerned with the psychopathological processes that account for the persistence of the disorder. This theory assumes a dysfunctional system for evaluating self-worth [6], whereby self-worth is largely or even exclusively defined in terms of shape and weight and related control [8]. This over-evaluation of shape and weight (OSW) can then lead to dietary restraint, which often includes the adoption of rigid dietary rules about eating and food [6][7][8][9][10].	h
CCT754	"A considerable treatment literature has been published on bulimia nervosa (BN) [1,2], which is marked by a chronic and relapse-ridden course, can result into serious medical complications, and is associated with severe comorbid psychopathology and functional impairment [3,4]. The bulk of this literature has focused on the use of cognitive-behavioural therapy (CBT), which is widely considered as the treatment of choice for BN [1,2,5]. The theory [6] that underpins and guides CBT [7] is primarily concerned with the psychopathological processes that account for the persistence of the disorder. This theory assumes a dysfunctional system for evaluating self-worth [6], whereby self-worth is largely or even exclusively defined in terms of shape and weight and related control #CITATION_TAG. This over-evaluation of shape and weight (OSW) can then lead to dietary restraint, which often includes the adoption of rigid dietary rules about eating and food [6][7][8][9][10]. Due to the psychological and physiological effects of dietary restraint, when these inflexible dietary rules, which are extremely difficult to maintain, are broken, all attempts to control eating are abandoned and a binge occurs [6]. Although several randomised controlled trials have shown that CBT is more effective than a wide range of alternative treatments [1,2,5,11], amongst BN treatment completers, only 40-50 % have a full and lasting response [12][13][14]. The developers of the original CB theory argued that four additional factors might account for the persistence of dysfunctional cognitions (OSW) and eating-disordered behaviours in some patients that present obstacles for change: (a) interpersonal problems; (b) core low selfesteem; (c) clinical perfectionism; and (d) mood intolerance [12,13]. Accordingly, they reformulated the original CB theory into an enhanced version by encapsulating these factors that considered being ""trans-diagnostic"" as well [13]. According to the enhanced CB version (CB-E) [13], the difficulties in establishing and/or maintaining interpersonal relationships may directly precipitate episodes of binge eating, affect all of the other maintenance factors and/or amplify OSW [12,15]. The pervasive low self-esteem that often persists after recovery [16] is thought to lead to attempts to control shape and weight and similarly contribute to negative affect [13,17]. Despite adverse consequences, when clinical perfectionism or over-evaluation of striving for and achieving personally demanding standards [18] is present, it might encourage increased striving to achieve unrealistic high standards in the valued domain of shape and weight and foster dietary restraint [13,[18][19][20]. The final maintenance factor of mood intolerance (i.e. inability to appropriately cope with adverse affective states followed by dysfunctional impulsive behaviours) [13] is believed to directly affect and maintain binge eating [12,17,[21][22][23][24]. The CB-E approach is consistent with research that documented two subtypes of patients with BN and binge eating disorder (BED) based on purely dietary restraint (i.e. approximately 60-70 % of samples) versus dietarynegative affect (i.e. approximately 30-40 % of samples) dimensions [25,26]."	1	A considerable treatment literature has been published on bulimia nervosa (BN) [1,2], which is marked by a chronic and relapse-ridden course, can result into serious medical complications, and is associated with severe comorbid psychopathology and functional impairment [3,4]. The bulk of this literature has focused on the use of cognitive-behavioural therapy (CBT), which is widely considered as the treatment of choice for BN [1,2,5]. The theory [6] that underpins and guides CBT [7] is primarily concerned with the psychopathological processes that account for the persistence of the disorder. This theory assumes a dysfunctional system for evaluating self-worth [6], whereby self-worth is largely or even exclusively defined in terms of shape and weight and related control #CITATION_TAG. This over-evaluation of shape and weight (OSW) can then lead to dietary restraint, which often includes the adoption of rigid dietary rules about eating and food [6][7][8][9][10]. Due to the psychological and physiological effects of dietary restraint, when these inflexible dietary rules, which are extremely difficult to maintain, are broken, all attempts to control eating are abandoned and a binge occurs [6]. Although several randomised controlled trials have shown that CBT is more effective than a wide range of alternative treatments [1,2,5,11], amongst BN treatment completers, only 40-50 % have a full and lasting response [12][13][14].	s
CCT755	"After re-categorizing all DSM-IV cases using DSM-5 diagnostic criteria, differences in demographic and clinical variables between diagnostic groups were assessed by means of ANOVA or œá 2 test, as appropriate, followed by post hoc pairwise comparisons with Bonferroni correction if needed #CITATION_TAG. The appropriate measures of effect size for continuous (partial Œ∑ 2 ) or categorical variables (Cramer"" s œï) were calculated. Cut-off conventions for partial Œ∑ 2 are as follows: small (.01-.09), medium (.10-.24), and large (‚â•.25) [46]. Cut-off conventions for Cramer"" s œï (with df = 2) are as follows: small (.07-.20), medium (.21-.34), and large (‚â•.35) [46]. There were no missing data. Latent variable structural equation modelling (SEM) was used to examine both hypothesized CB models, depicted in Fig. 1. It involves estimation of (a) a measurement model and (b) a structural m o d e l w h i l e a c c o u n t i n g f o r m e a s u r e m e n t error [39]. The measurement model tests the proposed measurement of study constructs by estimating factor loadings between observed/measured variables and underlying latent variables (Online Resource 3), using confirmatory factor analysis. The structural model retains the components of the measurement model and tests the specified structural relationships between latent variables (i.e. the directional paths; Fig. 1); BMI and depression severity (i.e. BDI score) were covariates in each structural model and specified to predict each of the latent variables [39] in an attempt to reduce their effects on the relationships between the latent variables under investigation [17,48]. 5 EM analyses were performed in Mplus version 6.12 [49] with a maximum likelihood approach (as pre-analysis of the data did not reveal any evidence for univariate and multivariate non-normality). Criteria for good measurement and structural model fit were as follows: Comparative Fit Index and Tucker-Lewis Index values ‚â•.95, standardized root-mean-square residual values ‚â§.08, and root-mean-square error of approximation values ‚â§.06 [39,49]. The Chi-square statistic (œá 2 ) is also reported. To obtain the most parsimonious and accurate representation of the data, we planned to trim non-significant structural paths and to add paths not originally specified (trimmed/revised model) but that impacted the fit of the model to the data based on the modification indices values (MIs > 5.0) provided by Mplus [39,49]; the trimmed/ revised models were re-examined for good fit, and the initial (hypothesized) and trimmed/revised (nested) models were compared using the Chi-square difference test (‚àÜœá 2 ) [39]. Because the original and CB-E structural models were not nested models (i.e. hierarchically related to one other in the sense that their parameter sets are subsets of one another), it was not possible to use the ‚àÜœá 2 to statistically compare model fit, and therefore, we compared the predictive utility of each CB model by examining the percentage of variance accounted for in dietary restraint and binge eating by each model, as recommended [24,39]."	0	"After re-categorizing all DSM-IV cases using DSM-5 diagnostic criteria, differences in demographic and clinical variables between diagnostic groups were assessed by means of ANOVA or œá 2 test, as appropriate, followed by post hoc pairwise comparisons with Bonferroni correction if needed #CITATION_TAG. The appropriate measures of effect size for continuous (partial Œ∑ 2 ) or categorical variables (Cramer"" s œï) were calculated. Cut-off conventions for partial Œ∑ 2 are as follows: small (. 01-."	A
CCT756	"The current study aimed at extending research in this area by testing and comparing the original and CB-E models in a large clinical sample seeking treatment for bulimic-type EDs, which include BN and its variants [bulimic-type ED not otherwise specified (EDNOS), i.e. EDs ""clinically significant but not meeting full DSM-IV diagnostic criteria for BN, or needing additional study, such as BED] [29]. It was expected that even though both theoretical models (Fig. 1) would provide a good fit to the observed data, the CB-E maintenance model would account for a greater proportion of the variance in dietary restraint and binge eating (i.e. the hallmark behaviour of all bulimic-type EDs) [13,29]. Evaluating whether the strength of the conceptual relationships of both CB maintenance models is similar or different across diagnostic groups and formally testing the significance of the mediation or indirect effects embedded within the CB models (Fig. 1) in each diagnostic group were additional aims of the study. It is worth of note that prior the completion of the study, the APA Task Force made several changes to ED diagnoses in the DSM-5 [30] in order to reduce the preponderance of the DSM-IV [31] Anorexic and bulimictype EDNOS category [29,32] that formed the most common ED among those seeking treatment [33]. Regarding bulimic-type EDNOS, in addition to making BED a formal diagnosis, DSM-5 [30] revised the behavioural criteria (i.e. the threshold for frequency and duration), eliminated the diagnostic subtypes for BN, and changed the EDNOS designation to Other Specified Feeding or ED; Online Resource 1 summarizes the diagnostic criteria for bulimic-type EDs from the fourth to the fifth editions. As a consequence, all cases initially diagnosed as BN and bulimic-type EDNOS using the DSM-IV [31] criteria were re-categorized using the new DSM-5 criteria [30]. All analyses conducted to evaluate our hypothesis (Fig. 1) and potential differences across groups were based on DSM-5 diagnosis of BN, BED, and bulimic-type EDNOS 1 ; for simplicity, this last term was used in the current manuscript to refer to bulimic-type diagnoses that fell into the Other Specified Feeding or ED group. Re-categorizing diagnoses also allowed us to evaluate the degree to which the use of DSM-5 criteria [30] decreased the proportion of DSM-IV [31] bulimic-type EDNOS cases. This is also a novel contribution to the current literature given that prior research using the same [34] or a similar [3,35] procedure focused on community samples rather than on clinical treatment seeking samples. 1 This is also a novel contribution to the current literature given that prior research using the same #CITATION_TAG or a similar [3,35] procedure focused on community samples rather than on clinical treatment seeking samples. 1 It is should be noted that, although both CB models posit that binge eating may encourage in some individuals compensatory behaviours aimed at counteracting the effects of binge eating on weight [6,13] for details, in the current manuscript we focused on binge eating and did not incorporate compensatory behaviours neither in the form of purging nor in the form of non-purging for three main reasons: (1) the scheme distinguishing purging and non-purging BN subtypes has been eliminated from DSM-5 (Online Resource 1); (2) the DSM-5 BN and BED diagnoses are distinguished by the presence versus absence of recurrent inappropriate compensatory behaviours (Online Resource 1); and (3) the necessary prerequisite of the advanced statistical procedure (see ""Statistical Analyses"") used for evaluating if the strength of the conceptual relationships of both CB maintenance models (Fig. 1) is similar or different across DSM-5 BN, BED, and bulimic-type EDNOS (that includes also sub-threshold BED cases) is that the model under investigation should contain the same number of latent variables, each of which includes the same number of measured/observed variables for all groups of interest [39]."	0	"All analyses conducted to evaluate our hypothesis (Fig. 1) and potential differences across groups were based on DSM-5 diagnosis of BN, BED, and bulimic-type EDNOS 1 ; for simplicity, this last term was used in the current manuscript to refer to bulimic-type diagnoses that fell into the Other Specified Feeding or ED group. Re-categorizing diagnoses also allowed us to evaluate the degree to which the use of DSM-5 criteria [30] decreased the proportion of DSM-IV [31] bulimic-type EDNOS cases. This is also a novel contribution to the current literature given that prior research using the same [34] or a similar [3,35] procedure focused on community samples rather than on clinical treatment seeking samples. 1 This is also a novel contribution to the current literature given that prior research using the same #CITATION_TAG or a similar [3,35] procedure focused on community samples rather than on clinical treatment seeking samples. 1 It is should be noted that, although both CB models posit that binge eating may encourage in some individuals compensatory behaviours aimed at counteracting the effects of binge eating on weight [6,13] for details, in the current manuscript we focused on binge eating and did not incorporate compensatory behaviours neither in the form of purging nor in the form of non-purging for three main reasons: (1) the scheme distinguishing purging and non-purging BN subtypes has been eliminated from DSM-5 (Online Resource 1); (2) the DSM-5 BN and BED diagnoses are distinguished by the presence versus absence of recurrent inappropriate compensatory behaviours (Online Resource 1); and (3) the necessary prerequisite of the advanced statistical procedure (see ""Statistical Analyses"") used for evaluating if the strength of the conceptual relationships of both CB maintenance models (Fig. 1) is similar or different across DSM-5 BN, BED, and bulimic-type EDNOS (that includes also sub-threshold BED cases) is that the model under investigation should contain the same number of latent variables, each of which includes the same number of measured/observed variables for all groups of interest [39]."	 
CCT757	Participants were drawn from a sample of 893 individuals consecutively referred to, and assessed for treatment of an ED, at five medium-large sized specialized care centres for EDs in Northern, Central, and Southern Italy between February 2011 and June 2013. Though a portion of this data set has already been used to evaluate the role of attachment in DSM-IV EDs [36], there is no overlap between those results and those presented here. In the current study, participants, who met DSM-IV diagnostic criteria for BN (n = 275) or bulimic-type EDNOS (n = 404), were included. Exclusion criteria comprised concurrent treatment for eating and weight-related disturbances, severe psychiatric conditions (psychosis) and intellectual disabilities, and insufficient knowledge of Italian. The flowchart of study participants is available in Online Resource 2. DSM-IV [31] ED and lifetime Axis I psychiatric disorder diagnoses were based on the Structured Clinical Interview for DSM-IV Axis I Disorders (SCID-I/P) #CITATION_TAG. The ED diagnoses were confirmed by findings from the Eating Disorder Examination-Interview-12.0D (EDE) [38], administered to assess dietary restraint and frequency of binge eating episodes as well (see measures section). At each participating centre, clinicians with experience and training in assessing and treating EDs carried out the diagnostic procedures. Approximately 22 % of the SCID-I/Ps and 20 % of the EDEs conducted were audio-recorded and rated by a blinded clinician to establish inter-rater reliability (Œ∫), which was as follows: between .95 and 1.0 for lifetime and current (i.e. EDs) Axis I disorders; and 1.0 for diagnoses of EDs assessed by the means of EDE. All cases initially diagnosed as BN and bulimic-type EDNOS using the DSM-IV [31] criteria were re-categorized with the new DSM-5 criteria [30] on the basis of information from the interview records [34]. 2	5	In the current study, participants, who met DSM-IV diagnostic criteria for BN (n = 275) or bulimic-type EDNOS (n = 404), were included. Exclusion criteria comprised concurrent treatment for eating and weight-related disturbances, severe psychiatric conditions (psychosis) and intellectual disabilities, and insufficient knowledge of Italian. The flowchart of study participants is available in Online Resource 2. DSM-IV [31] ED and lifetime Axis I psychiatric disorder diagnoses were based on the Structured Clinical Interview for DSM-IV Axis I Disorders (SCID-I/P) #CITATION_TAG. The ED diagnoses were confirmed by findings from the Eating Disorder Examination-Interview-12.0D (EDE) [38], administered to assess dietary restraint and frequency of binge eating episodes as well (see measures section). At each participating centre, clinicians with experience and training in assessing and treating EDs carried out the diagnostic procedures. Approximately 22 % of the SCID-I/Ps and 20 % of the EDEs conducted were audio-recorded and rated by a blinded clinician to establish inter-rater reliability (Œ∫), which was as follows: between .95 and 1.0 for lifetime and current (i.e. EDs) Axis I disorders; and 1.0 for diagnoses of EDs assessed by the means of EDE.	V
CCT758	"While clinical perfectionism was the only maintaining variable directly linked to dietary restraint, interpersonal problems and mood intolerance were directly linked to binge eating, emphasizing the direct key role that both factors may have in its occurrence [11,21,22,44,48,52,53]. The positive and significant relationships between mood intolerance and binge eating are in accordance with CB-E model, which postulate that binge eating has a regulatory function and occur in an attempt to reduce the negative affective states [13]. However, in the current study, there was no direct relationship between dietary restraint and binge eating. This finding, as well as the evidence that interventions for binge eating that do not focus on reducing OSW and/or dietary restraint (i.e. interpersonal therapy, dialectical-behaviour therapy) decrease binge eating relative to assessment-only control conditions [1,2,11,54,#CITATION_TAG], seems incompatible with the theoretical assertion of both CB models, i.e. OSW affects binging indirectly through increasing the likelihood of dietary restraint [6,13]. Although there is evidence that initial dietary restraint levels predict future onset of binge eating among asymptomatic individuals [24,56,57], as in this study, prior research using clinical interviews or ecological momentary assessment failed to support the dietary restraint-binge eating relationship among bulimic-type ED patients [9,[58][59][60]. Although, the impact of dietary restraint on binge eating deserves further elucidation, the direct paths from interpersonal problems and mood intolerance to binge eating lend some credence to scholars"" suggestion that factors other than restraint may play a more critical role in the maintenance of binge eating among clinical samples [21,47,48,54,55], and highlight the importance of their inclusion in the CB-E theory, assessment, and target [12,13,21,23,28]. Moreover, the present study indicated that the dietary restraint-binge eating relationship is fully mediated and explained by mood intolerance. Although this indirect effect was unexpected, it appears consistent with findings from studies indicating that dietary manipulations that transiently deplete tryptophan levels (and consequently 5-HT synthesis in the brain) contribute to dysphoric mood in bulimic-type ED subjects [61,62], increasing the likelihood that an individual might binge eat to relieve dysphoria [21,22,48,60,61]. Furthermore, based on the results of neurobiological, molecular-genetic, and brain-imaging studies, Steiger and colleagues [63] postulated that factors affecting 5-HT functional activity may indirectly influence susceptibility to binge eating by heightening affective instability. Abnormal 5-HT status in subjects with bulimictype EDs may represents the cumulative effects of chronic dietary restraint [64][65][66], an inherited disposition, the consequence of exposure to intense developmental stressors, and traumatic experiences, and/or their combination [63]. Thus, a better understanding of the underlying serotonergic susceptibilities may explain heterogeneous clinical manifestations within the bulimic-type ED population and help clinicians to select the most appropriate treatment [63]. For instance, people with bulimic-type EDs whose variations in 5-HT status are mainly secondary consequences of dietary attempts may have relatively focal treatment needs (i.e. eating-symptom-focused therapies, such as the original version of CBT). However, different clinical pictures need to be considered. bulimic-type ED patients may benefit from more elaborate forms of interventions, such as the CBT-E [7,12,13,27], in case of more severe 5-HT abnormalities [63], and particularly if they are at least partly linked to affective instability mediated by 5-HT functioning or severe developmental disruptions that can affect both 5-HT functioning and affective instability [63]. Apart from the biological perceptive, cognitive factors may also play a central role in understanding the nature of the association between dietary restraint and binge eating. For instance, according to the abstinence violation effect (AVE) model, the inevitable violation of strict and inflexible dietary rules is thought to activate all-or-none thinking (e.g. perfect restraint vs. complete failure) [67]. This ""dichotomous"" thinking style, which is common among people who binge eat and addressed within CBT and CBT-E [7,13], is believed to heighten negative mood and disinhibit attempts to control what one eats [47,67]. Support for the AVE has been observed among binge-eaters [68,69]. Furthermore, longitudinal investigations amongst asymptomatic individuals revealed that the emotional distress caused by repeated perceived dietary failures increases mood deflection, which in turn results in increase binge eating [48,57]."	1	"While clinical perfectionism was the only maintaining variable directly linked to dietary restraint, interpersonal problems and mood intolerance were directly linked to binge eating, emphasizing the direct key role that both factors may have in its occurrence [11,21,22,44,48,52,53]. The positive and significant relationships between mood intolerance and binge eating are in accordance with CB-E model, which postulate that binge eating has a regulatory function and occur in an attempt to reduce the negative affective states [13]. However, in the current study, there was no direct relationship between dietary restraint and binge eating. This finding, as well as the evidence that interventions for binge eating that do not focus on reducing OSW and/or dietary restraint (i.e. interpersonal therapy, dialectical-behaviour therapy) decrease binge eating relative to assessment-only control conditions [1,2,11,54,#CITATION_TAG], seems incompatible with the theoretical assertion of both CB models, i.e. OSW affects binging indirectly through increasing the likelihood of dietary restraint [6,13]. Although there is evidence that initial dietary restraint levels predict future onset of binge eating among asymptomatic individuals [24,56,57], as in this study, prior research using clinical interviews or ecological momentary assessment failed to support the dietary restraint-binge eating relationship among bulimic-type ED patients [9,[58][59][60]. Although, the impact of dietary restraint on binge eating deserves further elucidation, the direct paths from interpersonal problems and mood intolerance to binge eating lend some credence to scholars"" suggestion that factors other than restraint may play a more critical role in the maintenance of binge eating among clinical samples [21,47,48,54,55], and highlight the importance of their inclusion in the CB-E theory, assessment, and target [12,13,21,23,28]. Moreover, the present study indicated that the dietary restraint-binge eating relationship is fully mediated and explained by mood intolerance."	s
CCT759	57 This difficulty is also stressed by Duffie (2007). 58 The role of correlations between underlying risks and counterparty credit risks in hedging arrangements is discussed in #CITATION_TAG (1995). The problem appeared conspicuously in the Thai crisis of 1997 when international banks, which had tried to eliminate exchange rate risk by denominating loans in dollars rather than baht, found out that, after the devaluation of the baht, Thai entrepreneurs, who were earning money in baht, had difficulties servicing their dollar-denominated debts to Thai banks, which in turn then had difficulties servicing their debts to international banks.	5	57 This difficulty is also stressed by Duffie (2007). 58 The role of correlations between underlying risks and counterparty credit risks in hedging arrangements is discussed in #CITATION_TAG (1995). The problem appeared conspicuously in the Thai crisis of 1997 when international banks, which had tried to eliminate exchange rate risk by denominating loans in dollars rather than baht, found out that, after the devaluation of the baht, Thai entrepreneurs, who were earning money in baht, had difficulties servicing their dollar-denominated debts to Thai banks, which in turn then had difficulties servicing their debts to international banks.	8
CCT760	"When the market prices of asset-backed securities began to drop in the second half of 2007 and fair value accounting required this drop to be acknowledged in the books, the institutions that held such securities had to react almost immediately. Some of them managed to obtain new equity. Others had to begin to deleverage, i.e., to reduce their lending or to sell assets in order to adapt the scale of their operations to their reduced equity. Given the need to satisfy regulatory requirements, they did not have much choice on whether they thought that market values of assets provided the right signals ""for making long-term value-maximizing decisions"". Because the equity capital that they held in excess of regulatory requirements did not suffice to 91 In public discussion, the regime change tends to be associated with the recent replacement of ""Basel I"" by ""Basel II"". In fact, the change of paradigm came already with the 1996 Amendment to ""Basel I"". 92 On this point, see the contribution of Zuberb√ºhler to #CITATION_TAG and Staub (1996). 93 For expressions of this view, see Wuffli (1995) and Gumerlock""s contribution to Hellwig and Staub (1996)."	0	"Given the need to satisfy regulatory requirements, they did not have much choice on whether they thought that market values of assets provided the right signals ""for making long-term value-maximizing decisions"". Because the equity capital that they held in excess of regulatory requirements did not suffice to 91 In public discussion, the regime change tends to be associated with the recent replacement of ""Basel I"" by ""Basel II"". In fact, the change of paradigm came already with the 1996 Amendment to ""Basel I"". 92 On this point, see the contribution of Zuberb√ºhler to #CITATION_TAG and Staub (1996). 93 For expressions of this view, see Wuffli (1995) and Gumerlock""s contribution to Hellwig and Staub (1996)."	t
CCT761	"111 On this development, see Baltensperger and Dermine (1987), Englund (1990), M√©litz (1990), Vives (1990), OECD (1992). 112 For an example of regulatory thinking at the time, see Carosio (1990). 113 However, even here, one may question whether, e.g., real-estate loans in different countries should be treated as being equally risky; see #CITATION_TAG (1990). 114 For criticisms of the lack of theoretical or empirical foundations, see King (1990) and Schaefer (1990). Both point out that neither the regulatory community nor the academic community have any framework for assessing the bankers"" claim that equity capital is very costly: Are these private costs to bank managers that have to go to the market to get additional equity capital? Or are these social costs because additional equity for a bank means less equity for other purposes? According to the Modigliani-Miller Theorem of corporate finance, it is not clear that there would be any social costs. Hellwig (1996) compares ""the speed with which the regulatory community moved from the April 1993 and April 1995 proposals to the actual Amendment to the Capital Accord to Incorporate Market Risks of January 1996 to the time and expenses it takes for a private company to get a new drug approved for sale"" and notes that ""both the 1988 Accord and the 1996 Amendment to the 1988 Accord were enacted with hardly any evidence about the economic effects of capital requirements for banks."	0	"111 On this development, see Baltensperger and Dermine (1987), Englund (1990), M√©litz (1990), Vives (1990), OECD (1992). 112 For an example of regulatory thinking at the time, see Carosio (1990). 113 However, even here, one may question whether, e.g., real-estate loans in different countries should be treated as being equally risky; see #CITATION_TAG (1990). 114 For criticisms of the lack of theoretical or empirical foundations, see King (1990) and Schaefer (1990). Both point out that neither the regulatory community nor the academic community have any framework for assessing the bankers"" claim that equity capital is very costly: Are these private costs to bank managers that have to go to the market to get additional equity capital? Or are these social costs because additional equity for a bank means less equity for other purposes?"	3
CCT762	"-There was an excessive emphasis on revenue and growth, with insufficient attention given to risk and risk capacity. The focus on growth was motivated by a concern that UBS was falling behind leading competitors in investment banking. The ""competitive gap"" was deemed to be particularly large in the area of fixed-income securities. Activities in asset-backed securities, mortgage-backed securities, and adjustable-rate mortgages ""were identified as significant revenue growth opportunities"". -There never was any ""holistic"" or comprehensive assessment of this strategy and of the risks that it involved. Risk management and risk control put excessive confidence in credit ratings provided by rating agencies and failed to provide their own analysis of credit risks in the underlying securities. They also put excessive confidence in received quantitative methods of analysis, stress tests and estimates of value at risk using statistical models based on time series data of the past five years. At the same time, they neglected possible correlations between the risk involved in ""warehousing"" securities in the process of securitization and the risk inherent in the securities that were held on the bank\""s own account. They also paid insufficient attention to systemic risks such as failures of counterparties to 46 Demyanyk and Van Hemert (2008); see also #CITATION_TAG and Mills (2007). 47 UBS (2008)."	0	"Risk management and risk control put excessive confidence in credit ratings provided by rating agencies and failed to provide their own analysis of credit risks in the underlying securities. They also put excessive confidence in received quantitative methods of analysis, stress tests and estimates of value at risk using statistical models based on time series data of the past five years. At the same time, they neglected possible correlations between the risk involved in ""warehousing"" securities in the process of securitization and the risk inherent in the securities that were held on the bank\""s own account. They also paid insufficient attention to systemic risks such as failures of counterparties to 46 Demyanyk and Van Hemert (2008); see also #CITATION_TAG and Mills (2007). 47 UBS (2008)."	o
CCT763	In the downturn that we have been experiencing, all three of these effects have been at work. The breakdowns of conduits and SIVs as well as some of the credit insurers and, most recently, the failure of Lehman Brothers exerted domino effects through contractual links on sponsors, clients, creditors, and, not least, the insurers of the risk that Lehman Brothers might default. 99 The interplay of markets, fair value accounting, regulatory requirements, and corrective actions of banks with insufficient equity can be seen as a chain of  Staub (1998a) and Hellwig (1998b) only refer to domino effects through contractual relations and to information contagion. The importance of dominos effects through asset prices is stressed by #CITATION_TAG and Shin (2004) and Carletti (2006, 2008). 99 The crisis of the large insurance company AIG, which followed almost immediately, was in large part due to their having provided such insurance.	5	In the downturn that we have been experiencing, all three of these effects have been at work. The breakdowns of conduits and SIVs as well as some of the credit insurers and, most recently, the failure of Lehman Brothers exerted domino effects through contractual links on sponsors, clients, creditors, and, not least, the insurers of the risk that Lehman Brothers might default. 99 The interplay of markets, fair value accounting, regulatory requirements, and corrective actions of banks with insufficient equity can be seen as a chain of  Staub (1998a) and Hellwig (1998b) only refer to domino effects through contractual relations and to information contagion. The importance of dominos effects through asset prices is stressed by #CITATION_TAG and Shin (2004) and Carletti (2006, 2008). 99 The crisis of the large insurance company AIG, which followed almost immediately, was in large part due to their having provided such insurance.	 
CCT764	"Another approach to the problem of risk allocation in real-estate finance was provided by securitization. This financial innovation was developed in the eighties in the United States. In the nineties, reliance on securitization greatly expanded so that, by the end of the decade, it accounted for the bulk of real-estate finance. Under securitization, sometimes referred to as the originate-and-distribute model of mortgage finance, the originating institution, traditionally a bank or a savings institution, will transfer mortgage titles to a special-purpose vehicle, a specialized institution that puts a large set of 13 See Kane (1985Kane ( , 1989, Benston et al. (1991). 14 The shift to adjustable-rate instruments in the first half of the eighties is deemed to explain at least part of the increase in credit risk in this decade; see Hendershott and Shilling (1991), #CITATION_TAG and Torous (1991). 15 In the UK, the brunt of the crisis was actually borne by the insurance industry that had provided the building societies with credit insurance on the basis of the idea that default on a loan is an insurable event! mortgages into a package and that refinances itself by issuing ""mortgagebacked securities i.e. securities whose claims are defined with reference to the returns that are earned by the package of mortgages. The risks of mortgage finance are thus transferred from the originating institution to the special purpose vehicle and to the holders of the mortgage-backed securities."	0	"This financial innovation was developed in the eighties in the United States. In the nineties, reliance on securitization greatly expanded so that, by the end of the decade, it accounted for the bulk of real-estate finance. Under securitization, sometimes referred to as the originate-and-distribute model of mortgage finance, the originating institution, traditionally a bank or a savings institution, will transfer mortgage titles to a special-purpose vehicle, a specialized institution that puts a large set of 13 See Kane (1985Kane ( , 1989, Benston et al. (1991). 14 The shift to adjustable-rate instruments in the first half of the eighties is deemed to explain at least part of the increase in credit risk in this decade; see Hendershott and Shilling (1991), #CITATION_TAG and Torous (1991). 15 In the UK, the brunt of the crisis was actually borne by the insurance industry that had provided the building societies with credit insurance on the basis of the idea that default on a loan is an insurable event! mortgages into a package and that refinances itself by issuing ""mortgagebacked securities i.e. securities whose claims are defined with reference to the returns that are earned by the package of mortgages. The risks of mortgage finance are thus transferred from the originating institution to the special purpose vehicle and to the holders of the mortgage-backed securities."	h
CCT765	"111 On this development, see Baltensperger and Dermine (1987), Englund (1990), M√©litz (1990), #CITATION_TAG (1990), OECD (1992). 112 For an example of regulatory thinking at the time, see Carosio (1990). 113 However, even here, one may question whether, e.g., real-estate loans in different countries should be treated as being equally risky; see Schaefer (1990). 114 For criticisms of the lack of theoretical or empirical foundations, see King (1990) and Schaefer (1990). Both point out that neither the regulatory community nor the academic community have any framework for assessing the bankers"" claim that equity capital is very costly: Are these private costs to bank managers that have to go to the market to get additional equity capital? Or are these social costs because additional equity for a bank means less equity for other purposes? According to the Modigliani-Miller Theorem of corporate finance, it is not clear that there would be any social costs. Hellwig (1996) compares ""the speed with which the regulatory community moved from the April 1993 and April 1995 proposals to the actual Amendment to the Capital Accord to Incorporate Market Risks of January 1996 to the time and expenses it takes for a private company to get a new drug approved for sale"" and notes that ""both the 1988 Accord and the 1996 Amendment to the 1988 Accord were enacted with hardly any evidence about the economic effects of capital requirements for banks."	0	111 On this development, see Baltensperger and Dermine (1987), Englund (1990), M√©litz (1990), #CITATION_TAG (1990), OECD (1992). 112 For an example of regulatory thinking at the time, see Carosio (1990). 113 However, even here, one may question whether, e.g., real-estate loans in different countries should be treated as being equally risky; see Schaefer (1990). 114 For criticisms of the lack of theoretical or empirical foundations, see King (1990) and Schaefer (1990).	1
CCT766	57 This difficulty is also stressed by #CITATION_TAG (2007). 58 The role of correlations between underlying risks and counterparty credit risks in hedging arrangements is discussed in Hellwig (1995). The problem appeared conspicuously in the Thai crisis of 1997 when international banks, which had tried to eliminate exchange rate risk by denominating loans in dollars rather than baht, found out that, after the devaluation of the baht, Thai entrepreneurs, who were earning money in baht, had difficulties servicing their dollar-denominated debts to Thai banks, which in turn then had difficulties servicing their debts to international banks.	0	57 This difficulty is also stressed by #CITATION_TAG (2007). 58 The role of correlations between underlying risks and counterparty credit risks in hedging arrangements is discussed in Hellwig (1995). The problem appeared conspicuously in the Thai crisis of 1997 when international banks, which had tried to eliminate exchange rate risk by denominating loans in dollars rather than baht, found out that, after the devaluation of the baht, Thai entrepreneurs, who were earning money in baht, had difficulties servicing their dollar-denominated debts to Thai banks, which in turn then had difficulties servicing their debts to international banks.	5
CCT767	"111 On this development, see Baltensperger and Dermine (1987), #CITATION_TAG (1990), M√©litz (1990), Vives (1990), OECD (1992). 112 For an example of regulatory thinking at the time, see Carosio (1990). 113 However, even here, one may question whether, e.g., real-estate loans in different countries should be treated as being equally risky; see Schaefer (1990). 114 For criticisms of the lack of theoretical or empirical foundations, see King (1990) and Schaefer (1990). Both point out that neither the regulatory community nor the academic community have any framework for assessing the bankers"" claim that equity capital is very costly: Are these private costs to bank managers that have to go to the market to get additional equity capital? Or are these social costs because additional equity for a bank means less equity for other purposes? According to the Modigliani-Miller Theorem of corporate finance, it is not clear that there would be any social costs. Hellwig (1996) compares ""the speed with which the regulatory community moved from the April 1993 and April 1995 proposals to the actual Amendment to the Capital Accord to Incorporate Market Risks of January 1996 to the time and expenses it takes for a private company to get a new drug approved for sale"" and notes that ""both the 1988 Accord and the 1996 Amendment to the 1988 Accord were enacted with hardly any evidence about the economic effects of capital requirements for banks."	0	111 On this development, see Baltensperger and Dermine (1987), #CITATION_TAG (1990), M√©litz (1990), Vives (1990), OECD (1992). 112 For an example of regulatory thinking at the time, see Carosio (1990). 113 However, even here, one may question whether, e.g., real-estate loans in different countries should be treated as being equally risky; see Schaefer (1990). 114 For criticisms of the lack of theoretical or empirical foundations, see King (1990) and Schaefer (1990).	1
CCT768	"In particular, there is no room for asking what risks are taken in order to achieve the 25% rate-of-return benchmark. From the theory of capital markets, we know that, on average, higher rates of return can be achieved by 61 Indeed, at the very time when it was becoming politically correct to refer to ""shareholder value"" in boardroom discussions, in the early nineties, corporate management in the United States, with the support of state legislatures and the courts successfully installed measures that all but eliminated hostile takeovers and made it all but impossible for outside shareholders to interfere with the corporation against the wishes of management; see #CITATION_TAG (1993). 62 For a detailed, critical discussion of ""market discipline see Hellwig (2005). 63 This interpretation of ""shareholder value"" rhetoric as a justification of managerial enrichment raises the question why ""shareholder value"" did not play much of a role before 1990. Possibly, the opportunities and the needs for corporate restructuring that became apparent in the eighties and that have been pursued all through the nineties shifted the balance from a system involving remuneration through power and incumbency to one involving remuneration through a share in the profits from restructuring. pursuing riskier strategies. If two assets have the same expected return, but one is riskier than the other, the riskier asset must trade at a discount relative to the safer one. On average, therefore, the rate of return on the riskier asset is higher. Quite possibly, therefore, the reported 25% rate-of-return benchmark for leading banking institutions reflects risk taking as well as efficiency. Perhaps also these institutions have simply been ""economizing"" on equity, using a small capitalization to support a large volume of activity. After all, we have seen the equity of institutions like Deutsche Bank or UBS going down from somewhere near 10% of their overall balance sheets in the early nineties to somewhere between 2 and 3% in the recent past."	0	"In particular, there is no room for asking what risks are taken in order to achieve the 25% rate-of-return benchmark. From the theory of capital markets, we know that, on average, higher rates of return can be achieved by 61 Indeed, at the very time when it was becoming politically correct to refer to ""shareholder value"" in boardroom discussions, in the early nineties, corporate management in the United States, with the support of state legislatures and the courts successfully installed measures that all but eliminated hostile takeovers and made it all but impossible for outside shareholders to interfere with the corporation against the wishes of management; see #CITATION_TAG (1993). 62 For a detailed, critical discussion of ""market discipline see Hellwig (2005). 63 This interpretation of ""shareholder value"" rhetoric as a justification of managerial enrichment raises the question why ""shareholder value"" did not play much of a role before 1990. Possibly, the opportunities and the needs for corporate restructuring that became apparent in the eighties and that have been pursued all through the nineties shifted the balance from a system involving remuneration through power and incumbency to one involving remuneration through a share in the profits from restructuring."	r
CCT769	What then went wrong? In several important respects, the practice was different from the theory: First, moral hazard in origination was not 20 Duffie (2007). A general treatment of the role of standardization is provided by Gale (1992). 21 For a more detailed account of the argument, see #CITATION_TAG and Krahnen (2006). eliminated, but was actually enhanced by several developments. Second, many of the mortgage-backed securities did not end up in the portfolios of insurance companies or pension funds, but in the portfolios of highly levered institutions that engaged in substantial maturity transformation and were in constant need of refinancing. Third, the markets for refinancing these highly leveraged institutions broke down in the crisis.	0	What then went wrong? In several important respects, the practice was different from the theory: First, moral hazard in origination was not 20 Duffie (2007). A general treatment of the role of standardization is provided by Gale (1992). 21 For a more detailed account of the argument, see #CITATION_TAG and Krahnen (2006). eliminated, but was actually enhanced by several developments. Second, many of the mortgage-backed securities did not end up in the portfolios of insurance companies or pension funds, but in the portfolios of highly levered institutions that engaged in substantial maturity transformation and were in constant need of refinancing. Third, the markets for refinancing these highly leveraged institutions broke down in the crisis.	F
CCT770	"In principle, shifting this risk away from the originating institution and its debtor makes sense because there are other market participants who are better able to bear this risk. Some market participants actually have long investment horizons and therefore do not consider the interest risk of real-estate finance to be a risk at all. Thus, an insurance company or a pension fund has liabilities with maturities of twenty years or more, not too far removed from the economic life of a real-estate investment or the maturity of a mortgage instrument. If such an institution invests in a long-term fixed-rate instrument, i.e., a mortgage or a mortgage-backed security, the question of how the market values this instrument at intervening dates is irrelevant because there is no point in liquidating this investment anyway and the institution""s ability to fulfil its obligation to its own financiers depends on the returns from the security rather than the market""s assessment. Indeed, for an insurance company or pension fund, a fall in the value of long-term securities that is induced by an increase in interest rates tends to be unproblematic. The very increase in interest rates provides the institution with scope to earn higher returns on new investments and thereby to better fulfil its obligations to its insurance and pension customers. 16 ven if one cannot a priori distinguish between short-term and long-term investors, the securitization of long-term investments can still make economic sense. Thus, in the context of a model in which investors do not know beforehand when they will want to consume, #CITATION_TAG (1994a) shows that it is optimal to have an arrangement where people stipulate the amounts of short-term and long-term assets that they want to hold, with the proviso that, if they find that they want to consume early, they should bear the interest-induced valuation risk of long-term investments, and, if they want to consume late, they should bear the interest-induced reinvestment risk of short-term investments. All risks that are associated with changes in interest rates should thus be shifted to final investors. Securitization provides one way to achieve this."	5	Indeed, for an insurance company or pension fund, a fall in the value of long-term securities that is induced by an increase in interest rates tends to be unproblematic. The very increase in interest rates provides the institution with scope to earn higher returns on new investments and thereby to better fulfil its obligations to its insurance and pension customers. 16 ven if one cannot a priori distinguish between short-term and long-term investors, the securitization of long-term investments can still make economic sense. Thus, in the context of a model in which investors do not know beforehand when they will want to consume, #CITATION_TAG (1994a) shows that it is optimal to have an arrangement where people stipulate the amounts of short-term and long-term assets that they want to hold, with the proviso that, if they find that they want to consume early, they should bear the interest-induced valuation risk of long-term investments, and, if they want to consume late, they should bear the interest-induced reinvestment risk of short-term investments. All risks that are associated with changes in interest rates should thus be shifted to final investors. Securitization provides one way to achieve this.	n
CCT771	"A second issue concerns the systemic implications of regulatory intervention when an institution is in difficulties. This complements the concern, raised above, that the mechanical imposition of capital requirements may 121 A commentator has suggested that the problems of counterparty credit risk and its correlations with underlying macro risks are mitigated if the counterparties themselves are subject to supervision ensuring their viability. To the extent that the ""if"" in this statement is valid, this is true. However, the crisis shows that, in the presence of macro shocks affecting the entire financial system or of a macro shock that the financial system is generating all on its own, there is little assurance that supervision of the counterparties will ensure their viability. Indeed, if one looks at the various banking crises of the nineties, one finds that regulatory requirements had often been overfulfilled -until the crisis broke. 122 The basic idea is developed in #CITATION_TAG (1994b). increase the bank""s insolvency risk by forcing it to sell assets in an illiquid and panicky market in which these assets are undervalued. Besides the negative effects on the bank itself, such an intervention also has negative effects on the asset markets and thereby on other market participants. At this point in my discussion, I hardly need to add that such negative effects of corrective actions of banks have played a significant role in the crisis."	5	"To the extent that the ""if"" in this statement is valid, this is true. However, the crisis shows that, in the presence of macro shocks affecting the entire financial system or of a macro shock that the financial system is generating all on its own, there is little assurance that supervision of the counterparties will ensure their viability. Indeed, if one looks at the various banking crises of the nineties, one finds that regulatory requirements had often been overfulfilled -until the crisis broke. 122 The basic idea is developed in #CITATION_TAG (1994b). increase the bank""s insolvency risk by forcing it to sell assets in an illiquid and panicky market in which these assets are undervalued. Besides the negative effects on the bank itself, such an intervention also has negative effects on the asset markets and thereby on other market participants. At this point in my discussion, I hardly need to add that such negative effects of corrective actions of banks have played a significant role in the crisis."	h
CCT772	"111 On this development, see Baltensperger and Dermine (1987), Englund (1990), M√©litz (1990), Vives (1990), OECD (1992). 112 For an example of regulatory thinking at the time, see Carosio (1990). 113 However, even here, one may question whether, e.g., real-estate loans in different countries should be treated as being equally risky; see Schaefer (1990). 114 For criticisms of the lack of theoretical or empirical foundations, see King (1990) and Schaefer (1990). Both point out that neither the regulatory community nor the academic community have any framework for assessing the bankers"" claim that equity capital is very costly: Are these private costs to bank managers that have to go to the market to get additional equity capital? Or are these social costs because additional equity for a bank means less equity for other purposes? According to the Modigliani-Miller Theorem of corporate finance, it is not clear that there would be any social costs. #CITATION_TAG (1996) compares ""the speed with which the regulatory community moved from the April 1993 and April 1995 proposals to the actual Amendment to the Capital Accord to Incorporate Market Risks of January 1996 to the time and expenses it takes for a private company to get a new drug approved for sale"" and notes that ""both the 1988 Accord and the 1996 Amendment to the 1988 Accord were enacted with hardly any evidence about the economic effects of capital requirements for banks."" In my view, prudential regulation under the Basel Accords has the following major shortcomings:"	0	"Both point out that neither the regulatory community nor the academic community have any framework for assessing the bankers"" claim that equity capital is very costly: Are these private costs to bank managers that have to go to the market to get additional equity capital? Or are these social costs because additional equity for a bank means less equity for other purposes? According to the Modigliani-Miller Theorem of corporate finance, it is not clear that there would be any social costs. #CITATION_TAG (1996) compares ""the speed with which the regulatory community moved from the April 1993 and April 1995 proposals to the actual Amendment to the Capital Accord to Incorporate Market Risks of January 1996 to the time and expenses it takes for a private company to get a new drug approved for sale"" and notes that ""both the 1988 Accord and the 1996 Amendment to the 1988 Accord were enacted with hardly any evidence about the economic effects of capital requirements for banks"". In my view, prudential regulation under the Basel Accords has the following major shortcomings:"	O
CCT773	"In particular, there is no room for asking what risks are taken in order to achieve the 25% rate-of-return benchmark. From the theory of capital markets, we know that, on average, higher rates of return can be achieved by 61 Indeed, at the very time when it was becoming politically correct to refer to ""shareholder value"" in boardroom discussions, in the early nineties, corporate management in the United States, with the support of state legislatures and the courts successfully installed measures that all but eliminated hostile takeovers and made it all but impossible for outside shareholders to interfere with the corporation against the wishes of management; see Useem (1993). 62 For a detailed, critical discussion of ""market discipline see #CITATION_TAG (2005). 63 This interpretation of ""shareholder value"" rhetoric as a justification of managerial enrichment raises the question why ""shareholder value"" did not play much of a role before 1990. Possibly, the opportunities and the needs for corporate restructuring that became apparent in the eighties and that have been pursued all through the nineties shifted the balance from a system involving remuneration through power and incumbency to one involving remuneration through a share in the profits from restructuring. pursuing riskier strategies. If two assets have the same expected return, but one is riskier than the other, the riskier asset must trade at a discount relative to the safer one. On average, therefore, the rate of return on the riskier asset is higher. Quite possibly, therefore, the reported 25% rate-of-return benchmark for leading banking institutions reflects risk taking as well as efficiency. Perhaps also these institutions have simply been ""economizing"" on equity, using a small capitalization to support a large volume of activity. After all, we have seen the equity of institutions like Deutsche Bank or UBS going down from somewhere near 10% of their overall balance sheets in the early nineties to somewhere between 2 and 3% in the recent past."	5	"In particular, there is no room for asking what risks are taken in order to achieve the 25% rate-of-return benchmark. From the theory of capital markets, we know that, on average, higher rates of return can be achieved by 61 Indeed, at the very time when it was becoming politically correct to refer to ""shareholder value"" in boardroom discussions, in the early nineties, corporate management in the United States, with the support of state legislatures and the courts successfully installed measures that all but eliminated hostile takeovers and made it all but impossible for outside shareholders to interfere with the corporation against the wishes of management; see Useem (1993). 62 For a detailed, critical discussion of ""market discipline see #CITATION_TAG (2005). 63 This interpretation of ""shareholder value"" rhetoric as a justification of managerial enrichment raises the question why ""shareholder value"" did not play much of a role before 1990. Possibly, the opportunities and the needs for corporate restructuring that became apparent in the eighties and that have been pursued all through the nineties shifted the balance from a system involving remuneration through power and incumbency to one involving remuneration through a share in the profits from restructuring. pursuing riskier strategies."	 
CCT774	"As mentioned in the introduction, the IMF estimates that the total volume of non-prime mortgage-backed securities in the United States amounts to some 1.1 trillion dollars. 72 In absolute terms, this is a large number. However, this number amounts to less than one fifth of the value of all residential mortgage-backed securities in the United States (5.6 trillion dollars), less than one tenth of the value of all residential mortgages in the United States (13 trillion dollars), less than one twentieth of the value of residential real estate in the United States (20-30 trillion dollars), and presumably less than one fortieth of the value of total private wealth in the United States. 73 ore to the point, the estimated 500 billion dollars of losses in non-prime mortgage-backed securities are much smaller than stock market losses after the burst of the technology bubble in 2000; 74 they are also smaller than the 71 International Monetary Fund (2007, p. 7). In a similar vein, the 2006/2007 Annual Report of the Bank for International Settlements (BIS), published in June 2007, mentions the subprime mortgage crisis as a threat for financial stability, without, however, conveying any sense of urgency. In late June, at the 6th Annual BIS Conference, on ""Financial System and Macroeconomic Resilience nobody, myself included, seems to have had an inkling of the crisis that was about to unfold. 72 The April 2007 Global Financial Stability Report of the IMF gave an estimate of 824 billion dollars of subprime mortgage-backed securities; I cannot tell whether the difference between the more recent estimates and this one is due to growth in 2007 or to the inclusion of Alt-A along with subprime mortgage-backed securities. 73 Comparisons are made on the basis of numbers given in International Monetary Fund (2007) and #CITATION_TAG (2006). 74 For US stocks traded on the New York Stock Exchange alone, stock market capitalization declined from 11.5 trillion dollars at the end of 1999 and at the end of 2000 to 11.0 trillion dollars at the end of 2001 and to 9.0 trillion dollars at the end of 2002; for US stocks traded on NASDAQ, the decline went from 5.2 trillion dollars at the end of 1999 to 3.6 trillion dollars at the end of 2000, 2.7 trillion dollars at the end of 2001, and 2.0 trillion dollars at the end of 2002. Data are taken from the World Federation of Exchanges at 600-800 billion dollars of losses that, at the peak of the S&L crisis around 1990, were guesstimated as losses of the US savings and loans industry. Yet, the effects of the burst of the stock market bubble and of the S&L crisis on the global financial system were rather more limited; in the case of the S&L crisis, these effects were hardly noticeable. Why then has the impact of the subprime mortgage crisis on the rest of the financial system been so much more severe?"	0	"In a similar vein, the 2006/2007 Annual Report of the Bank for International Settlements (BIS), published in June 2007, mentions the subprime mortgage crisis as a threat for financial stability, without, however, conveying any sense of urgency. In late June, at the 6th Annual BIS Conference, on ""Financial System and Macroeconomic Resilience nobody, myself included, seems to have had an inkling of the crisis that was about to unfold. 72 The April 2007 Global Financial Stability Report of the IMF gave an estimate of 824 billion dollars of subprime mortgage-backed securities; I cannot tell whether the difference between the more recent estimates and this one is due to growth in 2007 or to the inclusion of Alt-A along with subprime mortgage-backed securities. 73 Comparisons are made on the basis of numbers given in International Monetary Fund (2007) and #CITATION_TAG (2006). 74 For US stocks traded on the New York Stock Exchange alone, stock market capitalization declined from 11.5 trillion dollars at the end of 1999 and at the end of 2000 to 11.0 trillion dollars at the end of 2001 and to 9.0 trillion dollars at the end of 2002; for US stocks traded on NASDAQ, the decline went from 5.2 trillion dollars at the end of 1999 to 3.6 trillion dollars at the end of 2000, 2.7 trillion dollars at the end of 2001, and 2.0 trillion dollars at the end of 2002. Data are taken from the World Federation of Exchanges at 600-800 billion dollars of losses that, at the peak of the S&L crisis around 1990, were guesstimated as losses of the US savings and loans industry. Yet, the effects of the burst of the stock market bubble and of the S&L crisis on the global financial system were rather more limited; in the case of the S&L crisis, these effects were hardly noticeable."	a
CCT775	"Another approach to the problem of risk allocation in real-estate finance was provided by securitization. This financial innovation was developed in the eighties in the United States. In the nineties, reliance on securitization greatly expanded so that, by the end of the decade, it accounted for the bulk of real-estate finance. Under securitization, sometimes referred to as the originate-and-distribute model of mortgage finance, the originating institution, traditionally a bank or a savings institution, will transfer mortgage titles to a special-purpose vehicle, a specialized institution that puts a large set of 13 See Kane (1985Kane ( , 1989, Benston et al. (1991). 14 The shift to adjustable-rate instruments in the first half of the eighties is deemed to explain at least part of the increase in credit risk in this decade; see #CITATION_TAG and Shilling (1991), Schwartz and Torous (1991). 15 In the UK, the brunt of the crisis was actually borne by the insurance industry that had provided the building societies with credit insurance on the basis of the idea that default on a loan is an insurable event! mortgages into a package and that refinances itself by issuing ""mortgagebacked securities i.e. securities whose claims are defined with reference to the returns that are earned by the package of mortgages. The risks of mortgage finance are thus transferred from the originating institution to the special purpose vehicle and to the holders of the mortgage-backed securities."	0	"This financial innovation was developed in the eighties in the United States. In the nineties, reliance on securitization greatly expanded so that, by the end of the decade, it accounted for the bulk of real-estate finance. Under securitization, sometimes referred to as the originate-and-distribute model of mortgage finance, the originating institution, traditionally a bank or a savings institution, will transfer mortgage titles to a special-purpose vehicle, a specialized institution that puts a large set of 13 See Kane (1985Kane ( , 1989, Benston et al. (1991). 14 The shift to adjustable-rate instruments in the first half of the eighties is deemed to explain at least part of the increase in credit risk in this decade; see #CITATION_TAG and Shilling (1991), Schwartz and Torous (1991). 15 In the UK, the brunt of the crisis was actually borne by the insurance industry that had provided the building societies with credit insurance on the basis of the idea that default on a loan is an insurable event! mortgages into a package and that refinances itself by issuing ""mortgagebacked securities i.e. securities whose claims are defined with reference to the returns that are earned by the package of mortgages. The risks of mortgage finance are thus transferred from the originating institution to the special purpose vehicle and to the holders of the mortgage-backed securities."	h
CCT776	"Moral hazard is, in principle, present in any financial transaction. A person who works with his or her own money has greater incentives to take care of what happens with the investment than a person who works with somebody else""s money. 23 In the case of a financial institution, this moral hazard is particularly bothersome because the institution""s assets are very diverse and highly fungible. This makes it difficult for outside investors to monitor the institution""s activities and to take corrective actions if they see something going wrong. 24 In the theory of financial institutions, therefore, the paradigmatic model of viable financial intermediation, due to #CITATION_TAG (1984), postulates an intermediary holding a fully diversified portfolio of assets, with outside finance taking entirely the form of debt, with claims that are independent of the returns which the intermediary earns on his portfolio: If the claims on the financial intermediary are independent of returns on the intermediary""s assets and if diversification ensures that the probability of default is zero, any benefits of taking greater effort in managing assets, e.g., more thorough monitoring of loans clients, accrue entirely to the intermediary. The problem of moral hazard in relations between the intermediary and his financiers is thereby eliminated altogether."	5	"A person who works with his or her own money has greater incentives to take care of what happens with the investment than a person who works with somebody else""s money. 23 In the case of a financial institution, this moral hazard is particularly bothersome because the institution""s assets are very diverse and highly fungible. This makes it difficult for outside investors to monitor the institution""s activities and to take corrective actions if they see something going wrong. 24 In the theory of financial institutions, therefore, the paradigmatic model of viable financial intermediation, due to #CITATION_TAG (1984), postulates an intermediary holding a fully diversified portfolio of assets, with outside finance taking entirely the form of debt, with claims that are independent of the returns which the intermediary earns on his portfolio: If the claims on the financial intermediary are independent of returns on the intermediary""s assets and if diversification ensures that the probability of default is zero, any benefits of taking greater effort in managing assets, e.g., more thorough monitoring of loans clients, accrue entirely to the intermediary. The problem of moral hazard in relations between the intermediary and his financiers is thereby eliminated altogether."	n
CCT777	"Another approach to the problem of risk allocation in real-estate finance was provided by securitization. This financial innovation was developed in the eighties in the United States. In the nineties, reliance on securitization greatly expanded so that, by the end of the decade, it accounted for the bulk of real-estate finance. Under securitization, sometimes referred to as the originate-and-distribute model of mortgage finance, the originating institution, traditionally a bank or a savings institution, will transfer mortgage titles to a special-purpose vehicle, a specialized institution that puts a large set of 13 See #CITATION_TAG (1985Kane ( , 1989, Benston et al. (1991). 14 The shift to adjustable-rate instruments in the first half of the eighties is deemed to explain at least part of the increase in credit risk in this decade; see Hendershott and Shilling (1991), Schwartz and Torous (1991). 15 In the UK, the brunt of the crisis was actually borne by the insurance industry that had provided the building societies with credit insurance on the basis of the idea that default on a loan is an insurable event! mortgages into a package and that refinances itself by issuing ""mortgagebacked securities i.e. securities whose claims are defined with reference to the returns that are earned by the package of mortgages. The risks of mortgage finance are thus transferred from the originating institution to the special purpose vehicle and to the holders of the mortgage-backed securities."	0	"Another approach to the problem of risk allocation in real-estate finance was provided by securitization. This financial innovation was developed in the eighties in the United States. In the nineties, reliance on securitization greatly expanded so that, by the end of the decade, it accounted for the bulk of real-estate finance. Under securitization, sometimes referred to as the originate-and-distribute model of mortgage finance, the originating institution, traditionally a bank or a savings institution, will transfer mortgage titles to a special-purpose vehicle, a specialized institution that puts a large set of 13 See #CITATION_TAG (1985Kane ( , 1989, Benston et al. (1991). 14 The shift to adjustable-rate instruments in the first half of the eighties is deemed to explain at least part of the increase in credit risk in this decade; see Hendershott and Shilling (1991), Schwartz and Torous (1991). 15 In the UK, the brunt of the crisis was actually borne by the insurance industry that had provided the building societies with credit insurance on the basis of the idea that default on a loan is an insurable event! mortgages into a package and that refinances itself by issuing ""mortgagebacked securities i.e. securities whose claims are defined with reference to the returns that are earned by the package of mortgages."	e
CCT778	"111 On this development, see Baltensperger and Dermine (1987), Englund (1990), M√©litz (1990), Vives (1990), OECD (1992). 112 For an example of regulatory thinking at the time, see Carosio (1990). 113 However, even here, one may question whether, e.g., real-estate loans in different countries should be treated as being equally risky; see Schaefer (1990). 114 For criticisms of the lack of theoretical or empirical foundations, see #CITATION_TAG (1990) and Schaefer (1990). Both point out that neither the regulatory community nor the academic community have any framework for assessing the bankers"" claim that equity capital is very costly: Are these private costs to bank managers that have to go to the market to get additional equity capital? Or are these social costs because additional equity for a bank means less equity for other purposes? According to the Modigliani-Miller Theorem of corporate finance, it is not clear that there would be any social costs. Hellwig (1996) compares ""the speed with which the regulatory community moved from the April 1993 and April 1995 proposals to the actual Amendment to the Capital Accord to Incorporate Market Risks of January 1996 to the time and expenses it takes for a private company to get a new drug approved for sale"" and notes that ""both the 1988 Accord and the 1996 Amendment to the 1988 Accord were enacted with hardly any evidence about the economic effects of capital requirements for banks."	1	"111 On this development, see Baltensperger and Dermine (1987), Englund (1990), M√©litz (1990), Vives (1990), OECD (1992). 112 For an example of regulatory thinking at the time, see Carosio (1990). 113 However, even here, one may question whether, e.g., real-estate loans in different countries should be treated as being equally risky; see Schaefer (1990). 114 For criticisms of the lack of theoretical or empirical foundations, see #CITATION_TAG (1990) and Schaefer (1990). Both point out that neither the regulatory community nor the academic community have any framework for assessing the bankers"" claim that equity capital is very costly: Are these private costs to bank managers that have to go to the market to get additional equity capital? Or are these social costs because additional equity for a bank means less equity for other purposes? According to the Modigliani-Miller Theorem of corporate finance, it is not clear that there would be any social costs."	 
CCT779	"At this point, I come back to the discussion of biases in bank governance in Section 3.6 above. As discussed there, discourse inside the banks and in relations between the banks and the representatives of ""market discipline"" seems to have focussed on yield, without questioning the implications for the institution\""s exposure to risk. The ability to control risk through model-based risk management was taken for granted, to be handled as a matter of routine. In the case of the Swiss bank UBS, this attitude provided the investment banking branch with the means to prevent any comprehensive risk assessment of their activities by Senior Group Management until the summer of 2007. The very same attitude seems to have been responsible for the extent to which such institutions were ""economizing"" on equity. 107 The very same attitude seems to have been responsible for the extent to which such institutions were ""economizing"" on equity. 107 bove, I have suggested that the focus on yield at the expense of risk may be reinforced by governance mechanisms that rely on ""market discipline"" in the name of ""shareholder value and that the ease of measuring returns and of communicating about returns as opposed to measuring risks and communicating about risks introduces a bias in favour of strategies that involve 106 The classic reference on this point is #CITATION_TAG (1975). 107 For UBS and Cr√©dit Suisse, the Financial Stability Department of the Swiss National Bank has raised concerns about the insufficiency of equity capital since at least 2001 and had put forward proposals to supplement existing capital regulation by a leverage ratio which would install an overall floor for the equity ratio; see Bichsel and Blum (2001, 2005), Blum (2008. Prior to the crisis, these proposals met with the response that the size of the balance sheet was not a good indicator of risk because, for many assets and liabilities, returns and obligations were so highly correlated that the net impact of these positions on the risk of the bank was negligible and hardly any equity was needed to cushion this risk. The notion that there might be limits to the ability of quantitative models to assess the ""negligibility"" of risks, which underlay the Swiss National Bank\""s concerns, does not seem to have entered the banks\"" decision making. greater risk taking. All these arguments are relevant for assessing strategies of ""economizing"" on equity as well as strategies of investing in high-yield securities."	5	"In the case of the Swiss bank UBS, this attitude provided the investment banking branch with the means to prevent any comprehensive risk assessment of their activities by Senior Group Management until the summer of 2007. The very same attitude seems to have been responsible for the extent to which such institutions were ""economizing"" on equity. 107 The very same attitude seems to have been responsible for the extent to which such institutions were ""economizing"" on equity. 107 bove, I have suggested that the focus on yield at the expense of risk may be reinforced by governance mechanisms that rely on ""market discipline"" in the name of ""shareholder value and that the ease of measuring returns and of communicating about returns as opposed to measuring risks and communicating about risks introduces a bias in favour of strategies that involve 106 The classic reference on this point is #CITATION_TAG (1975). 107 For UBS and Cr√©dit Suisse, the Financial Stability Department of the Swiss National Bank has raised concerns about the insufficiency of equity capital since at least 2001 and had put forward proposals to supplement existing capital regulation by a leverage ratio which would install an overall floor for the equity ratio; see Bichsel and Blum (2001, 2005), Blum (2008. Prior to the crisis, these proposals met with the response that the size of the balance sheet was not a good indicator of risk because, for many assets and liabilities, returns and obligations were so highly correlated that the net impact of these positions on the risk of the bank was negligible and hardly any equity was needed to cushion this risk. The notion that there might be limits to the ability of quantitative models to assess the ""negligibility"" of risks, which underlay the Swiss National Bank\""s concerns, does not seem to have entered the banks\"" decision making."	v
CCT780	116 Formal models to this effects have been provided by #CITATION_TAG (1992), Dewatripont and Tirole (1994). 117 This was the rationale for the system of graduated responses stipulated by the Federal Deposit Insurance Corporation Improvement Act (FDICIA) of 1991 in the United States.	5	116 Formal models to this effects have been provided by #CITATION_TAG (1992), Dewatripont and Tirole (1994). 117 This was the rationale for the system of graduated responses stipulated by the Federal Deposit Insurance Corporation Improvement Act (FDICIA) of 1991 in the United States.	1
CCT781	"Information and incentive problems make trading partners wary lest the offer they are considering should be harmful to them. #CITATION_TAG (1970)""s famous model of the used-car market is paradigmatic for the problem. In Akerlof\""s analysis, people who know their cars to be of good quality are less willing to sell them at ""the going price"" than people who know their cars to be ""lemons i.e., poorly made. 12 At any given price, potential buyers appreciate that the cars that are being offered at this price represent a negative or ""adverse"" selection. In the absence of a mechanism for quality certification, the average price of a used car that is traded in the market must therefore involve a discount relative to the price that would be paid for a car whose quality is known to correspond to the average for that make and year. Trading volume is therefore less than it would be under complete information. Nor does the problem stop there: The discount itself is likely to discourage further car owners from offering their cars for sale. The adverse-selection problem is thereby exacerbated. This may require a further discount in the price, which in turn can exacerbate the adverse-selection problem. In extreme cases, the market may break down completely, i.e., no car may be traded even though, in terms of the underlying needs and preferences, it would be mutually beneficial to have trades that reallocate cars from people who need them less to people who need them more."	5	"Information and incentive problems make trading partners wary lest the offer they are considering should be harmful to them. #CITATION_TAG (1970)""s famous model of the used-car market is paradigmatic for the problem. In Akerlof\""s analysis, people who know their cars to be of good quality are less willing to sell them at ""the going price"" than people who know their cars to be ""lemons i.e., poorly made. 12 At any given price, potential buyers appreciate that the cars that are being offered at this price represent a negative or ""adverse"" selection. In the absence of a mechanism for quality certification, the average price of a used car that is traded in the market must therefore involve a discount relative to the price that would be paid for a car whose quality is known to correspond to the average for that make and year."	C
CCT782	116 Formal models to this effects have been provided by Rochet (1992), #CITATION_TAG and Tirole (1994). 117 This was the rationale for the system of graduated responses stipulated by the Federal Deposit Insurance Corporation Improvement Act (FDICIA) of 1991 in the United States.	5	116 Formal models to this effects have been provided by Rochet (1992), #CITATION_TAG and Tirole (1994). 117 This was the rationale for the system of graduated responses stipulated by the Federal Deposit Insurance Corporation Improvement Act (FDICIA) of 1991 in the United States.	1
CCT783	"Presumably, an institution\""s accounting system should provide the institution\""s management with proper guidance for choosing value-maximizing 87 The classic theoretical piece on ""market discipline"" for banks is #CITATION_TAG and Kahn (1991); for policy recommendations, see, e.g., Calomiris (1999). The conflict between ""market discipline"" by shareholders and ""market discipline"" by creditors, which I discussed in fn. 65 above, plays no role in this literature. 88 For theoretical treatments of the problem, see Carletti (2006, 2008), Gale (2006). 89 International Monetary Fund (2008a, pp. 65f)."	0	"Presumably, an institution\""s accounting system should provide the institution\""s management with proper guidance for choosing value-maximizing 87 The classic theoretical piece on ""market discipline"" for banks is #CITATION_TAG and Kahn (1991); for policy recommendations, see, e.g., Calomiris (1999). The conflict between ""market discipline"" by shareholders and ""market discipline"" by creditors, which I discussed in fn. 65 above, plays no role in this literature. 88 For theoretical treatments of the problem, see Carletti (2006, 2008), Gale (2006)."	P
CCT784	"Presumably, an institution\""s accounting system should provide the institution\""s management with proper guidance for choosing value-maximizing 87 The classic theoretical piece on ""market discipline"" for banks is Calomiris and Kahn (1991); for policy recommendations, see, e.g., Calomiris (1999). The conflict between ""market discipline"" by shareholders and ""market discipline"" by creditors, which I discussed in fn. 65 above, plays no role in this literature. 88 For theoretical treatments of the problem, see Carletti (2006, 2008), #CITATION_TAG (2006). 89 International Monetary Fund (2008a, pp. 65f)."	5	"Presumably, an institution\""s accounting system should provide the institution\""s management with proper guidance for choosing value-maximizing 87 The classic theoretical piece on ""market discipline"" for banks is Calomiris and Kahn (1991); for policy recommendations, see, e.g., Calomiris (1999). The conflict between ""market discipline"" by shareholders and ""market discipline"" by creditors, which I discussed in fn. 65 above, plays no role in this literature. 88 For theoretical treatments of the problem, see Carletti (2006, 2008), #CITATION_TAG (2006). 89 International Monetary Fund (2008a, pp. 65f)."	F
CCT785	"111 On this development, see #CITATION_TAG and Dermine (1987), Englund (1990), M√©litz (1990), Vives (1990), OECD (1992). 112 For an example of regulatory thinking at the time, see Carosio (1990). 113 However, even here, one may question whether, e.g., real-estate loans in different countries should be treated as being equally risky; see Schaefer (1990). 114 For criticisms of the lack of theoretical or empirical foundations, see King (1990) and Schaefer (1990). Both point out that neither the regulatory community nor the academic community have any framework for assessing the bankers"" claim that equity capital is very costly: Are these private costs to bank managers that have to go to the market to get additional equity capital? Or are these social costs because additional equity for a bank means less equity for other purposes? According to the Modigliani-Miller Theorem of corporate finance, it is not clear that there would be any social costs. Hellwig (1996) compares ""the speed with which the regulatory community moved from the April 1993 and April 1995 proposals to the actual Amendment to the Capital Accord to Incorporate Market Risks of January 1996 to the time and expenses it takes for a private company to get a new drug approved for sale"" and notes that ""both the 1988 Accord and the 1996 Amendment to the 1988 Accord were enacted with hardly any evidence about the economic effects of capital requirements for banks."	0	111 On this development, see #CITATION_TAG and Dermine (1987), Englund (1990), M√©litz (1990), Vives (1990), OECD (1992). 112 For an example of regulatory thinking at the time, see Carosio (1990). 113 However, even here, one may question whether, e.g., real-estate loans in different countries should be treated as being equally risky; see Schaefer (1990). 114 For criticisms of the lack of theoretical or empirical foundations, see King (1990) and Schaefer (1990).	1
CCT786	"Another approach to the problem of risk allocation in real-estate finance was provided by securitization. This financial innovation was developed in the eighties in the United States. In the nineties, reliance on securitization greatly expanded so that, by the end of the decade, it accounted for the bulk of real-estate finance. Under securitization, sometimes referred to as the originate-and-distribute model of mortgage finance, the originating institution, traditionally a bank or a savings institution, will transfer mortgage titles to a special-purpose vehicle, a specialized institution that puts a large set of 13 See Kane (1985Kane ( , 1989, #CITATION_TAG et al. (1991). 14 The shift to adjustable-rate instruments in the first half of the eighties is deemed to explain at least part of the increase in credit risk in this decade; see Hendershott and Shilling (1991), Schwartz and Torous (1991). 15 In the UK, the brunt of the crisis was actually borne by the insurance industry that had provided the building societies with credit insurance on the basis of the idea that default on a loan is an insurable event! mortgages into a package and that refinances itself by issuing ""mortgagebacked securities i.e. securities whose claims are defined with reference to the returns that are earned by the package of mortgages. The risks of mortgage finance are thus transferred from the originating institution to the special purpose vehicle and to the holders of the mortgage-backed securities."	0	"Another approach to the problem of risk allocation in real-estate finance was provided by securitization. This financial innovation was developed in the eighties in the United States. In the nineties, reliance on securitization greatly expanded so that, by the end of the decade, it accounted for the bulk of real-estate finance. Under securitization, sometimes referred to as the originate-and-distribute model of mortgage finance, the originating institution, traditionally a bank or a savings institution, will transfer mortgage titles to a special-purpose vehicle, a specialized institution that puts a large set of 13 See Kane (1985Kane ( , 1989, #CITATION_TAG et al. (1991). 14 The shift to adjustable-rate instruments in the first half of the eighties is deemed to explain at least part of the increase in credit risk in this decade; see Hendershott and Shilling (1991), Schwartz and Torous (1991). 15 In the UK, the brunt of the crisis was actually borne by the insurance industry that had provided the building societies with credit insurance on the basis of the idea that default on a loan is an insurable event! mortgages into a package and that refinances itself by issuing ""mortgagebacked securities i.e. securities whose claims are defined with reference to the returns that are earned by the package of mortgages."	e
CCT787	"The IMF""s estimates of losses on mortgage-backed securities are not actually based on estimates of the incidence of borrower defaults. 5 These estimates reflect declines in market valuations. In well functioning markets, we would expect these valuations to reflect expectations of future debt service. However, since August 2007, markets have not been functioning well. For some securities, indeed, they have not been functioning at all; in these cases, the losses reflect expectations of what the market valuations would be if markets were 2 According to the IMF""s Global Financial Stability Report of April 2008(2008a, mortgagebacked securities as such were subject to a discount of 30% in the market and MBS collateralized debt obligations (MBS CDOs) subject to a discount of 60%. When applying these ratios to the outstanding 400 billion dollars of MBS CDOs and to the 1100 ‚àí 400 = 700 billion dollars of mortgage-backed securities that are not accounted for by MBS CDOs, one obtains the IMF""s loss estimates of 240 billion and 210 billion for these two sets of securities, for a total of 450 billion dollars. In the Global Financial Stability Report of October 2008, the discount for MBS CDOs has been raised to 72.5%; and the loss estimates have risen accordingly. 3 The actual down payment rate in subprime mortgage contracts was 6% on average, in Alt-A mortgage contracts 12% on average. For mortgage contracts concluded in 2004 or 2005, the property appreciation that occurred until the summer of 2006 would provide an additional buffer. 4 According to the S&P/Case-Shiller U.S. National Home Price Index; see indices at http:// www.standardandpoors.com. 5 As of the first quarter of 2008, the delinquency rate, i.e., the share of mortgages with payments outstanding 90 or more days, was 6.35% altogether, the foreclosure rate 2.47% (Mortgage Bankers Association, http://www.mortgagebankers.org/NewsandMedia/PressCenter/62936. htm). Among adjustable-rate subprime mortgages, i.e. the instruments with the lowest overall creditworthiness, 25% were delinquent or in foreclosure (#CITATION_TAG 2008)."	0	5 As of the first quarter of 2008, the delinquency rate, i.e., the share of mortgages with payments outstanding 90 or more days, was 6.35% altogether, the foreclosure rate 2.47% (Mortgage Bankers Association, http://www. mortgagebankers.org/NewsandMedia/PressCenter/62936. htm). Among adjustable-rate subprime mortgages, i.e. the instruments with the lowest overall creditworthiness, 25% were delinquent or in foreclosure (#CITATION_TAG 2008).	l
CCT788	"For a long time, moral hazard in origination seems to have been reasonably contained. The creation of mortgage-backed securities was almost entirely in the hands of Fannie Mae and Freddie Mac, as the Federal National Mortgage Association and the Federal Home Loan Mortgage Corporation are commonly called. These government-sponsored enterprises 28 provided the buyers of mortgage-backed securities with a guarantee for the promised debt service; at the same time, they imposed certain minimum standards on mortgage debtors, namely, high credit scores reflecting large down payments, low ratios of debt service to documented available income, and reliable credit histories of mortgage borrowers. For mortgages that met these standards, socalled ""prime mortgages delinquency rates and default rates were -and still are -very low. 29 annie Mae and Freddie Mac had in fact played a key role in the development of the markets for mortgage-backed securities. When they began to buy mortgages, to package them, and to sell the mortgage-backed securities in the open market, the mortgage-backed securities were acceptable to investors because Fannie Mae and Freddie Mac also provided guarantees for the promised payments from these securities. The origins of Fannie Mae and Freddie Mac as government institutions led many investors to believe that, even though these institutions had been privatized, their guarantees had some kind of backing from the government 30 and could therefore be deemed to be reliable. 31 owever, in the years since 2000, Fannie Mae and Freddie Mac have been challenged by competition from other financial institutions, in particular, private investment banks, which did not guarantee their issues of mortgagebacked securities in the same way as Fannie Mae and Freddie Mac. The share of the government-sponsored enterprises in the issuance of mortgage-backed securities went from 76% in 2003 to 43% in 2006. 32 At the same time, there was a relative decline in prime mortgage lending and a significant increase in subprime mortgage lending, i.e., in the issuance of mortgages that did not 29 The difficulties that Fannie Mae and Freddie Mac have had in the crisis had more to do with their being pressured by the political system to provide support for subprime mortgagebacked securities in 2007 than with problems in the prime mortgages that had been their main business. However, one suspects that the expansion in prime mortgage lending between 1995 and 2003 may have been accompanied by a decline in borrower quality. This would be the analogue for prime mortgages of findings of #CITATION_TAG and Van Hemert (2008) showing that, since 2001, in subprime mortgage lending, there have been declines in borrower quality that go beyond the effects of changes in observables such as down payment rates, credit scores and the like. 30 Since the privatization of these institutions in the late sixties, this belief would not have had any basis in the law. Even so, the developments since July 2008 have shown that this belief was justified. The position of Fannie Mae and Freddie Mac in the system of housing finance in the United States is too important for the government to look aside when these institutions run into trouble. 31 Thus, at the time when the system of mortgage-backed securities was developed, the neglect of moral hazard induced by securitization was at least partly due to a reliance of market participants on government guarantees. 32 See Dodd (2007). The challenge in the market was preceded by political discussions about these institutions"" roles including accusations by the US Government of errors in dealing with new accounting rules for derivatives. These discussions induced the government-sponsored enterprises to retrench their activities in the market. meet the standards of the government-sponsored enterprises. The share of subprime mortgages rose from around 9% of new mortgages in the early 2000""s to above 40% in 2006. 33 By the end of 2006, subprime mortgages accounted for some 14% of the total stock of outstanding securitized mortgages (7% in 2001). 34 hese changes have caused the quality of mortgages to go down. According to the International Monetary Fund (2007), the share of the stock of securitized mortgages in which the loan accounted for more than 90% of the property value went from about 5% in 2001 to 14% in 2006; the share of securitized mortgages with limited documentation of income went from 7% in 2001 to 18% in 2006. These changes in mortgage quality are linked to the rise of nonprime lending: Average down payments in near prime mortgages, the so-called Alt-A mortgages, and in subprime mortgages were 12% and 6%, respectively, substantially below down payments in prime mortgages; in many instances, there was no down payment at all. In 2006, there was less than full documentation of income in 81% of Alt-A and 50% of subprime mortgages, as opposed to 36% of prime mortgages. 35 hese years also saw the resurrection of adjustable-rate mortgages. Their share of the stock of outstanding mortgages went from 6% in 2001 to 26% in 2006. 36 In 2006 indeed, 92% of newly issued subprime mortgages, 68% of newly issued Alt-A mortgages, and 23% of newly issued prime mortgages had adjustable rates. 37 The lesson of the eighties, that adjustable rates cause credit risk to be higher, seems to have been lost -perhaps forgotten, perhaps also neglected because, after all, the credit risk would affect the holders of mortgage-backed securities rather than the originators of the mortgages."	0	The share of the government-sponsored enterprises in the issuance of mortgage-backed securities went from 76% in 2003 to 43% in 2006. 32 At the same time, there was a relative decline in prime mortgage lending and a significant increase in subprime mortgage lending, i.e., in the issuance of mortgages that did not 29 The difficulties that Fannie Mae and Freddie Mac have had in the crisis had more to do with their being pressured by the political system to provide support for subprime mortgagebacked securities in 2007 than with problems in the prime mortgages that had been their main business. However, one suspects that the expansion in prime mortgage lending between 1995 and 2003 may have been accompanied by a decline in borrower quality. This would be the analogue for prime mortgages of findings of #CITATION_TAG and Van Hemert (2008) showing that, since 2001, in subprime mortgage lending, there have been declines in borrower quality that go beyond the effects of changes in observables such as down payment rates, credit scores and the like. 30 Since the privatization of these institutions in the late sixties, this belief would not have had any basis in the law. Even so, the developments since July 2008 have shown that this belief was justified. The position of Fannie Mae and Freddie Mac in the system of housing finance in the United States is too important for the government to look aside when these institutions run into trouble.	b
CCT789	"-Equity capital affects incentives for risk taking. 116 -Capital regulation provides room for intervention by the supervisor at a time when the bank is not yet subjected to insolvency proceedings. 117 e might consider that the difference does not matter if, in fact, capital regulation can serve all three purposes. However, the rule for determining required capital will depend on which of the three purposes one is thinking of. If one is thinking of equity capital as a buffer against insolvency risk, one is concerned about the total risk to which the institution is subjected. The risk weights of different assets should then be tied to the total contribution that each asset makes to the institution""s risk. If one is thinking of equity capital as an incentive device, one must be concerned about incentive effects at the margin and attune the risk weights of different assets to the marginal impact of increases in the different asset positions on the institution""s risk. With correlations of returns on the different assets, there is no reason why risk weights attuned to marginal risk contributions should coincide with risk weights attuned to total risk contributions. Finally, if capital requirements are there to provide room for supervisory intervention before the onset of bankruptcy, there is no reason why risk weights of assets should matter at all. In this case, it seems more important to make sure that the intervention threshold cannot be manipulated and to have a plan for how to intervene when the threshold is reached. To the extent that different assets should carry different weights at all, the different weights should probably be attuned to differences in marketability of these assets, because these differences affect the difficulty 115 For evidence of the heterogeneity of rationales, see the discussion documented in #CITATION_TAG (1995)."	0	With correlations of returns on the different assets, there is no reason why risk weights attuned to marginal risk contributions should coincide with risk weights attuned to total risk contributions. Finally, if capital requirements are there to provide room for supervisory intervention before the onset of bankruptcy, there is no reason why risk weights of assets should matter at all. In this case, it seems more important to make sure that the intervention threshold cannot be manipulated and to have a plan for how to intervene when the threshold is reached. To the extent that different assets should carry different weights at all, the different weights should probably be attuned to differences in marketability of these assets, because these differences affect the difficulty 115 For evidence of the heterogeneity of rationales, see the discussion documented in #CITATION_TAG (1995).	e
CCT790	"At this point, I come back to the discussion of biases in bank governance in Section 3.6 above. As discussed there, discourse inside the banks and in relations between the banks and the representatives of ""market discipline"" seems to have focussed on yield, without questioning the implications for the institution\""s exposure to risk. The ability to control risk through model-based risk management was taken for granted, to be handled as a matter of routine. In the case of the Swiss bank UBS, this attitude provided the investment banking branch with the means to prevent any comprehensive risk assessment of their activities by Senior Group Management until the summer of 2007. The very same attitude seems to have been responsible for the extent to which such institutions were ""economizing"" on equity. 107 bove, I have suggested that the focus on yield at the expense of risk may be reinforced by governance mechanisms that rely on ""market discipline"" in the name of ""shareholder value and that the ease of measuring returns and of communicating about returns as opposed to measuring risks and communicating about risks introduces a bias in favour of strategies that involve 106 The classic reference on this point is Peltzman (1975). 107 For UBS and Cr√©dit Suisse, the Financial Stability Department of the Swiss National Bank has raised concerns about the insufficiency of equity capital since at least 2001 and had put forward proposals to supplement existing capital regulation by a leverage ratio which would install an overall floor for the equity ratio; see Bichsel and Blum (2001, 2005), #CITATION_TAG (2008. Prior to the crisis, these proposals met with the response that the size of the balance sheet was not a good indicator of risk because, for many assets and liabilities, returns and obligations were so highly correlated that the net impact of these positions on the risk of the bank was negligible and hardly any equity was needed to cushion this risk. The notion that there might be limits to the ability of quantitative models to assess the ""negligibility"" of risks, which underlay the Swiss National Bank\""s concerns, does not seem to have entered the banks\"" decision making. greater risk taking. All these arguments are relevant for assessing strategies of ""economizing"" on equity as well as strategies of investing in high-yield securities."	0	"In the case of the Swiss bank UBS, this attitude provided the investment banking branch with the means to prevent any comprehensive risk assessment of their activities by Senior Group Management until the summer of 2007. The very same attitude seems to have been responsible for the extent to which such institutions were ""economizing"" on equity. 107 bove, I have suggested that the focus on yield at the expense of risk may be reinforced by governance mechanisms that rely on ""market discipline"" in the name of ""shareholder value and that the ease of measuring returns and of communicating about returns as opposed to measuring risks and communicating about risks introduces a bias in favour of strategies that involve 106 The classic reference on this point is Peltzman (1975). 107 For UBS and Cr√©dit Suisse, the Financial Stability Department of the Swiss National Bank has raised concerns about the insufficiency of equity capital since at least 2001 and had put forward proposals to supplement existing capital regulation by a leverage ratio which would install an overall floor for the equity ratio; see Bichsel and Blum (2001, 2005), #CITATION_TAG (2008. Prior to the crisis, these proposals met with the response that the size of the balance sheet was not a good indicator of risk because, for many assets and liabilities, returns and obligations were so highly correlated that the net impact of these positions on the risk of the bank was negligible and hardly any equity was needed to cushion this risk. The notion that there might be limits to the ability of quantitative models to assess the ""negligibility"" of risks, which underlay the Swiss National Bank\""s concerns, does not seem to have entered the banks\"" decision making. greater risk taking."	r
CCT791	"When the market prices of asset-backed securities began to drop in the second half of 2007 and fair value accounting required this drop to be acknowledged in the books, the institutions that held such securities had to react almost immediately. Some of them managed to obtain new equity. Others had to begin to deleverage, i.e., to reduce their lending or to sell assets in order to adapt the scale of their operations to their reduced equity. Given the need to satisfy regulatory requirements, they did not have much choice on whether they thought that market values of assets provided the right signals ""for making long-term value-maximizing decisions"". Because the equity capital that they held in excess of regulatory requirements did not suffice to 91 In public discussion, the regime change tends to be associated with the recent replacement of ""Basel I"" by ""Basel II"". In fact, the change of paradigm came already with the 1996 Amendment to ""Basel I"". 92 On this point, see the contribution of Zuberb√ºhler to Hellwig and Staub (1996). 93 For expressions of this view, see #CITATION_TAG (1995) and Gumerlock""s contribution to Hellwig and Staub (1996)."	0	"Because the equity capital that they held in excess of regulatory requirements did not suffice to 91 In public discussion, the regime change tends to be associated with the recent replacement of ""Basel I"" by ""Basel II"". In fact, the change of paradigm came already with the 1996 Amendment to ""Basel I"". 92 On this point, see the contribution of Zuberb√ºhler to Hellwig and Staub (1996). 93 For expressions of this view, see #CITATION_TAG (1995) and Gumerlock""s contribution to Hellwig and Staub (1996)."	e
CCT792	"111 On this development, see Baltensperger and Dermine (1987), Englund (1990), M√©litz (1990), Vives (1990), OECD (1992). 112 For an example of regulatory thinking at the time, see #CITATION_TAG (1990). 113 However, even here, one may question whether, e.g., real-estate loans in different countries should be treated as being equally risky; see Schaefer (1990). 114 For criticisms of the lack of theoretical or empirical foundations, see King (1990) and Schaefer (1990). Both point out that neither the regulatory community nor the academic community have any framework for assessing the bankers"" claim that equity capital is very costly: Are these private costs to bank managers that have to go to the market to get additional equity capital? Or are these social costs because additional equity for a bank means less equity for other purposes? According to the Modigliani-Miller Theorem of corporate finance, it is not clear that there would be any social costs. Hellwig (1996) compares ""the speed with which the regulatory community moved from the April 1993 and April 1995 proposals to the actual Amendment to the Capital Accord to Incorporate Market Risks of January 1996 to the time and expenses it takes for a private company to get a new drug approved for sale"" and notes that ""both the 1988 Accord and the 1996 Amendment to the 1988 Accord were enacted with hardly any evidence about the economic effects of capital requirements for banks."	0	"111 On this development, see Baltensperger and Dermine (1987), Englund (1990), M√©litz (1990), Vives (1990), OECD (1992). 112 For an example of regulatory thinking at the time, see #CITATION_TAG (1990). 113 However, even here, one may question whether, e.g., real-estate loans in different countries should be treated as being equally risky; see Schaefer (1990). 114 For criticisms of the lack of theoretical or empirical foundations, see King (1990) and Schaefer (1990). Both point out that neither the regulatory community nor the academic community have any framework for assessing the bankers"" claim that equity capital is very costly: Are these private costs to bank managers that have to go to the market to get additional equity capital?"	1
CCT793	66 According to #CITATION_TAG (2007), total funds managed by hedge funds more than doubled between 2002 and 2006, growing from under 800 billion dollars to around 1600 billion dollars, at an annual rate of roughly 19%. 67 Dodd (2007), Kiff and Mills (2007). 68 Duffie (2007).	0	66 According to #CITATION_TAG (2007), total funds managed by hedge funds more than doubled between 2002 and 2006, growing from under 800 billion dollars to around 1600 billion dollars, at an annual rate of roughly 19%. 67 Dodd (2007), Kiff and Mills (2007). 68 Duffie (2007).	6
CCT794	On the other hand, elements with a structural accent may cross an element that is accented but given. In (51), the subjects are given due to the pair-list/distributive context question, they are not linearized immediately and receive their contrastive accents later. 35 The answer in ( 52) is possible only if a contextually given set of Fritz and Irina (and Karl) may be accommodated, i.e., the subject Irina may be interpreted as given. Otherwise, Irina is newly introduced (see also #CITATION_TAG and van de Koot 2008), and as such it obligatorily receives a structural accent, which leads to an intervention effect with the fronted focused object. 34 Recall that multiple wh-contexts where both elements are not contextually given do not allow inversion. The elements receive structural accents and undergo immediate linearization (cf. examples ( 30)-(31) in Sect. 3.2). 35 Examples ( 14) and ( 16) in Sect. 3 represent a slightly different case, the crossed elements being functional elements that do not receive structural accents. We conclude that the necessary condition for the possibility of accent crossing is that the two participating elements are not both structurally accented. In rise-fall constructions, crossing is limited to contexts rendering one of the participants contextually given (or to contexts with one of the participants being a functional expression), which results in constellations where only one of the participants receives a structural accent. It is not important whether the fronted categories are contrastive topics or foci or their parts, as long as this condition is fulfilled. Accentuation of given elements is further subject to interface conditions: contrastive topics and foci ultimately have to receive an accent, accent marking of topics is optional. 36	1	On the other hand, elements with a structural accent may cross an element that is accented but given. In (51), the subjects are given due to the pair-list/distributive context question, they are not linearized immediately and receive their contrastive accents later. 35 The answer in ( 52) is possible only if a contextually given set of Fritz and Irina (and Karl) may be accommodated, i.e., the subject Irina may be interpreted as given. Otherwise, Irina is newly introduced (see also #CITATION_TAG and van de Koot 2008), and as such it obligatorily receives a structural accent, which leads to an intervention effect with the fronted focused object. 34 Recall that multiple wh-contexts where both elements are not contextually given do not allow inversion. The elements receive structural accents and undergo immediate linearization (cf. examples ( 30)-(31) in Sect. 3.2). 35 Examples ( 14) and ( 16) in Sect. 3 represent a slightly different case, the crossed elements being functional elements that do not receive structural accents.	e
CCT795	( The present paper argues that this view is misguided. Accentuation rather than informational status determines which categories can be fronted, but this special role of accentuation does not imply that syntax refers to prosodic features. Accentuation comes into play indirectly only, its relevance for fronting stems from the fact that accentuation is a side-effect of cyclic linearization in the sense of #CITATION_TAG and Pesetsky (2005) and M√ºller (2007). In addition to offering a new analysis of Czech and German constituent order, our paper therefore also addresses broader theoretical issues. First, our findings support the view (see, e.g., Chomsky 2008) that notions of information structure do not figure in the syntactic derivation, at least not in the sense of being formally responsible for movement. Second, the analysis proposes a treatment of accent-related locality constraints on movement, which is relevant for the issue of the interaction of syntax and phonology.	5	( The present paper argues that this view is misguided. Accentuation rather than informational status determines which categories can be fronted, but this special role of accentuation does not imply that syntax refers to prosodic features. Accentuation comes into play indirectly only, its relevance for fronting stems from the fact that accentuation is a side-effect of cyclic linearization in the sense of #CITATION_TAG and Pesetsky (2005) and M√ºller (2007). In addition to offering a new analysis of Czech and German constituent order, our paper therefore also addresses broader theoretical issues. First, our findings support the view (see, e.g., Chomsky 2008) that notions of information structure do not figure in the syntactic derivation, at least not in the sense of being formally responsible for movement. Second, the analysis proposes a treatment of accent-related locality constraints on movement, which is relevant for the issue of the interaction of syntax and phonology.	c
CCT796	The idea suggests itself that the fronting of XPs to the left periphery of declaratives finds the same analysis (Thiersch 1978). Most generative approaches to German subscribe to this view (but see M√ºller 2004). One remaining issue is whether wh-phrases and non-wh-phrases target the same slot, a question answered negatively in cartographic approaches (#CITATION_TAG 1997), which split up Comp into at least four different heads. Abstracting away from such questions, den Josef appears in SpecCP in (1a), and the finite verb is placed in C.	0	The idea suggests itself that the fronting of XPs to the left periphery of declaratives finds the same analysis (Thiersch 1978). Most generative approaches to German subscribe to this view (but see M√ºller 2004). One remaining issue is whether wh-phrases and non-wh-phrases target the same slot, a question answered negatively in cartographic approaches (#CITATION_TAG 1997), which split up Comp into at least four different heads. Abstracting away from such questions, den Josef appears in SpecCP in (1a), and the finite verb is placed in C.	e
CCT797	"Finally, the analysis of LP-movement in terms of information structure features turns out to be empirically inadequate. Topics and foci are fronted in only a subset of the LP-movement contexts. When neither the focus nor the topic moves to first position (because their left peripheral placement is optional), some elements may go there in the absence of any discourse motivation. This holds, for instance, for sentential adverbs, as in (7), and for subjects, as in (8). The movement of these elements cannot serve the checking of topic/focus features. The import of such examples was first noted by Travis (1984), who argued for a TP-analysis of (8). Van Craenenbroek and Haegeman (2007) show, however, that subject-initial verb second clauses cannot be analysed as TPs. Based on a suggestion of H. Haider, Fanselow (2002) and #CITATION_TAG (2005) argue that (7-8) illustrate the same phenomenon: any category that can appear leftmost in TP can move to SpecCP without possessing any special discourse marking. 7 We follow Frey (2005) in calling this movement ""formal fronting"" (FF), but the label is just a shorthand for a particular constellation arising from the application of LP-movement, and not a name for a separate syntactic process. As we will see below (Sect. 4.3.2), FF constructions are less restricted than envisaged by Fanselow and Frey, and they can place scrambled objects into SpecCP."	1	"The movement of these elements cannot serve the checking of topic/focus features. The import of such examples was first noted by Travis (1984), who argued for a TP-analysis of (8). Van Craenenbroek and Haegeman (2007) show, however, that subject-initial verb second clauses cannot be analysed as TPs. Based on a suggestion of H. Haider, Fanselow (2002) and #CITATION_TAG (2005) argue that (7-8) illustrate the same phenomenon: any category that can appear leftmost in TP can move to SpecCP without possessing any special discourse marking. 7 We follow Frey (2005) in calling this movement ""formal fronting"" (FF), but the label is just a shorthand for a particular constellation arising from the application of LP-movement, and not a name for a separate syntactic process. As we will see below (Sect. 4.3. 2), FF constructions are less restricted than envisaged by Fanselow and Frey, and they can place scrambled objects into SpecCP."	n
CCT798	( The present paper argues that this view is misguided. Accentuation rather than informational status determines which categories can be fronted, but this special role of accentuation does not imply that syntax refers to prosodic features. Accentuation comes into play indirectly only, its relevance for fronting stems from the fact that accentuation is a side-effect of cyclic linearization in the sense of Fox and Pesetsky (2005) and M√ºller (2007). In addition to offering a new analysis of Czech and German constituent order, our paper therefore also addresses broader theoretical issues. First, our findings support the view (see, e.g., #CITATION_TAG 2008) that notions of information structure do not figure in the syntactic derivation, at least not in the sense of being formally responsible for movement. Second, the analysis proposes a treatment of accent-related locality constraints on movement, which is relevant for the issue of the interaction of syntax and phonology.	0	Accentuation rather than informational status determines which categories can be fronted, but this special role of accentuation does not imply that syntax refers to prosodic features. Accentuation comes into play indirectly only, its relevance for fronting stems from the fact that accentuation is a side-effect of cyclic linearization in the sense of Fox and Pesetsky (2005) and M√ºller (2007). In addition to offering a new analysis of Czech and German constituent order, our paper therefore also addresses broader theoretical issues. First, our findings support the view (see, e.g., #CITATION_TAG 2008) that notions of information structure do not figure in the syntactic derivation, at least not in the sense of being formally responsible for movement. Second, the analysis proposes a treatment of accent-related locality constraints on movement, which is relevant for the issue of the interaction of syntax and phonology.	t
CCT799	For several reasons, however, LP-movement cannot be successfully captured in terms of information structure driven movement. First, such accounts seem problematic from a minimalist point of view. The use of focus/topic features in the syntactic derivation violates the inclusiveness condition (#CITATION_TAG 1995), according to which only those features can figure in syntactic computations that represent properties of lexical items. On obvious grounds, being a focus or a topic is not a lexical propertywords and phrases can be classified as such only when used in a specific context (see Szendr≈ëi 2004 andden Dikken 2006 for pertinent discussion).	0	For several reasons, however, LP-movement cannot be successfully captured in terms of information structure driven movement. First, such accounts seem problematic from a minimalist point of view. The use of focus/topic features in the syntactic derivation violates the inclusiveness condition (#CITATION_TAG 1995), according to which only those features can figure in syntactic computations that represent properties of lexical items. On obvious grounds, being a focus or a topic is not a lexical propertywords and phrases can be classified as such only when used in a specific context (see Szendr≈ëi 2004 andden Dikken 2006 for pertinent discussion).	e
CCT800	14 Frey (2005) points out that some idioms have a quasi-compositional structure (Nunberg et al. 1994) relative to which parts of idioms could have an informational value of their own. However, #CITATION_TAG (2003) has shown that thematically non-compositional idioms are transparent for movement in German as well.	1	14 Frey (2005) points out that some idioms have a quasi-compositional structure (Nunberg et al. 1994) relative to which parts of idioms could have an informational value of their own. However, #CITATION_TAG (2003) has shown that thematically non-compositional idioms are transparent for movement in German as well.	o
CCT801	Along with hypochlorhydria (that can predispose the elderly to small intestine overgrowth, Fe malabsorption, and vitamin B12 deficiency), evidence suggests that reduction in gastric compliance, particularly of the fundus, plays an important role in the anorexia of ageing and satiety response. 2 The loss of neurons in both submucosal, gastric and enteric plexus begins early in life, along with a reduction in the expression of acetylcholine (ACh) and nitric oxide (NO). 1,2 Furthermore, orexigenic factors like neuropeptide Y decline with ageing, and leptin (a hormone related to satiety) have been shown to increase, particularly in men, probably due to a decrease in testosterone. 2 he increase in colonic transit time and decline in propulsive activity are hypothesized to be related to neurodegeneration and reduction in NO and ACh, making the elderly prone to constipation. 2 The colon plays little role in nutrition, but is an important element for gut microbiome; the number of colony-forming units (CFU) increases from 10 2 CFU in the upper small bowel to 10 12 CFU in the colon. 2 s the authors stated, 1 the gut microbiota plays an important role in the maintenance of the host health and disease in all age groups, but particularly in the elderly. 3 The mechanisms related to the benefits of probiotics are incompletely understood. However, four general benefits have been described: (1) suppression of growth or epithelial binding/invasion by pathogenic bacteria, (2) improvement of intestinal barrier function, (3) modulation of the immune system, and (4) modulation of pain perception. 1,3,4 he majority of bacteria in the colon are anaerobes that can ferment carbohydrates that escape digestion, to form short chain fatty acids (SCFAs) and anions that have a distinct role in promoting gut health (e.g., acetate, propionate, and butyrate). 3 Studies in the elderly described a shift in the composition of intestinal microbiota, with a lower number of beneficial organisms such as bifidobacteria and lactobacilli 1 and an increase in Enterobacteriaceae and certain Proteobacteria. 3 Compared to younger adult controls, aged persons seem to have a lower number of Firmicutes and more abundant Bacteroidetes. 3 Butyrate is the major energy source for the colonic epithelium, and its levels are usually lower in the elderly, with concomitant increased levels of SCFAs, ammonia, and phenols. 3 Evidence showed that lactate accumulation in the colon might be indicative of gut microbiome imbalance, and it was suggested that this could be a target for the development of novel probiotics to prevent lactate accumulation. 3 espite previous good to moderate evidence of the beneficial effects of probiotic and synbiotic administration, recent larger randomized controlled trials reported contradictory results related to the reduction in the risk of infections [Clostridium difficile-associated diarrhea (CDAD), upper respiratory tract infections, antibiotic-associated-diarrhea (AAD), etc.]. The PLACIDE Trial reported no evidence of a multi strain preparation of lactobacilli and bifidobacteria in the prevention of AAD and CDAD. 4 nother recent large trial evaluated the evidence of the preventive effect of probiotics on upper respiratory tract infections (URTI) in an aged sample, and was unable to find differences between groups. #CITATION_TAG Only in the subgroup analysis did the authors find that probiotics probably reduced the duration of acute URTI. 5 espite good evidence of the clinical benefit of probiotic use in children and under some specific conditions, there are no metaanalysis and systematic reviews, to date, that address the use of probiotics in the elderly for infection prevention and control. This issue, we hope, will soon be covered by a systematic review protocol that we are already developing.	1	3 espite previous good to moderate evidence of the beneficial effects of probiotic and synbiotic administration, recent larger randomized controlled trials reported contradictory results related to the reduction in the risk of infections [Clostridium difficile-associated diarrhea (CDAD), upper respiratory tract infections, antibiotic-associated-diarrhea (AAD), etc.]. The PLACIDE Trial reported no evidence of a multi strain preparation of lactobacilli and bifidobacteria in the prevention of AAD and CDAD. 4 nother recent large trial evaluated the evidence of the preventive effect of probiotics on upper respiratory tract infections (URTI) in an aged sample, and was unable to find differences between groups. #CITATION_TAG Only in the subgroup analysis did the authors find that probiotics probably reduced the duration of acute URTI. 5 espite good evidence of the clinical benefit of probiotic use in children and under some specific conditions, there are no metaanalysis and systematic reviews, to date, that address the use of probiotics in the elderly for infection prevention and control. This issue, we hope, will soon be covered by a systematic review protocol that we are already developing.	l
CCT802	In order to enable transaction from object to subject, namely from RVC to robot companion, the research activity focuses on product design and GUI development. The product design defines both the practical aspect of carrying a parasite robot on a RVC and morphological aspects that, in addition to behaviors #CITATION_TAG, improve acceptance. The graphical user interface (GUI) is a mediator of the human-robot interaction (HRI) and consists, mainly, of notifications and visualizations of all the data collected by the robot. At the GUI prototyping phase, follows usability tests, the GUI is submitted to a group of users in order to identify the level of acceptance, appeal, effectiveness and decay of interest over time. The feedbacks obtained with the tests are the base for the subsequent developments of the GUI. The project includes also a preliminary phase that consists of a survey on technology and domestic environment, and a subsequent phase of hardware and software prototyping.	0	In order to enable transaction from object to subject, namely from RVC to robot companion, the research activity focuses on product design and GUI development. The product design defines both the practical aspect of carrying a parasite robot on a RVC and morphological aspects that, in addition to behaviors #CITATION_TAG, improve acceptance. The graphical user interface (GUI) is a mediator of the human-robot interaction (HRI) and consists, mainly, of notifications and visualizations of all the data collected by the robot. At the GUI prototyping phase, follows usability tests, the GUI is submitted to a group of users in order to identify the level of acceptance, appeal, effectiveness and decay of interest over time. The feedbacks obtained with the tests are the base for the subsequent developments of the GUI.	h
CCT803	Today we are witnessing the diffusion of a large number of small robots that started to populate service environments like workplaces, public spaces and, especially, homes. Mobile robotics in domestic environment is quite diffused and consists primarily of cleaning robots, such as robotic vacuum cleaner, mopping robots or floor scrubbing robots. These types of robots are, then, crucial to understand how people perceive robots #CITATION_TAG and accept them in daily life. Recent studies [4] highlight common habits in Robotic Vacuum Cleaners owners, e.g. helping children to crawl, conversing, entertaining pets, watching for fun and, above all, naming the robot [4]. Indeed naming, in other words the act of giving a name declares the fact that the robot is perceived as a subject instead of an object. This high level of acceptance arises from the fact that users have low expectations towards RVC, due to the fact that is not perceived as a robot but rather as an household appliance [6]. High level of acceptance of these robots collides with the small cognitive capabilities. As a matter of fact, they are usually, able to move autonomously and avoid obstacles but do not have interaction and companioning capabilities. The presence of RVC in domestic environments is, anyway, extremely important because it, also, paves the way to the acceptance of other robots, as it is explained in [4], a survey conducted on 379 Roomba owners, the presence of RVC in domestic environments is the first step towards a wider acceptation of robots in daily life.	0	Today we are witnessing the diffusion of a large number of small robots that started to populate service environments like workplaces, public spaces and, especially, homes. Mobile robotics in domestic environment is quite diffused and consists primarily of cleaning robots, such as robotic vacuum cleaner, mopping robots or floor scrubbing robots. These types of robots are, then, crucial to understand how people perceive robots #CITATION_TAG and accept them in daily life. Recent studies [4] highlight common habits in Robotic Vacuum Cleaners owners, e.g. helping children to crawl, conversing, entertaining pets, watching for fun and, above all, naming the robot [4]. Indeed naming, in other words the act of giving a name declares the fact that the robot is perceived as a subject instead of an object. This high level of acceptance arises from the fact that users have low expectations towards RVC, due to the fact that is not perceived as a robot but rather as an household appliance [6].	e
CCT804	The intent is to develop a robot companion, able to inform users and suggest them good practices for daily life improvement. This robot is able to detect environmental information like: humidity, temperature, electromagnetic pollution, smoke, CO2, benzene, various air pollutants and gas. Due to the potential offered by the current and perspective presence of RVC into home environment, this robot is developed as a parasite #CITATION_TAG in shape and behavior: it is physically attached to (clung) the RVC of which exploit the ability of movement. It also take advantages of the high level of acceptance that robotic vacuum cleaner already has, enhancing it as a robot companion. The human-robot interaction takes place on two levels: direct interaction, consisting of visual and sound signals; and mediated interaction, through a GUI for smartphone or tablet, and a wearable key (beacon) that allows the robot to recognize the presence of the user in the house. The robot, therefore, assumes the role of a mentor [1]: instead of taking actions in the environment, it advises the user, feature that makes it highly acceptable by the user [5].	0	The intent is to develop a robot companion, able to inform users and suggest them good practices for daily life improvement. This robot is able to detect environmental information like: humidity, temperature, electromagnetic pollution, smoke, CO2, benzene, various air pollutants and gas. Due to the potential offered by the current and perspective presence of RVC into home environment, this robot is developed as a parasite #CITATION_TAG in shape and behavior: it is physically attached to (clung) the RVC of which exploit the ability of movement. It also take advantages of the high level of acceptance that robotic vacuum cleaner already has, enhancing it as a robot companion. The human-robot interaction takes place on two levels: direct interaction, consisting of visual and sound signals; and mediated interaction, through a GUI for smartphone or tablet, and a wearable key (beacon) that allows the robot to recognize the presence of the user in the house. The robot, therefore, assumes the role of a mentor [1]: instead of taking actions in the environment, it advises the user, feature that makes it highly acceptable by the user [5].	e
CCT805	Today we are witnessing the diffusion of a large number of small robots that started to populate service environments like workplaces, public spaces and, especially, homes. Mobile robotics in domestic environment is quite diffused and consists primarily of cleaning robots, such as robotic vacuum cleaner, mopping robots or floor scrubbing robots. These types of robots are, then, crucial to understand how people perceive robots [4] and accept them in daily life. Recent studies [4] highlight common habits in Robotic Vacuum Cleaners owners, e.g. helping children to crawl, conversing, entertaining pets, watching for fun and, above all, naming the robot [4]. Indeed naming, in other words the act of giving a name declares the fact that the robot is perceived as a subject instead of an object. This high level of acceptance arises from the fact that users have low expectations towards RVC, due to the fact that is not perceived as a robot but rather as an household appliance #CITATION_TAG. High level of acceptance of these robots collides with the small cognitive capabilities. As a matter of fact, they are usually, able to move autonomously and avoid obstacles but do not have interaction and companioning capabilities. The presence of RVC in domestic environments is, anyway, extremely important because it, also, paves the way to the acceptance of other robots, as it is explained in [4], a survey conducted on 379 Roomba owners, the presence of RVC in domestic environments is the first step towards a wider acceptation of robots in daily life.	0	These types of robots are, then, crucial to understand how people perceive robots [4] and accept them in daily life. Recent studies [4] highlight common habits in Robotic Vacuum Cleaners owners, e.g. helping children to crawl, conversing, entertaining pets, watching for fun and, above all, naming the robot [4]. Indeed naming, in other words the act of giving a name declares the fact that the robot is perceived as a subject instead of an object. This high level of acceptance arises from the fact that users have low expectations towards RVC, due to the fact that is not perceived as a robot but rather as an household appliance #CITATION_TAG. High level of acceptance of these robots collides with the small cognitive capabilities. As a matter of fact, they are usually, able to move autonomously and avoid obstacles but do not have interaction and companioning capabilities. The presence of RVC in domestic environments is, anyway, extremely important because it, also, paves the way to the acceptance of other robots, as it is explained in [4], a survey conducted on 379 Roomba owners, the presence of RVC in domestic environments is the first step towards a wider acceptation of robots in daily life.	h
CCT806	However, one potentially important point that research using same/different tasks leaves unanswered is the exact nature and quality of the memory recollection for both the unique (A, B, C, and D) and common features (X) of the presented stimuli. Indeed, one prediction directly derived from the account proposed by  is that intermixed presentation will result in good, probably detailed, memory for the unique features of the stimuli (see #CITATION_TAG, Kadib, Mitchell, & Hall, 2011) and poor memory for the common features. Blocked presentation, on the other hand, will result in equally good (or poor) memory for both the unique and common features of the stimuli.	0	However, one potentially important point that research using same/different tasks leaves unanswered is the exact nature and quality of the memory recollection for both the unique (A, B, C, and D) and common features (X) of the presented stimuli. Indeed, one prediction directly derived from the account proposed by  is that intermixed presentation will result in good, probably detailed, memory for the unique features of the stimuli (see #CITATION_TAG, Kadib, Mitchell, & Hall, 2011) and poor memory for the common features. Blocked presentation, on the other hand, will result in equally good (or poor) memory for both the unique and common features of the stimuli.	n
CCT807	Research in perceptual learning has long shown that intermixed presentations result in improved ability to discriminate stimuli when compared to blocking different stimuli separately. For instance, using coloured checkerboards  demonstrated that preexposing stimuli intermixed resulted in improved discrimination accuracy in a same/ different task, when compared to blocked preexposure. #CITATION_TAG, Honey, and Dwyer (2007) obtained analogous results using morphed pictures of human faces. Moreover, these authors included a nonpreexposure group that resulted in worse performance than both the groups with blocked and intermixed preexposure (for similar results using checkerboards see Mundy, Honey, & Dwyer, 2009). One simple explanation for this advantage might be that intermixing directs attention to the relevant features of the stimuli. Indeed, in her influential theory of perceptual learning, Eleanor Gibson (1969) proposed that preexposure enhances discrimination through a process of differentiation. This mechanism involved the abstraction of the relevant features of the stimuli and filtering, or ignoring, the irrelevant features. Moreover, the process would be enhanced by situations that allowed for greater opportunity for comparison, as the intermixed schedule of presentation.	0	Research in perceptual learning has long shown that intermixed presentations result in improved ability to discriminate stimuli when compared to blocking different stimuli separately. For instance, using coloured checkerboards  demonstrated that preexposing stimuli intermixed resulted in improved discrimination accuracy in a same/ different task, when compared to blocked preexposure. #CITATION_TAG, Honey, and Dwyer (2007) obtained analogous results using morphed pictures of human faces. Moreover, these authors included a nonpreexposure group that resulted in worse performance than both the groups with blocked and intermixed preexposure (for similar results using checkerboards see Mundy, Honey, & Dwyer, 2009). One simple explanation for this advantage might be that intermixing directs attention to the relevant features of the stimuli. Indeed, in her influential theory of perceptual learning, Eleanor Gibson (1969) proposed that preexposure enhances discrimination through a process of differentiation.	I
CCT808	"Parental social position was indicated by paternal occupational position at the birth of the cohort child. We adapted the approach by Power et al, #CITATION_TAG classifying the Registrar General""s Social Classes of the cohort children""s father as: 1-professional or managerial (I and II); 2-skilled non-manual (III non-manual); 3-skilled manual (III manual); 4-partly skilled or unskilled (IV and V) and children who were born in a mother-only household. Midwives provided the information relevant to the birth of the cohort children, while the presence of phlegm or cough was assessed via the parental interview."	5	"Parental social position was indicated by paternal occupational position at the birth of the cohort child. We adapted the approach by Power et al, #CITATION_TAG classifying the Registrar General""s Social Classes of the cohort children""s father as: 1-professional or managerial (I and II); 2-skilled non-manual (III non-manual); 3-skilled manual (III manual); 4-partly skilled or unskilled (IV and V) and children who were born in a mother-only household. Midwives provided the information relevant to the birth of the cohort children, while the presence of phlegm or cough was assessed via the parental interview."	e
CCT809	A pattern of co-occurring phlegm and cough (no symptoms, phlegm only, cough only, phlegm and cough) in adulthood was the outcome of this study. Cohort participants were asked to respond whether they usually brought up phlegm or experienced coughing in the morning, during the day or at night in the winter when they were 29 years old. These questions were from the Medical Research Council (MRC) Questionnaire on respiratory symptoms and have been widely used, including in the previous cohort study (ie, National Child Developmental Study). 21 We adapted the method used by #CITATION_TAG et al 22 and created a variable to indicate presence of each respiratory symptom ( phlegm or cough), which cohort participants might have experienced at any time of day. After that we derived a variable with four response patterns of adult respiratory symptoms by combining the response to each variable obtained at age 29: 0 no respiratory symptoms, 1 phlegm only, 2 cough only and 3 phlegm and cough.	5	A pattern of co-occurring phlegm and cough (no symptoms, phlegm only, cough only, phlegm and cough) in adulthood was the outcome of this study. Cohort participants were asked to respond whether they usually brought up phlegm or experienced coughing in the morning, during the day or at night in the winter when they were 29 years old. These questions were from the Medical Research Council (MRC) Questionnaire on respiratory symptoms and have been widely used, including in the previous cohort study (ie, National Child Developmental Study). 21 We adapted the method used by #CITATION_TAG et al 22 and created a variable to indicate presence of each respiratory symptom ( phlegm or cough), which cohort participants might have experienced at any time of day. After that we derived a variable with four response patterns of adult respiratory symptoms by combining the response to each variable obtained at age 29: 0 no respiratory symptoms, 1 phlegm only, 2 cough only and 3 phlegm and cough.	W
CCT810	A pattern of co-occurring phlegm and cough (no symptoms, phlegm only, cough only, phlegm and cough) in adulthood was the outcome of this study. Cohort participants were asked to respond whether they usually brought up phlegm or experienced coughing in the morning, during the day or at night in the winter when they were 29 years old. These questions were from the Medical Research Council (MRC) Questionnaire on respiratory symptoms and have been widely used, including in the previous cohort study (ie, National Child Developmental Study). 21 We adapted the method used by Strachan et al #CITATION_TAG and created a variable to indicate presence of each respiratory symptom ( phlegm or cough), which cohort participants might have experienced at any time of day. After that we derived a variable with four response patterns of adult respiratory symptoms by combining the response to each variable obtained at age 29: 0 no respiratory symptoms, 1 phlegm only, 2 cough only and 3 phlegm and cough.	5	A pattern of co-occurring phlegm and cough (no symptoms, phlegm only, cough only, phlegm and cough) in adulthood was the outcome of this study. Cohort participants were asked to respond whether they usually brought up phlegm or experienced coughing in the morning, during the day or at night in the winter when they were 29 years old. These questions were from the Medical Research Council (MRC) Questionnaire on respiratory symptoms and have been widely used, including in the previous cohort study (ie, National Child Developmental Study). 21 We adapted the method used by Strachan et al #CITATION_TAG and created a variable to indicate presence of each respiratory symptom ( phlegm or cough), which cohort participants might have experienced at any time of day. After that we derived a variable with four response patterns of adult respiratory symptoms by combining the response to each variable obtained at age 29: 0 no respiratory symptoms, 1 phlegm only, 2 cough only and 3 phlegm and cough.	W
CCT811	Our finding linking household dampness with presence of phlegm in adulthood is similar to the findings by Sahlberg et al 26 that adults exposed to household dampness showed increased occurrence of mucosal symptoms 10 years later. Our finding is also similar to the meta-analyses results by Mendell et al #CITATION_TAG showing a substantial association between indoor dampness and various respiratory symptoms, including cough. Our finding supports longitudinal associations between childhood exposures and adult respiratory symptoms similar to the study by Mann et al. 7 We are the first to show a substantial contribution of childhood exposure to household dampness to co-occurring phlegm and cough at age 29.	1	Our finding linking household dampness with presence of phlegm in adulthood is similar to the findings by Sahlberg et al 26 that adults exposed to household dampness showed increased occurrence of mucosal symptoms 10 years later. Our finding is also similar to the meta-analyses results by Mendell et al #CITATION_TAG showing a substantial association between indoor dampness and various respiratory symptoms, including cough. Our finding supports longitudinal associations between childhood exposures and adult respiratory symptoms similar to the study by Mann et al. 7 We are the first to show a substantial contribution of childhood exposure to household dampness to co-occurring phlegm and cough at age 29.	u
CCT812	Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Most approaches are inductive in the sense that statistical or machine learning methods are used to find predictive models based on attributes derived from static code analysis and/or process metrics such as change data. Useful systematic literature reviews of research progress may be found in [1,#CITATION_TAG].	0	Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Most approaches are inductive in the sense that statistical or machine learning methods are used to find predictive models based on attributes derived from static code analysis and/or process metrics such as change data. Useful systematic literature reviews of research progress may be found in [1,#CITATION_TAG].	f
CCT813	Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Most approaches are inductive in the sense that statistical or machine learning methods are used to find predictive models based on attributes derived from static code analysis and/or process metrics such as change data. Useful systematic literature reviews of research progress may be found in [#CITATION_TAG,2].	0	Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Most approaches are inductive in the sense that statistical or machine learning methods are used to find predictive models based on attributes derived from static code analysis and/or process metrics such as change data. Useful systematic literature reviews of research progress may be found in [#CITATION_TAG,2].	f
CCT814	A challenge has been that whilst there has been much research activity and ingenuity in devising new techniques there has been rather less agreement upon the relative effectiveness of these different techniques and clearly no one technique dominates #CITATION_TAG. This inability to replicate results is hindering our ability to make progress and make practical recommendations to practitioners.	0	A challenge has been that whilst there has been much research activity and ingenuity in devising new techniques there has been rather less agreement upon the relative effectiveness of these different techniques and clearly no one technique dominates #CITATION_TAG. This inability to replicate results is hindering our ability to make progress and make practical recommendations to practitioners.	A
CCT815	Bias is not a new phenomenon and has been widely reported in other scientific disciplines such as psychology #CITATION_TAG and medicine [5]. The purpose of scientific methods are to reduce bias through the pursuit of transparency and the reduction of subjectivity.	5	Bias is not a new phenomenon and has been widely reported in other scientific disciplines such as psychology #CITATION_TAG and medicine [5]. The purpose of scientific methods are to reduce bias through the pursuit of transparency and the reduction of subjectivity.	B
CCT816	Bias is not a new phenomenon and has been widely reported in other scientific disciplines such as psychology [4] and medicine #CITATION_TAG. The purpose of scientific methods are to reduce bias through the pursuit of transparency and the reduction of subjectivity.	5	Bias is not a new phenomenon and has been widely reported in other scientific disciplines such as psychology [4] and medicine #CITATION_TAG. The purpose of scientific methods are to reduce bias through the pursuit of transparency and the reduction of subjectivity.	B
CCT817	"The ROC curve and its properties have been extensively studied and are well understood -see [10,11]  t represent two values of the threshold. When such convex regions occur, it is possible to define a ""randomised"" diagnostic test which yields a ROC curve corresponding to a dominating curve, and which has sensitivity which is always equal to or greater than that of the original test, for all values of specificity. We will not go into details here, since it will distract us from the core of the argument. Interested readers can refer to #CITATION_TAG (though note that, in accordance with machine learning conventions, that paper uses the terms ""convex"" and ""concave"" in the sense opposite to that used above -see the paper for details, and explanations). For simplicity of exposition, in what follows we will assume that the ROC curve is strictly monotonic increasing, and that the first derivative is strictly monotonic decreasing. We will also assume that the ROC curve is continuous and everywhere differentiable. These simplifying assumptions do not detract from the generality of the conclusions, and the program described at the end of Section 4 can handle general cases."	0	"The ROC curve and its properties have been extensively studied and are well understood -see [10,11]  t represent two values of the threshold. When such convex regions occur, it is possible to define a ""randomised"" diagnostic test which yields a ROC curve corresponding to a dominating curve, and which has sensitivity which is always equal to or greater than that of the original test, for all values of specificity. We will not go into details here, since it will distract us from the core of the argument. Interested readers can refer to #CITATION_TAG (though note that, in accordance with machine learning conventions, that paper uses the terms ""convex"" and ""concave"" in the sense opposite to that used above -see the paper for details, and explanations). For simplicity of exposition, in what follows we will assume that the ROC curve is strictly monotonic increasing, and that the first derivative is strictly monotonic decreasing. We will also assume that the ROC curve is continuous and everywhere differentiable. These simplifying assumptions do not detract from the generality of the conclusions, and the program described at the end of Section 4 can handle general cases."	e
CCT818	Diagnosis is the first step in medical care. Correct diagnosis can lead to cure, and mistaken diagnosis to incorrect treatment, sometimes with serious consequences. For this reason, there is now an extensive literature on the evaluation of diagnostic tests: that is, on methods and measures to determine how effective a given test is. This literature is spread throughout the medical specialities, and also within the more general statistical and biostatistical literature. There are now several books devoted entirely to evaluating diagnostic tests [#CITATION_TAG,2].	0	Correct diagnosis can lead to cure, and mistaken diagnosis to incorrect treatment, sometimes with serious consequences. For this reason, there is now an extensive literature on the evaluation of diagnostic tests: that is, on methods and measures to determine how effective a given test is. This literature is spread throughout the medical specialities, and also within the more general statistical and biostatistical literature. There are now several books devoted entirely to evaluating diagnostic tests [#CITATION_TAG,2].	e
CCT819	"To produce a single measure of performance of a diagnostic test (by means of which tests can be evaluated and compared), sensitivity and specificity need to be combined. This can be done in an unlimited number of different ways. Since each way represents a different aspect of performance, it would be incorrect to assert that any one of these ways was ""wrong"" and others ""right"" -they merely measure different things -but, in general, one should match one""s measure of performance to what one is trying to achieve. These and related issues are discussed further in [3,4,5,#CITATION_TAG]."	0	"To produce a single measure of performance of a diagnostic test (by means of which tests can be evaluated and compared), sensitivity and specificity need to be combined. This can be done in an unlimited number of different ways. Since each way represents a different aspect of performance, it would be incorrect to assert that any one of these ways was ""wrong"" and others ""right"" -they merely measure different things -but, in general, one should match one""s measure of performance to what one is trying to achieve. These and related issues are discussed further in [3,4,5,#CITATION_TAG]."	s
CCT820	Diagnosis is the first step in medical care. Correct diagnosis can lead to cure, and mistaken diagnosis to incorrect treatment, sometimes with serious consequences. For this reason, there is now an extensive literature on the evaluation of diagnostic tests: that is, on methods and measures to determine how effective a given test is. This literature is spread throughout the medical specialities, and also within the more general statistical and biostatistical literature. There are now several books devoted entirely to evaluating diagnostic tests [1,#CITATION_TAG].	0	Correct diagnosis can lead to cure, and mistaken diagnosis to incorrect treatment, sometimes with serious consequences. For this reason, there is now an extensive literature on the evaluation of diagnostic tests: that is, on methods and measures to determine how effective a given test is. This literature is spread throughout the medical specialities, and also within the more general statistical and biostatistical literature. There are now several books devoted entirely to evaluating diagnostic tests [1,#CITATION_TAG].	e
CCT821	"To produce a single measure of performance of a diagnostic test (by means of which tests can be evaluated and compared), sensitivity and specificity need to be combined. This can be done in an unlimited number of different ways. Since each way represents a different aspect of performance, it would be incorrect to assert that any one of these ways was ""wrong"" and others ""right"" -they merely measure different things -but, in general, one should match one""s measure of performance to what one is trying to achieve. These and related issues are discussed further in [3,#CITATION_TAG,5,6]."	4	"To produce a single measure of performance of a diagnostic test (by means of which tests can be evaluated and compared), sensitivity and specificity need to be combined. This can be done in an unlimited number of different ways. Since each way represents a different aspect of performance, it would be incorrect to assert that any one of these ways was ""wrong"" and others ""right"" -they merely measure different things -but, in general, one should match one""s measure of performance to what one is trying to achieve. These and related issues are discussed further in [3,#CITATION_TAG,5,6]."	s
CCT822	"To produce a single measure of performance of a diagnostic test (by means of which tests can be evaluated and compared), sensitivity and specificity need to be combined. This can be done in an unlimited number of different ways. Since each way represents a different aspect of performance, it would be incorrect to assert that any one of these ways was ""wrong"" and others ""right"" -they merely measure different things -but, in general, one should match one""s measure of performance to what one is trying to achieve. These and related issues are discussed further in [3,4,#CITATION_TAG,6]."	5	"To produce a single measure of performance of a diagnostic test (by means of which tests can be evaluated and compared), sensitivity and specificity need to be combined. This can be done in an unlimited number of different ways. Since each way represents a different aspect of performance, it would be incorrect to assert that any one of these ways was ""wrong"" and others ""right"" -they merely measure different things -but, in general, one should match one""s measure of performance to what one is trying to achieve. These and related issues are discussed further in [3,4,#CITATION_TAG,6]."	s
CCT823	"Misclassification rate or error rate uses ( ) ( ) and is reported in #CITATION_TAG, in a meta-analysis of classification studies, as being used in ""the vast majority"" of comparative studies of classification rules (p19). The Kolmogorov-Smirnov statistic uses ( ) ( )"	4	"Misclassification rate or error rate uses ( ) ( ) and is reported in #CITATION_TAG, in a meta-analysis of classification studies, as being used in ""the vast majority"" of comparative studies of classification rules (p19). The Kolmogorov-Smirnov statistic uses ( ) ( )"	M
CCT824	"The ROC curve and its properties have been extensively studied and are well understood -see [#CITATION_TAG,11]  t represent two values of the threshold. When such convex regions occur, it is possible to define a ""randomised"" diagnostic test which yields a ROC curve corresponding to a dominating curve, and which has sensitivity which is always equal to or greater than that of the original test, for all values of specificity. We will not go into details here, since it will distract us from the core of the argument. Interested readers can refer to [12] (though note that, in accordance with machine learning conventions, that paper uses the terms ""convex"" and ""concave"" in the sense opposite to that used above -see the paper for details, and explanations). For simplicity of exposition, in what follows we will assume that the ROC curve is strictly monotonic increasing, and that the first derivative is strictly monotonic decreasing. We will also assume that the ROC curve is continuous and everywhere differentiable. These simplifying assumptions do not detract from the generality of the conclusions, and the program described at the end of Section 4 can handle general cases."	0	"The ROC curve and its properties have been extensively studied and are well understood -see [#CITATION_TAG,11]  t represent two values of the threshold. When such convex regions occur, it is possible to define a ""randomised"" diagnostic test which yields a ROC curve corresponding to a dominating curve, and which has sensitivity which is always equal to or greater than that of the original test, for all values of specificity. We will not go into details here, since it will distract us from the core of the argument. Interested readers can refer to [12] (though note that, in accordance with machine learning conventions, that paper uses the terms ""convex"" and ""concave"" in the sense opposite to that used above -see the paper for details, and explanations)."	T
CCT825	Partly in an attempt to overcome this problem, and partly in recognition of the fact that it is likely that not all values of sensitivity or specificity will be regarded as relevant, various researchers have proposed the use of the partial AUC, PAUC, in which the integration in (3) is not over the entire range of sensitivity (or specificity), but over some interval [ ] , a b within [ ] 0,1 , regarded as of particular relevance (see, for example, #CITATION_TAG). Of course, this requires the user to specify a and b, which means that the non-subjective merit of the AUC is lost. In any case, it is entirely possible that the interval [ ] , a b will include a point where the ROC curves cross. Furthermore, the PAUC has the unfortunate implication that values of sensitivity just outside the interval are discounted, whereas those just inside are included. An alternative solution would be to choose a smooth non-uniform distribution with support [ ] 0,1 .	1	Partly in an attempt to overcome this problem, and partly in recognition of the fact that it is likely that not all values of sensitivity or specificity will be regarded as relevant, various researchers have proposed the use of the partial AUC, PAUC, in which the integration in (3) is not over the entire range of sensitivity (or specificity), but over some interval [ ] , a b within [ ] 0,1 , regarded as of particular relevance (see, for example, #CITATION_TAG). Of course, this requires the user to specify a and b, which means that the non-subjective merit of the AUC is lost. In any case, it is entirely possible that the interval [ ] , a b will include a point where the ROC curves cross. Furthermore, the PAUC has the unfortunate implication that values of sensitivity just outside the interval are discounted, whereas those just inside are included.	P
CCT826	Incidentally, it has been pointed out in #CITATION_TAG that estimates of the area under the ROC curve based on the data used to derive the score function will tend to be optimistically biased. This is similar to the more well-known optimism of estimates of misclassification rate resulting when the same data set is used to construct a diagnostic rule and estimate its likely future misclassification rate. The same effect will apply for the H measure.	0	Incidentally, it has been pointed out in #CITATION_TAG that estimates of the area under the ROC curve based on the data used to derive the score function will tend to be optimistically biased. This is similar to the more well-known optimism of estimates of misclassification rate resulting when the same data set is used to construct a diagnostic rule and estimate its likely future misclassification rate. The same effect will apply for the H measure.	I
CCT827	"Often (perhaps almost always), however, deciding exactly what this balance should be is difficult. We therefore suggested that, instead of picking a particular balance, one should take an expectation of the minimum weighted misclassification loss over a distribution of values of the weights defining the balance. This is analogous to the AUC, which is an average of specificity over a uniform distribution of sensitivity, except that we take the expectation over the severity balance between the two kinds of misdiagnosis, instead of over sensitivity. We then showed that the AUC itself could be expressed as an expectation over the minimum balanced misclassification loss. However, it turns out that the expectation is with respect to distributions of the relative severity of the two kinds of misclassification which differ between different diagnostic tests. This is simply a consequence of the way the AUC is defined. This seems inappropriate: one""s beliefs about the relative severity of the consequences of the two kinds of misclassification cannot depend on the diagnostic test one happens to have chosen. It would mean that one could alleviate suffering simply by choosing a different diagnostic instrument. Although the AUC has been criticised on various methodological grounds (see, for example, [#CITATION_TAG,16]) this interpretation suggests that it also has a core theoretical weakness, at least when viewed from some perspectives."	0	"This is simply a consequence of the way the AUC is defined. This seems inappropriate: one""s beliefs about the relative severity of the consequences of the two kinds of misclassification cannot depend on the diagnostic test one happens to have chosen. It would mean that one could alleviate suffering simply by choosing a different diagnostic instrument. Although the AUC has been criticised on various methodological grounds (see, for example, [#CITATION_TAG,16]) this interpretation suggests that it also has a core theoretical weakness, at least when viewed from some perspectives."	 
CCT828	"Often (perhaps almost always), however, deciding exactly what this balance should be is difficult. We therefore suggested that, instead of picking a particular balance, one should take an expectation of the minimum weighted misclassification loss over a distribution of values of the weights defining the balance. This is analogous to the AUC, which is an average of specificity over a uniform distribution of sensitivity, except that we take the expectation over the severity balance between the two kinds of misdiagnosis, instead of over sensitivity. We then showed that the AUC itself could be expressed as an expectation over the minimum balanced misclassification loss. However, it turns out that the expectation is with respect to distributions of the relative severity of the two kinds of misclassification which differ between different diagnostic tests. This is simply a consequence of the way the AUC is defined. This seems inappropriate: one""s beliefs about the relative severity of the consequences of the two kinds of misclassification cannot depend on the diagnostic test one happens to have chosen. It would mean that one could alleviate suffering simply by choosing a different diagnostic instrument. Although the AUC has been criticised on various methodological grounds (see, for example, [15,#CITATION_TAG]) this interpretation suggests that it also has a core theoretical weakness, at least when viewed from some perspectives."	1	"This is simply a consequence of the way the AUC is defined. This seems inappropriate: one""s beliefs about the relative severity of the consequences of the two kinds of misclassification cannot depend on the diagnostic test one happens to have chosen. It would mean that one could alleviate suffering simply by choosing a different diagnostic instrument. Although the AUC has been criticised on various methodological grounds (see, for example, [15,#CITATION_TAG]) this interpretation suggests that it also has a core theoretical weakness, at least when viewed from some perspectives."	 
CCT829	"type of analysis to explore social responsibility phenomena (for exceptions, see Crilly, 2013;Crilly et al., 2012). Accordingly, this analysis shows that fsQCA is a valuable analytical tool that researchers can use in conjunction with other analytical techniques (e.g., SEM, MRA) with a view to developing better explanations on how causes combine to create an outcome (Ragin, 2008;Stanko & Olleros, 2013). Thus, fsQCA is a powerful, new, and proper analytical tool that can help in further advancing of the knowledge in the CSR domain. From a managerial perspective, the findings produce several implications. First, CSR skepticism seems to emerge in the presence of egoistic-driven attributions, absence of values-driven motives, and lack of customer orientation. Therefore, managers should consider concentrating efforts on understanding their customers, closely monitoring their perceptions about the company, and devoting attention to accommodating their individual requirements (#CITATION_TAG et al., 2011). In this way, companies might be in a better position to manage CSR skepticism, understand how customers"" perceive different socially responsible actions, and appropriately take action when the need arises. Second, the absence of CSR skepticism and the presence of customer orientation can help retailers build equity. Therefore, managers should keep skepticism levels as low as possible to allow customers to understand the value proposition offered."	0	"Thus, fsQCA is a powerful, new, and proper analytical tool that can help in further advancing of the knowledge in the CSR domain. From a managerial perspective, the findings produce several implications. First, CSR skepticism seems to emerge in the presence of egoistic-driven attributions, absence of values-driven motives, and lack of customer orientation. Therefore, managers should consider concentrating efforts on understanding their customers, closely monitoring their perceptions about the company, and devoting attention to accommodating their individual requirements (#CITATION_TAG et al., 2011). In this way, companies might be in a better position to manage CSR skepticism, understand how customers"" perceive different socially responsible actions, and appropriately take action when the need arises. Second, the absence of CSR skepticism and the presence of customer orientation can help retailers build equity. Therefore, managers should keep skepticism levels as low as possible to allow customers to understand the value proposition offered."	f
CCT830	"The present study builds on the existing literature that underscores the value of fuzzy-set qualitative comparative analysis (fsQCA) (e.g., Fiss, 2011;#CITATION_TAG, 2013;Woodside & Zhang, 2013) and shows that the proposed methodological tool offers much in terms of understanding causal relationships, by virtue of providing information that is unique in comparison with the information that conventional correlational methods provide. In this regard, the study implements fsQCA with SL""s dataset and illustrates how this technique can supplement correlational techniques, by offering a more holistic, combinatorial view of the examined inter-relationships."	0	"The present study builds on the existing literature that underscores the value of fuzzy-set qualitative comparative analysis (fsQCA) (e.g., Fiss, 2011;#CITATION_TAG, 2013;Woodside & Zhang, 2013) and shows that the proposed methodological tool offers much in terms of understanding causal relationships, by virtue of providing information that is unique in comparison with the information that conventional correlational methods provide. In this regard, the study implements fsQCA with SL""s dataset and illustrates how this technique can supplement correlational techniques, by offering a more holistic, combinatorial view of the examined inter-relationships."	T
CCT831	The majority of fsQCA applications are in political science and sociology. Representative contributions from various sub-fields include policy analysis (e.g., Blake & Adolino, 2001), political parties (e.g., Gordin, 2001), social and political change (e.g., Berg-Schlosser & De Meur, 1994), social movements (e.g., Nomiya, 2001), welfare states (e.g., Peillon, 1996), law and criminology (e.g., Tarohmaru, 2001), linguistics (e.g., Mendel & Korjani, 2012), psychology (e.g., Theuns, 1994), and addictive behavior (e.g., Eng & Woodside, 2012). Applications of the technique in business and management are fewer, though representative examples are available in areas such as international business (e.g., Pajunen, 2008;Schneider et al., 2010), innovation (e.g., Cheng et al., 2013;Ganter & Hecker, 2013;Stanko & Olleros, 2013), organizational behavior and strategic management (e.g., Fiss, 2011;Greckhamer et al., 2008;Stokke, 2007), inter-organizational alliances (e.g., Leischnig et al., 2013), tourism management (e.g., Woodside et al., 2011), socially responsible practices (e.g., Crilly et al., 2012), and labor relations (e.g., Coverdill et al., 1994). Ragin (2000) was the first to introduce fsQCA; this technique differs from regression-based methods and other conventional statistical techniques in important ways (Mahoney & Goertz, 2006;Pajunen, 2008). For example, in contrast with correlational techniques, which attempt to estimate the net effect of an independent variable on an outcome variable, fsQCA attempts to identify the conditions that lead to a given outcome (Schneider et al., 2010). As such, fsQCA is a proficient tool that helps supplement traditional correlational analyses in three main ways: (1) asymmetry (i.e., the relationships between independent and dependent variables are treated as not symmetric), ( 2) equifinality (i.e., multiple pathways and solutions lead to the same outcome), and (3) causal complexity (i.e., combinations of causal antecedent conditions lead to the outcome, and thus the researcher focuses not on the estimation of independent net effects but on the estimation of combinatorial effects) (#CITATION_TAG, 2013).	0	Applications of the technique in business and management are fewer, though representative examples are available in areas such as international business (e.g., Pajunen, 2008;Schneider et al., 2010), innovation (e.g., Cheng et al., 2013;Ganter & Hecker, 2013;Stanko & Olleros, 2013), organizational behavior and strategic management (e.g., Fiss, 2011;Greckhamer et al., 2008;Stokke, 2007), inter-organizational alliances (e.g., Leischnig et al., 2013), tourism management (e.g., Woodside et al., 2011), socially responsible practices (e.g., Crilly et al., 2012), and labor relations (e.g., Coverdill et al., 1994). Ragin (2000) was the first to introduce fsQCA; this technique differs from regression-based methods and other conventional statistical techniques in important ways (Mahoney & Goertz, 2006;Pajunen, 2008). For example, in contrast with correlational techniques, which attempt to estimate the net effect of an independent variable on an outcome variable, fsQCA attempts to identify the conditions that lead to a given outcome (Schneider et al., 2010). As such, fsQCA is a proficient tool that helps supplement traditional correlational analyses in three main ways: (1) asymmetry (i.e., the relationships between independent and dependent variables are treated as not symmetric), ( 2) equifinality (i.e., multiple pathways and solutions lead to the same outcome), and (3) causal complexity (i.e., combinations of causal antecedent conditions lead to the outcome, and thus the researcher focuses not on the estimation of independent net effects but on the estimation of combinatorial effects) (#CITATION_TAG, 2013).	c
CCT832	"The present study builds on the existing literature that underscores the value of fuzzy-set qualitative comparative analysis (fsQCA) (e.g., #CITATION_TAG, 2011;Woodside, 2013;Woodside & Zhang, 2013) and shows that the proposed methodological tool offers much in terms of understanding causal relationships, by virtue of providing information that is unique in comparison with the information that conventional correlational methods provide. In this regard, the study implements fsQCA with SL""s dataset and illustrates how this technique can supplement correlational techniques, by offering a more holistic, combinatorial view of the examined inter-relationships."	0	"The present study builds on the existing literature that underscores the value of fuzzy-set qualitative comparative analysis (fsQCA) (e.g., #CITATION_TAG, 2011;Woodside, 2013;Woodside & Zhang, 2013) and shows that the proposed methodological tool offers much in terms of understanding causal relationships, by virtue of providing information that is unique in comparison with the information that conventional correlational methods provide. In this regard, the study implements fsQCA with SL""s dataset and illustrates how this technique can supplement correlational techniques, by offering a more holistic, combinatorial view of the examined inter-relationships."	T
CCT833	This study contributes to the literature in two ways. First, from a methodological perspective, the study demonstrates the value of complex combinatorial fsQCA and the advantages of this technique over traditional correlational methods; that is, fsQCA enables examination of different configurations of conditions that give rise to an outcome of interest (Ganter & Hecker, 2013;#CITATION_TAG & Olleros, 2013). Second, from a theoretical perspective, the study builds and expands on the findings of SL by showing that alternative routes to CSR skepticism and its outcomes likely occur, in addition to those SL present. Overall, the aim is to estimate the alternative complex antecedent conditions (or causal recipes) that lead to high membership in four outcome conditions: (1) CSR consumer skepticism, (2) retailer equity, (3) resilience to negative information about the retailer, and (4) WOM. The value of this study lies in the effort to describe combinatorial complexities assuming asymmetrical relationships between variables, rather than symmetrical net effects that multiple regression analysis (MRA) and SEM usually estimate.	0	This study contributes to the literature in two ways. First, from a methodological perspective, the study demonstrates the value of complex combinatorial fsQCA and the advantages of this technique over traditional correlational methods; that is, fsQCA enables examination of different configurations of conditions that give rise to an outcome of interest (Ganter & Hecker, 2013;#CITATION_TAG & Olleros, 2013). Second, from a theoretical perspective, the study builds and expands on the findings of SL by showing that alternative routes to CSR skepticism and its outcomes likely occur, in addition to those SL present. Overall, the aim is to estimate the alternative complex antecedent conditions (or causal recipes) that lead to high membership in four outcome conditions: (1) CSR consumer skepticism, (2) retailer equity, (3) resilience to negative information about the retailer, and (4) WOM. The value of this study lies in the effort to describe combinatorial complexities assuming asymmetrical relationships between variables, rather than symmetrical net effects that multiple regression analysis (MRA) and SEM usually estimate.	i
CCT834	The majority of fsQCA applications are in political science and sociology. Representative contributions from various sub-fields include policy analysis (e.g., Blake & Adolino, 2001), political parties (e.g., Gordin, 2001), social and political change (e.g., Berg-Schlosser & De Meur, 1994), social movements (e.g., Nomiya, 2001), welfare states (e.g., Peillon, 1996), law and criminology (e.g., Tarohmaru, 2001), linguistics (e.g., Mendel & Korjani, 2012), psychology (e.g., Theuns, 1994), and addictive behavior (e.g., Eng & Woodside, 2012). Applications of the technique in business and management are fewer, though representative examples are available in areas such as international business (e.g., Pajunen, 2008;Schneider et al., 2010), innovation (e.g., Cheng et al., 2013;Ganter & Hecker, 2013;Stanko & Olleros, 2013), organizational behavior and strategic management (e.g., Fiss, 2011;Greckhamer et al., 2008;Stokke, 2007), inter-organizational alliances (e.g., Leischnig et al., 2013), tourism management (e.g., Woodside et al., 2011), socially responsible practices (e.g., Crilly et al., 2012), and labor relations (e.g., Coverdill et al., 1994). Ragin (2000) was the first to introduce fsQCA; this technique differs from regression-based methods and other conventional statistical techniques in important ways (Mahoney & Goertz, 2006;Pajunen, 2008). For example, in contrast with correlational techniques, which attempt to estimate the net effect of an independent variable on an outcome variable, fsQCA attempts to identify the conditions that lead to a given outcome (#CITATION_TAG et al., 2010). As such, fsQCA is a proficient tool that helps supplement traditional correlational analyses in three main ways: (1) asymmetry (i.e., the relationships between independent and dependent variables are treated as not symmetric), ( 2) equifinality (i.e., multiple pathways and solutions lead to the same outcome), and (3) causal complexity (i.e., combinations of causal antecedent conditions lead to the outcome, and thus the researcher focuses not on the estimation of independent net effects but on the estimation of combinatorial effects) (Elliott, 2013).	5	Representative contributions from various sub-fields include policy analysis (e.g., Blake & Adolino, 2001), political parties (e.g., Gordin, 2001), social and political change (e.g., Berg-Schlosser & De Meur, 1994), social movements (e.g., Nomiya, 2001), welfare states (e.g., Peillon, 1996), law and criminology (e.g., Tarohmaru, 2001), linguistics (e.g., Mendel & Korjani, 2012), psychology (e.g., Theuns, 1994), and addictive behavior (e.g., Eng & Woodside, 2012). Applications of the technique in business and management are fewer, though representative examples are available in areas such as international business (e.g., Pajunen, 2008;Schneider et al., 2010), innovation (e.g., Cheng et al., 2013;Ganter & Hecker, 2013;Stanko & Olleros, 2013), organizational behavior and strategic management (e.g., Fiss, 2011;Greckhamer et al., 2008;Stokke, 2007), inter-organizational alliances (e.g., Leischnig et al., 2013), tourism management (e.g., Woodside et al., 2011), socially responsible practices (e.g., Crilly et al., 2012), and labor relations (e.g., Coverdill et al., 1994). Ragin (2000) was the first to introduce fsQCA; this technique differs from regression-based methods and other conventional statistical techniques in important ways (Mahoney & Goertz, 2006;Pajunen, 2008). For example, in contrast with correlational techniques, which attempt to estimate the net effect of an independent variable on an outcome variable, fsQCA attempts to identify the conditions that lead to a given outcome (#CITATION_TAG et al., 2010). As such, fsQCA is a proficient tool that helps supplement traditional correlational analyses in three main ways: (1) asymmetry (i.e., the relationships between independent and dependent variables are treated as not symmetric), ( 2) equifinality (i.e., multiple pathways and solutions lead to the same outcome), and (3) causal complexity (i.e., combinations of causal antecedent conditions lead to the outcome, and thus the researcher focuses not on the estimation of independent net effects but on the estimation of combinatorial effects) (Elliott, 2013).	e
CCT835	"A complex solution makes no simplifying assumptions. As a result, if the researcher considers a large number of causal antecedent conditions, the derived solution will be fairly complicated. The parsimonious solution uses the remainders (i.e., combinations of the antecedent conditions not observed in the dataset) to simplify the solution. With such a strong assumption, the parsimonious solution should only be used if the assumptions are fully justified. Finally, the intermediate solution distinguishes between ""easy"" and ""strong"" assumptions and takes into consideration only the ""easy"" remainders when simplifying the solution. Thus, the complex solution, which makes no assumptions, is the most appropriate; prior research highly recommends this solution especially when the number of causal antecedent conditions is not large (Elliott, 2013;#CITATION_TAG & Sonnett, 2005)."	5	"The parsimonious solution uses the remainders (i.e., combinations of the antecedent conditions not observed in the dataset) to simplify the solution. With such a strong assumption, the parsimonious solution should only be used if the assumptions are fully justified. Finally, the intermediate solution distinguishes between ""easy"" and ""strong"" assumptions and takes into consideration only the ""easy"" remainders when simplifying the solution. Thus, the complex solution, which makes no assumptions, is the most appropriate; prior research highly recommends this solution especially when the number of causal antecedent conditions is not large (Elliott, 2013;#CITATION_TAG & Sonnett, 2005)."	 
CCT836	This study contributes to the literature in two ways. First, from a methodological perspective, the study demonstrates the value of complex combinatorial fsQCA and the advantages of this technique over traditional correlational methods; that is, fsQCA enables examination of different configurations of conditions that give rise to an outcome of interest (#CITATION_TAG & Hecker, 2013;Stanko & Olleros, 2013). Second, from a theoretical perspective, the study builds and expands on the findings of SL by showing that alternative routes to CSR skepticism and its outcomes likely occur, in addition to those SL present. Overall, the aim is to estimate the alternative complex antecedent conditions (or causal recipes) that lead to high membership in four outcome conditions: (1) CSR consumer skepticism, (2) retailer equity, (3) resilience to negative information about the retailer, and (4) WOM. The value of this study lies in the effort to describe combinatorial complexities assuming asymmetrical relationships between variables, rather than symmetrical net effects that multiple regression analysis (MRA) and SEM usually estimate.	5	This study contributes to the literature in two ways. First, from a methodological perspective, the study demonstrates the value of complex combinatorial fsQCA and the advantages of this technique over traditional correlational methods; that is, fsQCA enables examination of different configurations of conditions that give rise to an outcome of interest (#CITATION_TAG & Hecker, 2013;Stanko & Olleros, 2013). Second, from a theoretical perspective, the study builds and expands on the findings of SL by showing that alternative routes to CSR skepticism and its outcomes likely occur, in addition to those SL present. Overall, the aim is to estimate the alternative complex antecedent conditions (or causal recipes) that lead to high membership in four outcome conditions: (1) CSR consumer skepticism, (2) retailer equity, (3) resilience to negative information about the retailer, and (4) WOM. The value of this study lies in the effort to describe combinatorial complexities assuming asymmetrical relationships between variables, rather than symmetrical net effects that multiple regression analysis (MRA) and SEM usually estimate.	i
CCT837	"The need for alternative techniques 3.1. Focus on the ""net effect"" estimation Multiple regression equations follow a net effects estimation approach (i.e., estimation of the effect size of each independent variable on the dependent variable, after controlling for the impact of the other independent variables also included in the equation). However, multicollinearity (i.e., significant correlations among the independent variables) is common, especially in cases with a large number of independent variables (e.g., Mittal et al., 1998;Wittink & Bayer, 1994). If multicollinearity is high, the regression estimator becomes inefficient and may yield statistically non-significant estimates or estimates inconsistent with the supposed associations (e.g., Van der Meer et al., 2005). Even in cases of low multicollinearity, the estimated net effects of the independent variables may change from significant to non-significant depending on the additional independent variables that enter the equation (Woodside, 2013). #CITATION_TAG (2012) posits that researchers who use regression analysis falsely assume that by entering variables into the equation, they somehow control for these variables. However, adding variables in non-experimental studies does not mean controlling for them because predictors usually co-vary with each other."	5	However, multicollinearity (i.e., significant correlations among the independent variables) is common, especially in cases with a large number of independent variables (e.g., Mittal et al., 1998;Wittink & Bayer, 1994). If multicollinearity is high, the regression estimator becomes inefficient and may yield statistically non-significant estimates or estimates inconsistent with the supposed associations (e.g., Van der Meer et al., 2005). Even in cases of low multicollinearity, the estimated net effects of the independent variables may change from significant to non-significant depending on the additional independent variables that enter the equation (Woodside, 2013). #CITATION_TAG (2012) posits that researchers who use regression analysis falsely assume that by entering variables into the equation, they somehow control for these variables. However, adding variables in non-experimental studies does not mean controlling for them because predictors usually co-vary with each other.	T
CCT838	The majority of fsQCA applications are in political science and sociology. Representative contributions from various sub-fields include policy analysis (e.g., Blake & Adolino, 2001), political parties (e.g., Gordin, 2001), social and political change (e.g., Berg-Schlosser & De Meur, 1994), social movements (e.g., Nomiya, 2001), welfare states (e.g., Peillon, 1996), law and criminology (e.g., Tarohmaru, 2001), linguistics (e.g., Mendel & Korjani, 2012), psychology (e.g., Theuns, 1994), and addictive behavior (e.g., Eng & Woodside, 2012). Applications of the technique in business and management are fewer, though representative examples are available in areas such as international business (e.g., Pajunen, 2008;Schneider et al., 2010), innovation (e.g., #CITATION_TAG et al., 2013;Ganter & Hecker, 2013;Stanko & Olleros, 2013), organizational behavior and strategic management (e.g., Fiss, 2011;Greckhamer et al., 2008;Stokke, 2007), inter-organizational alliances (e.g., Leischnig et al., 2013), tourism management (e.g., Woodside et al., 2011), socially responsible practices (e.g., Crilly et al., 2012), and labor relations (e.g., Coverdill et al., 1994). Ragin (2000) was the first to introduce fsQCA; this technique differs from regression-based methods and other conventional statistical techniques in important ways (Mahoney & Goertz, 2006;Pajunen, 2008). For example, in contrast with correlational techniques, which attempt to estimate the net effect of an independent variable on an outcome variable, fsQCA attempts to identify the conditions that lead to a given outcome (Schneider et al., 2010). As such, fsQCA is a proficient tool that helps supplement traditional correlational analyses in three main ways: (1) asymmetry (i.e., the relationships between independent and dependent variables are treated as not symmetric), ( 2) equifinality (i.e., multiple pathways and solutions lead to the same outcome), and (3) causal complexity (i.e., combinations of causal antecedent conditions lead to the outcome, and thus the researcher focuses not on the estimation of independent net effects but on the estimation of combinatorial effects) (Elliott, 2013).	2	The majority of fsQCA applications are in political science and sociology. Representative contributions from various sub-fields include policy analysis (e.g., Blake & Adolino, 2001), political parties (e.g., Gordin, 2001), social and political change (e.g., Berg-Schlosser & De Meur, 1994), social movements (e.g., Nomiya, 2001), welfare states (e.g., Peillon, 1996), law and criminology (e.g., Tarohmaru, 2001), linguistics (e.g., Mendel & Korjani, 2012), psychology (e.g., Theuns, 1994), and addictive behavior (e.g., Eng & Woodside, 2012). Applications of the technique in business and management are fewer, though representative examples are available in areas such as international business (e.g., Pajunen, 2008;Schneider et al., 2010), innovation (e.g., #CITATION_TAG et al., 2013;Ganter & Hecker, 2013;Stanko & Olleros, 2013), organizational behavior and strategic management (e.g., Fiss, 2011;Greckhamer et al., 2008;Stokke, 2007), inter-organizational alliances (e.g., Leischnig et al., 2013), tourism management (e.g., Woodside et al., 2011), socially responsible practices (e.g., Crilly et al., 2012), and labor relations (e.g., Coverdill et al., 1994). Ragin (2000) was the first to introduce fsQCA; this technique differs from regression-based methods and other conventional statistical techniques in important ways (Mahoney & Goertz, 2006;Pajunen, 2008). For example, in contrast with correlational techniques, which attempt to estimate the net effect of an independent variable on an outcome variable, fsQCA attempts to identify the conditions that lead to a given outcome (Schneider et al., 2010). As such, fsQCA is a proficient tool that helps supplement traditional correlational analyses in three main ways: (1) asymmetry (i.e., the relationships between independent and dependent variables are treated as not symmetric), ( 2) equifinality (i.e., multiple pathways and solutions lead to the same outcome), and (3) causal complexity (i.e., combinations of causal antecedent conditions lead to the outcome, and thus the researcher focuses not on the estimation of independent net effects but on the estimation of combinatorial effects) (Elliott, 2013).	p
CCT839	The majority of fsQCA applications are in political science and sociology. Representative contributions from various sub-fields include policy analysis (e.g., Blake & Adolino, 2001), political parties (e.g., Gordin, 2001), social and political change (e.g., Berg-Schlosser & De Meur, 1994), social movements (e.g., Nomiya, 2001), welfare states (e.g., Peillon, 1996), law and criminology (e.g., Tarohmaru, 2001), linguistics (e.g., Mendel & Korjani, 2012), psychology (e.g., Theuns, 1994), and addictive behavior (e.g., #CITATION_TAG & Woodside, 2012). Applications of the technique in business and management are fewer, though representative examples are available in areas such as international business (e.g., Pajunen, 2008;Schneider et al., 2010), innovation (e.g., Cheng et al., 2013;Ganter & Hecker, 2013;Stanko & Olleros, 2013), organizational behavior and strategic management (e.g., Fiss, 2011;Greckhamer et al., 2008;Stokke, 2007), inter-organizational alliances (e.g., Leischnig et al., 2013), tourism management (e.g., Woodside et al., 2011), socially responsible practices (e.g., Crilly et al., 2012), and labor relations (e.g., Coverdill et al., 1994). Ragin (2000) was the first to introduce fsQCA; this technique differs from regression-based methods and other conventional statistical techniques in important ways (Mahoney & Goertz, 2006;Pajunen, 2008). For example, in contrast with correlational techniques, which attempt to estimate the net effect of an independent variable on an outcome variable, fsQCA attempts to identify the conditions that lead to a given outcome (Schneider et al., 2010). As such, fsQCA is a proficient tool that helps supplement traditional correlational analyses in three main ways: (1) asymmetry (i.e., the relationships between independent and dependent variables are treated as not symmetric), ( 2) equifinality (i.e., multiple pathways and solutions lead to the same outcome), and (3) causal complexity (i.e., combinations of causal antecedent conditions lead to the outcome, and thus the researcher focuses not on the estimation of independent net effects but on the estimation of combinatorial effects) (Elliott, 2013).	1	The majority of fsQCA applications are in political science and sociology. Representative contributions from various sub-fields include policy analysis (e.g., Blake & Adolino, 2001), political parties (e.g., Gordin, 2001), social and political change (e.g., Berg-Schlosser & De Meur, 1994), social movements (e.g., Nomiya, 2001), welfare states (e.g., Peillon, 1996), law and criminology (e.g., Tarohmaru, 2001), linguistics (e.g., Mendel & Korjani, 2012), psychology (e.g., Theuns, 1994), and addictive behavior (e.g., #CITATION_TAG & Woodside, 2012). Applications of the technique in business and management are fewer, though representative examples are available in areas such as international business (e.g., Pajunen, 2008;Schneider et al., 2010), innovation (e.g., Cheng et al., 2013;Ganter & Hecker, 2013;Stanko & Olleros, 2013), organizational behavior and strategic management (e.g., Fiss, 2011;Greckhamer et al., 2008;Stokke, 2007), inter-organizational alliances (e.g., Leischnig et al., 2013), tourism management (e.g., Woodside et al., 2011), socially responsible practices (e.g., Crilly et al., 2012), and labor relations (e.g., Coverdill et al., 1994). Ragin (2000) was the first to introduce fsQCA; this technique differs from regression-based methods and other conventional statistical techniques in important ways (Mahoney & Goertz, 2006;Pajunen, 2008). For example, in contrast with correlational techniques, which attempt to estimate the net effect of an independent variable on an outcome variable, fsQCA attempts to identify the conditions that lead to a given outcome (Schneider et al., 2010).	e
CCT840	The majority of fsQCA applications are in political science and sociology. Representative contributions from various sub-fields include policy analysis (e.g., #CITATION_TAG & Adolino, 2001), political parties (e.g., Gordin, 2001), social and political change (e.g., Berg-Schlosser & De Meur, 1994), social movements (e.g., Nomiya, 2001), welfare states (e.g., Peillon, 1996), law and criminology (e.g., Tarohmaru, 2001), linguistics (e.g., Mendel & Korjani, 2012), psychology (e.g., Theuns, 1994), and addictive behavior (e.g., Eng & Woodside, 2012). Applications of the technique in business and management are fewer, though representative examples are available in areas such as international business (e.g., Pajunen, 2008;Schneider et al., 2010), innovation (e.g., Cheng et al., 2013;Ganter & Hecker, 2013;Stanko & Olleros, 2013), organizational behavior and strategic management (e.g., Fiss, 2011;Greckhamer et al., 2008;Stokke, 2007), inter-organizational alliances (e.g., Leischnig et al., 2013), tourism management (e.g., Woodside et al., 2011), socially responsible practices (e.g., Crilly et al., 2012), and labor relations (e.g., Coverdill et al., 1994). Ragin (2000) was the first to introduce fsQCA; this technique differs from regression-based methods and other conventional statistical techniques in important ways (Mahoney & Goertz, 2006;Pajunen, 2008). For example, in contrast with correlational techniques, which attempt to estimate the net effect of an independent variable on an outcome variable, fsQCA attempts to identify the conditions that lead to a given outcome (Schneider et al., 2010). As such, fsQCA is a proficient tool that helps supplement traditional correlational analyses in three main ways: (1) asymmetry (i.e., the relationships between independent and dependent variables are treated as not symmetric), ( 2) equifinality (i.e., multiple pathways and solutions lead to the same outcome), and (3) causal complexity (i.e., combinations of causal antecedent conditions lead to the outcome, and thus the researcher focuses not on the estimation of independent net effects but on the estimation of combinatorial effects) (Elliott, 2013).	1	The majority of fsQCA applications are in political science and sociology. Representative contributions from various sub-fields include policy analysis (e.g., #CITATION_TAG & Adolino, 2001), political parties (e.g., Gordin, 2001), social and political change (e.g., Berg-Schlosser & De Meur, 1994), social movements (e.g., Nomiya, 2001), welfare states (e.g., Peillon, 1996), law and criminology (e.g., Tarohmaru, 2001), linguistics (e.g., Mendel & Korjani, 2012), psychology (e.g., Theuns, 1994), and addictive behavior (e.g., Eng & Woodside, 2012). Applications of the technique in business and management are fewer, though representative examples are available in areas such as international business (e.g., Pajunen, 2008;Schneider et al., 2010), innovation (e.g., Cheng et al., 2013;Ganter & Hecker, 2013;Stanko & Olleros, 2013), organizational behavior and strategic management (e.g., Fiss, 2011;Greckhamer et al., 2008;Stokke, 2007), inter-organizational alliances (e.g., Leischnig et al., 2013), tourism management (e.g., Woodside et al., 2011), socially responsible practices (e.g., Crilly et al., 2012), and labor relations (e.g., Coverdill et al., 1994). Ragin (2000) was the first to introduce fsQCA; this technique differs from regression-based methods and other conventional statistical techniques in important ways (Mahoney & Goertz, 2006;Pajunen, 2008). For example, in contrast with correlational techniques, which attempt to estimate the net effect of an independent variable on an outcome variable, fsQCA attempts to identify the conditions that lead to a given outcome (Schneider et al., 2010).	e
CCT841	"type of analysis to explore social responsibility phenomena (for exceptions, see #CITATION_TAG, 2013;Crilly et al., 2012). Accordingly, this analysis shows that fsQCA is a valuable analytical tool that researchers can use in conjunction with other analytical techniques (e.g., SEM, MRA) with a view to developing better explanations on how causes combine to create an outcome (Ragin, 2008;Stanko & Olleros, 2013). Thus, fsQCA is a powerful, new, and proper analytical tool that can help in further advancing of the knowledge in the CSR domain. From a managerial perspective, the findings produce several implications. First, CSR skepticism seems to emerge in the presence of egoistic-driven attributions, absence of values-driven motives, and lack of customer orientation. Therefore, managers should consider concentrating efforts on understanding their customers, closely monitoring their perceptions about the company, and devoting attention to accommodating their individual requirements (Eisingerich et al., 2011). In this way, companies might be in a better position to manage CSR skepticism, understand how customers"" perceive different socially responsible actions, and appropriately take action when the need arises. Second, the absence of CSR skepticism and the presence of customer orientation can help retailers build equity. Therefore, managers should keep skepticism levels as low as possible to allow customers to understand the value proposition offered."	1	type of analysis to explore social responsibility phenomena (for exceptions, see #CITATION_TAG, 2013;Crilly et al., 2012). Accordingly, this analysis shows that fsQCA is a valuable analytical tool that researchers can use in conjunction with other analytical techniques (e.g., SEM, MRA) with a view to developing better explanations on how causes combine to create an outcome (Ragin, 2008;Stanko & Olleros, 2013). Thus, fsQCA is a powerful, new, and proper analytical tool that can help in further advancing of the knowledge in the CSR domain. From a managerial perspective, the findings produce several implications.	t
CCT842	The measure of consistency is analogous to a correlation coefficient, and the measure of coverage is analogous to the coefficient of determination (i.e., r 2 ) (Woodside, 2013). The higher the consistency cutoff point the researcher sets for selecting the best combinations, the higher the final consistency will be, but the lower the respective coverage (Elliott, 2013;#CITATION_TAG, 2006). Research (e.g., Ragin, 2008;Woodside, 2013) suggests that a model (solution) is informative when consistency is above 0.74 and coverage is between 0.25 and 0.65.	5	The measure of consistency is analogous to a correlation coefficient, and the measure of coverage is analogous to the coefficient of determination (i.e., r 2 ) (Woodside, 2013). The higher the consistency cutoff point the researcher sets for selecting the best combinations, the higher the final consistency will be, but the lower the respective coverage (Elliott, 2013;#CITATION_TAG, 2006). Research (e.g., Ragin, 2008;Woodside, 2013) suggests that a model (solution) is informative when consistency is above 0.74 and coverage is between 0.25 and 0.65.	h
CCT843	"Table 5 illustrates how this study builds and expands on the findings of SL. More specifically, Table 5 shows the derived results for the recipes that lead to high membership scores in the four outcome conditions and compares the conclusions with those of SL. The notation used in Table 5 is consistent with the notation #CITATION_TAG and Fiss (2008) and Fiss (2011) use. The black circles indicate very high presence of a condition, and the white circles indicate very low presence (i.e., absence) of a condition. Large black (white) circles indicate a core, necessary condition of presence (absence), and ""√ò"" indicates a peripheral (not necessary) condition. Blank spaces in a pathway indicate a ""don\""t care"" situation, in which the causal condition may be either present or absent. The table also compares the conclusions of this study with the research findings of SL. ‚àö"" indicates that the respective hypothesis or link presented in SL\""s study is supported by the present fsQCA analysis, ""¬¢"" indicates a hypothesis or link that is conditionally supported by the present analysis, and ""√ó"" indicates a hypothesis or link that is not supported by the present analysis."	5	"Table 5 illustrates how this study builds and expands on the findings of SL. More specifically, Table 5 shows the derived results for the recipes that lead to high membership scores in the four outcome conditions and compares the conclusions with those of SL. The notation used in Table 5 is consistent with the notation #CITATION_TAG and Fiss (2008) and Fiss (2011) use. The black circles indicate very high presence of a condition, and the white circles indicate very low presence (i.e., absence) of a condition. Large black (white) circles indicate a core, necessary condition of presence (absence), and ""√ò"" indicates a peripheral (not necessary) condition. Blank spaces in a pathway indicate a ""don\""t care"" situation, in which the causal condition may be either present or absent."	e
CCT844	CSR is a widely debated topic in both academic and management circles. While increasingly more companies undertake CSR initiatives in an attempt to contribute to society or pursue their strategic goals, examples of corporate social irresponsibility abound (e.g., #CITATION_TAG, 2003;Lange & Washburn, 2012;Murphy & Schlegelmilch, 2013). Corporate wrongdoing attracts the attention of the media and watchdog organizations, triggering questions about why companies engage in CSR and how they contribute to social well-being (Bielak et al., 2007;Wagner et al., 2009). As a result, many people express doubts about the extent to which companies live up to their professed standards, and growing skepticism emerges about corporate social involvement.	3	CSR is a widely debated topic in both academic and management circles. While increasingly more companies undertake CSR initiatives in an attempt to contribute to society or pursue their strategic goals, examples of corporate social irresponsibility abound (e.g., #CITATION_TAG, 2003;Lange & Washburn, 2012;Murphy & Schlegelmilch, 2013). Corporate wrongdoing attracts the attention of the media and watchdog organizations, triggering questions about why companies engage in CSR and how they contribute to social well-being (Bielak et al., 2007;Wagner et al., 2009). As a result, many people express doubts about the extent to which companies live up to their professed standards, and growing skepticism emerges about corporate social involvement.	h
CCT845	Skepticism generally reflects doubt about the truth of something. Many disciplines discuss skepticism, including politics (e.g., Taber & Lodge, 2006), philosophy (e.g., McGrath, 2011), sociology (e.g., Freudenburg et al., 2008), and psychology (e.g., Lilienfeld, 2012). Research in business examines skepticism in the areas of advertising, promotion, and public relations (e.g., #CITATION_TAG et al., 1994;Obermiller et al., 2005); corporate social marketing (Forehand & Grier, 2003); environmental claims (Mohr et al., 1998); cause-related claims (Singh et al., 2009); CSR communication during crises (Vanhamme & Grobben, 2009); and CSR programs (Pirsch et al., 2007).	1	Skepticism generally reflects doubt about the truth of something. Many disciplines discuss skepticism, including politics (e.g., Taber & Lodge, 2006), philosophy (e.g., McGrath, 2011), sociology (e.g., Freudenburg et al., 2008), and psychology (e.g., Lilienfeld, 2012). Research in business examines skepticism in the areas of advertising, promotion, and public relations (e.g., #CITATION_TAG et al., 1994;Obermiller et al., 2005); corporate social marketing (Forehand & Grier, 2003); environmental claims (Mohr et al., 1998); cause-related claims (Singh et al., 2009); CSR communication during crises (Vanhamme & Grobben, 2009); and CSR programs (Pirsch et al., 2007).	s
CCT846	Skepticism generally reflects doubt about the truth of something. Many disciplines discuss skepticism, including politics (e.g., Taber & Lodge, 2006), philosophy (e.g., McGrath, 2011), sociology (e.g., Freudenburg et al., 2008), and psychology (e.g., Lilienfeld, 2012). Research in business examines skepticism in the areas of advertising, promotion, and public relations (e.g., Boush et al., 1994;Obermiller et al., 2005); corporate social marketing (Forehand & Grier, 2003); environmental claims (Mohr et al., 1998); cause-related claims (#CITATION_TAG et al., 2009); CSR communication during crises (Vanhamme & Grobben, 2009); and CSR programs (Pirsch et al., 2007).	1	Skepticism generally reflects doubt about the truth of something. Many disciplines discuss skepticism, including politics (e.g., Taber & Lodge, 2006), philosophy (e.g., McGrath, 2011), sociology (e.g., Freudenburg et al., 2008), and psychology (e.g., Lilienfeld, 2012). Research in business examines skepticism in the areas of advertising, promotion, and public relations (e.g., Boush et al., 1994;Obermiller et al., 2005); corporate social marketing (Forehand & Grier, 2003); environmental claims (Mohr et al., 1998); cause-related claims (#CITATION_TAG et al., 2009); CSR communication during crises (Vanhamme & Grobben, 2009); and CSR programs (Pirsch et al., 2007).	s
CCT847	Using structural equation modeling (SEM), #CITATION_TAG and Leonidou (2013) (hereinafter SL) find that attributions of egoistic-and stakeholder-driven motives provoke consumer skepticism about corporate social responsibility (CSR) while values-driven attributions alleviate skepticism. Their results also provide support for the hypotheses that CSR skepticism results in lower levels of consumer-based retailer equity, decreased consumer resistance to negative information about the retailer, and unfavorable word of mouth (WOM).	0	Using structural equation modeling (SEM), #CITATION_TAG and Leonidou (2013) (hereinafter SL) find that attributions of egoistic-and stakeholder-driven motives provoke consumer skepticism about corporate social responsibility (CSR) while values-driven attributions alleviate skepticism. Their results also provide support for the hypotheses that CSR skepticism results in lower levels of consumer-based retailer equity, decreased consumer resistance to negative information about the retailer, and unfavorable word of mouth (WOM).	U
CCT848	Fuzzy sets are relatively new to social science, with their first introduction in 1987 by Smithson though applications were few until the integration of the basic fuzzy-set principles with qualitative comparative analysis (#CITATION_TAG, 1987(Ragin, , 2000. The combination of these two concepts produced fsQCA, a family of methods that provides researchers an alternative to conventional, correlational reasoning methods.	5	Fuzzy sets are relatively new to social science, with their first introduction in 1987 by Smithson though applications were few until the integration of the basic fuzzy-set principles with qualitative comparative analysis (#CITATION_TAG, 1987(Ragin, , 2000. The combination of these two concepts produced fsQCA, a family of methods that provides researchers an alternative to conventional, correlational reasoning methods.	F
CCT849	Skepticism generally reflects doubt about the truth of something. Many disciplines discuss skepticism, including politics (e.g., #CITATION_TAG & Lodge, 2006), philosophy (e.g., McGrath, 2011), sociology (e.g., Freudenburg et al., 2008), and psychology (e.g., Lilienfeld, 2012). Research in business examines skepticism in the areas of advertising, promotion, and public relations (e.g., Boush et al., 1994;Obermiller et al., 2005); corporate social marketing (Forehand & Grier, 2003); environmental claims (Mohr et al., 1998); cause-related claims (Singh et al., 2009); CSR communication during crises (Vanhamme & Grobben, 2009); and CSR programs (Pirsch et al., 2007).	0	Skepticism generally reflects doubt about the truth of something. Many disciplines discuss skepticism, including politics (e.g., #CITATION_TAG & Lodge, 2006), philosophy (e.g., McGrath, 2011), sociology (e.g., Freudenburg et al., 2008), and psychology (e.g., Lilienfeld, 2012). Research in business examines skepticism in the areas of advertising, promotion, and public relations (e.g., Boush et al., 1994;Obermiller et al., 2005); corporate social marketing (Forehand & Grier, 2003); environmental claims (Mohr et al., 1998); cause-related claims (Singh et al., 2009); CSR communication during crises (Vanhamme & Grobben, 2009); and CSR programs (Pirsch et al., 2007).	a
CCT850	"The need for alternative techniques 3.1. Focus on the ""net effect"" estimation Multiple regression equations follow a net effects estimation approach (i.e., estimation of the effect size of each independent variable on the dependent variable, after controlling for the impact of the other independent variables also included in the equation). However, multicollinearity (i.e., significant correlations among the independent variables) is common, especially in cases with a large number of independent variables (e.g., Mittal et al., 1998;Wittink & Bayer, 1994). If multicollinearity is high, the regression estimator becomes inefficient and may yield statistically non-significant estimates or estimates inconsistent with the supposed associations (e.g., #CITATION_TAG et al., 2005). Even in cases of low multicollinearity, the estimated net effects of the independent variables may change from significant to non-significant depending on the additional independent variables that enter the equation (Woodside, 2013). Armstrong (2012) posits that researchers who use regression analysis falsely assume that by entering variables into the equation, they somehow control for these variables. However, adding variables in non-experimental studies does not mean controlling for them because predictors usually co-vary with each other."	5	"The need for alternative techniques 3.1. Focus on the ""net effect"" estimation Multiple regression equations follow a net effects estimation approach (i.e., estimation of the effect size of each independent variable on the dependent variable, after controlling for the impact of the other independent variables also included in the equation). However, multicollinearity (i.e., significant correlations among the independent variables) is common, especially in cases with a large number of independent variables (e.g., Mittal et al., 1998;Wittink & Bayer, 1994). If multicollinearity is high, the regression estimator becomes inefficient and may yield statistically non-significant estimates or estimates inconsistent with the supposed associations (e.g., #CITATION_TAG et al., 2005). Even in cases of low multicollinearity, the estimated net effects of the independent variables may change from significant to non-significant depending on the additional independent variables that enter the equation (Woodside, 2013). Armstrong (2012) posits that researchers who use regression analysis falsely assume that by entering variables into the equation, they somehow control for these variables. However, adding variables in non-experimental studies does not mean controlling for them because predictors usually co-vary with each other."	m
CCT851	CSR is a widely debated topic in both academic and management circles. While increasingly more companies undertake CSR initiatives in an attempt to contribute to society or pursue their strategic goals, examples of corporate social irresponsibility abound (e.g., Carson, 2003;Lange & Washburn, 2012;Murphy & Schlegelmilch, 2013). Corporate wrongdoing attracts the attention of the media and watchdog organizations, triggering questions about why companies engage in CSR and how they contribute to social well-being (Bielak et al., 2007;#CITATION_TAG et al., 2009). As a result, many people express doubts about the extent to which companies live up to their professed standards, and growing skepticism emerges about corporate social involvement.	0	CSR is a widely debated topic in both academic and management circles. While increasingly more companies undertake CSR initiatives in an attempt to contribute to society or pursue their strategic goals, examples of corporate social irresponsibility abound (e.g., Carson, 2003;Lange & Washburn, 2012;Murphy & Schlegelmilch, 2013). Corporate wrongdoing attracts the attention of the media and watchdog organizations, triggering questions about why companies engage in CSR and how they contribute to social well-being (Bielak et al., 2007;#CITATION_TAG et al., 2009). As a result, many people express doubts about the extent to which companies live up to their professed standards, and growing skepticism emerges about corporate social involvement.	r
CCT852	"The need for alternative techniques 3.1. Focus on the ""net effect"" estimation Multiple regression equations follow a net effects estimation approach (i.e., estimation of the effect size of each independent variable on the dependent variable, after controlling for the impact of the other independent variables also included in the equation). However, multicollinearity (i.e., significant correlations among the independent variables) is common, especially in cases with a large number of independent variables (e.g., Mittal et al., 1998;#CITATION_TAG & Bayer, 1994). If multicollinearity is high, the regression estimator becomes inefficient and may yield statistically non-significant estimates or estimates inconsistent with the supposed associations (e.g., Van der Meer et al., 2005). Even in cases of low multicollinearity, the estimated net effects of the independent variables may change from significant to non-significant depending on the additional independent variables that enter the equation (Woodside, 2013). Armstrong (2012) posits that researchers who use regression analysis falsely assume that by entering variables into the equation, they somehow control for these variables. However, adding variables in non-experimental studies does not mean controlling for them because predictors usually co-vary with each other."	5	"The need for alternative techniques 3.1. Focus on the ""net effect"" estimation Multiple regression equations follow a net effects estimation approach (i.e., estimation of the effect size of each independent variable on the dependent variable, after controlling for the impact of the other independent variables also included in the equation). However, multicollinearity (i.e., significant correlations among the independent variables) is common, especially in cases with a large number of independent variables (e.g., Mittal et al., 1998;#CITATION_TAG & Bayer, 1994). If multicollinearity is high, the regression estimator becomes inefficient and may yield statistically non-significant estimates or estimates inconsistent with the supposed associations (e.g., Van der Meer et al., 2005). Even in cases of low multicollinearity, the estimated net effects of the independent variables may change from significant to non-significant depending on the additional independent variables that enter the equation (Woodside, 2013). Armstrong (2012) posits that researchers who use regression analysis falsely assume that by entering variables into the equation, they somehow control for these variables."	w
CCT853	CSR is a widely debated topic in both academic and management circles. While increasingly more companies undertake CSR initiatives in an attempt to contribute to society or pursue their strategic goals, examples of corporate social irresponsibility abound (e.g., Carson, 2003;Lange & Washburn, 2012;Murphy & Schlegelmilch, 2013). Corporate wrongdoing attracts the attention of the media and watchdog organizations, triggering questions about why companies engage in CSR and how they contribute to social well-being (#CITATION_TAG et al., 2007;Wagner et al., 2009). As a result, many people express doubts about the extent to which companies live up to their professed standards, and growing skepticism emerges about corporate social involvement.	0	CSR is a widely debated topic in both academic and management circles. While increasingly more companies undertake CSR initiatives in an attempt to contribute to society or pursue their strategic goals, examples of corporate social irresponsibility abound (e.g., Carson, 2003;Lange & Washburn, 2012;Murphy & Schlegelmilch, 2013). Corporate wrongdoing attracts the attention of the media and watchdog organizations, triggering questions about why companies engage in CSR and how they contribute to social well-being (#CITATION_TAG et al., 2007;Wagner et al., 2009). As a result, many people express doubts about the extent to which companies live up to their professed standards, and growing skepticism emerges about corporate social involvement.	r
CCT854	In general, fsQCA is an analysis of set relationships. A set can be a group of elements or, in the case of fsQCA, a group of values. The main aim of the technique is to identify all necessary and sufficient conditions that lead to a specific outcome condition (#CITATION_TAG, 1999). Necessary conditions are those that produce the outcome. All cases (e.g., individuals) that display the outcome also display the necessary condition; however, necessary conditions by themselves are not always enough to produce the outcome. Sufficient conditions are those that always lead to the given outcome; however, they may not be the only conditions that lead to this outcome, because several alternative sufficient conditions may co-exist. In set notation, the outcome set is a subset of the necessary condition set, and this sufficient condition set is a subset of the outcome set (Ragin, 2008).	5	In general, fsQCA is an analysis of set relationships. A set can be a group of elements or, in the case of fsQCA, a group of values. The main aim of the technique is to identify all necessary and sufficient conditions that lead to a specific outcome condition (#CITATION_TAG, 1999). Necessary conditions are those that produce the outcome. All cases (e.g., individuals) that display the outcome also display the necessary condition; however, necessary conditions by themselves are not always enough to produce the outcome. Sufficient conditions are those that always lead to the given outcome; however, they may not be the only conditions that lead to this outcome, because several alternative sufficient conditions may co-exist.	e
CCT855	The majority of fsQCA applications are in political science and sociology. Representative contributions from various sub-fields include policy analysis (e.g., Blake & Adolino, 2001), political parties (e.g., Gordin, 2001), social and political change (e.g., Berg-Schlosser & De Meur, 1994), social movements (e.g., Nomiya, 2001), welfare states (e.g., Peillon, 1996), law and criminology (e.g., Tarohmaru, 2001), linguistics (e.g., Mendel & Korjani, 2012), psychology (e.g., Theuns, 1994), and addictive behavior (e.g., Eng & Woodside, 2012). Applications of the technique in business and management are fewer, though representative examples are available in areas such as international business (e.g., Pajunen, 2008;Schneider et al., 2010), innovation (e.g., Cheng et al., 2013;Ganter & Hecker, 2013;Stanko & Olleros, 2013), organizational behavior and strategic management (e.g., Fiss, 2011;Greckhamer et al., 2008;Stokke, 2007), inter-organizational alliances (e.g., Leischnig et al., 2013), tourism management (e.g., Woodside et al., 2011), socially responsible practices (e.g., Crilly et al., 2012), and labor relations (e.g., Coverdill et al., 1994). Ragin (2000) was the first to introduce fsQCA; this technique differs from regression-based methods and other conventional statistical techniques in important ways (#CITATION_TAG & Goertz, 2006;Pajunen, 2008). For example, in contrast with correlational techniques, which attempt to estimate the net effect of an independent variable on an outcome variable, fsQCA attempts to identify the conditions that lead to a given outcome (Schneider et al., 2010). As such, fsQCA is a proficient tool that helps supplement traditional correlational analyses in three main ways: (1) asymmetry (i.e., the relationships between independent and dependent variables are treated as not symmetric), ( 2) equifinality (i.e., multiple pathways and solutions lead to the same outcome), and (3) causal complexity (i.e., combinations of causal antecedent conditions lead to the outcome, and thus the researcher focuses not on the estimation of independent net effects but on the estimation of combinatorial effects) (Elliott, 2013).	5	The majority of fsQCA applications are in political science and sociology. Representative contributions from various sub-fields include policy analysis (e.g., Blake & Adolino, 2001), political parties (e.g., Gordin, 2001), social and political change (e.g., Berg-Schlosser & De Meur, 1994), social movements (e.g., Nomiya, 2001), welfare states (e.g., Peillon, 1996), law and criminology (e.g., Tarohmaru, 2001), linguistics (e.g., Mendel & Korjani, 2012), psychology (e.g., Theuns, 1994), and addictive behavior (e.g., Eng & Woodside, 2012). Applications of the technique in business and management are fewer, though representative examples are available in areas such as international business (e.g., Pajunen, 2008;Schneider et al., 2010), innovation (e.g., Cheng et al., 2013;Ganter & Hecker, 2013;Stanko & Olleros, 2013), organizational behavior and strategic management (e.g., Fiss, 2011;Greckhamer et al., 2008;Stokke, 2007), inter-organizational alliances (e.g., Leischnig et al., 2013), tourism management (e.g., Woodside et al., 2011), socially responsible practices (e.g., Crilly et al., 2012), and labor relations (e.g., Coverdill et al., 1994). Ragin (2000) was the first to introduce fsQCA; this technique differs from regression-based methods and other conventional statistical techniques in important ways (#CITATION_TAG & Goertz, 2006;Pajunen, 2008). For example, in contrast with correlational techniques, which attempt to estimate the net effect of an independent variable on an outcome variable, fsQCA attempts to identify the conditions that lead to a given outcome (Schneider et al., 2010). As such, fsQCA is a proficient tool that helps supplement traditional correlational analyses in three main ways: (1) asymmetry (i.e., the relationships between independent and dependent variables are treated as not symmetric), ( 2) equifinality (i.e., multiple pathways and solutions lead to the same outcome), and (3) causal complexity (i.e., combinations of causal antecedent conditions lead to the outcome, and thus the researcher focuses not on the estimation of independent net effects but on the estimation of combinatorial effects) (Elliott, 2013).	i
CCT856	Skepticism generally reflects doubt about the truth of something. Many disciplines discuss skepticism, including politics (e.g., Taber & Lodge, 2006), philosophy (e.g., McGrath, 2011), sociology (e.g., #CITATION_TAG et al., 2008), and psychology (e.g., Lilienfeld, 2012). Research in business examines skepticism in the areas of advertising, promotion, and public relations (e.g., Boush et al., 1994;Obermiller et al., 2005); corporate social marketing (Forehand & Grier, 2003); environmental claims (Mohr et al., 1998); cause-related claims (Singh et al., 2009); CSR communication during crises (Vanhamme & Grobben, 2009); and CSR programs (Pirsch et al., 2007).	0	Skepticism generally reflects doubt about the truth of something. Many disciplines discuss skepticism, including politics (e.g., Taber & Lodge, 2006), philosophy (e.g., McGrath, 2011), sociology (e.g., #CITATION_TAG et al., 2008), and psychology (e.g., Lilienfeld, 2012). Research in business examines skepticism in the areas of advertising, promotion, and public relations (e.g., Boush et al., 1994;Obermiller et al., 2005); corporate social marketing (Forehand & Grier, 2003); environmental claims (Mohr et al., 1998); cause-related claims (Singh et al., 2009); CSR communication during crises (Vanhamme & Grobben, 2009); and CSR programs (Pirsch et al., 2007).	a
CCT857	"MRA also assumes that relationships between independent and dependent variables are linear. Many authors, however, stress that, pragmatically, most observable relationships are not 100% linear and, thus, that correlation coefficients cannot accurately describe them (Armstrong, 2012;Woodside, 2013). For example, Woodside (2013) stresses that relationships are rarely linear and are better explained by ""tipping points. In other words, a change in an independent variable may have little or no impact on a dependent variable, until this change reaches a certain threshold (#CITATION_TAG, 2000)."	5	"MRA also assumes that relationships between independent and dependent variables are linear. Many authors, however, stress that, pragmatically, most observable relationships are not 100% linear and, thus, that correlation coefficients cannot accurately describe them (Armstrong, 2012;Woodside, 2013). For example, Woodside (2013) stresses that relationships are rarely linear and are better explained by ""tipping points. In other words, a change in an independent variable may have little or no impact on a dependent variable, until this change reaches a certain threshold (#CITATION_TAG, 2000)."	o
CCT858	CSR is a widely debated topic in both academic and management circles. While increasingly more companies undertake CSR initiatives in an attempt to contribute to society or pursue their strategic goals, examples of corporate social irresponsibility abound (e.g., Carson, 2003;#CITATION_TAG & Washburn, 2012;Murphy & Schlegelmilch, 2013). Corporate wrongdoing attracts the attention of the media and watchdog organizations, triggering questions about why companies engage in CSR and how they contribute to social well-being (Bielak et al., 2007;Wagner et al., 2009). As a result, many people express doubts about the extent to which companies live up to their professed standards, and growing skepticism emerges about corporate social involvement.	0	CSR is a widely debated topic in both academic and management circles. While increasingly more companies undertake CSR initiatives in an attempt to contribute to society or pursue their strategic goals, examples of corporate social irresponsibility abound (e.g., Carson, 2003;#CITATION_TAG & Washburn, 2012;Murphy & Schlegelmilch, 2013). Corporate wrongdoing attracts the attention of the media and watchdog organizations, triggering questions about why companies engage in CSR and how they contribute to social well-being (Bielak et al., 2007;Wagner et al., 2009). As a result, many people express doubts about the extent to which companies live up to their professed standards, and growing skepticism emerges about corporate social involvement.	h
CCT859	Skepticism generally reflects doubt about the truth of something. Many disciplines discuss skepticism, including politics (e.g., Taber & Lodge, 2006), philosophy (e.g., McGrath, 2011), sociology (e.g., Freudenburg et al., 2008), and psychology (e.g., #CITATION_TAG, 2012). Research in business examines skepticism in the areas of advertising, promotion, and public relations (e.g., Boush et al., 1994;Obermiller et al., 2005); corporate social marketing (Forehand & Grier, 2003); environmental claims (Mohr et al., 1998); cause-related claims (Singh et al., 2009); CSR communication during crises (Vanhamme & Grobben, 2009); and CSR programs (Pirsch et al., 2007).	0	Skepticism generally reflects doubt about the truth of something. Many disciplines discuss skepticism, including politics (e.g., Taber & Lodge, 2006), philosophy (e.g., McGrath, 2011), sociology (e.g., Freudenburg et al., 2008), and psychology (e.g., #CITATION_TAG, 2012). Research in business examines skepticism in the areas of advertising, promotion, and public relations (e.g., Boush et al., 1994;Obermiller et al., 2005); corporate social marketing (Forehand & Grier, 2003); environmental claims (Mohr et al., 1998); cause-related claims (Singh et al., 2009); CSR communication during crises (Vanhamme & Grobben, 2009); and CSR programs (Pirsch et al., 2007).	a
CCT860	Skepticism generally reflects doubt about the truth of something. Many disciplines discuss skepticism, including politics (e.g., Taber & Lodge, 2006), philosophy (e.g., #CITATION_TAG, 2011), sociology (e.g., Freudenburg et al., 2008), and psychology (e.g., Lilienfeld, 2012). Research in business examines skepticism in the areas of advertising, promotion, and public relations (e.g., Boush et al., 1994;Obermiller et al., 2005); corporate social marketing (Forehand & Grier, 2003); environmental claims (Mohr et al., 1998); cause-related claims (Singh et al., 2009); CSR communication during crises (Vanhamme & Grobben, 2009); and CSR programs (Pirsch et al., 2007).	0	Skepticism generally reflects doubt about the truth of something. Many disciplines discuss skepticism, including politics (e.g., Taber & Lodge, 2006), philosophy (e.g., #CITATION_TAG, 2011), sociology (e.g., Freudenburg et al., 2008), and psychology (e.g., Lilienfeld, 2012). Research in business examines skepticism in the areas of advertising, promotion, and public relations (e.g., Boush et al., 1994;Obermiller et al., 2005); corporate social marketing (Forehand & Grier, 2003); environmental claims (Mohr et al., 1998); cause-related claims (Singh et al., 2009); CSR communication during crises (Vanhamme & Grobben, 2009); and CSR programs (Pirsch et al., 2007).	a
CCT861	CSR is a widely debated topic in both academic and management circles. While increasingly more companies undertake CSR initiatives in an attempt to contribute to society or pursue their strategic goals, examples of corporate social irresponsibility abound (e.g., Carson, 2003;Lange & Washburn, 2012;#CITATION_TAG & Schlegelmilch, 2013). Corporate wrongdoing attracts the attention of the media and watchdog organizations, triggering questions about why companies engage in CSR and how they contribute to social well-being (Bielak et al., 2007;Wagner et al., 2009). As a result, many people express doubts about the extent to which companies live up to their professed standards, and growing skepticism emerges about corporate social involvement.	0	CSR is a widely debated topic in both academic and management circles. While increasingly more companies undertake CSR initiatives in an attempt to contribute to society or pursue their strategic goals, examples of corporate social irresponsibility abound (e.g., Carson, 2003;Lange & Washburn, 2012;#CITATION_TAG & Schlegelmilch, 2013). Corporate wrongdoing attracts the attention of the media and watchdog organizations, triggering questions about why companies engage in CSR and how they contribute to social well-being (Bielak et al., 2007;Wagner et al., 2009). As a result, many people express doubts about the extent to which companies live up to their professed standards, and growing skepticism emerges about corporate social involvement.	h
CCT862	In the context of IR optimization, stochastic approaches have been exploited to improve the IR effectiveness; for example genetic algorithms have been used for improving the effectiveness of IR systems [36,37,41], for query reformulation [38], for query selection [17] and improving [57]. Other techniques make use of Fuzzy algorithms [33,47], local context analysis [56], clustering [59], and ranking improvement #CITATION_TAG.	0	In the context of IR optimization, stochastic approaches have been exploited to improve the IR effectiveness; for example genetic algorithms have been used for improving the effectiveness of IR systems [36,37,41], for query reformulation [38], for query selection [17] and improving [57]. Other techniques make use of Fuzzy algorithms [33,47], local context analysis [56], clustering [59], and ranking improvement #CITATION_TAG.	t
CCT863	Multilingual documents require query or metadata translation for information retrieval. The first approach reduces the memory usage and each document is stored only once in the index [35], while the second produces larger indexes and avoids query translation issues. Indeed, the automatic query translation process could create word ambiguity, poly-semy, inflection and homonymy issues #CITATION_TAG, especially in the case of short queries [25]. Disambiguation techniques can be applied, for example using co-occurrences of pair terms [58], or a general statistical approach. Query expansion [6], for example pseudo-relevance feedback technique [4,7], thesauri such as WordNet [20] or structured translation [49] can be used to increase the efficiency of a retrieval system.	0	Multilingual documents require query or metadata translation for information retrieval. The first approach reduces the memory usage and each document is stored only once in the index [35], while the second produces larger indexes and avoids query translation issues. Indeed, the automatic query translation process could create word ambiguity, poly-semy, inflection and homonymy issues #CITATION_TAG, especially in the case of short queries [25]. Disambiguation techniques can be applied, for example using co-occurrences of pair terms [58], or a general statistical approach. Query expansion [6], for example pseudo-relevance feedback technique [4,7], thesauri such as WordNet [20] or structured translation [49] can be used to increase the efficiency of a retrieval system.	d
CCT864	Therefore, the proposed cross media content indexing solution was designed and tuned for the ECLAP social portal, best practice networks, in the area of Performing Arts. The technical solution is capable to cope with runtime exceptions, index schema updates, different metadata sets and content types. The ECLAP information model for cross-media integrates sources coming from 35 different international institutions [9,#CITATION_TAG].	2	Therefore, the proposed cross media content indexing solution was designed and tuned for the ECLAP social portal, best practice networks, in the area of Performing Arts. The technical solution is capable to cope with runtime exceptions, index schema updates, different metadata sets and content types. The ECLAP information model for cross-media integrates sources coming from 35 different international institutions [9,#CITATION_TAG].	e
CCT865	Other possible approaches for dealing with multilingual documents refer to Self-Organizing Maps (SOMs) [28] or make use of sentence clustering before the translation process [18]. An alternative query translation approach involves the use of parallel or comparable Corpora [40]. They consist in a collection of natural language texts, where each document is translated in various languages; aligned parallel corpora are annotated to match each sentence in the source document with their respective translations. Thus, documents are comparable when they use the same vocabulary and deal with the same topic #CITATION_TAG.	0	Other possible approaches for dealing with multilingual documents refer to Self-Organizing Maps (SOMs) [28] or make use of sentence clustering before the translation process [18]. An alternative query translation approach involves the use of parallel or comparable Corpora [40]. They consist in a collection of natural language texts, where each document is translated in various languages; aligned parallel corpora are annotated to match each sentence in the source document with their respective translations. Thus, documents are comparable when they use the same vocabulary and deal with the same topic #CITATION_TAG.	s
CCT866	Relevant examples of fuzzy techniques application include semantic search [27], ontologies [2], Cloud Computing [30], image text analysis [12], query expansion [51], clustering [34] and popular search platforms such as Apache Lucene. Multidimensional dynamic taxonomies models (i.e., faceted search [43,52]) are also very popular, especially in e-commerce sites, where the user needs a way to easily explore the contents, and each facet can be represented with a taxonomy #CITATION_TAG. Document type detection and parsing algorithms for metadata extraction are a valuable key factor for integrating rich text resources (e.g., semi-structured or unstructured documents) in digital indexes, with the aim of Natural Language Processing (NLP) techniques; example approaches include machine learning methods [24], table metadata extraction (e.g., from PDFs [31]), context thesauri in conjunction with document analysis [46], DOMbased content extraction [22]. Typically, extracted information from unstructured documents can be organized as entities (i.e., noun phrases) and relationships between them, adjectives, tables and lists [45].	0	Relevant examples of fuzzy techniques application include semantic search [27], ontologies [2], Cloud Computing [30], image text analysis [12], query expansion [51], clustering [34] and popular search platforms such as Apache Lucene. Multidimensional dynamic taxonomies models (i.e., faceted search [43,52]) are also very popular, especially in e-commerce sites, where the user needs a way to easily explore the contents, and each facet can be represented with a taxonomy #CITATION_TAG. Document type detection and parsing algorithms for metadata extraction are a valuable key factor for integrating rich text resources (e.g., semi-structured or unstructured documents) in digital indexes, with the aim of Natural Language Processing (NLP) techniques; example approaches include machine learning methods [24], table metadata extraction (e.g., from PDFs [31]), context thesauri in conjunction with document analysis [46], DOMbased content extraction [22]. Typically, extracted information from unstructured documents can be organized as entities (i.e., noun phrases) and relationships between them, adjectives, tables and lists [45].	u
CCT867	Multilingual documents require query or metadata translation for information retrieval. The first approach reduces the memory usage and each document is stored only once in the index #CITATION_TAG, while the second produces larger indexes and avoids query translation issues. Indeed, the automatic query translation process could create word ambiguity, poly-semy, inflection and homonymy issues [1], especially in the case of short queries [25]. Disambiguation techniques can be applied, for example using co-occurrences of pair terms [58], or a general statistical approach. Query expansion [6], for example pseudo-relevance feedback technique [4,7], thesauri such as WordNet [20] or structured translation [49] can be used to increase the efficiency of a retrieval system.	0	Multilingual documents require query or metadata translation for information retrieval. The first approach reduces the memory usage and each document is stored only once in the index #CITATION_TAG, while the second produces larger indexes and avoids query translation issues. Indeed, the automatic query translation process could create word ambiguity, poly-semy, inflection and homonymy issues [1], especially in the case of short queries [25]. Disambiguation techniques can be applied, for example using co-occurrences of pair terms [58], or a general statistical approach. Query expansion [6], for example pseudo-relevance feedback technique [4,7], thesauri such as WordNet [20] or structured translation [49] can be used to increase the efficiency of a retrieval system.	h
CCT868	In the context of IR optimization, stochastic approaches have been exploited to improve the IR effectiveness; for example genetic algorithms have been used for improving the effectiveness of IR systems [#CITATION_TAG,37,41], for query reformulation [38], for query selection [17] and improving [57]. Other techniques make use of Fuzzy algorithms [33,47], local context analysis [56], clustering [59], and ranking improvement [54].	0	In the context of IR optimization, stochastic approaches have been exploited to improve the IR effectiveness; for example genetic algorithms have been used for improving the effectiveness of IR systems [#CITATION_TAG,37,41], for query reformulation [38], for query selection [17] and improving [57]. Other techniques make use of Fuzzy algorithms [33,47], local context analysis [56], clustering [59], and ranking improvement [54].	I
CCT869	Other possible approaches for dealing with multilingual documents refer to Self-Organizing Maps (SOMs) [28] or make use of sentence clustering before the translation process [18]. An alternative query translation approach involves the use of parallel or comparable Corpora #CITATION_TAG. They consist in a collection of natural language texts, where each document is translated in various languages; aligned parallel corpora are annotated to match each sentence in the source document with their respective translations. Thus, documents are comparable when they use the same vocabulary and deal with the same topic [32].	0	Other possible approaches for dealing with multilingual documents refer to Self-Organizing Maps (SOMs) [28] or make use of sentence clustering before the translation process [18]. An alternative query translation approach involves the use of parallel or comparable Corpora #CITATION_TAG. They consist in a collection of natural language texts, where each document is translated in various languages; aligned parallel corpora are annotated to match each sentence in the source document with their respective translations. Thus, documents are comparable when they use the same vocabulary and deal with the same topic [32].	n
CCT870	Relevant examples of fuzzy techniques application include semantic search [27], ontologies [2], Cloud Computing [30], image text analysis [12], query expansion [51], clustering [34] and popular search platforms such as Apache Lucene. Multidimensional dynamic taxonomies models (i.e., faceted search [43,52]) are also very popular, especially in e-commerce sites, where the user needs a way to easily explore the contents, and each facet can be represented with a taxonomy [42]. Document type detection and parsing algorithms for metadata extraction are a valuable key factor for integrating rich text resources (e.g., semi-structured or unstructured documents) in digital indexes, with the aim of Natural Language Processing (NLP) techniques; example approaches include machine learning methods [24], table metadata extraction (e.g., from PDFs [31]), context thesauri in conjunction with document analysis [46], DOMbased content extraction [22]. Typically, extracted information from unstructured documents can be organized as entities (i.e., noun phrases) and relationships between them, adjectives, tables and lists #CITATION_TAG.	0	Relevant examples of fuzzy techniques application include semantic search [27], ontologies [2], Cloud Computing [30], image text analysis [12], query expansion [51], clustering [34] and popular search platforms such as Apache Lucene. Multidimensional dynamic taxonomies models (i.e., faceted search [43,52]) are also very popular, especially in e-commerce sites, where the user needs a way to easily explore the contents, and each facet can be represented with a taxonomy [42]. Document type detection and parsing algorithms for metadata extraction are a valuable key factor for integrating rich text resources (e.g., semi-structured or unstructured documents) in digital indexes, with the aim of Natural Language Processing (NLP) techniques; example approaches include machine learning methods [24], table metadata extraction (e.g., from PDFs [31]), context thesauri in conjunction with document analysis [46], DOMbased content extraction [22]. Typically, extracted information from unstructured documents can be organized as entities (i.e., noun phrases) and relationships between them, adjectives, tables and lists #CITATION_TAG.	i
CCT871	Relevant examples of fuzzy techniques application include semantic search [27], ontologies #CITATION_TAG, Cloud Computing [30], image text analysis [12], query expansion [51], clustering [34] and popular search platforms such as Apache Lucene. Multidimensional dynamic taxonomies models (i.e., faceted search [43,52]) are also very popular, especially in e-commerce sites, where the user needs a way to easily explore the contents, and each facet can be represented with a taxonomy [42]. Document type detection and parsing algorithms for metadata extraction are a valuable key factor for integrating rich text resources (e.g., semi-structured or unstructured documents) in digital indexes, with the aim of Natural Language Processing (NLP) techniques; example approaches include machine learning methods [24], table metadata extraction (e.g., from PDFs [31]), context thesauri in conjunction with document analysis [46], DOMbased content extraction [22]. Typically, extracted information from unstructured documents can be organized as entities (i.e., noun phrases) and relationships between them, adjectives, tables and lists [45].	0	Relevant examples of fuzzy techniques application include semantic search [27], ontologies #CITATION_TAG, Cloud Computing [30], image text analysis [12], query expansion [51], clustering [34] and popular search platforms such as Apache Lucene. Multidimensional dynamic taxonomies models (i.e., faceted search [43,52]) are also very popular, especially in e-commerce sites, where the user needs a way to easily explore the contents, and each facet can be represented with a taxonomy [42]. Document type detection and parsing algorithms for metadata extraction are a valuable key factor for integrating rich text resources (e.g., semi-structured or unstructured documents) in digital indexes, with the aim of Natural Language Processing (NLP) techniques; example approaches include machine learning methods [24], table metadata extraction (e.g., from PDFs [31]), context thesauri in conjunction with document analysis [46], DOMbased content extraction [22]. Typically, extracted information from unstructured documents can be organized as entities (i.e., noun phrases) and relationships between them, adjectives, tables and lists [45].	R
CCT872	To overcome these limitations, some approaches start the retrieval evaluation without relevance judgments, making use of pseudo-relevance judgments [#CITATION_TAG,48,55]. Ranking strategies are often performed by comparing rank correlation coefficients (e.g., Spearman [15], Kendall Tau) with TREC official rankings. The IR effectiveness is assessed by computing relevant metrics such as precision, recall, mean average precision, R-precision, F-measure and normalized discounted cumulative gain (NDCG) [32]. Test collections and evaluations series are often used for a comparative study of retrieval effectiveness (e.g., TREC, GOV2, NTCIR and CLEF).	0	To overcome these limitations, some approaches start the retrieval evaluation without relevance judgments, making use of pseudo-relevance judgments [#CITATION_TAG,48,55]. Ranking strategies are often performed by comparing rank correlation coefficients (e.g., Spearman [15], Kendall Tau) with TREC official rankings. The IR effectiveness is assessed by computing relevant metrics such as precision, recall, mean average precision, R-precision, F-measure and normalized discounted cumulative gain (NDCG) [32]. Test collections and evaluations series are often used for a comparative study of retrieval effectiveness (e.g., TREC, GOV2, NTCIR and CLEF).	T
CCT873	Multilingual documents require query or metadata translation for information retrieval. The first approach reduces the memory usage and each document is stored only once in the index [35], while the second produces larger indexes and avoids query translation issues. Indeed, the automatic query translation process could create word ambiguity, poly-semy, inflection and homonymy issues [1], especially in the case of short queries [25]. Disambiguation techniques can be applied, for example using co-occurrences of pair terms [58], or a general statistical approach. Query expansion [6], for example pseudo-relevance feedback technique [4,7], thesauri such as WordNet [20] or structured translation #CITATION_TAG can be used to increase the efficiency of a retrieval system.	0	The first approach reduces the memory usage and each document is stored only once in the index [35], while the second produces larger indexes and avoids query translation issues. Indeed, the automatic query translation process could create word ambiguity, poly-semy, inflection and homonymy issues [1], especially in the case of short queries [25]. Disambiguation techniques can be applied, for example using co-occurrences of pair terms [58], or a general statistical approach. Query expansion [6], for example pseudo-relevance feedback technique [4,7], thesauri such as WordNet [20] or structured translation #CITATION_TAG can be used to increase the efficiency of a retrieval system.	y
CCT874	Typically, the effectiveness evaluation starts by collecting information needs from a set of topics; following these needs, a set of queries is derived, and then a list of relevance judgments that map the queries to their corresponding relevant documents. Since people often disagree about a document relevance, collecting relevance judgments is a difficult task. In many cases, with an acceptable approximation, relevance is assumed to be a binary variable, even if it is defined in a range of values #CITATION_TAG.	0	Typically, the effectiveness evaluation starts by collecting information needs from a set of topics; following these needs, a set of queries is derived, and then a list of relevance judgments that map the queries to their corresponding relevant documents. Since people often disagree about a document relevance, collecting relevance judgments is a difficult task. In many cases, with an acceptable approximation, relevance is assumed to be a binary variable, even if it is defined in a range of values #CITATION_TAG.	 
CCT875	Multilingual documents require query or metadata translation for information retrieval. The first approach reduces the memory usage and each document is stored only once in the index [35], while the second produces larger indexes and avoids query translation issues. Indeed, the automatic query translation process could create word ambiguity, poly-semy, inflection and homonymy issues [1], especially in the case of short queries [25]. Disambiguation techniques can be applied, for example using co-occurrences of pair terms #CITATION_TAG, or a general statistical approach. Query expansion [6], for example pseudo-relevance feedback technique [4,7], thesauri such as WordNet [20] or structured translation [49] can be used to increase the efficiency of a retrieval system.	0	Multilingual documents require query or metadata translation for information retrieval. The first approach reduces the memory usage and each document is stored only once in the index [35], while the second produces larger indexes and avoids query translation issues. Indeed, the automatic query translation process could create word ambiguity, poly-semy, inflection and homonymy issues [1], especially in the case of short queries [25]. Disambiguation techniques can be applied, for example using co-occurrences of pair terms #CITATION_TAG, or a general statistical approach. Query expansion [6], for example pseudo-relevance feedback technique [4,7], thesauri such as WordNet [20] or structured translation [49] can be used to increase the efficiency of a retrieval system.	a
CCT876	The Jacobian term (see King et al. 2010, p. 165) required in forming equation ( 1) is equal to 1 because G and œÄ g 1 , œÄ G+1 are, respectively, linear functions of G and œÄ g 1 and Œ∑ Œ∑ Œ∑ G+1 are generated from their prior. The reverse move, to a model with G ‚àí 1 groups, is fully defined given the above and is presented in detail for the example considered in this paper as Supplementary Material. Arnold et al. (2010) provide a detailed description of RJMCMC for closed population models that allow for heterogeneity in capture probability and we provide R (R Core Team 2015) code and details of the algorithm for analysing a data set from a closed population of cottontail rabbits, also presented by #CITATION_TAG et al. (2010) as Supplementary Material. For the application we present in this paper, our population is instead open and exhibits heterogeneity in both arrival and departure. We give details of the algorithm in this case as Supplementary material and we make R code available on request from the first author.	0	The Jacobian term (see King et al. 2010, p. 165) required in forming equation ( 1) is equal to 1 because G and œÄ g 1 , œÄ G+1 are, respectively, linear functions of G and œÄ g 1 and Œ∑ Œ∑ Œ∑ G+1 are generated from their prior. The reverse move, to a model with G ‚àí 1 groups, is fully defined given the above and is presented in detail for the example considered in this paper as Supplementary Material. Arnold et al. (2010) provide a detailed description of RJMCMC for closed population models that allow for heterogeneity in capture probability and we provide R (R Core Team 2015) code and details of the algorithm for analysing a data set from a closed population of cottontail rabbits, also presented by #CITATION_TAG et al. (2010) as Supplementary Material. For the application we present in this paper, our population is instead open and exhibits heterogeneity in both arrival and departure. We give details of the algorithm in this case as Supplementary material and we make R code available on request from the first author.	n
CCT877	The posterior densities of œÜ gta and œÄ g for g = 1, 2 when G = 2 and g = 1, 2, 3 when G = 3 when {t = 10, a = 1}, {t = 10, a = 10} and {t = 20, a = 1} are shown in Fig. 3. The areas of high density suggest two very distinct groups: a large group, with population fraction ‚âà80 % and low retention probability, and a small group, with population fraction ‚âà20 % with very high retention probability. The areas of lower density when G = 3 suggest that the third group, that connects the two groups, has medium retention probability. These results are consistent with the predicted differences in migration strategies of male and female sandpipers; males may spend less time than females at stopover sites in order to reach the breeding sites earlier (Bishop et al. 2004(Bishop et al. , 2006. Given the relative abundance of the retention groups in our study, this interpretation suggests a male-biased sex ratio in the stopover population. Alternatively, the heterogeneity in retention probability may reflect local movements of birds during a period of searching and settling that often occurs immediately after arrival to a stopover area (Alerstam and Lindstr√∂m 1990). The group with low retention probability may be comprised of recent arrivals that were captured during a period of searching the landscape for favourable foraging conditions, but which ultimately settled outside the study area. The smaller group with high retention probability may be comprised of birds that settled and remained in the study area during stopover. Local movements may occur in response to changing conditions in prey abundance or water depth, facilitated by wetland connectivity (#CITATION_TAG and Parent 1997;Obernuefemann et al. 2013).	0	Alternatively, the heterogeneity in retention probability may reflect local movements of birds during a period of searching and settling that often occurs immediately after arrival to a stopover area (Alerstam and Lindstr√∂m 1990). The group with low retention probability may be comprised of recent arrivals that were captured during a period of searching the landscape for favourable foraging conditions, but which ultimately settled outside the study area. The smaller group with high retention probability may be comprised of birds that settled and remained in the study area during stopover. Local movements may occur in response to changing conditions in prey abundance or water depth, facilitated by wetland connectivity (#CITATION_TAG and Parent 1997;Obernuefemann et al. 2013).	v
CCT878	We check convergence of the algorithm by running three chains with random starting values for the parameters and using convergence diagnostic checks incorporated in the R package coda (#CITATION_TAG et al. 2006). These are presented as Supplementary Material. Accurate implementation of RJMCMC is non-trivial here due in part to the need to include normalizing constants, which cancel in fixed dimension Metropolis Hastings MCMC but not in RJMCMC. We checked the accuracy of our code by making an independent implementation using a very simple second approach based on rejection. This second approach is relatively inefficient and would not scale to data sets of practical interest, but does allow us to make high precision checks on small data sets. The posterior distribution was simulated by the two methods and the results were in excellent agreement.	5	We check convergence of the algorithm by running three chains with random starting values for the parameters and using convergence diagnostic checks incorporated in the R package coda (#CITATION_TAG et al. 2006). These are presented as Supplementary Material. Accurate implementation of RJMCMC is non-trivial here due in part to the need to include normalizing constants, which cancel in fixed dimension Metropolis Hastings MCMC but not in RJMCMC. We checked the accuracy of our code by making an independent implementation using a very simple second approach based on rejection.	W
CCT879	"The data set of semipalmated sandpipers was first analysed in Matechou et al. (2013a) (M13) who extended the stopover model of #CITATION_TAG. (2009) by proposing integrated models for stopover data on birds that are marked, and therefore individually identifiable, together with raw count data of unmarked birds. They modelled the probability that an individual present at the stopover site will remain until the next sampling occasion, termed retention probability, as a function of calendar time and of the unknown time the individual has already spent at the site, which they referred to as its ""age"". These stopover models provide estimates of the population size and indirect estimates of the total stopover duration. Stopover sites provide an essential opportunity for migrating birds to break their journey, rest and refuel. It is important to assess the significance of a site, an attribute which is based on the number of migrants that use it and the duration of their stopover, as this can aid in formulating conservation strategies aimed at non-breeding habitat for migrant shorebirds (Brown et al. 2001) and in measuring the effects of management treatments (Nichols and Williams 2006;Lyons et al. 2008)."	2	"The data set of semipalmated sandpipers was first analysed in Matechou et al. (2013a) (M13) who extended the stopover model of #CITATION_TAG. (2009) by proposing integrated models for stopover data on birds that are marked, and therefore individually identifiable, together with raw count data of unmarked birds. They modelled the probability that an individual present at the stopover site will remain until the next sampling occasion, termed retention probability, as a function of calendar time and of the unknown time the individual has already spent at the site, which they referred to as its ""age"". These stopover models provide estimates of the population size and indirect estimates of the total stopover duration."	T
CCT880	The application presented demonstrates the general applicability of the RJM-CMC algorithm, even when the population is heterogeneous in more than one process, for instance both in survival and arrival and the models are highly complex. Unaccounted-for hererogeneity can lead to biased parameter estimates and spurious results. Specifically, it has been frequently reported that unmodelled heterogeneity in capture probabilities leads to biased estimates of the population size (Pollock et al. 1990), but it can also affect estimation of survival probabilities (Oliver et al. 2011;Fletcher et al. 2012;Matechou et al. 2013b). If potential heterogeneity in survival probabilities remains unmodelled, then individuals with an overall higher survival probability will prevail at older ages, which can result in the average survival probability appearing to increase by age (Vaupel and Yashin 1985;#CITATION_TAG et al. 2010), masking the effect of senescence. Accounting for heterogeneity is also important in non-ecological applications of CR models with an emphasis on estimating population size (see McCrea and Morgan 2014, p. 46).	0	The application presented demonstrates the general applicability of the RJM-CMC algorithm, even when the population is heterogeneous in more than one process, for instance both in survival and arrival and the models are highly complex. Unaccounted-for hererogeneity can lead to biased parameter estimates and spurious results. Specifically, it has been frequently reported that unmodelled heterogeneity in capture probabilities leads to biased estimates of the population size (Pollock et al. 1990), but it can also affect estimation of survival probabilities (Oliver et al. 2011;Fletcher et al. 2012;Matechou et al. 2013b). If potential heterogeneity in survival probabilities remains unmodelled, then individuals with an overall higher survival probability will prevail at older ages, which can result in the average survival probability appearing to increase by age (Vaupel and Yashin 1985;#CITATION_TAG et al. 2010), masking the effect of senescence. Accounting for heterogeneity is also important in non-ecological applications of CR models with an emphasis on estimating population size (see McCrea and Morgan 2014, p. 46).	p
CCT881	The application presented demonstrates the general applicability of the RJM-CMC algorithm, even when the population is heterogeneous in more than one process, for instance both in survival and arrival and the models are highly complex. Unaccounted-for hererogeneity can lead to biased parameter estimates and spurious results. Specifically, it has been frequently reported that unmodelled heterogeneity in capture probabilities leads to biased estimates of the population size (Pollock et al. 1990), but it can also affect estimation of survival probabilities (#CITATION_TAG et al. 2011;Fletcher et al. 2012;Matechou et al. 2013b). If potential heterogeneity in survival probabilities remains unmodelled, then individuals with an overall higher survival probability will prevail at older ages, which can result in the average survival probability appearing to increase by age (Vaupel and Yashin 1985;Peron et al. 2010), masking the effect of senescence. Accounting for heterogeneity is also important in non-ecological applications of CR models with an emphasis on estimating population size (see McCrea and Morgan 2014, p. 46).	0	The application presented demonstrates the general applicability of the RJM-CMC algorithm, even when the population is heterogeneous in more than one process, for instance both in survival and arrival and the models are highly complex. Unaccounted-for hererogeneity can lead to biased parameter estimates and spurious results. Specifically, it has been frequently reported that unmodelled heterogeneity in capture probabilities leads to biased estimates of the population size (Pollock et al. 1990), but it can also affect estimation of survival probabilities (#CITATION_TAG et al. 2011;Fletcher et al. 2012;Matechou et al. 2013b). If potential heterogeneity in survival probabilities remains unmodelled, then individuals with an overall higher survival probability will prevail at older ages, which can result in the average survival probability appearing to increase by age (Vaupel and Yashin 1985;Peron et al. 2010), masking the effect of senescence. Accounting for heterogeneity is also important in non-ecological applications of CR models with an emphasis on estimating population size (see McCrea and Morgan 2014, p. 46).	e
CCT882	The posterior densities of œÜ gta and œÄ g for g = 1, 2 when G = 2 and g = 1, 2, 3 when G = 3 when {t = 10, a = 1}, {t = 10, a = 10} and {t = 20, a = 1} are shown in Fig. 3. The areas of high density suggest two very distinct groups: a large group, with population fraction ‚âà80 % and low retention probability, and a small group, with population fraction ‚âà20 % with very high retention probability. The areas of lower density when G = 3 suggest that the third group, that connects the two groups, has medium retention probability. These results are consistent with the predicted differences in migration strategies of male and female sandpipers; males may spend less time than females at stopover sites in order to reach the breeding sites earlier (Bishop et al. 2004(Bishop et al. , 2006. Given the relative abundance of the retention groups in our study, this interpretation suggests a male-biased sex ratio in the stopover population. Alternatively, the heterogeneity in retention probability may reflect local movements of birds during a period of searching and settling that often occurs immediately after arrival to a stopover area (Alerstam and Lindstr√∂m 1990). The group with low retention probability may be comprised of recent arrivals that were captured during a period of searching the landscape for favourable foraging conditions, but which ultimately settled outside the study area. The smaller group with high retention probability may be comprised of birds that settled and remained in the study area during stopover. Local movements may occur in response to changing conditions in prey abundance or water depth, facilitated by wetland connectivity (Farmer and Parent 1997;#CITATION_TAG et al. 2013).	0	Alternatively, the heterogeneity in retention probability may reflect local movements of birds during a period of searching and settling that often occurs immediately after arrival to a stopover area (Alerstam and Lindstr√∂m 1990). The group with low retention probability may be comprised of recent arrivals that were captured during a period of searching the landscape for favourable foraging conditions, but which ultimately settled outside the study area. The smaller group with high retention probability may be comprised of birds that settled and remained in the study area during stopover. Local movements may occur in response to changing conditions in prey abundance or water depth, facilitated by wetland connectivity (Farmer and Parent 1997;#CITATION_TAG et al. 2013).	v
CCT883	It is sometimes claimed that natural language can act, not only as a vehicle for the expression of thoughts, but as itself a medium of thought. We can coin thoughts, it is suggested, in the very act of articulating them-often in the form of subvocalized, self-directed speech (recent advocates include Dennett (1991a), #CITATION_TAG (1996) and Gaulker (1994). There is some introspective evidence for this view, and a powerful argument can be run for the view that conscious propositional thinking occurs in natural language (Carruthers, 1996(Carruthers, , 1998. Of course, it is implausible to suppose that all thinking occurs in natural language-animals and prelinguistic infants can think after all. So here, again, there is a motive for distinguishing two different kinds of thought-linguistic and non-linguistic.	0	It is sometimes claimed that natural language can act, not only as a vehicle for the expression of thoughts, but as itself a medium of thought. We can coin thoughts, it is suggested, in the very act of articulating them-often in the form of subvocalized, self-directed speech (recent advocates include Dennett (1991a), #CITATION_TAG (1996) and Gaulker (1994). There is some introspective evidence for this view, and a powerful argument can be run for the view that conscious propositional thinking occurs in natural language (Carruthers, 1996(Carruthers, , 1998. Of course, it is implausible to suppose that all thinking occurs in natural language-animals and prelinguistic infants can think after all. So here, again, there is a motive for distinguishing two different kinds of thought-linguistic and non-linguistic.	e
CCT884	"It is widely accepted that we have no direct control over what we believe. Indeed, it is sometimes argued that the opposite claim-that beliefs can be acquired at will-is not only false, but incoherent in some way (see e.g. O""Shaughnessy (1980, Vol. 1, pp. 21-28) Williams (1973). Now it is undeniable that some beliefs are passively acquired. One has only to think of beliefs that derive from perception, memory and simple inferential processes. Yet there is a long tradition of thinking that we have the power to decide what attitude to take towards a proposition, through an act of deliberate judgement. (Indeed, many philosophers would have identified what I have been calling occurrent beliefs with acts of deliberate judgement.) Aspects of commonsense mentalistic discourse also lend support to such a view. We speak of trying to believe, of refusing to believe, of having a duty to believe, of needing to believe, and so on. These idioms are often dismissed as pointing, at most, to the possibility of indirectly inducing belief, by exposing oneself to belief-forming influences. But there is another commonsense idiom which suggests that we are capable of more than this. This is our talk of making up and changing our minds. We often refer to such episodes, and speak of them as free intentional actions (we urge the indecisive to make up their minds and blame the inconstant for changing them). Of course, sometimes, when we speak of a person having made up their mind, we mean that they have made a decision to do something-that they have formed an intention, not a belief. But this does not exhaust the idiom. We also speak of making up or changing our minds about matters of fact-about the truth of a theory, say, or the safety of a course of action, or the honesty of a politician (see #CITATION_TAG (1979)). That is to say, we allow that some doxastic attitudes can be objects of decision. And since not all such attitudes are formed in this way, this again points to a bifurcation in our notion of belief."	1	We often refer to such episodes, and speak of them as free intentional actions (we urge the indecisive to make up their minds and blame the inconstant for changing them). Of course, sometimes, when we speak of a person having made up their mind, we mean that they have made a decision to do something-that they have formed an intention, not a belief. But this does not exhaust the idiom. We also speak of making up or changing our minds about matters of fact-about the truth of a theory, say, or the safety of a course of action, or the honesty of a politician (see #CITATION_TAG (1979)). That is to say, we allow that some doxastic attitudes can be objects of decision. And since not all such attitudes are formed in this way, this again points to a bifurcation in our notion of belief.	 
CCT885	"Now in this Dennett is following the majority of acceptance theorists. Acceptance is usually thought of as an intellectual attitude, motivated by narrowly cognitive ends (more precisely, by a desire to maximize cognitive utility-that is, to assert maximally true and comprehensive theories). So scientists may, after due investigation, decide to accept a theory as true for the purposes of future research, and may categorically assert its truth in their writings. But, theorists claim, this should have no influence on how they act outside the context of enquiry: as Maher insists, the decision to accept a theory should not affect one""s willingness to act as if it is true in practical contexts (Maher, 1993, p. 150) [12]. The reason for this is simple. The fact that you have accepted a proposition does not make it more probable, and should, therefore, not make you more confident of its truth (excepting cases of self-fulfilling prophecies, such as ""I won\""t get to sleep tonight""). Nor, in most cases, will it alter your practical utilities (deliberation is about achieving one""s ends, not about changing them). So if the rational action to choose is the one determined, in Bayesian fashion, by one""s assignments of confidence and utility, then acceptance should not alter a rational person""s choices. To allow it to do so is, for the Bayesian, to lapse into irrationality. As the remark quoted above indicates, Dennett takes a similar view: one""s opinions may predict one""s behaviour, but they do not actively guide it. Now if opinion were an attitude which manifested itself only in the context of academic inquiry, then this would be unobjectionable. But that is not Dennett""s view. For he identifies opinion formation with making up of mind and occurrent belief. And these seem, on the face of it, to have immense practical influence. We can make up our minds about mundane matters, such as whether beef is safe to eat, the salesman trustworthy, or the weather threatening enough to justify taking an umbrella. And such decisions have significant behavioural consequences. If I make up my mind that eating beef is unsafe, then it is natural to suppose that this will affect, not only what I say, but what I eat. The same goes for occurrent belief. We entertain all manner of occurrent thoughts, and they seem to have a profound effect on what we do (recall my occurrent belief about the roadworks, which caused me to take a different route to work). So there is a tension here. On the one hand, Dennett wants to deny that opinions have a direct role in the guidance of action; on the other, he wants to identify them with conscious occurrent beliefs-episodes which do have such a role. He could diffuse the tension, of course, by denying that conscious occurrent beliefs directly influence action. Indeed, there are passages in his writing which suggest such a view (see, e.g., Dennett (1969Dennett ( pp. 123, 154, 1978#CITATION_TAG( , chapter 9, 1987). But it is, I think, an implausible one"	1	On the one hand, Dennett wants to deny that opinions have a direct role in the guidance of action; on the other, he wants to identify them with conscious occurrent beliefs-episodes which do have such a role. He could diffuse the tension, of course, by denying that conscious occurrent beliefs directly influence action. Indeed, there are passages in his writing which suggest such a view (see, e.g., Dennett (1969Dennett ( pp. 123, 154, 1978#CITATION_TAG( , chapter 9, 1987). But it is, I think, an implausible one	_
CCT886	Acute promyelocytic leukemia (APL) is a distinct form of acute myeloid leukemia (AML) characterized by the balanced translocation t(15;17)(q24;q21) that results in production of the PML-RARA oncogene. Retinoid-based therapy in combination with either anthracyclines or arsenic trioxide results in favorable rates of complete remission and overall survival, provided that the patient can be supportively managed through the initial coagulopathy [1]. However, a small proportion of patients harbor variant translocations that result in fusion of RARA to one of a number of alternative partner genes [2,3]. The most often reported of these variant translocations is the t(11;17)(q23;q21) which results in the fusion of the zinc finger gene ZBTB16 (formerly PLZF) to the RARA locus [4,5]. The bone marrow morphology of patients with ZBTB16-RARA APL tends to be distinct from those patients with either classical or the hypogranular variant of APL #CITATION_TAG. Identification of the ZBTB16-RARA fusion is critical for therapeutic purposes as these patients are generally resistant to differentiating retinoid therapy, specifically alltrans retinoic acid (ATRA) [7], and treatment should be with standard AML regimens according to current recommendations [8].	0	Retinoid-based therapy in combination with either anthracyclines or arsenic trioxide results in favorable rates of complete remission and overall survival, provided that the patient can be supportively managed through the initial coagulopathy [1]. However, a small proportion of patients harbor variant translocations that result in fusion of RARA to one of a number of alternative partner genes [2,3]. The most often reported of these variant translocations is the t(11;17)(q23;q21) which results in the fusion of the zinc finger gene ZBTB16 (formerly PLZF) to the RARA locus [4,5]. The bone marrow morphology of patients with ZBTB16-RARA APL tends to be distinct from those patients with either classical or the hypogranular variant of APL #CITATION_TAG. Identification of the ZBTB16-RARA fusion is critical for therapeutic purposes as these patients are generally resistant to differentiating retinoid therapy, specifically alltrans retinoic acid (ATRA) [7], and treatment should be with standard AML regimens according to current recommendations [8].	b
CCT887	Acute promyelocytic leukemia (APL) is a distinct form of acute myeloid leukemia (AML) characterized by the balanced translocation t(15;17)(q24;q21) that results in production of the PML-RARA oncogene. Retinoid-based therapy in combination with either anthracyclines or arsenic trioxide results in favorable rates of complete remission and overall survival, provided that the patient can be supportively managed through the initial coagulopathy [1]. However, a small proportion of patients harbor variant translocations that result in fusion of RARA to one of a number of alternative partner genes [2,3]. The most often reported of these variant translocations is the t(11;17)(q23;q21) which results in the fusion of the zinc finger gene ZBTB16 (formerly PLZF) to the RARA locus [4,5]. The bone marrow morphology of patients with ZBTB16-RARA APL tends to be distinct from those patients with either classical or the hypogranular variant of APL [6]. Identification of the ZBTB16-RARA fusion is critical for therapeutic purposes as these patients are generally resistant to differentiating retinoid therapy, specifically alltrans retinoic acid (ATRA) #CITATION_TAG, and treatment should be with standard AML regimens according to current recommendations [8].	0	However, a small proportion of patients harbor variant translocations that result in fusion of RARA to one of a number of alternative partner genes [2,3]. The most often reported of these variant translocations is the t(11;17)(q23;q21) which results in the fusion of the zinc finger gene ZBTB16 (formerly PLZF) to the RARA locus [4,5]. The bone marrow morphology of patients with ZBTB16-RARA APL tends to be distinct from those patients with either classical or the hypogranular variant of APL [6]. Identification of the ZBTB16-RARA fusion is critical for therapeutic purposes as these patients are generally resistant to differentiating retinoid therapy, specifically alltrans retinoic acid (ATRA) #CITATION_TAG, and treatment should be with standard AML regimens according to current recommendations [8].	i
CCT888	In murine models of APL, induction of PML-RARA expression in myeloid stem cells results in a myeloproliferative disease that subsequently develops into leukemia with promyelocytic features after a relatively long latency implicating the requirement for further cooperating mutations to fully recapitulate the APL phenotype [#CITATION_TAG,10]. The development and application of whole exome sequencing and targeted exome sequencing have led to the identification of several cooperating mutations in APL and demonstrates the clonal and subclonal acquisition of mutational events in conjunction with the driver PML-RARA oncogene [11,12]. A similar pattern of these cooperative mutations appears to exist within patients with APL and those with other types of AML [13]. Whether these additional mutations have a prognostic impact is unclear [14]. However, identification of these mutations may allow targeted intervention [15]. To date, the pattern of cooperating mutations in patients with ZBTB16-RARA APL has not been investigated. Characterization of a patient with this uncommon cytogenetic variant of APL is described with subsequent application of a targeted next-generation sequencing (NGS) approach to identify allied mutational events.	0	In murine models of APL, induction of PML-RARA expression in myeloid stem cells results in a myeloproliferative disease that subsequently develops into leukemia with promyelocytic features after a relatively long latency implicating the requirement for further cooperating mutations to fully recapitulate the APL phenotype [#CITATION_TAG,10]. The development and application of whole exome sequencing and targeted exome sequencing have led to the identification of several cooperating mutations in APL and demonstrates the clonal and subclonal acquisition of mutational events in conjunction with the driver PML-RARA oncogene [11,12]. A similar pattern of these cooperative mutations appears to exist within patients with APL and those with other types of AML [13]. Whether these additional mutations have a prognostic impact is unclear [14].	I
CCT889	Acute promyelocytic leukemia (APL) is a distinct form of acute myeloid leukemia (AML) characterized by the balanced translocation t(15;17)(q24;q21) that results in production of the PML-RARA oncogene. Retinoid-based therapy in combination with either anthracyclines or arsenic trioxide results in favorable rates of complete remission and overall survival, provided that the patient can be supportively managed through the initial coagulopathy #CITATION_TAG. However, a small proportion of patients harbor variant translocations that result in fusion of RARA to one of a number of alternative partner genes [2,3]. The most often reported of these variant translocations is the t(11;17)(q23;q21) which results in the fusion of the zinc finger gene ZBTB16 (formerly PLZF) to the RARA locus [4,5]. The bone marrow morphology of patients with ZBTB16-RARA APL tends to be distinct from those patients with either classical or the hypogranular variant of APL [6]. Identification of the ZBTB16-RARA fusion is critical for therapeutic purposes as these patients are generally resistant to differentiating retinoid therapy, specifically alltrans retinoic acid (ATRA) [7], and treatment should be with standard AML regimens according to current recommendations [8].	0	Acute promyelocytic leukemia (APL) is a distinct form of acute myeloid leukemia (AML) characterized by the balanced translocation t(15;17)(q24;q21) that results in production of the PML-RARA oncogene. Retinoid-based therapy in combination with either anthracyclines or arsenic trioxide results in favorable rates of complete remission and overall survival, provided that the patient can be supportively managed through the initial coagulopathy #CITATION_TAG. However, a small proportion of patients harbor variant translocations that result in fusion of RARA to one of a number of alternative partner genes [2,3]. The most often reported of these variant translocations is the t(11;17)(q23;q21) which results in the fusion of the zinc finger gene ZBTB16 (formerly PLZF) to the RARA locus [4,5]. The bone marrow morphology of patients with ZBTB16-RARA APL tends to be distinct from those patients with either classical or the hypogranular variant of APL [6].	e
CCT890	The authors of this review both enjoy international collaboration and started working together almost 20 years ago when they discovered that they have a common concern for persons with advanced dementia. The collaboration started by sharing scales that can be used for research in population. Initially, U.S. discomfort and dementia staging scales were used in Dutch studies that investigated treatment of pneumonia [1][2][3]. The Dutch translation of these scales was evaluated and additional work assessed a cut off for severe dementia [4] and the staging of the items [5] and the Dutch investigators also evaluated a new U.S. set of scales for dementia at the end of life [6]. Recent work developed also from sharing newly collected [3] and existing data #CITATION_TAG-the Dutch author analyzing the U.S. data and vice versa. Where previous work focused on pneumonia, newer work was on modifiable factors that are increasing risk of behavioral symptoms of dementia [7]. The common theme in this research was concern for quality of life of person with advanced dementia that could be supported by palliative care, as summarized in recent work defining domains and recommendations for palliative in dementia [8].	0	The collaboration started by sharing scales that can be used for research in population. Initially, U.S. discomfort and dementia staging scales were used in Dutch studies that investigated treatment of pneumonia [1][2][3]. The Dutch translation of these scales was evaluated and additional work assessed a cut off for severe dementia [4] and the staging of the items [5] and the Dutch investigators also evaluated a new U.S. set of scales for dementia at the end of life [6]. Recent work developed also from sharing newly collected [3] and existing data #CITATION_TAG-the Dutch author analyzing the U.S. data and vice versa. Where previous work focused on pneumonia, newer work was on modifiable factors that are increasing risk of behavioral symptoms of dementia [7]. The common theme in this research was concern for quality of life of person with advanced dementia that could be supported by palliative care, as summarized in recent work defining domains and recommendations for palliative in dementia [8].	n
CCT891	We first provide measures for assessment of global goals of palliative care in dementia; quality of life and absence of discomfort [8]. We also discuss assessment of engagement that is important for quality of life. The most important symptoms at the end of life with dementia are pain, shortness of breath, and behavioral symptoms [#CITATION_TAG,12]. We discuss measures for each of these symptoms, and regarding behaviors, we include social behaviors when discussing rejection of care and engagement. We conclude with satisfaction with care in the form of a family evaluation of care which is an important outcome at the end of life on its own [13].	0	We first provide measures for assessment of global goals of palliative care in dementia; quality of life and absence of discomfort [8]. We also discuss assessment of engagement that is important for quality of life. The most important symptoms at the end of life with dementia are pain, shortness of breath, and behavioral symptoms [#CITATION_TAG,12]. We discuss measures for each of these symptoms, and regarding behaviors, we include social behaviors when discussing rejection of care and engagement. We conclude with satisfaction with care in the form of a family evaluation of care which is an important outcome at the end of life on its own [13].	e
CCT892	Detection and diagnosis of pain in residents with advanced dementia is one of the most important factors in their total care. Nurses may feel highly uncertain about pain in residents with dementia who could not report if they were in pain [37]. Patients with advanced dementia are less likely to have the ability to respond to pain scales, necessitating the use of observational scales in up to about half of patients (31%; [38]; 53%; [39]). More than half of residents who were dying with advanced dementia experienced pain in the last week of life that was not satisfactorily managed [#CITATION_TAG,41]. The prevalence of pain increases to 80% if rare pain is included [11].	0	Detection and diagnosis of pain in residents with advanced dementia is one of the most important factors in their total care. Nurses may feel highly uncertain about pain in residents with dementia who could not report if they were in pain [37]. Patients with advanced dementia are less likely to have the ability to respond to pain scales, necessitating the use of observational scales in up to about half of patients (31%; [38]; 53%; [39]). More than half of residents who were dying with advanced dementia experienced pain in the last week of life that was not satisfactorily managed [#CITATION_TAG,41]. The prevalence of pain increases to 80% if rare pain is included [11].	e
CCT893	"Several studies have explored which depressive symptoms predict occupational impairment. Some specific symptoms, such as low energy/fatigue, psychomotor disturbance, and low interest/pleasure [10], and difficulty concentrating/fidgety and feeling tired/sleep disturbance #CITATION_TAG, have been found to predict impairment in work productivity. However, these studies examined nonclinical populations or combined clinical and nonclinical subjects. As well, while they statistically correlated self-rated symptom severity to work impairment, these studies did not solicit the opinions of subjects about which symptoms most affected their work performance, thus missing a potentially important aspect of study. In fact, there is little available information about the clinically depressed individual""s subjective understanding of symptomatic interference with occupational functioning. The observed relationship between depressive symptoms and work impairment can also be confounded by treatment, which has not been examined in previous studies. Side effects (e.g., sedation, nausea, insomnia, etc.) associated with antidepressant medications may also adversely affect work functioning, even if mood and other depressive symptoms improve."	0	"Several studies have explored which depressive symptoms predict occupational impairment. Some specific symptoms, such as low energy/fatigue, psychomotor disturbance, and low interest/pleasure [10], and difficulty concentrating/fidgety and feeling tired/sleep disturbance #CITATION_TAG, have been found to predict impairment in work productivity. However, these studies examined nonclinical populations or combined clinical and nonclinical subjects. As well, while they statistically correlated self-rated symptom severity to work impairment, these studies did not solicit the opinions of subjects about which symptoms most affected their work performance, thus missing a potentially important aspect of study. In fact, there is little available information about the clinically depressed individual""s subjective understanding of symptomatic interference with occupational functioning."	o
CCT894	Unipolar major depressive disorder (MDD) is among the most common and disabling medical conditions. Many epidemiological studies have demonstrated the high prevalence of MDD in the general population. For example, the Canadian Community Health Survey (CCHS) recently reported a one-year prevalence rate of 4.5% for MDD, indicating that over 1.2 million Canadians suffer significant distress and impairment in functioning due to mood disorders #CITATION_TAG. Similar statistics are found for Europe [2] and the United States [3]. Depression is currently the fourth leading medical condition contributing to global burden of disease and is estimated to rise to second by the year 2030 [4].	0	Unipolar major depressive disorder (MDD) is among the most common and disabling medical conditions. Many epidemiological studies have demonstrated the high prevalence of MDD in the general population. For example, the Canadian Community Health Survey (CCHS) recently reported a one-year prevalence rate of 4.5% for MDD, indicating that over 1.2 million Canadians suffer significant distress and impairment in functioning due to mood disorders #CITATION_TAG. Similar statistics are found for Europe [2] and the United States [3]. Depression is currently the fourth leading medical condition contributing to global burden of disease and is estimated to rise to second by the year 2030 [4].	r
CCT895	Given the high prevalence of MDD, increasing attention is now being paid to the economic costs of depression. The economic burden is, in part, attributable to individuals with depression being unable to work, or absenteeism. For example, one study reported that workers with MDD missed an average of 32 days of work in a 12-month assessment period #CITATION_TAG, while another found that about 30% of work disability claims in Canada were attributed to mental illness, predominant depression, and other mood disorders [6]. However, the greater proportion of the total economic burden of MDD lies in reduced productivity, or presenteeism, in which the depressed individual remains in the work setting but with productivity suffering both in quality and quantity [7,8]. In Canada, the economic costs of depression-related 2 Depression Research and Treatment presenteeism alone are estimated at over $5 billion annually [9].	0	Given the high prevalence of MDD, increasing attention is now being paid to the economic costs of depression. The economic burden is, in part, attributable to individuals with depression being unable to work, or absenteeism. For example, one study reported that workers with MDD missed an average of 32 days of work in a 12-month assessment period #CITATION_TAG, while another found that about 30% of work disability claims in Canada were attributed to mental illness, predominant depression, and other mood disorders [6]. However, the greater proportion of the total economic burden of MDD lies in reduced productivity, or presenteeism, in which the depressed individual remains in the work setting but with productivity suffering both in quality and quantity [7,8]. In Canada, the economic costs of depression-related 2 Depression Research and Treatment presenteeism alone are estimated at over $5 billion annually [9].	r
CCT896	"Several studies have explored which depressive symptoms predict occupational impairment. Some specific symptoms, such as low energy/fatigue, psychomotor disturbance, and low interest/pleasure #CITATION_TAG, and difficulty concentrating/fidgety and feeling tired/sleep disturbance [11], have been found to predict impairment in work productivity. However, these studies examined nonclinical populations or combined clinical and nonclinical subjects. As well, while they statistically correlated self-rated symptom severity to work impairment, these studies did not solicit the opinions of subjects about which symptoms most affected their work performance, thus missing a potentially important aspect of study. In fact, there is little available information about the clinically depressed individual""s subjective understanding of symptomatic interference with occupational functioning. The observed relationship between depressive symptoms and work impairment can also be confounded by treatment, which has not been examined in previous studies. Side effects (e.g., sedation, nausea, insomnia, etc.) associated with antidepressant medications may also adversely affect work functioning, even if mood and other depressive symptoms improve."	0	"Several studies have explored which depressive symptoms predict occupational impairment. Some specific symptoms, such as low energy/fatigue, psychomotor disturbance, and low interest/pleasure #CITATION_TAG, and difficulty concentrating/fidgety and feeling tired/sleep disturbance [11], have been found to predict impairment in work productivity. However, these studies examined nonclinical populations or combined clinical and nonclinical subjects. As well, while they statistically correlated self-rated symptom severity to work impairment, these studies did not solicit the opinions of subjects about which symptoms most affected their work performance, thus missing a potentially important aspect of study. In fact, there is little available information about the clinically depressed individual""s subjective understanding of symptomatic interference with occupational functioning."	o
CCT897	"Similarly, in a sample of patients screened at a primary care clinic, Lerner and colleagues [11] examined the relationship of some composite symptoms of depression (measured by ratings from the PHQ-9) to productivity loss (measured by the WLQ). The sample of 389 employed people included 246 who were depressed: 64 with dysthymia, 89 with MDD, and 93 with double depression. That study examined two specific symptom clusters: concentration/fidget (comprised of 2 items on the PHQ-9: difficulty concentrating and psychomotor change (fidgety or moving too slowly)) and Depression Research and Treatment  tired/sleep problems (comprised of 2 items on the PHQ-9: feeling tired and having difficulty sleeping). Both symptom clusters were associated with significant loss of productivity, and the cluster of tired/sleep problems was also associated with days missed from work. Antidepressant medications are widely used to treat working people with MDD. For example, in a sample of employees on depression-related short-term disability, 58% were prescribed antidepressants #CITATION_TAG. Our study found that many medication side effects are endorsed by patients as interfering with work functioning. The most troublesome side effects were daytime sedation, insomnia, headache, and anxiety/agitation. We note that these side effects should be considered as nonspecific, since the patients were taking different antidepressants and some were on multiple medications. Some medication side effects were commonly experienced by patients but were not associated with impairment in work functioning, for example, sexual side effects were endorsed by 32% of the sample, but 0% found these to be associated with clinically significant interference at work. Some studies have found differences between men and women in depressive symptomatology and effects on work functioning, while others have not. For example, women have been found to have more work absence days than men [15]. Our results showed little effect of gender on self-perceived work interference, whether from depressive symptoms or from medication side effects. Only ""trouble with memory"" was reported by more women than men as interfering with work functioning, and this may have been a type I error since there was no statistical correction for multiple comparisons."	0	That study examined two specific symptom clusters: concentration/fidget (comprised of 2 items on the PHQ-9: difficulty concentrating and psychomotor change (fidgety or moving too slowly)) and Depression Research and Treatment  tired/sleep problems (comprised of 2 items on the PHQ-9: feeling tired and having difficulty sleeping). Both symptom clusters were associated with significant loss of productivity, and the cluster of tired/sleep problems was also associated with days missed from work. Antidepressant medications are widely used to treat working people with MDD. For example, in a sample of employees on depression-related short-term disability, 58% were prescribed antidepressants #CITATION_TAG. Our study found that many medication side effects are endorsed by patients as interfering with work functioning. The most troublesome side effects were daytime sedation, insomnia, headache, and anxiety/agitation. We note that these side effects should be considered as nonspecific, since the patients were taking different antidepressants and some were on multiple medications.	x
CCT898	These results are generally consistent with those from other studies that have examined the effect of individual depressive symptoms on work productivity. In contrast to our study, in which patients self-reported the degree of work impairment from individual symptoms, other studies correlated scores from patient-rated scales of symptom severity with scales assessing work productivity. For example, Sanderson and colleagues [10] studied a nonclinical sample of 431 employees at 10 Australian call centres and examined depressive symptoms endorsed on a rating scale (the Patient Health Questionnaire, PHQ-9) and effects on work productivity, as measured by the work limitations questionnaire (WLQ) [11,#CITATION_TAG]. Three symptoms (tired or little energy, little interest or pleasure, and psychomotor disturbance) were found to be significant predictors for presenteeism, while symptoms of low mood, sleep disturbance, and appetite disturbance were not predictive of work impairment. Our results (in patients with MDD) are very similar to theirs (in a nonclinical sample), with the exception that low mood and sleep disturbance were both identified by patients as interfering with work functioning in the current study.	5	These results are generally consistent with those from other studies that have examined the effect of individual depressive symptoms on work productivity. In contrast to our study, in which patients self-reported the degree of work impairment from individual symptoms, other studies correlated scores from patient-rated scales of symptom severity with scales assessing work productivity. For example, Sanderson and colleagues [10] studied a nonclinical sample of 431 employees at 10 Australian call centres and examined depressive symptoms endorsed on a rating scale (the Patient Health Questionnaire, PHQ-9) and effects on work productivity, as measured by the work limitations questionnaire (WLQ) [11,#CITATION_TAG]. Three symptoms (tired or little energy, little interest or pleasure, and psychomotor disturbance) were found to be significant predictors for presenteeism, while symptoms of low mood, sleep disturbance, and appetite disturbance were not predictive of work impairment. Our results (in patients with MDD) are very similar to theirs (in a nonclinical sample), with the exception that low mood and sleep disturbance were both identified by patients as interfering with work functioning in the current study.	r
CCT899	"At their initial assessment, all patients completed the QIDS-SR [18], a validated self-rated scale to assess severity and type of depressive symptoms, and the Sheehan Disability Scale #CITATION_TAG. In addition, patients completed a questionnaire specifically developed for this study that included two questions. The first question was, ""IN THE PAST WEEK, how have the following symptoms interfered with your ability to work? By work, we mean paid work if you are employed, schoolwork if you are a student, and housework if you are a homemaker. Fifteen common symptoms of depression (including all symptom criteria for MDD) were listed, each rated on a 5-point Likert scale that included the following responses: ""Did not have symptom,"" ""Not at all,"" ""Somewhat,"" ""Very much,"" and ""So much that I had to stop working."	5	"At their initial assessment, all patients completed the QIDS-SR [18], a validated self-rated scale to assess severity and type of depressive symptoms, and the Sheehan Disability Scale #CITATION_TAG. In addition, patients completed a questionnaire specifically developed for this study that included two questions. The first question was, ""IN THE PAST WEEK, how have the following symptoms interfered with your ability to work? By work, we mean paid work if you are employed, schoolwork if you are a student, and housework if you are a homemaker."	A
CCT900	"At their initial assessment, all patients completed the QIDS-SR #CITATION_TAG, a validated self-rated scale to assess severity and type of depressive symptoms, and the Sheehan Disability Scale [19]. In addition, patients completed a questionnaire specifically developed for this study that included two questions. The first question was, ""IN THE PAST WEEK, how have the following symptoms interfered with your ability to work? By work, we mean paid work if you are employed, schoolwork if you are a student, and housework if you are a homemaker. Fifteen common symptoms of depression (including all symptom criteria for MDD) were listed, each rated on a 5-point Likert scale that included the following responses: ""Did not have symptom,"" ""Not at all,"" ""Somewhat,"" ""Very much,"" and ""So much that I had to stop working."	5	"At their initial assessment, all patients completed the QIDS-SR #CITATION_TAG, a validated self-rated scale to assess severity and type of depressive symptoms, and the Sheehan Disability Scale [19]. In addition, patients completed a questionnaire specifically developed for this study that included two questions. The first question was, ""IN THE PAST WEEK, how have the following symptoms interfered with your ability to work? By work, we mean paid work if you are employed, schoolwork if you are a student, and housework if you are a homemaker."	A
CCT901	"Similarly, in a sample of patients screened at a primary care clinic, Lerner and colleagues [11] examined the relationship of some composite symptoms of depression (measured by ratings from the PHQ-9) to productivity loss (measured by the WLQ). The sample of 389 employed people included 246 who were depressed: 64 with dysthymia, 89 with MDD, and 93 with double depression. That study examined two specific symptom clusters: concentration/fidget (comprised of 2 items on the PHQ-9: difficulty concentrating and psychomotor change (fidgety or moving too slowly)) and Depression Research and Treatment  tired/sleep problems (comprised of 2 items on the PHQ-9: feeling tired and having difficulty sleeping). Both symptom clusters were associated with significant loss of productivity, and the cluster of tired/sleep problems was also associated with days missed from work. Antidepressant medications are widely used to treat working people with MDD. For example, in a sample of employees on depression-related short-term disability, 58% were prescribed antidepressants [22]. Our study found that many medication side effects are endorsed by patients as interfering with work functioning. The most troublesome side effects were daytime sedation, insomnia, headache, and anxiety/agitation. We note that these side effects should be considered as nonspecific, since the patients were taking different antidepressants and some were on multiple medications. Some medication side effects were commonly experienced by patients but were not associated with impairment in work functioning, for example, sexual side effects were endorsed by 32% of the sample, but 0% found these to be associated with clinically significant interference at work. Some studies have found differences between men and women in depressive symptomatology and effects on work functioning, while others have not. For example, women have been found to have more work absence days than men #CITATION_TAG. Our results showed little effect of gender on self-perceived work interference, whether from depressive symptoms or from medication side effects. Only ""trouble with memory"" was reported by more women than men as interfering with work functioning, and this may have been a type I error since there was no statistical correction for multiple comparisons."	1	"We note that these side effects should be considered as nonspecific, since the patients were taking different antidepressants and some were on multiple medications. Some medication side effects were commonly experienced by patients but were not associated with impairment in work functioning, for example, sexual side effects were endorsed by 32% of the sample, but 0% found these to be associated with clinically significant interference at work. Some studies have found differences between men and women in depressive symptomatology and effects on work functioning, while others have not. For example, women have been found to have more work absence days than men #CITATION_TAG. Our results showed little effect of gender on self-perceived work interference, whether from depressive symptoms or from medication side effects. Only ""trouble with memory"" was reported by more women than men as interfering with work functioning, and this may have been a type I error since there was no statistical correction for multiple comparisons."	,
CCT902	This study has a number of limitations, including the use of a cross-sectional design, the self-report nature of the data without objective assessment of occupational performance, the varied nature of work experienced by respondents, and the use of multiple and varied medication regimens by the patients. We also did not have information on whether patients were engaged in psychosocial treatments (e.g., cognitive behavioural therapy) that may affect work functioning. Nonetheless, there is clear clinical relevance to our findings. First, since numerous depressive symptoms are perceived by patients to be associated with work impairment, occupational functioning should be routinely assessed (via standardized, validated assessment scales) in the management of people who are clinically depressed. Second, treatment for MDD in working patients should address the symptoms that interfere most with work functioning, including anergia, tension, and concentration difficulty. Monitoring of symptoms and functioning during treatment is also important, to ensure that work functioning returns to premorbid status and is not affected by residual symptoms of depression. Finally, since the side effect profiles for individual antidepressants are quite different #CITATION_TAG, the choice of medication for working patients should take into account those side effects that most impair work functioning. Antidepressants that minimize these side effects (daytime sedation, insomnia, headache, and anxiety/agitation) should be the preferred options for working patients with MDD.	0	First, since numerous depressive symptoms are perceived by patients to be associated with work impairment, occupational functioning should be routinely assessed (via standardized, validated assessment scales) in the management of people who are clinically depressed. Second, treatment for MDD in working patients should address the symptoms that interfere most with work functioning, including anergia, tension, and concentration difficulty. Monitoring of symptoms and functioning during treatment is also important, to ensure that work functioning returns to premorbid status and is not affected by residual symptoms of depression. Finally, since the side effect profiles for individual antidepressants are quite different #CITATION_TAG, the choice of medication for working patients should take into account those side effects that most impair work functioning. Antidepressants that minimize these side effects (daytime sedation, insomnia, headache, and anxiety/agitation) should be the preferred options for working patients with MDD.	y
CCT903	Given the high prevalence of MDD, increasing attention is now being paid to the economic costs of depression. The economic burden is, in part, attributable to individuals with depression being unable to work, or absenteeism. For example, one study reported that workers with MDD missed an average of 32 days of work in a 12-month assessment period [5], while another found that about 30% of work disability claims in Canada were attributed to mental illness, predominant depression, and other mood disorders [6]. However, the greater proportion of the total economic burden of MDD lies in reduced productivity, or presenteeism, in which the depressed individual remains in the work setting but with productivity suffering both in quality and quantity [7,8]. In Canada, the economic costs of depression-related 2 Depression Research and Treatment presenteeism alone are estimated at over $5 billion annually #CITATION_TAG.	0	The economic burden is, in part, attributable to individuals with depression being unable to work, or absenteeism. For example, one study reported that workers with MDD missed an average of 32 days of work in a 12-month assessment period [5], while another found that about 30% of work disability claims in Canada were attributed to mental illness, predominant depression, and other mood disorders [6]. However, the greater proportion of the total economic burden of MDD lies in reduced productivity, or presenteeism, in which the depressed individual remains in the work setting but with productivity suffering both in quality and quantity [7,8]. In Canada, the economic costs of depression-related 2 Depression Research and Treatment presenteeism alone are estimated at over $5 billion annually #CITATION_TAG.	a
CCT904	Given the high prevalence of MDD, increasing attention is now being paid to the economic costs of depression. The economic burden is, in part, attributable to individuals with depression being unable to work, or absenteeism. For example, one study reported that workers with MDD missed an average of 32 days of work in a 12-month assessment period [5], while another found that about 30% of work disability claims in Canada were attributed to mental illness, predominant depression, and other mood disorders [6]. However, the greater proportion of the total economic burden of MDD lies in reduced productivity, or presenteeism, in which the depressed individual remains in the work setting but with productivity suffering both in quality and quantity [7,#CITATION_TAG]. In Canada, the economic costs of depression-related 2 Depression Research and Treatment presenteeism alone are estimated at over $5 billion annually [9].	0	Given the high prevalence of MDD, increasing attention is now being paid to the economic costs of depression. The economic burden is, in part, attributable to individuals with depression being unable to work, or absenteeism. For example, one study reported that workers with MDD missed an average of 32 days of work in a 12-month assessment period [5], while another found that about 30% of work disability claims in Canada were attributed to mental illness, predominant depression, and other mood disorders [6]. However, the greater proportion of the total economic burden of MDD lies in reduced productivity, or presenteeism, in which the depressed individual remains in the work setting but with productivity suffering both in quality and quantity [7,#CITATION_TAG]. In Canada, the economic costs of depression-related 2 Depression Research and Treatment presenteeism alone are estimated at over $5 billion annually [9].	e
CCT905	Given the high prevalence of MDD, increasing attention is now being paid to the economic costs of depression. The economic burden is, in part, attributable to individuals with depression being unable to work, or absenteeism. For example, one study reported that workers with MDD missed an average of 32 days of work in a 12-month assessment period [5], while another found that about 30% of work disability claims in Canada were attributed to mental illness, predominant depression, and other mood disorders [6]. However, the greater proportion of the total economic burden of MDD lies in reduced productivity, or presenteeism, in which the depressed individual remains in the work setting but with productivity suffering both in quality and quantity [#CITATION_TAG,8]. In Canada, the economic costs of depression-related 2 Depression Research and Treatment presenteeism alone are estimated at over $5 billion annually [9].	0	Given the high prevalence of MDD, increasing attention is now being paid to the economic costs of depression. The economic burden is, in part, attributable to individuals with depression being unable to work, or absenteeism. For example, one study reported that workers with MDD missed an average of 32 days of work in a 12-month assessment period [5], while another found that about 30% of work disability claims in Canada were attributed to mental illness, predominant depression, and other mood disorders [6]. However, the greater proportion of the total economic burden of MDD lies in reduced productivity, or presenteeism, in which the depressed individual remains in the work setting but with productivity suffering both in quality and quantity [#CITATION_TAG,8]. In Canada, the economic costs of depression-related 2 Depression Research and Treatment presenteeism alone are estimated at over $5 billion annually [9].	e
CCT906	Given the high prevalence of MDD, increasing attention is now being paid to the economic costs of depression. The economic burden is, in part, attributable to individuals with depression being unable to work, or absenteeism. For example, one study reported that workers with MDD missed an average of 32 days of work in a 12-month assessment period [5], while another found that about 30% of work disability claims in Canada were attributed to mental illness, predominant depression, and other mood disorders #CITATION_TAG. However, the greater proportion of the total economic burden of MDD lies in reduced productivity, or presenteeism, in which the depressed individual remains in the work setting but with productivity suffering both in quality and quantity [7,8]. In Canada, the economic costs of depression-related 2 Depression Research and Treatment presenteeism alone are estimated at over $5 billion annually [9].	0	Given the high prevalence of MDD, increasing attention is now being paid to the economic costs of depression. The economic burden is, in part, attributable to individuals with depression being unable to work, or absenteeism. For example, one study reported that workers with MDD missed an average of 32 days of work in a 12-month assessment period [5], while another found that about 30% of work disability claims in Canada were attributed to mental illness, predominant depression, and other mood disorders #CITATION_TAG. However, the greater proportion of the total economic burden of MDD lies in reduced productivity, or presenteeism, in which the depressed individual remains in the work setting but with productivity suffering both in quality and quantity [7,8]. In Canada, the economic costs of depression-related 2 Depression Research and Treatment presenteeism alone are estimated at over $5 billion annually [9].	r
CCT907	Unipolar major depressive disorder (MDD) is among the most common and disabling medical conditions. Many epidemiological studies have demonstrated the high prevalence of MDD in the general population. For example, the Canadian Community Health Survey (CCHS) recently reported a one-year prevalence rate of 4.5% for MDD, indicating that over 1.2 million Canadians suffer significant distress and impairment in functioning due to mood disorders [1]. Similar statistics are found for Europe [2] and the United States [3]. Depression is currently the fourth leading medical condition contributing to global burden of disease and is estimated to rise to second by the year 2030 #CITATION_TAG.	0	Many epidemiological studies have demonstrated the high prevalence of MDD in the general population. For example, the Canadian Community Health Survey (CCHS) recently reported a one-year prevalence rate of 4.5% for MDD, indicating that over 1.2 million Canadians suffer significant distress and impairment in functioning due to mood disorders [1]. Similar statistics are found for Europe [2] and the United States [3]. Depression is currently the fourth leading medical condition contributing to global burden of disease and is estimated to rise to second by the year 2030 #CITATION_TAG.	e
CCT908	Unipolar major depressive disorder (MDD) is among the most common and disabling medical conditions. Many epidemiological studies have demonstrated the high prevalence of MDD in the general population. For example, the Canadian Community Health Survey (CCHS) recently reported a one-year prevalence rate of 4.5% for MDD, indicating that over 1.2 million Canadians suffer significant distress and impairment in functioning due to mood disorders [1]. Similar statistics are found for Europe [2] and the United States #CITATION_TAG. Depression is currently the fourth leading medical condition contributing to global burden of disease and is estimated to rise to second by the year 2030 [4].	0	Unipolar major depressive disorder (MDD) is among the most common and disabling medical conditions. Many epidemiological studies have demonstrated the high prevalence of MDD in the general population. For example, the Canadian Community Health Survey (CCHS) recently reported a one-year prevalence rate of 4.5% for MDD, indicating that over 1.2 million Canadians suffer significant distress and impairment in functioning due to mood disorders [1]. Similar statistics are found for Europe [2] and the United States #CITATION_TAG. Depression is currently the fourth leading medical condition contributing to global burden of disease and is estimated to rise to second by the year 2030 [4].	i
CCT909	"However, although the number of epithelial cells in the blood of healthy individuals and patients with a variety of nonmalignant disease is low, they may be present in 0.3% of cases [2]. Furthermore, using the EpCAM-based CellSearch (Veridex) methodology, Pantel et al. #CITATION_TAG showed that circulating epithelial cells are found in between 0% and 18.7% of patients with benign colonic disease; the EPISPOT Cytokeratin 19 assay found circulating epithelial cells in between 8.3% and 28.6% of patients with benign colonic disease. Therefore, in patients""s pretreatment, with suspicion of cancer, or during followup of cancer patients where normal tissue persists, such as in breast or colon cancer, the detection of these benign cells could be interpreted as a relapse of the primary cancer. This is in addition to the potential problem of CTCs that do not express EpCAM or cytokeratins [4]."	1	"However, although the number of epithelial cells in the blood of healthy individuals and patients with a variety of nonmalignant disease is low, they may be present in 0.3% of cases [2]. Furthermore, using the EpCAM-based CellSearch (Veridex) methodology, Pantel et al. #CITATION_TAG showed that circulating epithelial cells are found in between 0% and 18.7% of patients with benign colonic disease; the EPISPOT Cytokeratin 19 assay found circulating epithelial cells in between 8.3% and 28.6% of patients with benign colonic disease. Therefore, in patients""s pretreatment, with suspicion of cancer, or during followup of cancer patients where normal tissue persists, such as in breast or colon cancer, the detection of these benign cells could be interpreted as a relapse of the primary cancer. This is in addition to the potential problem of CTCs that do not express EpCAM or cytokeratins [4]."	u
CCT910	"It has been considered that only cancer cells have the ability to disseminate or migrate into the circulation. However, these results and those published by Pantel et al. [3] suggest that benign inflammatory disease cells can escape into the circulation. The diagnosis of positively tested patients for PSA positive CPCs was based according to the strict criteria defined by ISHAGE with internal positive and negative controls. This finding is consistent with the fact that inflammatory cytokines can stimulate the migration of epithelial cells #CITATION_TAG. With respect to prostate cancer and the role of CPCs in its detection or in patients"" pretreatment, the potential background of nonmalignant prostate cells in blood may be an important confounding factor and lead to false-positive findings in CPC diagnostics. The fact that these benign CPCs do not express P504S is important. In published studies using CPCs as a sequential test to detect prostate cancer [8], double immunostaining was used, only CPCs PSA (+) P504S (+) were considered to be malignant, whereas cells PSA (+) P504S (‚àí) were considered to be benign and patients were classified as negative for cancer."	1	"It has been considered that only cancer cells have the ability to disseminate or migrate into the circulation. However, these results and those published by Pantel et al. [3] suggest that benign inflammatory disease cells can escape into the circulation. The diagnosis of positively tested patients for PSA positive CPCs was based according to the strict criteria defined by ISHAGE with internal positive and negative controls. This finding is consistent with the fact that inflammatory cytokines can stimulate the migration of epithelial cells #CITATION_TAG. With respect to prostate cancer and the role of CPCs in its detection or in patients"" pretreatment, the potential background of nonmalignant prostate cells in blood may be an important confounding factor and lead to false-positive findings in CPC diagnostics. The fact that these benign CPCs do not express P504S is important. In published studies using CPCs as a sequential test to detect prostate cancer [8], double immunostaining was used, only CPCs PSA (+) P504S (+) were considered to be malignant, whereas cells PSA (+) P504S (‚àí) were considered to be benign and patients were classified as negative for cancer."	s
CCT911	The prostate tumor early cancer test (ProTECT) study was started in 2008; the first stage evaluated 409 consecutive men attending a prostate cancer screening program in Chile. The thirty women acting as controls were all CPC negative; in the 409 men, the frequency of malignant CPC detection increased significantly with age and PSA level and is associated with a biopsy positive for cancer [7]. It was possible to detect malignant CPCs even at serum PSA levels of <2.0 ng/mL. The second stage was to determine the diagnostic yield of men with suspicion of prostate cancer because of an elevated serum PSA and/or abnormal DRE; 228 consecutive men undergoing prostate biopsy had a blood sample taken immediately beforehand to determine the presence or absence of malignant CPCs. The detection of malignant CPCs had a sensibility of 86.2%, specificity of 90.8%, a positive predictive value of 78.9%, and a negative predictive value of 94.3% #CITATION_TAG. It was noted that in some men without cancer detected on biopsy P504S negative, CPCs were detected.	0	The thirty women acting as controls were all CPC negative; in the 409 men, the frequency of malignant CPC detection increased significantly with age and PSA level and is associated with a biopsy positive for cancer [7]. It was possible to detect malignant CPCs even at serum PSA levels of <2.0 ng/mL. The second stage was to determine the diagnostic yield of men with suspicion of prostate cancer because of an elevated serum PSA and/or abnormal DRE; 228 consecutive men undergoing prostate biopsy had a blood sample taken immediately beforehand to determine the presence or absence of malignant CPCs. The detection of malignant CPCs had a sensibility of 86.2%, specificity of 90.8%, a positive predictive value of 78.9%, and a negative predictive value of 94.3% #CITATION_TAG. It was noted that in some men without cancer detected on biopsy P504S negative, CPCs were detected.	d
CCT912	It is assumed that the detection of CTCs is associated with cancer, based on the finding that CTCs can be detected in all major cancers and not in healthy subjects or those with benign disease #CITATION_TAG. Most of the assays are based on enrichment and subsequent identification of CTCs using monoclonal antibodies directed against epithelial epitopes, for example, the transmembrane glycoprotein epithelial cell adhesion molecule (EpCAM) or cytokeratins that are expressed on both normal and malignant cells. This widely based approach is based on the fact that blood cells usually lack detectable expression of epithelial markers, being of mesenchymal origin. What remains to be confirmed is whether or not trafficking of normal epithelial cells could occur in certain benign conditions and might contribute to false positive findings in the current assay methods unless unambiguous criteria for the malignant nature of the marker positive cells are used.	0	It is assumed that the detection of CTCs is associated with cancer, based on the finding that CTCs can be detected in all major cancers and not in healthy subjects or those with benign disease #CITATION_TAG. Most of the assays are based on enrichment and subsequent identification of CTCs using monoclonal antibodies directed against epithelial epitopes, for example, the transmembrane glycoprotein epithelial cell adhesion molecule (EpCAM) or cytokeratins that are expressed on both normal and malignant cells. This widely based approach is based on the fact that blood cells usually lack detectable expression of epithelial markers, being of mesenchymal origin. What remains to be confirmed is whether or not trafficking of normal epithelial cells could occur in certain benign conditions and might contribute to false positive findings in the current assay methods unless unambiguous criteria for the malignant nature of the marker positive cells are used.	I
CCT913	Although the first report on circulating tumors was published by Ashworth in 1869 #CITATION_TAG, the lack of technology precluded further investigations on their clinical use until recently. Developments in immunological and quantitative real-time PCR-based analysis have enabled the detection, enumeration and characterization of circulating tumor cells (CTCs). The monitoring of CTCs has the potential to improve therapeutic management at an early stage and also to identify patients with increased risk of tumor progression or recurrence before the onset of clinically detected metastasis. Furthermore, the molecular profiling of CTCs can provide new insights into cancer biology and systemic treatment in neoadjuvant or adjuvant settings.	0	Although the first report on circulating tumors was published by Ashworth in 1869 #CITATION_TAG, the lack of technology precluded further investigations on their clinical use until recently. Developments in immunological and quantitative real-time PCR-based analysis have enabled the detection, enumeration and characterization of circulating tumor cells (CTCs). The monitoring of CTCs has the potential to improve therapeutic management at an early stage and also to identify patients with increased risk of tumor progression or recurrence before the onset of clinically detected metastasis. Furthermore, the molecular profiling of CTCs can provide new insights into cancer biology and systemic treatment in neoadjuvant or adjuvant settings.	A
CCT914	A CPC was defined according to the criteria of (international society of hematotherapy and genetic engineering) ISHAGE #CITATION_TAG and the expression of P504S according to the consensus of the american association of pathologists [12]. A malignant CPC was defined as a cell that expressed PSA and P504S and a benign CPC as a cell that expressed PSA but not P504S, and leucocytes could be P504S positive or negative but did not express PSA (Figures 1(a)-1(c)).	5	A CPC was defined according to the criteria of (international society of hematotherapy and genetic engineering) ISHAGE #CITATION_TAG and the expression of P504S according to the consensus of the american association of pathologists [12]. A malignant CPC was defined as a cell that expressed PSA and P504S and a benign CPC as a cell that expressed PSA but not P504S, and leucocytes could be P504S positive or negative but did not express PSA (Figures 1(a)-1(c)).	A
CCT915	This has implications on systems based on EpCAM, Cytokeratin, or PSA alone and may explain why no significant differences were found on the frequency of CPCs detected in early prostate cancer and controls [13][14][15]. Similarly using RT-PCR, 8% of patients with benign prostatic disease had CPCs detected #CITATION_TAG.	5	This has implications on systems based on EpCAM, Cytokeratin, or PSA alone and may explain why no significant differences were found on the frequency of CPCs detected in early prostate cancer and controls [13][14][15]. Similarly using RT-PCR, 8% of patients with benign prostatic disease had CPCs detected #CITATION_TAG.	i
CCT916	This has implications on systems based on EpCAM, Cytokeratin, or PSA alone and may explain why no significant differences were found on the frequency of CPCs detected in early prostate cancer and controls [13][14]#CITATION_TAG. Similarly using RT-PCR, 8% of patients with benign prostatic disease had CPCs detected [16].	1	This has implications on systems based on EpCAM, Cytokeratin, or PSA alone and may explain why no significant differences were found on the frequency of CPCs detected in early prostate cancer and controls [13][14]#CITATION_TAG. Similarly using RT-PCR, 8% of patients with benign prostatic disease had CPCs detected [16].	T
CCT917	This has implications on systems based on EpCAM, Cytokeratin, or PSA alone and may explain why no significant differences were found on the frequency of CPCs detected in early prostate cancer and controls [13]#CITATION_TAG[15]. Similarly using RT-PCR, 8% of patients with benign prostatic disease had CPCs detected [16].	1	This has implications on systems based on EpCAM, Cytokeratin, or PSA alone and may explain why no significant differences were found on the frequency of CPCs detected in early prostate cancer and controls [13]#CITATION_TAG[15]. Similarly using RT-PCR, 8% of patients with benign prostatic disease had CPCs detected [16].	T
CCT918	A CPC was defined according to the criteria of (international society of hematotherapy and genetic engineering) ISHAGE [11] and the expression of P504S according to the consensus of the american association of pathologists #CITATION_TAG. A malignant CPC was defined as a cell that expressed PSA and P504S and a benign CPC as a cell that expressed PSA but not P504S, and leucocytes could be P504S positive or negative but did not express PSA (Figures 1(a)-1(c)).	0	A CPC was defined according to the criteria of (international society of hematotherapy and genetic engineering) ISHAGE [11] and the expression of P504S according to the consensus of the american association of pathologists #CITATION_TAG. A malignant CPC was defined as a cell that expressed PSA and P504S and a benign CPC as a cell that expressed PSA but not P504S, and leucocytes could be P504S positive or negative but did not express PSA (Figures 1(a)-1(c)).	A
CCT919	Consecutive men, aged between 45 and 80 years presenting to a prostate cancer screening program, without a previous history of prostate cancer or prostate biopsy and fulfilling the criteria a 12-core ultrasound guided transrectal PB were invited to participate. Biopsy criteria were serum PSA ‚â•4.0 ng/mL, serum PSA >0.75 ng/mL/year, and/or digital rectal examination (DRE) abnormal or suspicious of cancer. This was defined as the presence of a nodule, areas of indurations, or asymmetry in the size of the lateral lobes #CITATION_TAG. An ultrasound guided 12-core biopsy was taken according to standard recommendations [10].	0	Consecutive men, aged between 45 and 80 years presenting to a prostate cancer screening program, without a previous history of prostate cancer or prostate biopsy and fulfilling the criteria a 12-core ultrasound guided transrectal PB were invited to participate. Biopsy criteria were serum PSA ‚â•4.0 ng/mL, serum PSA >0.75 ng/mL/year, and/or digital rectal examination (DRE) abnormal or suspicious of cancer. This was defined as the presence of a nodule, areas of indurations, or asymmetry in the size of the lateral lobes #CITATION_TAG. An ultrasound guided 12-core biopsy was taken according to standard recommendations [10].	i
CCT920	Consecutive men, aged between 45 and 80 years presenting to a prostate cancer screening program, without a previous history of prostate cancer or prostate biopsy and fulfilling the criteria a 12-core ultrasound guided transrectal PB were invited to participate. Biopsy criteria were serum PSA ‚â•4.0 ng/mL, serum PSA >0.75 ng/mL/year, and/or digital rectal examination (DRE) abnormal or suspicious of cancer. This was defined as the presence of a nodule, areas of indurations, or asymmetry in the size of the lateral lobes [9]. An ultrasound guided 12-core biopsy was taken according to standard recommendations #CITATION_TAG.	0	Consecutive men, aged between 45 and 80 years presenting to a prostate cancer screening program, without a previous history of prostate cancer or prostate biopsy and fulfilling the criteria a 12-core ultrasound guided transrectal PB were invited to participate. Biopsy criteria were serum PSA ‚â•4.0 ng/mL, serum PSA >0.75 ng/mL/year, and/or digital rectal examination (DRE) abnormal or suspicious of cancer. This was defined as the presence of a nodule, areas of indurations, or asymmetry in the size of the lateral lobes [9]. An ultrasound guided 12-core biopsy was taken according to standard recommendations #CITATION_TAG.	u
CCT921	The prostate tumor early cancer test (ProTECT) study was started in 2008; the first stage evaluated 409 consecutive men attending a prostate cancer screening program in Chile. The thirty women acting as controls were all CPC negative; in the 409 men, the frequency of malignant CPC detection increased significantly with age and PSA level and is associated with a biopsy positive for cancer #CITATION_TAG. It was possible to detect malignant CPCs even at serum PSA levels of <2.0 ng/mL. The second stage was to determine the diagnostic yield of men with suspicion of prostate cancer because of an elevated serum PSA and/or abnormal DRE; 228 consecutive men undergoing prostate biopsy had a blood sample taken immediately beforehand to determine the presence or absence of malignant CPCs. The detection of malignant CPCs had a sensibility of 86.2%, specificity of 90.8%, a positive predictive value of 78.9%, and a negative predictive value of 94.3% [8]. It was noted that in some men without cancer detected on biopsy P504S negative, CPCs were detected.	5	The prostate tumor early cancer test (ProTECT) study was started in 2008; the first stage evaluated 409 consecutive men attending a prostate cancer screening program in Chile. The thirty women acting as controls were all CPC negative; in the 409 men, the frequency of malignant CPC detection increased significantly with age and PSA level and is associated with a biopsy positive for cancer #CITATION_TAG. It was possible to detect malignant CPCs even at serum PSA levels of <2.0 ng/mL. The second stage was to determine the diagnostic yield of men with suspicion of prostate cancer because of an elevated serum PSA and/or abnormal DRE; 228 consecutive men undergoing prostate biopsy had a blood sample taken immediately beforehand to determine the presence or absence of malignant CPCs. The detection of malignant CPCs had a sensibility of 86.2%, specificity of 90.8%, a positive predictive value of 78.9%, and a negative predictive value of 94.3% [8].	h
CCT922	The use of the biomarker P504S, although not prostate specific [5], has facilitated the differentiation between normal, dysplastic, and malignant tissues in prostate biopsy samples. Normal or benign cells do not express P504S, whereas cells arising from prostatic intraepithelial neoplasia (PIN) or cancer are positive #CITATION_TAG. Thus, at least in prostate cancer patients, the use of double immunomarcation could resolve this problem, whereby a malignant circulating prostate cell (CPC) would need to express both PSA and P504S, a benign CPC only PSA.	5	The use of the biomarker P504S, although not prostate specific [5], has facilitated the differentiation between normal, dysplastic, and malignant tissues in prostate biopsy samples. Normal or benign cells do not express P504S, whereas cells arising from prostatic intraepithelial neoplasia (PIN) or cancer are positive #CITATION_TAG. Thus, at least in prostate cancer patients, the use of double immunomarcation could resolve this problem, whereby a malignant circulating prostate cell (CPC) would need to express both PSA and P504S, a benign CPC only PSA.	o
CCT923	The use of the biomarker P504S, although not prostate specific #CITATION_TAG, has facilitated the differentiation between normal, dysplastic, and malignant tissues in prostate biopsy samples. Normal or benign cells do not express P504S, whereas cells arising from prostatic intraepithelial neoplasia (PIN) or cancer are positive [6]. Thus, at least in prostate cancer patients, the use of double immunomarcation could resolve this problem, whereby a malignant circulating prostate cell (CPC) would need to express both PSA and P504S, a benign CPC only PSA.	5	The use of the biomarker P504S, although not prostate specific #CITATION_TAG, has facilitated the differentiation between normal, dysplastic, and malignant tissues in prostate biopsy samples. Normal or benign cells do not express P504S, whereas cells arising from prostatic intraepithelial neoplasia (PIN) or cancer are positive [6]. Thus, at least in prostate cancer patients, the use of double immunomarcation could resolve this problem, whereby a malignant circulating prostate cell (CPC) would need to express both PSA and P504S, a benign CPC only PSA.	T
CCT924	"However, although the number of epithelial cells in the blood of healthy individuals and patients with a variety of nonmalignant disease is low, they may be present in 0.3% of cases [2]. Furthermore, using the EpCAM-based CellSearch (Veridex) methodology, Pantel et al. [3] showed that circulating epithelial cells are found in between 0% and 18.7% of patients with benign colonic disease; the EPISPOT Cytokeratin 19 assay found circulating epithelial cells in between 8.3% and 28.6% of patients with benign colonic disease. Therefore, in patients""s pretreatment, with suspicion of cancer, or during followup of cancer patients where normal tissue persists, such as in breast or colon cancer, the detection of these benign cells could be interpreted as a relapse of the primary cancer. This is in addition to the potential problem of CTCs that do not express EpCAM or cytokeratins #CITATION_TAG."	5	"However, although the number of epithelial cells in the blood of healthy individuals and patients with a variety of nonmalignant disease is low, they may be present in 0.3% of cases [2]. Furthermore, using the EpCAM-based CellSearch (Veridex) methodology, Pantel et al. [3] showed that circulating epithelial cells are found in between 0% and 18.7% of patients with benign colonic disease; the EPISPOT Cytokeratin 19 assay found circulating epithelial cells in between 8.3% and 28.6% of patients with benign colonic disease. Therefore, in patients""s pretreatment, with suspicion of cancer, or during followup of cancer patients where normal tissue persists, such as in breast or colon cancer, the detection of these benign cells could be interpreted as a relapse of the primary cancer. This is in addition to the potential problem of CTCs that do not express EpCAM or cytokeratins #CITATION_TAG."	s
CCT925	In men after radical prostatectomy, there are no native prostate cells; thus all CPCs detected in blood have disseminated from metastatic microfoci and thus clinically represent cancer cells. This may explain why after primary surgery the use of EpCAM-, Cytokeratin-or PSA-based markers is associated with prognosis and survival #CITATION_TAG.	1	In men after radical prostatectomy, there are no native prostate cells; thus all CPCs detected in blood have disseminated from metastatic microfoci and thus clinically represent cancer cells. This may explain why after primary surgery the use of EpCAM-, Cytokeratin-or PSA-based markers is associated with prognosis and survival #CITATION_TAG.	h
CCT926	"The usual normal distribution, also known as Gaussian, plays an important role to all statistical problems as do the information measures related to it. New entropy type information measures were introduced in [3], generalizing the known Fisher""s entropy type information measure, while an exponential-power generalization of the usual normal distribution was introduced and studied in #CITATION_TAG[4][5]. This generalized normal, called the -order normal distribution, defined in Section 2, emerges as an extremal function for the Logarithmic Sobolev Inequality."	4	"The usual normal distribution, also known as Gaussian, plays an important role to all statistical problems as do the information measures related to it. New entropy type information measures were introduced in [3], generalizing the known Fisher""s entropy type information measure, while an exponential-power generalization of the usual normal distribution was introduced and studied in #CITATION_TAG[4][5]. This generalized normal, called the -order normal distribution, defined in Section 2, emerges as an extremal function for the Logarithmic Sobolev Inequality."	e
CCT927	Wireless communication has undergone a tremendous evolution to meet the demand of high traffic capacity due to the drastic increasing usage of smartphones and mobile electronic devices. Begin from 0G technology since 1970s, followed by 1G,2G, and 3G, until today 4G technology, they show a great development on mobile technology from Radio Common Carrier (0G-RCC) to Long Term Evolution Advance (4G-LTEA). In order to meet the fast growing wireless data capacity demands due to increasing users of smartphones, high growth in web and streaming, 5G technology now are highly given attention and undergo a huge research. The 5G technology has huge data capabilities to support multi-Gbps data rates and has ability to gather unrestricted call volumes as well as infinite data broadcast within latest mobile technology #CITATION_TAG. Therefore millimeter-wave communication systems are required.	3	Wireless communication has undergone a tremendous evolution to meet the demand of high traffic capacity due to the drastic increasing usage of smartphones and mobile electronic devices. Begin from 0G technology since 1970s, followed by 1G,2G, and 3G, until today 4G technology, they show a great development on mobile technology from Radio Common Carrier (0G-RCC) to Long Term Evolution Advance (4G-LTEA). In order to meet the fast growing wireless data capacity demands due to increasing users of smartphones, high growth in web and streaming, 5G technology now are highly given attention and undergo a huge research. The 5G technology has huge data capabilities to support multi-Gbps data rates and has ability to gather unrestricted call volumes as well as infinite data broadcast within latest mobile technology #CITATION_TAG. Therefore millimeter-wave communication systems are required.	 
CCT928	Millimeter-wave communication systems using narrow beams at the transmitter and receiver, which suppress the interference of neighboring beams. The narrow beam also strongly reduces the angular spread of the incoming waves and the multipath components of millimeter waves to be limited. Therefore, by having the beam forming, beam-forming weights can be adjusted to a desired area or location #CITATION_TAG. There are two types of beam forming technology. The first one is fixed beam forming and another is adaptive beam forming [3]. Adaptive beam forming forms effective beams by adapting beam width and beam direction depending on the surrounding state of radio channels. It requires high hardware complexity and needs extra feedback mechanism for beam forming. While in fixed beam forming, beams with a fixed direction and width are generated. Therefore, switched beam forming is introduced as it is simpler and lesser operation system than adaptive beam forming. The concepts of beam steering or beam shifting are developed for scanning array antennas. Scanning array antennas were developed initially for aircraft, maritime and aeronautical applications. In terms of practical implementation, various technologies such as GPS, radiofrequency identification (RFID), tracking, traffic control and collision avoidance radars and wireless local area network (W-LAN), have been employed in developing the indoor localization and scanning systems [4].	5	Millimeter-wave communication systems using narrow beams at the transmitter and receiver, which suppress the interference of neighboring beams. The narrow beam also strongly reduces the angular spread of the incoming waves and the multipath components of millimeter waves to be limited. Therefore, by having the beam forming, beam-forming weights can be adjusted to a desired area or location #CITATION_TAG. There are two types of beam forming technology. The first one is fixed beam forming and another is adaptive beam forming [3]. Adaptive beam forming forms effective beams by adapting beam width and beam direction depending on the surrounding state of radio channels.	e
CCT929	Millimeter-wave communication systems using narrow beams at the transmitter and receiver, which suppress the interference of neighboring beams. The narrow beam also strongly reduces the angular spread of the incoming waves and the multipath components of millimeter waves to be limited. Therefore, by having the beam forming, beam-forming weights can be adjusted to a desired area or location [2]. There are two types of beam forming technology. The first one is fixed beam forming and another is adaptive beam forming #CITATION_TAG. Adaptive beam forming forms effective beams by adapting beam width and beam direction depending on the surrounding state of radio channels. It requires high hardware complexity and needs extra feedback mechanism for beam forming. While in fixed beam forming, beams with a fixed direction and width are generated. Therefore, switched beam forming is introduced as it is simpler and lesser operation system than adaptive beam forming. The concepts of beam steering or beam shifting are developed for scanning array antennas. Scanning array antennas were developed initially for aircraft, maritime and aeronautical applications. In terms of practical implementation, various technologies such as GPS, radiofrequency identification (RFID), tracking, traffic control and collision avoidance radars and wireless local area network (W-LAN), have been employed in developing the indoor localization and scanning systems [4].	0	The narrow beam also strongly reduces the angular spread of the incoming waves and the multipath components of millimeter waves to be limited. Therefore, by having the beam forming, beam-forming weights can be adjusted to a desired area or location [2]. There are two types of beam forming technology. The first one is fixed beam forming and another is adaptive beam forming #CITATION_TAG. Adaptive beam forming forms effective beams by adapting beam width and beam direction depending on the surrounding state of radio channels. It requires high hardware complexity and needs extra feedback mechanism for beam forming. While in fixed beam forming, beams with a fixed direction and width are generated.	f
CCT930	Patch antennas are used as simple and highly preferred in many applications. Circular polarizations, dual characteristics, dual frequency operation, frequency agility, broad bandwidth, feed line flexibility and beam scanning can be easily obtained from these patch antennas [7]. The patch can take any shape with rectangular and circular configurations are the most famous. The radiation pattern of a patch array antenna is fixed. However, by controlling the progressive phase difference between the elements, the maximum radiation can be shifted in any desired direction to form a scanning array #CITATION_TAG. This type of antenna is called a phase array antenna.	0	Circular polarizations, dual characteristics, dual frequency operation, frequency agility, broad bandwidth, feed line flexibility and beam scanning can be easily obtained from these patch antennas [7]. The patch can take any shape with rectangular and circular configurations are the most famous. The radiation pattern of a patch array antenna is fixed. However, by controlling the progressive phase difference between the elements, the maximum radiation can be shifted in any desired direction to form a scanning array #CITATION_TAG. This type of antenna is called a phase array antenna.	v
CCT931	Millimeter-wave communication systems using narrow beams at the transmitter and receiver, which suppress the interference of neighboring beams. The narrow beam also strongly reduces the angular spread of the incoming waves and the multipath components of millimeter waves to be limited. Therefore, by having the beam forming, beam-forming weights can be adjusted to a desired area or location [2]. There are two types of beam forming technology. The first one is fixed beam forming and another is adaptive beam forming [3]. Adaptive beam forming forms effective beams by adapting beam width and beam direction depending on the surrounding state of radio channels. It requires high hardware complexity and needs extra feedback mechanism for beam forming. While in fixed beam forming, beams with a fixed direction and width are generated. Therefore, switched beam forming is introduced as it is simpler and lesser operation system than adaptive beam forming. The concepts of beam steering or beam shifting are developed for scanning array antennas. Scanning array antennas were developed initially for aircraft, maritime and aeronautical applications. In terms of practical implementation, various technologies such as GPS, radiofrequency identification (RFID), tracking, traffic control and collision avoidance radars and wireless local area network (W-LAN), have been employed in developing the indoor localization and scanning systems #CITATION_TAG.	0	Therefore, switched beam forming is introduced as it is simpler and lesser operation system than adaptive beam forming. The concepts of beam steering or beam shifting are developed for scanning array antennas. Scanning array antennas were developed initially for aircraft, maritime and aeronautical applications. In terms of practical implementation, various technologies such as GPS, radiofrequency identification (RFID), tracking, traffic control and collision avoidance radars and wireless local area network (W-LAN), have been employed in developing the indoor localization and scanning systems #CITATION_TAG.	 
CCT932	Modern wireless communication systems require a low profile, lightweight, high gain and simple structure antennas to ensure reliability, mobility, and high efficiency #CITATION_TAG. Therefore, mircostrip antenna is highly preferred due to its low profile, easy to fabricate and feed, and easy to use in the array or incorporate with other microstrip circuit elements [6].	5	Modern wireless communication systems require a low profile, lightweight, high gain and simple structure antennas to ensure reliability, mobility, and high efficiency #CITATION_TAG. Therefore, mircostrip antenna is highly preferred due to its low profile, easy to fabricate and feed, and easy to use in the array or incorporate with other microstrip circuit elements [6].	M
CCT933	Modern wireless communication systems require a low profile, lightweight, high gain and simple structure antennas to ensure reliability, mobility, and high efficiency [5]. Therefore, mircostrip antenna is highly preferred due to its low profile, easy to fabricate and feed, and easy to use in the array or incorporate with other microstrip circuit elements #CITATION_TAG.	5	Modern wireless communication systems require a low profile, lightweight, high gain and simple structure antennas to ensure reliability, mobility, and high efficiency [5]. Therefore, mircostrip antenna is highly preferred due to its low profile, easy to fabricate and feed, and easy to use in the array or incorporate with other microstrip circuit elements #CITATION_TAG.	h
CCT934	Patch antennas are used as simple and highly preferred in many applications. Circular polarizations, dual characteristics, dual frequency operation, frequency agility, broad bandwidth, feed line flexibility and beam scanning can be easily obtained from these patch antennas #CITATION_TAG. The patch can take any shape with rectangular and circular configurations are the most famous. The radiation pattern of a patch array antenna is fixed. However, by controlling the progressive phase difference between the elements, the maximum radiation can be shifted in any desired direction to form a scanning array [8]. This type of antenna is called a phase array antenna.	5	Patch antennas are used as simple and highly preferred in many applications. Circular polarizations, dual characteristics, dual frequency operation, frequency agility, broad bandwidth, feed line flexibility and beam scanning can be easily obtained from these patch antennas #CITATION_TAG. The patch can take any shape with rectangular and circular configurations are the most famous. The radiation pattern of a patch array antenna is fixed. However, by controlling the progressive phase difference between the elements, the maximum radiation can be shifted in any desired direction to form a scanning array [8].	i
CCT935	Figure 4 presents the measured and simulated reflection coefficient results of the fabricated antennas. Two different configurations of antennas designed (b) and (c) have an almost similar curve of due to both designed antennas are only opposite in the shape of the patch. The difference in the measured and simulated results is mainly caused by the shift in the resonant frequencies #CITATION_TAG. This frequency shift is due to fabrication tolerance on the insertion loss of Cu microstrip during etching and gravure processes. The reflection coefficients for all designed antennas are about -20 dB with some frequency shifting except for Antenna 4 which has the value of -12 dB. This is due to the structure of Antenna 4 causes significant mutual coupling between two radiating patches, influencing the return loss of the radiating elements [10].	1	Figure 4 presents the measured and simulated reflection coefficient results of the fabricated antennas. Two different configurations of antennas designed (b) and (c) have an almost similar curve of due to both designed antennas are only opposite in the shape of the patch. The difference in the measured and simulated results is mainly caused by the shift in the resonant frequencies #CITATION_TAG. This frequency shift is due to fabrication tolerance on the insertion loss of Cu microstrip during etching and gravure processes. The reflection coefficients for all designed antennas are about -20 dB with some frequency shifting except for Antenna 4 which has the value of -12 dB. This is due to the structure of Antenna 4 causes significant mutual coupling between two radiating patches, influencing the return loss of the radiating elements [10].	e
CCT936	Figure 4 presents the measured and simulated reflection coefficient results of the fabricated antennas. Two different configurations of antennas designed (b) and (c) have an almost similar curve of due to both designed antennas are only opposite in the shape of the patch. The difference in the measured and simulated results is mainly caused by the shift in the resonant frequencies [9]. This frequency shift is due to fabrication tolerance on the insertion loss of Cu microstrip during etching and gravure processes. The reflection coefficients for all designed antennas are about -20 dB with some frequency shifting except for Antenna 4 which has the value of -12 dB. This is due to the structure of Antenna 4 causes significant mutual coupling between two radiating patches, influencing the return loss of the radiating elements #CITATION_TAG.	2	The difference in the measured and simulated results is mainly caused by the shift in the resonant frequencies [9]. This frequency shift is due to fabrication tolerance on the insertion loss of Cu microstrip during etching and gravure processes. The reflection coefficients for all designed antennas are about -20 dB with some frequency shifting except for Antenna 4 which has the value of -12 dB. This is due to the structure of Antenna 4 causes significant mutual coupling between two radiating patches, influencing the return loss of the radiating elements #CITATION_TAG.	i
CCT937	Figure 5 shows simulated far-field for four different designed antennas. It can be seen that there is no beam shifting in Antenna (a) and Antenna (d) as there is no phase shift difference between two radiating patches. However, the main beam of the Antenna (b) and Antenna (c) have shifted by 15Àö. This is because the two radiating patch elements radiate at different rate due to the existence of phase shift difference. As a summary, manipulating the electrical length of the feeders can provide a phase difference between two patches of antennas. Table 2 shows the summary on the performances of the four units design antennas. Antenna 1 has the highest gain of 10.9 dB while Antenna 4 has the lowest gain of 9.54 dB. Antenna 2 and Antenna 3 have same gain of 10.4 dB as both structures are just opposite to each other. The simulated bandwidth (BW) and measured bandwidth show a good agreement as there is only slightly different in the taken reading. However, Antenna 4 has very low bandwidth with a simulated bandwidth of 0.51 dB and measured bandwidth of 0.60 dB. The low bandwidth is due to the strong mutual coupling between the elements that degrade the overall performance of the antenna array #CITATION_TAG. All the designed antennas have wide half power bandwidth of range 45Àö to 50Àö.	2	Antenna 2 and Antenna 3 have same gain of 10.4 dB as both structures are just opposite to each other. The simulated bandwidth (BW) and measured bandwidth show a good agreement as there is only slightly different in the taken reading. However, Antenna 4 has very low bandwidth with a simulated bandwidth of 0.51 dB and measured bandwidth of 0.60 dB. The low bandwidth is due to the strong mutual coupling between the elements that degrade the overall performance of the antenna array #CITATION_TAG. All the designed antennas have wide half power bandwidth of range 45Àö to 50Àö.	n
CCT938	For decades, people have endeavored to develop pioneering techniques for secret communication. In fact, Cryptography and Steganography are two popular techniques intended to protect and safely transmit secret data. The former scrambles information so that it becomes unreadable by unauthorized parties; whereas, the latter conceals the very existence of information by embedding it into a carrier medium such as image, audio file, video file, or text file #CITATION_TAG. In this respect, steganography can be considered as a stealthy method for secret communication as it hides the existence of communication, so much so that no one apart from the sender and the receiver would suspect any piece of data being communicated. Fundamentally, steganography is an information hiding technology that covers data into digital media files. Its applications are diverse, including secret communication, copyright protection, digital watermarking, and tamper proofing [2]. In practice, steganography works as follows: A message that needs to be secretly communicated is first encoded into a digital carrier file such as an image file. Then, the carrier is transmitted to the intended recipient, who upon reception, decodes it and eventually recovers the covered secret message. Obviously, the biggest advantage of steganography is that it hides the fact that a secret communication is taking place; thus, avoiding the detection of the secret message by eavesdroppers and malicious parties [3]. The strength of steganography resides in how strong the carrier medium is imperceptible and how much the covered message is difficult to be detected and uncovered by unauthorized observers. In critical situations, people known as steganalysts are hired to identify suspicious files and detect whether or not they contain secret information, and if possible, recover this information. Actually, developing a steganography algorithm that firmly conceals data in a hard-to-notice, hard-to-detect, and hard-to-recover way ensures that the secret information being communicated through certain carrier medium would pass undetected by forensics and illicit third parties. This paper proposes a novel steganography scheme for hiding digital data into uncompressed image files using a randomized algorithm. The proposed scheme uses two mediums to deliver the secret data. The first medium is a carrier image holding the secret data inside the LSBs of its pixels which, unlike traditional LSB techniques, these pixels are selected randomly and not in sequence. The second medium is a well-structured and syntactically correct English text made up of several English sentences pointing to the location of the random carrier pixels, that is, the location of the secret data in the carrier image. In effect, the second medium is not predefined but dynamically generated during the encoding process using a mini-version context-free grammar of the English language coupled with a lexicon of English words randomly categorized in 10 categories representing the 10 digits of the decimal system. These digits are used to generate all possible location values for the carrier pixels. The proposed scheme has such advantages as being hard-to-notice, hard-to-detect, hard-to-recover, binary-based, multilingual, and mutable. All in all, they enable it to be used for versatile types of data, in total secrecy, and without getting detected or recovered, tricking stego-analysts and misleading them from the true location of the covert data.	0	For decades, people have endeavored to develop pioneering techniques for secret communication. In fact, Cryptography and Steganography are two popular techniques intended to protect and safely transmit secret data. The former scrambles information so that it becomes unreadable by unauthorized parties; whereas, the latter conceals the very existence of information by embedding it into a carrier medium such as image, audio file, video file, or text file #CITATION_TAG. In this respect, steganography can be considered as a stealthy method for secret communication as it hides the existence of communication, so much so that no one apart from the sender and the receiver would suspect any piece of data being communicated. Fundamentally, steganography is an information hiding technology that covers data into digital media files. Its applications are diverse, including secret communication, copyright protection, digital watermarking, and tamper proofing [2].	e
CCT939	For decades, people have endeavored to develop pioneering techniques for secret communication. In fact, Cryptography and Steganography are two popular techniques intended to protect and safely transmit secret data. The former scrambles information so that it becomes unreadable by unauthorized parties; whereas, the latter conceals the very existence of information by embedding it into a carrier medium such as image, audio file, video file, or text file [1]. In this respect, steganography can be considered as a stealthy method for secret communication as it hides the existence of communication, so much so that no one apart from the sender and the receiver would suspect any piece of data being communicated. Fundamentally, steganography is an information hiding technology that covers data into digital media files. Its applications are diverse, including secret communication, copyright protection, digital watermarking, and tamper proofing #CITATION_TAG. In practice, steganography works as follows: A message that needs to be secretly communicated is first encoded into a digital carrier file such as an image file. Then, the carrier is transmitted to the intended recipient, who upon reception, decodes it and eventually recovers the covered secret message. Obviously, the biggest advantage of steganography is that it hides the fact that a secret communication is taking place; thus, avoiding the detection of the secret message by eavesdroppers and malicious parties [3]. The strength of steganography resides in how strong the carrier medium is imperceptible and how much the covered message is difficult to be detected and uncovered by unauthorized observers. In critical situations, people known as steganalysts are hired to identify suspicious files and detect whether or not they contain secret information, and if possible, recover this information. Actually, developing a steganography algorithm that firmly conceals data in a hard-to-notice, hard-to-detect, and hard-to-recover way ensures that the secret information being communicated through certain carrier medium would pass undetected by forensics and illicit third parties. This paper proposes a novel steganography scheme for hiding digital data into uncompressed image files using a randomized algorithm. The proposed scheme uses two mediums to deliver the secret data. The first medium is a carrier image holding the secret data inside the LSBs of its pixels which, unlike traditional LSB techniques, these pixels are selected randomly and not in sequence. The second medium is a well-structured and syntactically correct English text made up of several English sentences pointing to the location of the random carrier pixels, that is, the location of the secret data in the carrier image. In effect, the second medium is not predefined but dynamically generated during the encoding process using a mini-version context-free grammar of the English language coupled with a lexicon of English words randomly categorized in 10 categories representing the 10 digits of the decimal system. These digits are used to generate all possible location values for the carrier pixels. The proposed scheme has such advantages as being hard-to-notice, hard-to-detect, hard-to-recover, binary-based, multilingual, and mutable. All in all, they enable it to be used for versatile types of data, in total secrecy, and without getting detected or recovered, tricking stego-analysts and misleading them from the true location of the covert data.	0	The former scrambles information so that it becomes unreadable by unauthorized parties; whereas, the latter conceals the very existence of information by embedding it into a carrier medium such as image, audio file, video file, or text file [1]. In this respect, steganography can be considered as a stealthy method for secret communication as it hides the existence of communication, so much so that no one apart from the sender and the receiver would suspect any piece of data being communicated. Fundamentally, steganography is an information hiding technology that covers data into digital media files. Its applications are diverse, including secret communication, copyright protection, digital watermarking, and tamper proofing #CITATION_TAG. In practice, steganography works as follows: A message that needs to be secretly communicated is first encoded into a digital carrier file such as an image file. Then, the carrier is transmitted to the intended recipient, who upon reception, decodes it and eventually recovers the covered secret message. Obviously, the biggest advantage of steganography is that it hides the fact that a secret communication is taking place; thus, avoiding the detection of the secret message by eavesdroppers and malicious parties [3].	p
CCT940	"A context-free grammar or CFG is a mathematical system for modeling the structure of languages such as natural languages like English, French and Arabic, or computer programming languages like C++, Java, and C#CITATION_TAG. In essence, a context-free grammar consists of a set of rules known as production rules that specify how symbols and words of a language can be arranged and grouped together. An example of a rule would specify that in the English language a verb phrase ""VP"" must always start with a verb then followed by a noun phrase ""NP"". Another rule would state that a noun phrase ""NP"" can start with a proper noun ""ProperNoun"" or a determinant ""Det"". Following is a sample CFG for a hypothetical language called L, that is a subset of the English language."	5	"A context-free grammar or CFG is a mathematical system for modeling the structure of languages such as natural languages like English, French and Arabic, or computer programming languages like C++, Java, and C#CITATION_TAG. In essence, a context-free grammar consists of a set of rules known as production rules that specify how symbols and words of a language can be arranged and grouped together. An example of a rule would specify that in the English language a verb phrase ""VP"" must always start with a verb then followed by a noun phrase ""NP"". Another rule would state that a noun phrase ""NP"" can start with a proper noun ""ProperNoun"" or a determinant ""Det""."	A
CCT941	"A context-free grammar or CFG is a mathematical system for modeling the structure of languages such as natural languages like English, French and Arabic, or computer programming languages like C++, Java, and C#CITATION_TAG, independently of each other. The one of Backus is known as the Backus-Naur Form or BNF for short [16]. In essence, a context-free grammar consists of a set of rules known as production rules that specify how symbols and words of a language can be arranged and grouped together. An example of a rule would specify that in the English language a verb phrase ""VP"" must always start with a verb then followed by a noun phrase ""NP"". Another rule would state that a noun phrase ""NP"" can start with a proper noun ""ProperNoun"" or a determinant ""Det"". Following is a sample CFG for a hypothetical language called L, that is a subset of the English language."	5	"A context-free grammar or CFG is a mathematical system for modeling the structure of languages such as natural languages like English, French and Arabic, or computer programming languages like C++, Java, and C#CITATION_TAG, independently of each other. The one of Backus is known as the Backus-Naur Form or BNF for short [16]. In essence, a context-free grammar consists of a set of rules known as production rules that specify how symbols and words of a language can be arranged and grouped together. An example of a rule would specify that in the English language a verb phrase ""VP"" must always start with a verb then followed by a noun phrase ""NP""."	A
CCT942	"A context-free grammar or CFG is a mathematical system for modeling the structure of languages such as natural languages like English, French and Arabic, or computer programming languages like C++, Java, and C#CITATION_TAG and Backus [15], independently of each other. The one of Backus is known as the Backus-Naur Form or BNF for short [16]. In essence, a context-free grammar consists of a set of rules known as production rules that specify how symbols and words of a language can be arranged and grouped together. An example of a rule would specify that in the English language a verb phrase ""VP"" must always start with a verb then followed by a noun phrase ""NP"". Another rule would state that a noun phrase ""NP"" can start with a proper noun ""ProperNoun"" or a determinant ""Det"". Following is a sample CFG for a hypothetical language called L, that is a subset of the English language."	5	"A context-free grammar or CFG is a mathematical system for modeling the structure of languages such as natural languages like English, French and Arabic, or computer programming languages like C++, Java, and C#CITATION_TAG and Backus [15], independently of each other. The one of Backus is known as the Backus-Naur Form or BNF for short [16]. In essence, a context-free grammar consists of a set of rules known as production rules that specify how symbols and words of a language can be arranged and grouped together. An example of a rule would specify that in the English language a verb phrase ""VP"" must always start with a verb then followed by a noun phrase ""NP""."	A
CCT943	"A context-free grammar or CFG is a mathematical system for modeling the structure of languages such as natural languages like English, French and Arabic, or computer programming languages like C++, Java, and C#CITATION_TAG. Its formalism was originally set by Chomsky [14] and Backus [15], independently of each other. The one of Backus is known as the Backus-Naur Form or BNF for short [16]. In essence, a context-free grammar consists of a set of rules known as production rules that specify how symbols and words of a language can be arranged and grouped together. An example of a rule would specify that in the English language a verb phrase ""VP"" must always start with a verb then followed by a noun phrase ""NP"". Another rule would state that a noun phrase ""NP"" can start with a proper noun ""ProperNoun"" or a determinant ""Det"". Following is a sample CFG for a hypothetical language called L, that is a subset of the English language."	0	A context-free grammar or CFG is a mathematical system for modeling the structure of languages such as natural languages like English, French and Arabic, or computer programming languages like C++, Java, and C#CITATION_TAG. Its formalism was originally set by Chomsky [14] and Backus [15], independently of each other. The one of Backus is known as the Backus-Naur Form or BNF for short [16]. In essence, a context-free grammar consists of a set of rules known as production rules that specify how symbols and words of a language can be arranged and grouped together.	A
CCT944	The proposed scheme is designed to work on 24-bit True Color uncompressed digital images such as BMP. Basically, the pixels of a 24-bit BMP image are each composed of three 8-bit color components, namely R, G, and B components #CITATION_TAG. The proposed scheme hides the secret data into the three LSBs of each of these color components; thus, the hiding capacity is equal to 9 bits out of 24 bits or 37% of the total size of the carrier image (9/24=0.375=37%). The carrier image is manipulated as a 2D plane geometric object composed of a finite set of points along with their coordinates. These coordinates effectively indicate the locations of the pixels in the carrier image itself. Figure 1 depicts a BMP image as a geometric 2D plane as regarded by the proposed scheme. In effect, the proposed scheme does not hide the secret data sequentially into the carrier pixels; instead, it randomly selects pixels to carry in the secret data. Thus, shuffling and dispersing the secret data over the carrier image in a random manner. The actual positions of these randomly selected carrier pixels, which interchangeably are their coordinates, are mimicked by an English text composed of English sentences that are grammatically well structured. The English text is generated using a context-free grammar and a lexicon of words organized into 10 categories from category 0 till category 9. Words that constitute the English sentences are selected from these categories based on the coordinates of the carrier pixels. For instance, coordinates (019,421) are encoded by selecting a word from category 0, a word from category 1, a word from category 9, a word from category 4, a word from category 2, and a word from category 1 respectively. Actually, every coordinate (i.e. pixel location) is represented by an English sentence. As a result, multiple pixels would result in multiple sentences which eventually result in a complete English text. The context-free grammar is essential in order to generate a grammatically correct text, for instance, generating a sentence composed of a determinant, followed by a noun, followed by verb, followed by a preposition. It is worth noting that no common words exit between the categories of the lexicon as it would be later impossible to recover the real coordinates of the carrier pixels out the English text. Finally, together, the carrier image and the generated English text are sent to the receiver who has to use the same algorithm, the same grammar, and the same lexicon to recover the different locations of the carrier pixels and consequently the secret data.	5	The proposed scheme is designed to work on 24-bit True Color uncompressed digital images such as BMP. Basically, the pixels of a 24-bit BMP image are each composed of three 8-bit color components, namely R, G, and B components #CITATION_TAG. The proposed scheme hides the secret data into the three LSBs of each of these color components; thus, the hiding capacity is equal to 9 bits out of 24 bits or 37% of the total size of the carrier image (9/24=0.375=37%). The carrier image is manipulated as a 2D plane geometric object composed of a finite set of points along with their coordinates. These coordinates effectively indicate the locations of the pixels in the carrier image itself.	a
CCT945	"Terminals are usually provided by a lexicon of words; whereas, the non-terminals and the production rules are part of the parsing algorithm. Parsing is the process of deriving sentences for the language using the production rules of the CFG and the lexicon #CITATION_TAG. Parsing can also be used to confirm that the structure of a sentence complies with the CFG of the language. The proposed steganography scheme uses a mini-version CFG of the English language and a lexicon of predefined words to generate correct English sentences that can encode the coordinates of the carrier pixels. Figure 2 outlines the production rules of the CFG used by the proposed scheme. On the other hand, the lexicon of the CFG which is outlined in Table 1 is organized into 10 categories each of which contains a set of terminal words that belong to the English language. It is worth mentioning that no common words exist between the categories of the lexicon as it would be later impossible to recover the real coordinates of the carrier pixels out of the English text. Every word in the above categories uniquely encodes the category to which it belongs. For instance, the word ""this"" encodes the digit ""0"" exclusively because it belongs to category 0. The word ""Harvard"" encodes the digit ""9"" exclusively because it belongs to category 9, and so forth. It is not mandatory, in practice, that the lexicon of Table 1 is used exactly as is; the communicating parties can compile their own lexicon and use it mutually for the covering as well as the uncovering operation."	5	Terminals are usually provided by a lexicon of words; whereas, the non-terminals and the production rules are part of the parsing algorithm. Parsing is the process of deriving sentences for the language using the production rules of the CFG and the lexicon #CITATION_TAG. Parsing can also be used to confirm that the structure of a sentence complies with the CFG of the language. The proposed steganography scheme uses a mini-version CFG of the English language and a lexicon of predefined words to generate correct English sentences that can encode the coordinates of the carrier pixels. Figure 2 outlines the production rules of the CFG used by the proposed scheme.	a
CCT946	"So far, massive research work has been conducted in the development of steganography for digital images. One of the earliest techniques is the LSB technique which obscures data communication by inserting the secret data into the insignificant parts of the pixels of an image file, more particularly, into the least significant bits (LSB) [5]. The modified version of the image, which is called carrier file or stego file, is then sent to the receiver through a public channel. The foremost requirement of the LSB technique is that it should not exhibit any visual signs in the carrier image so as to not give any indications that secret data are being communicated covertly. Basically, the LSB technique is an insertion-based image steganography method that embeds secret data into uncompressed computer image files such as BMP and TIFF. In this technique, the data to hide are first converted into a series of bytes, then into a series of smaller chunks each of which is of size n bits. Then, n LSBs of the pixels of the carrier image are replaced by each of the chunks of the original data to hide. The ultimate result of this operation is a carrier image carrying the secret data into the LSBs of its pixels. As the color values that are determined by LSBs are insignificant to the naked eye, it is hard to tell the difference between the original image and the tampered one, taking into consideration that no more than a certain number of LSBs were used to conceal the secret data; Otherwise, visual artifacts and damages would be produced in the carrier image which would in turn draw suspicions and raise attention about something unusual in the carrier image. For instance, in 24-bit True Color BMP images, using more than three LSBs per color component to hide data may result in perceptible artifacts in the carrier image [6]. As an illustration for the LSB technique, let""s say that the letter H needs to be hidden into an 8-bit grayscale bitmap image. The ASCII representation for letter H is 72 in decimal or 01001000 in binary. Assuming that the letter H is divided into four chunks each of 2 bits, then four pixels are needed to totally hide the letter H. Moreover, assuming that four consecutive pixels are selected from the original image whose grayscale values are denoted by P 1 =11011000, P 2 =00110110, P 3 =11001111, and P 4 =10100011, then substituting every two LSBs in every of these four pixels by a 2-bit chunk of the letter H, would result in a new set of pixels denoted by P 1 = 11011001, P 2 =00110100, P 3 =11001110, and P 4 =10100000. Despite changing the actual grayscale values of the pixels, this has little impact on the visual appearance of the carrier image because characteristically, the Human Visual System (HVS) cannot differentiate between two images whose color values in the high frequency spectrum are marginally unalike #CITATION_TAG."	0	"As an illustration for the LSB technique, let""s say that the letter H needs to be hidden into an 8-bit grayscale bitmap image. The ASCII representation for letter H is 72 in decimal or 01001000 in binary. Assuming that the letter H is divided into four chunks each of 2 bits, then four pixels are needed to totally hide the letter H. Moreover, assuming that four consecutive pixels are selected from the original image whose grayscale values are denoted by P 1 =11011000, P 2 =00110110, P 3 =11001111, and P 4 =10100011, then substituting every two LSBs in every of these four pixels by a 2-bit chunk of the letter H, would result in a new set of pixels denoted by P 1 = 11011001, P 2 =00110100, P 3 =11001110, and P 4 =10100000. Despite changing the actual grayscale values of the pixels, this has little impact on the visual appearance of the carrier image because characteristically, the Human Visual System (HVS) cannot differentiate between two images whose color values in the high frequency spectrum are marginally unalike #CITATION_TAG."	i
CCT947	"So far, massive research work has been conducted in the development of steganography for digital images. One of the earliest techniques is the LSB technique which obscures data communication by inserting the secret data into the insignificant parts of the pixels of an image file, more particularly, into the least significant bits (LSB) [5]. The modified version of the image, which is called carrier file or stego file, is then sent to the receiver through a public channel. The foremost requirement of the LSB technique is that it should not exhibit any visual signs in the carrier image so as to not give any indications that secret data are being communicated covertly. Basically, the LSB technique is an insertion-based image steganography method that embeds secret data into uncompressed computer image files such as BMP and TIFF. In this technique, the data to hide are first converted into a series of bytes, then into a series of smaller chunks each of which is of size n bits. Then, n LSBs of the pixels of the carrier image are replaced by each of the chunks of the original data to hide. The ultimate result of this operation is a carrier image carrying the secret data into the LSBs of its pixels. As the color values that are determined by LSBs are insignificant to the naked eye, it is hard to tell the difference between the original image and the tampered one, taking into consideration that no more than a certain number of LSBs were used to conceal the secret data; Otherwise, visual artifacts and damages would be produced in the carrier image which would in turn draw suspicions and raise attention about something unusual in the carrier image. For instance, in 24-bit True Color BMP images, using more than three LSBs per color component to hide data may result in perceptible artifacts in the carrier image #CITATION_TAG. As an illustration for the LSB technique, let""s say that the letter H needs to be hidden into an 8-bit grayscale bitmap image. The ASCII representation for letter H is 72 in decimal or 01001000 in binary. Assuming that the letter H is divided into four chunks each of 2 bits, then four pixels are needed to totally hide the letter H. Moreover, assuming that four consecutive pixels are selected from the original image whose grayscale values are denoted by P 1 =11011000, P 2 =00110110, P 3 =11001111, and P 4 =10100011, then substituting every two LSBs in every of these four pixels by a 2-bit chunk of the letter H, would result in a new set of pixels denoted by P 1 = 11011001, P 2 =00110100, P 3 =11001110, and P 4 =10100000. Despite changing the actual grayscale values of the pixels, this has little impact on the visual appearance of the carrier image because characteristically, the Human Visual System (HVS) cannot differentiate between two images whose color values in the high frequency spectrum are marginally unalike [7]."	0	"Then, n LSBs of the pixels of the carrier image are replaced by each of the chunks of the original data to hide. The ultimate result of this operation is a carrier image carrying the secret data into the LSBs of its pixels. As the color values that are determined by LSBs are insignificant to the naked eye, it is hard to tell the difference between the original image and the tampered one, taking into consideration that no more than a certain number of LSBs were used to conceal the secret data; Otherwise, visual artifacts and damages would be produced in the carrier image which would in turn draw suspicions and raise attention about something unusual in the carrier image. For instance, in 24-bit True Color BMP images, using more than three LSBs per color component to hide data may result in perceptible artifacts in the carrier image #CITATION_TAG. As an illustration for the LSB technique, let""s say that the letter H needs to be hidden into an 8-bit grayscale bitmap image. The ASCII representation for letter H is 72 in decimal or 01001000 in binary. Assuming that the letter H is divided into four chunks each of 2 bits, then four pixels are needed to totally hide the letter H. Moreover, assuming that four consecutive pixels are selected from the original image whose grayscale values are denoted by P 1 =11011000, P 2 =00110110, P 3 =11001111, and P 4 =10100011, then substituting every two LSBs in every of these four pixels by a 2-bit chunk of the letter H, would result in a new set of pixels denoted by P 1 = 11011001, P 2 =00110100, P 3 =11001110, and P 4 =10100000."	n
CCT948	"So far, massive research work has been conducted in the development of steganography for digital images. One of the earliest techniques is the LSB technique which obscures data communication by inserting the secret data into the insignificant parts of the pixels of an image file, more particularly, into the least significant bits (LSB) #CITATION_TAG. The modified version of the image, which is called carrier file or stego file, is then sent to the receiver through a public channel. The foremost requirement of the LSB technique is that it should not exhibit any visual signs in the carrier image so as to not give any indications that secret data are being communicated covertly. Basically, the LSB technique is an insertion-based image steganography method that embeds secret data into uncompressed computer image files such as BMP and TIFF. In this technique, the data to hide are first converted into a series of bytes, then into a series of smaller chunks each of which is of size n bits. Then, n LSBs of the pixels of the carrier image are replaced by each of the chunks of the original data to hide. The ultimate result of this operation is a carrier image carrying the secret data into the LSBs of its pixels. As the color values that are determined by LSBs are insignificant to the naked eye, it is hard to tell the difference between the original image and the tampered one, taking into consideration that no more than a certain number of LSBs were used to conceal the secret data; Otherwise, visual artifacts and damages would be produced in the carrier image which would in turn draw suspicions and raise attention about something unusual in the carrier image. For instance, in 24-bit True Color BMP images, using more than three LSBs per color component to hide data may result in perceptible artifacts in the carrier image [6]. As an illustration for the LSB technique, let""s say that the letter H needs to be hidden into an 8-bit grayscale bitmap image. The ASCII representation for letter H is 72 in decimal or 01001000 in binary. Assuming that the letter H is divided into four chunks each of 2 bits, then four pixels are needed to totally hide the letter H. Moreover, assuming that four consecutive pixels are selected from the original image whose grayscale values are denoted by P 1 =11011000, P 2 =00110110, P 3 =11001111, and P 4 =10100011, then substituting every two LSBs in every of these four pixels by a 2-bit chunk of the letter H, would result in a new set of pixels denoted by P 1 = 11011001, P 2 =00110100, P 3 =11001110, and P 4 =10100000. Despite changing the actual grayscale values of the pixels, this has little impact on the visual appearance of the carrier image because characteristically, the Human Visual System (HVS) cannot differentiate between two images whose color values in the high frequency spectrum are marginally unalike [7]."	0	So far, massive research work has been conducted in the development of steganography for digital images. One of the earliest techniques is the LSB technique which obscures data communication by inserting the secret data into the insignificant parts of the pixels of an image file, more particularly, into the least significant bits (LSB) #CITATION_TAG. The modified version of the image, which is called carrier file or stego file, is then sent to the receiver through a public channel. The foremost requirement of the LSB technique is that it should not exhibit any visual signs in the carrier image so as to not give any indications that secret data are being communicated covertly. Basically, the LSB technique is an insertion-based image steganography method that embeds secret data into uncompressed computer image files such as BMP and TIFF.	n
CCT949	In order to successfully accomplish this task, the musician must perform and monitor multiple features of the performance, such as melody, harmony, rhythm, dynamics, articulation, and the playing of other musicians in the ensemble, simultaneously. Attending to all of these concurrent musical features is no easy task (#CITATION_TAG, 2001). Studies of divided attention show that performance decreases when attention must be divided amongst multiple tasks at once, especially when they are processed by similar mental resources (e.g., Klapp, 1979;Navon & Gopher, 1979;Pashler, 1994;Wickens, 2002). And yet, experienced musicians are somehow able to balance these competing demands during improvisation. This may be partly because, with practice, learned actions-even lengthy action sequences-can become automatized and stored as memorized patterns that require less active attention, freeing up additional resources in working memory . For example, in motor research, long action sequences have been shown to consist of concatenations of shorter memorized motion patterns known as Generalized Motor Programs-a basic building block of all movements (Park & Shea, 2005;Shea & Wulf, 2005). The importance of recurring sequences also extends to perceptual learning and information processing. For example, researchers who study language acquisition have reported that infants are able to decode patterns embedded within both natural and artificial languages (Saffran, 2003). These patterns are then used during language production in the form of motoric, sound, and meaning sequences that have been stored in memory to be reused later (Levelt, 2001).	0	In order to successfully accomplish this task, the musician must perform and monitor multiple features of the performance, such as melody, harmony, rhythm, dynamics, articulation, and the playing of other musicians in the ensemble, simultaneously. Attending to all of these concurrent musical features is no easy task (#CITATION_TAG, 2001). Studies of divided attention show that performance decreases when attention must be divided amongst multiple tasks at once, especially when they are processed by similar mental resources (e.g., Klapp, 1979;Navon & Gopher, 1979;Pashler, 1994;Wickens, 2002). And yet, experienced musicians are somehow able to balance these competing demands during improvisation. This may be partly because, with practice, learned actions-even lengthy action sequences-can become automatized and stored as memorized patterns that require less active attention, freeing up additional resources in working memory . For example, in motor research, long action sequences have been shown to consist of concatenations of shorter memorized motion patterns known as Generalized Motor Programs-a basic building block of all movements (Park & Shea, 2005;Shea & Wulf, 2005).	t
CCT950	In order to successfully accomplish this task, the musician must perform and monitor multiple features of the performance, such as melody, harmony, rhythm, dynamics, articulation, and the playing of other musicians in the ensemble, simultaneously. Attending to all of these concurrent musical features is no easy task (Keller, 2001). Studies of divided attention show that performance decreases when attention must be divided amongst multiple tasks at once, especially when they are processed by similar mental resources (e.g., #CITATION_TAG, 1979;Navon & Gopher, 1979;Pashler, 1994;Wickens, 2002). And yet, experienced musicians are somehow able to balance these competing demands during improvisation. This may be partly because, with practice, learned actions-even lengthy action sequences-can become automatized and stored as memorized patterns that require less active attention, freeing up additional resources in working memory . For example, in motor research, long action sequences have been shown to consist of concatenations of shorter memorized motion patterns known as Generalized Motor Programs-a basic building block of all movements (Park & Shea, 2005;Shea & Wulf, 2005). The importance of recurring sequences also extends to perceptual learning and information processing. For example, researchers who study language acquisition have reported that infants are able to decode patterns embedded within both natural and artificial languages (Saffran, 2003). These patterns are then used during language production in the form of motoric, sound, and meaning sequences that have been stored in memory to be reused later (Levelt, 2001).	5	In order to successfully accomplish this task, the musician must perform and monitor multiple features of the performance, such as melody, harmony, rhythm, dynamics, articulation, and the playing of other musicians in the ensemble, simultaneously. Attending to all of these concurrent musical features is no easy task (Keller, 2001). Studies of divided attention show that performance decreases when attention must be divided amongst multiple tasks at once, especially when they are processed by similar mental resources (e.g., #CITATION_TAG, 1979;Navon & Gopher, 1979;Pashler, 1994;Wickens, 2002). And yet, experienced musicians are somehow able to balance these competing demands during improvisation. This may be partly because, with practice, learned actions-even lengthy action sequences-can become automatized and stored as memorized patterns that require less active attention, freeing up additional resources in working memory . For example, in motor research, long action sequences have been shown to consist of concatenations of shorter memorized motion patterns known as Generalized Motor Programs-a basic building block of all movements (Park & Shea, 2005;Shea & Wulf, 2005). The importance of recurring sequences also extends to perceptual learning and information processing.	u
CCT951	In order to successfully accomplish this task, the musician must perform and monitor multiple features of the performance, such as melody, harmony, rhythm, dynamics, articulation, and the playing of other musicians in the ensemble, simultaneously. Attending to all of these concurrent musical features is no easy task (Keller, 2001). Studies of divided attention show that performance decreases when attention must be divided amongst multiple tasks at once, especially when they are processed by similar mental resources (e.g., Klapp, 1979;Navon & Gopher, 1979;Pashler, 1994;#CITATION_TAG, 2002). And yet, experienced musicians are somehow able to balance these competing demands during improvisation. This may be partly because, with practice, learned actions-even lengthy action sequences-can become automatized and stored as memorized patterns that require less active attention, freeing up additional resources in working memory . For example, in motor research, long action sequences have been shown to consist of concatenations of shorter memorized motion patterns known as Generalized Motor Programs-a basic building block of all movements (Park & Shea, 2005;Shea & Wulf, 2005). The importance of recurring sequences also extends to perceptual learning and information processing. For example, researchers who study language acquisition have reported that infants are able to decode patterns embedded within both natural and artificial languages (Saffran, 2003). These patterns are then used during language production in the form of motoric, sound, and meaning sequences that have been stored in memory to be reused later (Levelt, 2001).	5	In order to successfully accomplish this task, the musician must perform and monitor multiple features of the performance, such as melody, harmony, rhythm, dynamics, articulation, and the playing of other musicians in the ensemble, simultaneously. Attending to all of these concurrent musical features is no easy task (Keller, 2001). Studies of divided attention show that performance decreases when attention must be divided amongst multiple tasks at once, especially when they are processed by similar mental resources (e.g., Klapp, 1979;Navon & Gopher, 1979;Pashler, 1994;#CITATION_TAG, 2002). And yet, experienced musicians are somehow able to balance these competing demands during improvisation. This may be partly because, with practice, learned actions-even lengthy action sequences-can become automatized and stored as memorized patterns that require less active attention, freeing up additional resources in working memory . For example, in motor research, long action sequences have been shown to consist of concatenations of shorter memorized motion patterns known as Generalized Motor Programs-a basic building block of all movements (Park & Shea, 2005;Shea & Wulf, 2005). The importance of recurring sequences also extends to perceptual learning and information processing.	u
CCT952	REATIVITY RESEARCH IS TYPICALLY FOCUSED on creative processes and products conceived without time constraints (#CITATION_TAG, Grigorenko, & Singer, 2004). Less research has been done in areas where the creative product is produced in real time. In music, the distinction is exemplified by composition and improvisation. A three-minute composition may take hours or days to create whereas a three-minute musical improvisation is created in exactly three minutes. In both areas the creative product is typically shaped by style, including frameworks for tonal and rhythmic structures. However, in improvisation it is necessary to produce this output very rapidly; in group improvisation, the musician may also need to attend to multiple external sources and shape the note choices accordingly.	0	REATIVITY RESEARCH IS TYPICALLY FOCUSED on creative processes and products conceived without time constraints (#CITATION_TAG, Grigorenko, & Singer, 2004). Less research has been done in areas where the creative product is produced in real time. In music, the distinction is exemplified by composition and improvisation. A three-minute composition may take hours or days to create whereas a three-minute musical improvisation is created in exactly three minutes.	R
CCT953	In order to successfully accomplish this task, the musician must perform and monitor multiple features of the performance, such as melody, harmony, rhythm, dynamics, articulation, and the playing of other musicians in the ensemble, simultaneously. Attending to all of these concurrent musical features is no easy task (Keller, 2001). Studies of divided attention show that performance decreases when attention must be divided amongst multiple tasks at once, especially when they are processed by similar mental resources (e.g., Klapp, 1979;Navon & Gopher, 1979;Pashler, 1994;Wickens, 2002). And yet, experienced musicians are somehow able to balance these competing demands during improvisation. This may be partly because, with practice, learned actions-even lengthy action sequences-can become automatized and stored as memorized patterns that require less active attention, freeing up additional resources in working memory . For example, in motor research, long action sequences have been shown to consist of concatenations of shorter memorized motion patterns known as Generalized Motor Programs-a basic building block of all movements (Park & Shea, 2005;#CITATION_TAG & Wulf, 2005). The importance of recurring sequences also extends to perceptual learning and information processing. For example, researchers who study language acquisition have reported that infants are able to decode patterns embedded within both natural and artificial languages (Saffran, 2003). These patterns are then used during language production in the form of motoric, sound, and meaning sequences that have been stored in memory to be reused later (Levelt, 2001).	0	Attending to all of these concurrent musical features is no easy task (Keller, 2001). Studies of divided attention show that performance decreases when attention must be divided amongst multiple tasks at once, especially when they are processed by similar mental resources (e.g., Klapp, 1979;Navon & Gopher, 1979;Pashler, 1994;Wickens, 2002). And yet, experienced musicians are somehow able to balance these competing demands during improvisation. This may be partly because, with practice, learned actions-even lengthy action sequences-can become automatized and stored as memorized patterns that require less active attention, freeing up additional resources in working memory . For example, in motor research, long action sequences have been shown to consist of concatenations of shorter memorized motion patterns known as Generalized Motor Programs-a basic building block of all movements (Park & Shea, 2005;#CITATION_TAG & Wulf, 2005). The importance of recurring sequences also extends to perceptual learning and information processing. For example, researchers who study language acquisition have reported that infants are able to decode patterns embedded within both natural and artificial languages (Saffran, 2003). These patterns are then used during language production in the form of motoric, sound, and meaning sequences that have been stored in memory to be reused later (Levelt, 2001).	 
CCT954	In order to successfully accomplish this task, the musician must perform and monitor multiple features of the performance, such as melody, harmony, rhythm, dynamics, articulation, and the playing of other musicians in the ensemble, simultaneously. Attending to all of these concurrent musical features is no easy task (Keller, 2001). Studies of divided attention show that performance decreases when attention must be divided amongst multiple tasks at once, especially when they are processed by similar mental resources (e.g., Klapp, 1979;Navon & Gopher, 1979;Pashler, 1994;Wickens, 2002). And yet, experienced musicians are somehow able to balance these competing demands during improvisation. This may be partly because, with practice, learned actions-even lengthy action sequences-can become automatized and stored as memorized patterns that require less active attention, freeing up additional resources in working memory . For example, in motor research, long action sequences have been shown to consist of concatenations of shorter memorized motion patterns known as Generalized Motor Programs-a basic building block of all movements (Park & Shea, 2005;Shea & Wulf, 2005). The importance of recurring sequences also extends to perceptual learning and information processing. For example, researchers who study language acquisition have reported that infants are able to decode patterns embedded within both natural and artificial languages (#CITATION_TAG, 2003). These patterns are then used during language production in the form of motoric, sound, and meaning sequences that have been stored in memory to be reused later (Levelt, 2001).	0	And yet, experienced musicians are somehow able to balance these competing demands during improvisation. This may be partly because, with practice, learned actions-even lengthy action sequences-can become automatized and stored as memorized patterns that require less active attention, freeing up additional resources in working memory . For example, in motor research, long action sequences have been shown to consist of concatenations of shorter memorized motion patterns known as Generalized Motor Programs-a basic building block of all movements (Park & Shea, 2005;Shea & Wulf, 2005). The importance of recurring sequences also extends to perceptual learning and information processing. For example, researchers who study language acquisition have reported that infants are able to decode patterns embedded within both natural and artificial languages (#CITATION_TAG, 2003). These patterns are then used during language production in the form of motoric, sound, and meaning sequences that have been stored in memory to be reused later (Levelt, 2001).	a
CCT955	"To date, little experimental research on creativity has focused on attention and working memory demands during creation under real time constraints. In one such rare study, two experts"" subjective ratings of improvisations performed by 32 semi-professional cellists were found to increase over time for musicians with higher working memory capability but to decrease over time for those with low working memory (#CITATION_TAG, Nijstad, Baas, Wolsink, & Roskes, 2012). The authors suggest that the musicians with higher working memory capacities were more able to focus their attention on the task at hand as well as to inhibit tendencies to play repeated patterns."	1	"To date, little experimental research on creativity has focused on attention and working memory demands during creation under real time constraints. In one such rare study, two experts"" subjective ratings of improvisations performed by 32 semi-professional cellists were found to increase over time for musicians with higher working memory capability but to decrease over time for those with low working memory (#CITATION_TAG, Nijstad, Baas, Wolsink, & Roskes, 2012). The authors suggest that the musicians with higher working memory capacities were more able to focus their attention on the task at hand as well as to inhibit tendencies to play repeated patterns."	n
CCT956	In order to successfully accomplish this task, the musician must perform and monitor multiple features of the performance, such as melody, harmony, rhythm, dynamics, articulation, and the playing of other musicians in the ensemble, simultaneously. Attending to all of these concurrent musical features is no easy task (Keller, 2001). Studies of divided attention show that performance decreases when attention must be divided amongst multiple tasks at once, especially when they are processed by similar mental resources (e.g., Klapp, 1979;Navon & Gopher, 1979;#CITATION_TAG, 1994;Wickens, 2002). And yet, experienced musicians are somehow able to balance these competing demands during improvisation. This may be partly because, with practice, learned actions-even lengthy action sequences-can become automatized and stored as memorized patterns that require less active attention, freeing up additional resources in working memory . For example, in motor research, long action sequences have been shown to consist of concatenations of shorter memorized motion patterns known as Generalized Motor Programs-a basic building block of all movements (Park & Shea, 2005;Shea & Wulf, 2005). The importance of recurring sequences also extends to perceptual learning and information processing. For example, researchers who study language acquisition have reported that infants are able to decode patterns embedded within both natural and artificial languages (Saffran, 2003). These patterns are then used during language production in the form of motoric, sound, and meaning sequences that have been stored in memory to be reused later (Levelt, 2001).	5	In order to successfully accomplish this task, the musician must perform and monitor multiple features of the performance, such as melody, harmony, rhythm, dynamics, articulation, and the playing of other musicians in the ensemble, simultaneously. Attending to all of these concurrent musical features is no easy task (Keller, 2001). Studies of divided attention show that performance decreases when attention must be divided amongst multiple tasks at once, especially when they are processed by similar mental resources (e.g., Klapp, 1979;Navon & Gopher, 1979;#CITATION_TAG, 1994;Wickens, 2002). And yet, experienced musicians are somehow able to balance these competing demands during improvisation. This may be partly because, with practice, learned actions-even lengthy action sequences-can become automatized and stored as memorized patterns that require less active attention, freeing up additional resources in working memory . For example, in motor research, long action sequences have been shown to consist of concatenations of shorter memorized motion patterns known as Generalized Motor Programs-a basic building block of all movements (Park & Shea, 2005;Shea & Wulf, 2005). The importance of recurring sequences also extends to perceptual learning and information processing.	u
CCT957	"Despite the plethora of literature advocating the benefits of using stories for teaching English with EFL/ESL learners (Ellis & Brewster, 2014;Wajnryb, 2003), there is a dearth of research to support these claims (Lee, 2012;Tsou, Wang, & Tzeng, 2006). Among the relevant published studies, few of those reported have taken place in under-resourced learning environments. #CITATION_TAG""s (2009) and Megawati and Anugerahwati""s (2012) studies with secondary school students in Hong Kong and Indonesia, respectively, investigated the use of stories to enhance students"" motivation and their writing ability. The results were mixed; revealing that in one of the two teaching cycles the expected outcomes were not achieved. Yang (2009) reported that while the first cycle was a success, in the second cycle students"" motivation decreased when a longer story was introduced. Although the story in the students"" mother tongue version was actually popular, many students had difficulty in understanding the English version. In terms of Megawati and Anugerahawati""s (2012) study, most of the students did not achieve the minimum standard for their written products. Based on their reflections, they concluded that more supports and feedback were required during the process of students"" writing their stories. It could be argued that some possible factors influential to the use of stories in these studies were text selection (Yang, 2009) and the degree of support during the students"" story writing (Megawati & Anugerahwati, 2012)."	1	"Despite the plethora of literature advocating the benefits of using stories for teaching English with EFL/ESL learners (Ellis & Brewster, 2014;Wajnryb, 2003), there is a dearth of research to support these claims (Lee, 2012;Tsou, Wang, & Tzeng, 2006). Among the relevant published studies, few of those reported have taken place in under-resourced learning environments. #CITATION_TAG""s (2009) and Megawati and Anugerahwati""s (2012) studies with secondary school students in Hong Kong and Indonesia, respectively, investigated the use of stories to enhance students"" motivation and their writing ability. The results were mixed; revealing that in one of the two teaching cycles the expected outcomes were not achieved. Yang (2009) reported that while the first cycle was a success, in the second cycle students"" motivation decreased when a longer story was introduced. Although the story in the students"" mother tongue version was actually popular, many students had difficulty in understanding the English version."	I
CCT958	"Despite the plethora of literature advocating the benefits of using stories for teaching English with EFL/ESL learners (Ellis & Brewster, 2014;#CITATION_TAG, 2003), there is a dearth of research to support these claims (Lee, 2012;Tsou, Wang, & Tzeng, 2006). Among the relevant published studies, few of those reported have taken place in under-resourced learning environments. Yang""s (2009) and Megawati and Anugerahwati""s (2012) studies with secondary school students in Hong Kong and Indonesia, respectively, investigated the use of stories to enhance students"" motivation and their writing ability. The results were mixed; revealing that in one of the two teaching cycles the expected outcomes were not achieved. Yang (2009) reported that while the first cycle was a success, in the second cycle students"" motivation decreased when a longer story was introduced. Although the story in the students"" mother tongue version was actually popular, many students had difficulty in understanding the English version. In terms of Megawati and Anugerahawati""s (2012) study, most of the students did not achieve the minimum standard for their written products. Based on their reflections, they concluded that more supports and feedback were required during the process of students"" writing their stories. It could be argued that some possible factors influential to the use of stories in these studies were text selection (Yang, 2009) and the degree of support during the students"" story writing (Megawati & Anugerahwati, 2012)."	4	"Despite the plethora of literature advocating the benefits of using stories for teaching English with EFL/ESL learners (Ellis & Brewster, 2014;#CITATION_TAG, 2003), there is a dearth of research to support these claims (Lee, 2012;Tsou, Wang, & Tzeng, 2006). Among the relevant published studies, few of those reported have taken place in under-resourced learning environments. Yang""s (2009) and Megawati and Anugerahwati""s (2012) studies with secondary school students in Hong Kong and Indonesia, respectively, investigated the use of stories to enhance students"" motivation and their writing ability. The results were mixed; revealing that in one of the two teaching cycles the expected outcomes were not achieved."	D
CCT959	"A good deal of useful work for stories has been done with genre pedagogy in particular #CITATION_TAG and Plum""s (1997) description of narrative genre. In the SFL tradition, narratives are not the only genre identified within the story family. There are variations in stories which constitute narrative along with recount, anecdote, exemplum, and observations (Martin & Rose, 2008). Each of the story genres has similar stages but serves different social purposes. For example, narratives are to entertain, recount to share experience, anecdote to share a reaction, exemplums to share moral judgments, and observations to share a personal response to things or events. The stages commonly identified in these genres are started optionally with an Orientation stage introducing an expectant activity and a Coda at the end of the story. The variations that differentiate these stories are present depending on the unfolding stages that disrupt an expectant activity and types of responses to this disruption. The stages in narratives, as the focus of the study, will be further discussed below."	5	"A good deal of useful work for stories has been done with genre pedagogy in particular #CITATION_TAG and Plum""s (1997) description of narrative genre. In the SFL tradition, narratives are not the only genre identified within the story family. There are variations in stories which constitute narrative along with recount, anecdote, exemplum, and observations (Martin & Rose, 2008). Each of the story genres has similar stages but serves different social purposes."	A
CCT960	"(3). The method is based in part on Yuen""s (1974) method for comparing trimmed means with the familywise error rate (the probability of one or more Type I errors) controlled using a strategy that is similar to #CITATION_TAG""s (1980) T3 technique. More recently, a bootstrap variation was proposed and studied by Wilcox (2009). Now the familywise error rate can be controlled using some improvement on the Bonferroni method (e.g., Rom, 1990;Hochberg, 1988). The bootstrap method can, in principle, be used with any robust measure of location."	1	"(3). The method is based in part on Yuen""s (1974) method for comparing trimmed means with the familywise error rate (the probability of one or more Type I errors) controlled using a strategy that is similar to #CITATION_TAG""s (1980) T3 technique. More recently, a bootstrap variation was proposed and studied by Wilcox (2009). Now the familywise error rate can be controlled using some improvement on the Bonferroni method (e.g., Rom, 1990;Hochberg, 1988). The bootstrap method can, in principle, be used with any robust measure of location."	h
CCT961	The ontogeny of dorsal and ventral idiosomal setae is based on descriptions of larva and protonymphal instars of Gamasholapis variabilis given by Petrova (1977), protonymph of Parholaspulus breguetovae given by #CITATION_TAG et al. (2001), deutonymph of Gamasholaspis browningi given by Petrova (1967Petrova ( , 1968) and deutonymph of Parholaspulus paradichaetes given by #CITATION_TAG et al. (2001). Several setae of the caudal body region bear two different notations: superior notation, referring to the notation widely used and recommended and smaller size notation, referring to the possible sixth elements of the opistonotal region discussed by Lindquist (1994).	1	The ontogeny of dorsal and ventral idiosomal setae is based on descriptions of larva and protonymphal instars of Gamasholapis variabilis given by Petrova (1977), protonymph of Parholaspulus breguetovae given by #CITATION_TAG et al. (2001), deutonymph of Gamasholaspis browningi given by Petrova (1967Petrova ( , 1968) and deutonymph of Parholaspulus paradichaetes given by #CITATION_TAG et al. (2001). Several setae of the caudal body region bear two different notations: superior notation, referring to the notation widely used and recommended and smaller size notation, referring to the possible sixth elements of the opistonotal region discussed by Lindquist (1994).	T
CCT962	The ontogeny of dorsal and ventral idiosomal setae is based on descriptions of larva and protonymphal instars of Gamasholapis variabilis given by Petrova (1977), protonymph of Parholaspulus breguetovae given by Ma et al. (2001), deutonymph of Gamasholaspis browningi given by #CITATION_TAG (1967Petrova ( , 1968) and deutonymph of Parholaspulus paradichaetes given by Ma et al. (2001). Several setae of the caudal body region bear two different notations: superior notation, referring to the notation widely used and recommended and smaller size notation, referring to the possible sixth elements of the opistonotal region discussed by Lindquist (1994).	1	The ontogeny of dorsal and ventral idiosomal setae is based on descriptions of larva and protonymphal instars of Gamasholapis variabilis given by Petrova (1977), protonymph of Parholaspulus breguetovae given by Ma et al. (2001), deutonymph of Gamasholaspis browningi given by #CITATION_TAG (1967Petrova ( , 1968) and deutonymph of Parholaspulus paradichaetes given by Ma et al. (2001). Several setae of the caudal body region bear two different notations: superior notation, referring to the notation widely used and recommended and smaller size notation, referring to the possible sixth elements of the opistonotal region discussed by Lindquist (1994).	T
CCT963	The family Parholaspidae Evans, 1956 is found in tropical, subtropical and temperate zones with wet clime (Paleartic, Indomalayan, Neotropical and Neartic regions). Except for the works of Krantz (1960), Petrova (1967Petrova ( , 1970Petrova ( , 1977, Ishikawa (1978Ishikawa ( , 1980a, Datta & Bhattacharjee (1989 and Lee & Lee (2000), there are no extended publications of this family whose members are free living predaceous mites which live in litter, the surface layer of the soil, moss, in association with mammals Cricetidae, Muridae) (Gu & Guo, 1996;#CITATION_TAG et al., 1994) and even in caves (Ishikawa, 1995(Ishikawa, , 2002.	1	The family Parholaspidae Evans, 1956 is found in tropical, subtropical and temperate zones with wet clime (Paleartic, Indomalayan, Neotropical and Neartic regions). Except for the works of Krantz (1960), Petrova (1967Petrova ( , 1970Petrova ( , 1977, Ishikawa (1978Ishikawa ( , 1980a, Datta & Bhattacharjee (1989 and Lee & Lee (2000), there are no extended publications of this family whose members are free living predaceous mites which live in litter, the surface layer of the soil, moss, in association with mammals Cricetidae, Muridae) (Gu & Guo, 1996;#CITATION_TAG et al., 1994) and even in caves (Ishikawa, 1995(Ishikawa, , 2002.	x
CCT964	Oxygen compensation O 2 is related to rubisco specificity and CO 2 concentration (C). #CITATION_TAG (2011a) demonstrated that a single reciprocal function exists linking CO 2 and O 2 , and further showed that in large range of environmental parameters, the CO 2 and O 2 exchanges of the green (productive) part of plants can be fitted by a simple model that mimics the rubisco response to O 2 and CO 2 variations. The plant specificity factor (Sp) defined by Andr√© (2011a) takes into account both the specificity of the rubisco enzyme and also the CO 2 gradient between the atmosphere and the rubisco site. Where E is the gross O 2 evolution, a parameter linked to the electron transport rate generated by light in chloroplasts, and R is the rate of respiration, Andr√© (2011a) showed that a finite or realistic O 2 (stated in %; see Fig. 2) cannot be reached in a closed biosystem without a high rate of dark respiration (R):	1	Oxygen compensation O 2 is related to rubisco specificity and CO 2 concentration (C). #CITATION_TAG (2011a) demonstrated that a single reciprocal function exists linking CO 2 and O 2 , and further showed that in large range of environmental parameters, the CO 2 and O 2 exchanges of the green (productive) part of plants can be fitted by a simple model that mimics the rubisco response to O 2 and CO 2 variations. The plant specificity factor (Sp) defined by Andr√© (2011a) takes into account both the specificity of the rubisco enzyme and also the CO 2 gradient between the atmosphere and the rubisco site. Where E is the gross O 2 evolution, a parameter linked to the electron transport rate generated by light in chloroplasts, and R is the rate of respiration, Andr√© (2011a) showed that a finite or realistic O 2 (stated in %; see Fig. 2) cannot be reached in a closed biosystem without a high rate of dark respiration (R):	C
CCT965	"On a microscopic scale (e.g. chloroplasts), the CO 2 ""compensation point CO 2 (Farquhar et al., 1980), defines the equilibrium between CO 2 uptake by photosynthesis and release by photorespiration. In plants (e.g. in soil in a bell jar: Tolbert et al., 1995), the CO 2 compensation point is the CO 2 concentration at which net CO 2 fixation is zero. On the global scale (Berry et al., 1994), this is the CO 2 level for which the total CO 2 evolution (dark respiration) by all living organisms is equilibrated by carboxylation by plants. As carbon dioxide re-supply from the external environment (either from the air or dissolved gases in seawater which in turn have equilibrated with the air) is generally not limiting, this suggests a fundamental molecular control on the macroscopic CO 2 content in the air lying in the biochemistry of rubisco catalysis. If the external environment lies on the wrong side of the compensation barrier limit, net plant and algal growth ceases. If CO 2 is too low, organisms cannot capture carbon. O 2 and CO 2 are interlinked, with linear co-variance (Tolbert et al., 1995, but see Andr√© 2011a. Tolbert et al. (1995) postulated an O 2 compensation point CO 2 , defined as the upper limit of O 2 at a given CO 2 level, above which plants cannot have positive carbon uptake. On a planetary scale, this is the equilibrium point where O 2 production to atmosphere by all green plants (including both higher plants and also microbial oxygenesis) equals the consumption by all living biosystems consuming O 2 by dark respiration. The Tolbert et al. (1995) experimental data rather paradoxically implied the linkage of CO 2 to O 2 was disconnected from the linkage of O 2 to CO 2 . The experimental results of Tolbert et al. (1995) led #CITATION_TAG (2008) to propose the existence of a ""prohibited region"" in O 2 :CO 2 space, where oxygen partial pressure would be so high that plant growth would stop, and eventually the plant would respire itself to death. However, Andr√© (2011a, b) re-investigated the high-O 2 prohibited zone hypothesis, invalidating it by showing that the Tolbert et al. (1995) experiments, on which it was based, may have been affected by problems such as leakage artefacts."	1	"O 2 and CO 2 are interlinked, with linear co-variance (Tolbert et al., 1995, but see Andr√© 2011a. Tolbert et al. (1995) postulated an O 2 compensation point CO 2 , defined as the upper limit of O 2 at a given CO 2 level, above which plants cannot have positive carbon uptake. On a planetary scale, this is the equilibrium point where O 2 production to atmosphere by all green plants (including both higher plants and also microbial oxygenesis) equals the consumption by all living biosystems consuming O 2 by dark respiration. The Tolbert et al. (1995) experimental data rather paradoxically implied the linkage of CO 2 to O 2 was disconnected from the linkage of O 2 to CO 2 . The experimental results of Tolbert et al. (1995) led #CITATION_TAG (2008) to propose the existence of a ""prohibited region"" in O 2 :CO 2 space, where oxygen partial pressure would be so high that plant growth would stop, and eventually the plant would respire itself to death. However, Andr√© (2011a, b) re-investigated the high-O 2 prohibited zone hypothesis, invalidating it by showing that the Tolbert et al. (1995) experiments, on which it was based, may have been affected by problems such as leakage artefacts."	r
CCT966	Winter (December, January, February -DJF) wind regimes over Israel by self-organizing maps (SOM) were previously defined (Berkovic, 2017). This study extends this ability to other seasons. Therefore, some of the sections of Berkovic (2017) are repeated here for clarity. The climate in Israel is a Mediterranean climate, with a hot and dry summer, transitional seasons and rainy winter. Since the summer regime is well known it was omitted from the study. During the summer there is a single synoptic group (Persian trough) with a typical wind regime exhibiting diurnal veering according to the diurnal heating and topography (Skibin and Hod, 1979;Ziv et al., 2004). During the winter and the transitional seasons synoptic variability increases and therefore, a higher number of surface wind regimes prevail. Many previous studies referred to a subjective or semi-objective synoptic classification (Alpert et al., 2004); however, there is a need for an automatic objective classification when studying the surface winds on an hourly time scale. An automatic algorithm will greatly facilitate the definition of wind regimes or synoptic classes, since a subjective analysis is highly tedious. This study shows the ability of SOM to automatically reconstruct previous subjective studies (#CITATION_TAG et al., 1998;Levy et al., 2008;Ziv and Yair, 1994;Goldreich, 2003) characterizing the surface flow over Israel. SOM (self-organizing maps, Hewitson and Crane, 2002;Liu et al., 2006;Liu and Weisberg, 2011) is an objective non-linear clustering technique extensively used to determine the patterns of meteorological variables, e.g., sea surface temperature, wind, or geopotential height. This study employed SOM to define surface wind regimes over Israel at 12:00 UTC during winter, spring and autumn. The wind patterns are derived from surface wind measurements. Wind regimes at other synoptic hours (00:00, 06:00, 18:00 UTC) are not shown here for the sake of brevity. The relation between surface wind patterns and synoptic conditions is clarified by calculating the averages of the synoptic variables according to the SOM classification. The synoptic variables were derived from ECMWF ERA-INTERIM reanalysis data.	1	During the winter and the transitional seasons synoptic variability increases and therefore, a higher number of surface wind regimes prevail. Many previous studies referred to a subjective or semi-objective synoptic classification (Alpert et al., 2004); however, there is a need for an automatic objective classification when studying the surface winds on an hourly time scale. An automatic algorithm will greatly facilitate the definition of wind regimes or synoptic classes, since a subjective analysis is highly tedious. This study shows the ability of SOM to automatically reconstruct previous subjective studies (#CITATION_TAG et al., 1998;Levy et al., 2008;Ziv and Yair, 1994;Goldreich, 2003) characterizing the surface flow over Israel. SOM (self-organizing maps, Hewitson and Crane, 2002;Liu et al., 2006;Liu and Weisberg, 2011) is an objective non-linear clustering technique extensively used to determine the patterns of meteorological variables, e.g., sea surface temperature, wind, or geopotential height. This study employed SOM to define surface wind regimes over Israel at 12:00 UTC during winter, spring and autumn. The wind patterns are derived from surface wind measurements.	y
CCT967	On large scales, color tends to decrease faster than DOC along the land-sea continuum (Weyhenmeyer et al., 2012), partly because noncolored DOC might be added by algae in productive waters (Creed et al., 2015), but the circumstances allowing for preferential net losses of colored DOC in unproductive lakes are unclear. Some studies have reported relative losses of colored DOC across lake basins with increasing theoretical residence times (#CITATION_TAG et al., 2013;Curtis and Schindler, 1997), while other studies have found preferential loss of noncolored DOC in laboratory biodegradation experiments (Hansen et al., 2016) and in time series analyses of brown headwater lakes (Berggren et al., 2009). Although bacteria do consume colored humic substances at low rates (Tranvik, 1988), the biological degradation of DOC is unlikely a mechanism leading to selective color loss because bacteria tend to mainly consume noncolored DOC (Asmala et al., 2014;Hansen et al., 2016). An exception is the apparent preferential use of organo-ferric colloids by bacteria, whereby the removed color comes from iron, not DOC (Oleinikova et al., 2017). The UV light oxidation could theoretically explain losses of colored DOC and the production of noncolored DOC (Stubbins et al., 2010;Kellerman et al., 2014), but efficient photo-processing has been found mainly in relatively DOC poor water (Molot and Dillon, 1997) and in alkaline lakes (Reche et al., 1999) and not systematically in unproductive DOC-rich lakes (Amon and Benner, 1996;Molot and Dillon, 1997;Jonsson et al., 2001). Thus, the processing of colored DOC remains poorly understood in response to water transit through common unproductive DOCrich headwater systems (Weyhenmeyer et al., 2014).	1	On large scales, color tends to decrease faster than DOC along the land-sea continuum (Weyhenmeyer et al., 2012), partly because noncolored DOC might be added by algae in productive waters (Creed et al., 2015), but the circumstances allowing for preferential net losses of colored DOC in unproductive lakes are unclear. Some studies have reported relative losses of colored DOC across lake basins with increasing theoretical residence times (#CITATION_TAG et al., 2013;Curtis and Schindler, 1997), while other studies have found preferential loss of noncolored DOC in laboratory biodegradation experiments (Hansen et al., 2016) and in time series analyses of brown headwater lakes (Berggren et al., 2009). Although bacteria do consume colored humic substances at low rates (Tranvik, 1988), the biological degradation of DOC is unlikely a mechanism leading to selective color loss because bacteria tend to mainly consume noncolored DOC (Asmala et al., 2014;Hansen et al., 2016). An exception is the apparent preferential use of organo-ferric colloids by bacteria, whereby the removed color comes from iron, not DOC (Oleinikova et al., 2017). The UV light oxidation could theoretically explain losses of colored DOC and the production of noncolored DOC (Stubbins et al., 2010;Kellerman et al., 2014), but efficient photo-processing has been found mainly in relatively DOC poor water (Molot and Dillon, 1997) and in alkaline lakes (Reche et al., 1999) and not systematically in unproductive DOC-rich lakes (Amon and Benner, 1996;Molot and Dillon, 1997;Jonsson et al., 2001).	o
CCT968	On large scales, color tends to decrease faster than DOC along the land-sea continuum (Weyhenmeyer et al., 2012), partly because noncolored DOC might be added by algae in productive waters (Creed et al., 2015), but the circumstances allowing for preferential net losses of colored DOC in unproductive lakes are unclear. Some studies have reported relative losses of colored DOC across lake basins with increasing theoretical residence times (K√∂hler et al., 2013;#CITATION_TAG and Schindler, 1997), while other studies have found preferential loss of noncolored DOC in laboratory biodegradation experiments (Hansen et al., 2016) and in time series analyses of brown headwater lakes (Berggren et al., 2009). Although bacteria do consume colored humic substances at low rates (Tranvik, 1988), the biological degradation of DOC is unlikely a mechanism leading to selective color loss because bacteria tend to mainly consume noncolored DOC (Asmala et al., 2014;Hansen et al., 2016). An exception is the apparent preferential use of organo-ferric colloids by bacteria, whereby the removed color comes from iron, not DOC (Oleinikova et al., 2017). The UV light oxidation could theoretically explain losses of colored DOC and the production of noncolored DOC (Stubbins et al., 2010;Kellerman et al., 2014), but efficient photo-processing has been found mainly in relatively DOC poor water (Molot and Dillon, 1997) and in alkaline lakes (Reche et al., 1999) and not systematically in unproductive DOC-rich lakes (Amon and Benner, 1996;Molot and Dillon, 1997;Jonsson et al., 2001). Thus, the processing of colored DOC remains poorly understood in response to water transit through common unproductive DOCrich headwater systems (Weyhenmeyer et al., 2014).	1	On large scales, color tends to decrease faster than DOC along the land-sea continuum (Weyhenmeyer et al., 2012), partly because noncolored DOC might be added by algae in productive waters (Creed et al., 2015), but the circumstances allowing for preferential net losses of colored DOC in unproductive lakes are unclear. Some studies have reported relative losses of colored DOC across lake basins with increasing theoretical residence times (K√∂hler et al., 2013;#CITATION_TAG and Schindler, 1997), while other studies have found preferential loss of noncolored DOC in laboratory biodegradation experiments (Hansen et al., 2016) and in time series analyses of brown headwater lakes (Berggren et al., 2009). Although bacteria do consume colored humic substances at low rates (Tranvik, 1988), the biological degradation of DOC is unlikely a mechanism leading to selective color loss because bacteria tend to mainly consume noncolored DOC (Asmala et al., 2014;Hansen et al., 2016). An exception is the apparent preferential use of organo-ferric colloids by bacteria, whereby the removed color comes from iron, not DOC (Oleinikova et al., 2017). The UV light oxidation could theoretically explain losses of colored DOC and the production of noncolored DOC (Stubbins et al., 2010;Kellerman et al., 2014), but efficient photo-processing has been found mainly in relatively DOC poor water (Molot and Dillon, 1997) and in alkaline lakes (Reche et al., 1999) and not systematically in unproductive DOC-rich lakes (Amon and Benner, 1996;Molot and Dillon, 1997;Jonsson et al., 2001).	o
CCT969	In the multi-lake comparison our results demonstrate contrasting DOC quality dynamics for different types of lake ecosystems. We argue that changes in the DOC quality indices a 420 : DOC and the absorption ratio A 254 : A 265 strongly indicate that microbial processes dominated the DOC quality transformation in the brownest lakes, while photochemical processes dominated in the clearest lakes. Epilimnetic waters of relatively clear lakes showed losses in a 420 with WTTs, a pattern also found elsewhere in Sweden (#CITATION_TAG et al., 2013;Weyhenmeyer et al., 2012). Lakes of intermediate color were, however, relatively irresponsive to changes in WTT, suggesting that the DOC quality and color in these lakes would be less sensitive to hydrological events such as rainfall or drought.	1	In the multi-lake comparison our results demonstrate contrasting DOC quality dynamics for different types of lake ecosystems. We argue that changes in the DOC quality indices a 420 : DOC and the absorption ratio A 254 : A 265 strongly indicate that microbial processes dominated the DOC quality transformation in the brownest lakes, while photochemical processes dominated in the clearest lakes. Epilimnetic waters of relatively clear lakes showed losses in a 420 with WTTs, a pattern also found elsewhere in Sweden (#CITATION_TAG et al., 2013;Weyhenmeyer et al., 2012). Lakes of intermediate color were, however, relatively irresponsive to changes in WTT, suggesting that the DOC quality and color in these lakes would be less sensitive to hydrological events such as rainfall or drought.	i
CCT970	Regardless of whether one accepts that any such ideas can be transferred from ecology to disaster risk reduction, there is no doubt that Holling and the other ecologists made a significant innovation when they began to utilise adaptive management in resilience studies (#CITATION_TAG, 1999). Recent work (Djalate et al., 2011) has extended this concept to adaptive governance -i.e. adaptive co-management as a continuous problem-solving process.	2	Regardless of whether one accepts that any such ideas can be transferred from ecology to disaster risk reduction, there is no doubt that Holling and the other ecologists made a significant innovation when they began to utilise adaptive management in resilience studies (#CITATION_TAG, 1999). Recent work (Djalate et al., 2011) has extended this concept to adaptive governance -i.e. adaptive co-management as a continuous problem-solving process.	R
CCT971	"Many students of the robustness of people, objects and systems believe that ""resilience"" was coined by C. S. Holling in his landmark 1973 paper on systems ecology (Holling, 1973). For example, Berkes (2007, p. 286) wrote, ""Originally developed as an ecological concept, resilience is being applied to coupled human-environment systems. Djalate et al. (2011, p. 3) wrote ""the concept of resilience was originally developed in the field of ecology"". Goldstein and Brooks (2006, p. 3) were a little more generous with time when they stated that ""The study of resilience traces its roots back a scant 50 years"". In reality, the word has a very much longer history (OED, 2013). It stems from resilire, resilio, Latin for ""bounce"" -hence the idea of ""bouncing back"" (#CITATION_TAG et al., 2011)."	3	"Djalate et al. (2011, p. 3) wrote ""the concept of resilience was originally developed in the field of ecology"". Goldstein and Brooks (2006, p. 3) were a little more generous with time when they stated that ""The study of resilience traces its roots back a scant 50 years"". In reality, the word has a very much longer history (OED, 2013). It stems from resilire, resilio, Latin for ""bounce"" -hence the idea of ""bouncing back"" (#CITATION_TAG et al., 2011)."	e
CCT972	"with attempts to create a resilience paradigm in various disciplines. In theory, the term can be applied to any phenomenon that involves shocks to a system, whether it be physical or social, and whether the shock involve disasters or merely a hard knock in the literal or figurative sense. The amount of literature on resilience is now so copious that it is becoming increasingly difficult to summarise. Comparative tables of definitions of the term appear in Zhou et al. (2008) and Garschagen (2013), mirroring similar compilations for vulnerability (Weichselgartner, 2001, p. 88) and risk (Brooks 2003, p. 7). Manyena (2006) listed 12 definitions of resilience and 20 of vulnerability (the number of definitions of the latter present in the disaster risk reduction literature has swollen to at least twice that - Haimes, 2011). After two books on ""What is a Disaster"" (Quarantelli, 1998;#CITATION_TAG and Quarantelli, 2005), it seems that no one can agree on the meaning of terms in the disaster risk reduction field."	2	"The amount of literature on resilience is now so copious that it is becoming increasingly difficult to summarise. Comparative tables of definitions of the term appear in Zhou et al. (2008) and Garschagen (2013), mirroring similar compilations for vulnerability (Weichselgartner, 2001, p. 88) and risk (Brooks 2003, p. 7). Manyena (2006) listed 12 definitions of resilience and 20 of vulnerability (the number of definitions of the latter present in the disaster risk reduction literature has swollen to at least twice that - Haimes, 2011). After two books on ""What is a Disaster"" (Quarantelli, 1998;#CITATION_TAG and Quarantelli, 2005), it seems that no one can agree on the meaning of terms in the disaster risk reduction field."	 
CCT973	"with attempts to create a resilience paradigm in various disciplines. In theory, the term can be applied to any phenomenon that involves shocks to a system, whether it be physical or social, and whether the shock involve disasters or merely a hard knock in the literal or figurative sense. The amount of literature on resilience is now so copious that it is becoming increasingly difficult to summarise. Comparative tables of definitions of the term appear in Zhou et al. (2008) and Garschagen (2013), mirroring similar compilations for vulnerability (Weichselgartner, 2001, p. 88) and risk (Brooks 2003, p. 7). Manyena (2006) listed 12 definitions of resilience and 20 of vulnerability (the number of definitions of the latter present in the disaster risk reduction literature has swollen to at least twice that - Haimes, 2011). After two books on ""What is a Disaster"" (#CITATION_TAG, 1998;Perry and Quarantelli, 2005), it seems that no one can agree on the meaning of terms in the disaster risk reduction field."	2	"The amount of literature on resilience is now so copious that it is becoming increasingly difficult to summarise. Comparative tables of definitions of the term appear in Zhou et al. (2008) and Garschagen (2013), mirroring similar compilations for vulnerability (Weichselgartner, 2001, p. 88) and risk (Brooks 2003, p. 7). Manyena (2006) listed 12 definitions of resilience and 20 of vulnerability (the number of definitions of the latter present in the disaster risk reduction literature has swollen to at least twice that - Haimes, 2011). After two books on ""What is a Disaster"" (#CITATION_TAG, 1998;Perry and Quarantelli, 2005), it seems that no one can agree on the meaning of terms in the disaster risk reduction field."	 
CCT974	"At this point, it is worth adding that many other terms used in disaster risk reduction have long and rich histories that involve a fair degree of ambiguity. For example, the D. E. Alexander: Resilience and disaster risk reduction: an etymological journey term ""governance"" entered the English language in the late 1300s from Old French and Mediaeval Latin. For centuries, its sole meaning appears to have been ""the action or manner of governing"" (OED, 2013), although this often had benign overtones. Since the Second World War it has also been used as a euphemism for repressive national civil administrations when dealing with the civil administrations of dictatorships (cf. Jenkins, 2001) and also the transfer of power from states to corporations (#CITATION_TAG and McMichael, 2005), but in its more recent period of being fashionable has reverted to a more traditional meaning as one of ""good government"". In line with the modern desire to promote democratic values, this has tended to signify participatory forms of democracy (UNDP, 2012)."	2	"At this point, it is worth adding that many other terms used in disaster risk reduction have long and rich histories that involve a fair degree of ambiguity. For example, the D. E. Alexander: Resilience and disaster risk reduction: an etymological journey term ""governance"" entered the English language in the late 1300s from Old French and Mediaeval Latin. For centuries, its sole meaning appears to have been ""the action or manner of governing"" (OED, 2013), although this often had benign overtones. Since the Second World War it has also been used as a euphemism for repressive national civil administrations when dealing with the civil administrations of dictatorships (cf. Jenkins, 2001) and also the transfer of power from states to corporations (#CITATION_TAG and McMichael, 2005), but in its more recent period of being fashionable has reverted to a more traditional meaning as one of ""good government"". In line with the modern desire to promote democratic values, this has tended to signify participatory forms of democracy (UNDP, 2012)."	c
CCT975	"Rubisco I may have evolved in cyanobacteria nearly 3 Ga ago (Nisbet et al., 2007), yet rubisco\""s ""specificity"" (its preference for CO 2 over O 2 ) remains paradoxically restricted. In contrast with other enzymes, rubisco seems inefficient, with a sluggish reaction rate (#CITATION_TAG et al., 2006). However, rubisco\""s ""inefficiency"" may be deceptive. On a molecular level, analysis of the kinetics and isotopic fractionation of rubisco I in oxygenic photosynthetic organisms (Tcherkez et al., 2006) suggests that evolution has led to a near-perfect compromise between catalytic turnover and CO 2 :O 2 specificity (Gutteridge and Pierce, 2006). Organisms that that are adapted to higher CO 2 :O 2 ratios contain rubisco with higher catalytic rates and lower specificity. In contrast, a rubisco enzyme with a higher specificity (i.e. more able to select for CO 2 at low CO 2 :O 2 ratios) will operate only at lower temperatures and lower rates (Tcherkez et al., 2006), and will thus suit organisms adapted to a different range of habitats on the climatically varied planet. In each photosynthetic species, the rubisco enzymes may be nearly optimally fitted to their specific tasks, each exquisitely tuned to the local environment (Tcherkez et al., 2006;Gutteridge and Pierce, 2006) under a globally mixed atmosphere."	2	"Rubisco I may have evolved in cyanobacteria nearly 3 Ga ago (Nisbet et al., 2007), yet rubisco\""s ""specificity"" (its preference for CO 2 over O 2 ) remains paradoxically restricted. In contrast with other enzymes, rubisco seems inefficient, with a sluggish reaction rate (#CITATION_TAG et al., 2006). However, rubisco\""s ""inefficiency"" may be deceptive. On a molecular level, analysis of the kinetics and isotopic fractionation of rubisco I in oxygenic photosynthetic organisms (Tcherkez et al., 2006) suggests that evolution has led to a near-perfect compromise between catalytic turnover and CO 2 :O 2 specificity (Gutteridge and Pierce, 2006). Organisms that that are adapted to higher CO 2 :O 2 ratios contain rubisco with higher catalytic rates and lower specificity."	n
CCT976	Over time, the Sun has steadily warmed (Gough et al., 1981) with significant consequences for life on Earth (Sagan and Chyba, 1997;Goldblatt et al., 2009;Nisbet and Nisbet, 2008;Ueno et al., 2009;#CITATION_TAG et al., 2010; see also Fig. 8.1 in Kasting, 2008). It might be expected that, under the faint young Sun, the Hadean and Archaean Earth would have been covered in ice (see Nisbet and Sleep, 2001;Nisbet and Fowler, 2004). If the oceans are cool now, in a modern world subject to repeated ice ages, then billions of years ago under a faint Sun, the planet ought to have existed in deep permafrost, too cold for life except near volcanic vents. However, the evidence in Jack Hills zircons in Western Australia that implies the presence of liquid water oceans 4.3 Ga ago (Wilde et al., 2001), and the presence of sedimentary rocks in the 3.8 Ga old Isua belt (Rosing, 1999), both imply that surface temperatures permitted liquid water. High concentrations of atmospheric greenhouse gases, either CO 2 or perhaps methane, could have prevented the oceans from freezing over.	2	Over time, the Sun has steadily warmed (Gough et al., 1981) with significant consequences for life on Earth (Sagan and Chyba, 1997;Goldblatt et al., 2009;Nisbet and Nisbet, 2008;Ueno et al., 2009;#CITATION_TAG et al., 2010; see also Fig. 8.1 in Kasting, 2008). It might be expected that, under the faint young Sun, the Hadean and Archaean Earth would have been covered in ice (see Nisbet and Sleep, 2001;Nisbet and Fowler, 2004). If the oceans are cool now, in a modern world subject to repeated ice ages, then billions of years ago under a faint Sun, the planet ought to have existed in deep permafrost, too cold for life except near volcanic vents. However, the evidence in Jack Hills zircons in Western Australia that implies the presence of liquid water oceans 4.3 Ga ago (Wilde et al., 2001), and the presence of sedimentary rocks in the 3.8 Ga old Isua belt (Rosing, 1999), both imply that surface temperatures permitted liquid water.	O
CCT977	As the Earth has evolved, the continental area may have changed over time (but see discussion in #CITATION_TAG and Nisbet, 2012). Moreover, as the potential temperature of the mantle has cooled, thickening lithosphere may have became more capable of supporting mountains and hence more erosion of silicates taking up CO 2 . Thus, there may be purely inorganic feedbacks capable of changing and managing the greenhouse over time as the external inputs varied. Zeebe and Caldeira (2008) demonstrated a close mass balance of carbon cycle fluxes in the late Pleistocene, which they interpreted as evidence for control by the weathering feedback.	2	As the Earth has evolved, the continental area may have changed over time (but see discussion in #CITATION_TAG and Nisbet, 2012). Moreover, as the potential temperature of the mantle has cooled, thickening lithosphere may have became more capable of supporting mountains and hence more erosion of silicates taking up CO 2 . Thus, there may be purely inorganic feedbacks capable of changing and managing the greenhouse over time as the external inputs varied. Zeebe and Caldeira (2008) demonstrated a close mass balance of carbon cycle fluxes in the late Pleistocene, which they interpreted as evidence for control by the weathering feedback.	A
CCT978	"To illustrate, the movement to restrict master""s training, licensure or other government authorization to practice, and employment to those sanctioned by one counselor education accrediting body, the Council for the Accreditation of Counseling and Related Educational Programs (CACREP), threatens the viability of counseling psychology (Jackson &amp; Scheel, 2013) and professional counseling (#CITATION_TAG, 2012;Hansen, 2012) in the U.S"	2	"To illustrate, the movement to restrict master""s training, licensure or other government authorization to practice, and employment to those sanctioned by one counselor education accrediting body, the Council for the Accreditation of Counseling and Related Educational Programs (CACREP), threatens the viability of counseling psychology (Jackson &amp; Scheel, 2013) and professional counseling (#CITATION_TAG, 2012;Hansen, 2012) in the U.S"	T
CCT979	"To illustrate, the movement to restrict master""s training, licensure or other government authorization to practice, and employment to those sanctioned by one counselor education accrediting body, the Council for the Accreditation of Counseling and Related Educational Programs (CACREP), threatens the viability of counseling psychology (Jackson &amp; Scheel, 2013) and professional counseling (Brady-Amoon, 2012;#CITATION_TAG, 2012) in the U.S"	2	"To illustrate, the movement to restrict master""s training, licensure or other government authorization to practice, and employment to those sanctioned by one counselor education accrediting body, the Council for the Accreditation of Counseling and Related Educational Programs (CACREP), threatens the viability of counseling psychology (Jackson &amp; Scheel, 2013) and professional counseling (Brady-Amoon, 2012;#CITATION_TAG, 2012) in the U.S"	T
CCT980	Counseling psychology, which is historically and currently at the intersection of psychology and professional counseling (Moore & Rae, 2009;#CITATION_TAG & Woolfe, 2010), is well positioned to bridge gaps between and among allied professions. Moreover, the professions are strengthened and services to the public enhanced when counseling psychology and counseling, which provide a critically important alternative to dominant models in psychology and health care, work together to assure their shared philosophy and approaches remain vibrant.	0	Counseling psychology, which is historically and currently at the intersection of psychology and professional counseling (Moore & Rae, 2009;#CITATION_TAG & Woolfe, 2010), is well positioned to bridge gaps between and among allied professions. Moreover, the professions are strengthened and services to the public enhanced when counseling psychology and counseling, which provide a critically important alternative to dominant models in psychology and health care, work together to assure their shared philosophy and approaches remain vibrant.	C
CCT981	A final theoretical model used to explain repository development is innovation diffusion theory (IDT). This has been deployed by Jones, Andrew, and MacColl (2006) in a practitioner context to frame a discussion of the development of an institutional-level advocacy campaign aimed at promoting the use of an institutional repository. IDT has also been used at a different level by #CITATION_TAG (2012) to explain different adoption patterns of both OA journals and repositories worldwide. His analysis usefully incorporates discussion of technological, cultural, and policy factors that influence varying take-up globally. These studies using IDT illustrate a particular strength of diffusion theory in that it can be used to explain adoption characteristics at a number of levels, including the local level (taking into account the behaviors of individual actors) and the global level (taking into account large-scale cultural and technological trends). It is deployed later in this paper to provide an explanatory framework for the data presented, which relate to the levels already described but also, crucially, to organizational-level adoption.	2	A final theoretical model used to explain repository development is innovation diffusion theory (IDT). This has been deployed by Jones, Andrew, and MacColl (2006) in a practitioner context to frame a discussion of the development of an institutional-level advocacy campaign aimed at promoting the use of an institutional repository. IDT has also been used at a different level by #CITATION_TAG (2012) to explain different adoption patterns of both OA journals and repositories worldwide. His analysis usefully incorporates discussion of technological, cultural, and policy factors that influence varying take-up globally. These studies using IDT illustrate a particular strength of diffusion theory in that it can be used to explain adoption characteristics at a number of levels, including the local level (taking into account the behaviors of individual actors) and the global level (taking into account large-scale cultural and technological trends). It is deployed later in this paper to provide an explanatory framework for the data presented, which relate to the levels already described but also, crucially, to organizational-level adoption.	T
CCT982	In this paper, to overcome the limitations of the aforementioned results we study the admission problem for the MOdel-based SElf-adaptation of SOA systems (MOSES) service broker we proposed in [#CITATION_TAG,7], which manages a composite service offering differentiated QoS service classes. We formulate the optimal admission control problem as a Markov Decision Process (MDP) problem with the goal to maximise the broker discounted expected infinite horizon reward while guaranteeing non-functional QoS requirements to its users. Our results show the MDP-based admission control always guarantees significantly higher average rewards than the blind policy. We also considered finite horizon policies which are computationally more efficient than the infinite horizon counterpart and that allow us to tradeoff optimality with computational complexity/timehorizon length. Our findings show that even with the simple 1-step horizon policy it is possible to achieve better results with respect to the blind policy, quite close to the infinite horizon optimum, but at a fraction of the computational cost.	2	In this paper, to overcome the limitations of the aforementioned results we study the admission problem for the MOdel-based SElf-adaptation of SOA systems (MOSES) service broker we proposed in [#CITATION_TAG,7], which manages a composite service offering differentiated QoS service classes. We formulate the optimal admission control problem as a Markov Decision Process (MDP) problem with the goal to maximise the broker discounted expected infinite horizon reward while guaranteeing non-functional QoS requirements to its users. Our results show the MDP-based admission control always guarantees significantly higher average rewards than the blind policy. We also considered finite horizon policies which are computationally more efficient than the infinite horizon counterpart and that allow us to tradeoff optimality with computational complexity/timehorizon length.	I
CCT983	"Phytophagous (plant-eating) insects are tremendously diverse-constituting perhaps as much as one third of all animal species (Strong et al. 1984)-and their speciation has been tied to extrinsic reproductive barriers arising during changes in host plant use (Bush 1969;Wood and Keese 1990;Berlocher 1998;Nason et al. 2002;Funk et al. 2011). Many insects find mates on or near the female""s oviposition substrate (the host plant), so emergent preferences for novel hosts may often translate into assortative mating and behaviorally isolate different host-associated populations (e.g., Emelianov et al. 2001;Berlocher and Feder 2002). The result is the formation of partially isolated races, presumed to be an early step along the so-called """"speciation continuum"""" (Mallet 2008). Genetically differentiated races within morphologically defined species have also been found to coexist on a single plant species, particularly among taxa that have recently undergone adaptive radiations (Marsteller et al. 2009;Stireman et al. 2012). Further, recent empirical and theoretical work demonstrating that populations can diverge even in the face of effective migration (#CITATION_TAG 2008;Nosil and Feder 2012), as well as new information about the permeability of genomes to between-lineage gene flow (Turner et al. 1999;Michel et al. 2010;Gompert et al. 2010) both suggest that persistent hybridization between closely related lineages may occur without leading to lineage fusion or breakdown of reproductive barriers. Such studies imply that ecology plays a central role in insect diversity, but many questions remain as to the interplay between gene flow and host plant mediated selection during the early stages of speciation."	2	"Many insects find mates on or near the female""s oviposition substrate (the host plant), so emergent preferences for novel hosts may often translate into assortative mating and behaviorally isolate different host-associated populations (e.g., Emelianov et al. 2001;Berlocher and Feder 2002). The result is the formation of partially isolated races, presumed to be an early step along the so-called """"speciation continuum"""" (Mallet 2008). Genetically differentiated races within morphologically defined species have also been found to coexist on a single plant species, particularly among taxa that have recently undergone adaptive radiations (Marsteller et al. 2009;Stireman et al. 2012). Further, recent empirical and theoretical work demonstrating that populations can diverge even in the face of effective migration (#CITATION_TAG 2008;Nosil and Feder 2012), as well as new information about the permeability of genomes to between-lineage gene flow (Turner et al. 1999;Michel et al. 2010;Gompert et al. 2010) both suggest that persistent hybridization between closely related lineages may occur without leading to lineage fusion or breakdown of reproductive barriers. Such studies imply that ecology plays a central role in insect diversity, but many questions remain as to the interplay between gene flow and host plant mediated selection during the early stages of speciation."	h
CCT984	In most phospholipids, the fatty acid at the sn-1 position is palmitic (16:0), stearic (18:0) or oleic acid (18:1) while either a saturated, unsaturated or a polyunsaturated fatty acids (PUFAs) can be found at the sn-2 position of the glycerol backbone. In certain classes and subclasses found in cells or tissues, PUFAs are the major fatty acids at the sn-2 position. This distribution gives rise to subclasses of lipids that are targeted for the release of PUFAs and the generation of specific lipid mediators and signaling molecules. An example is 1-alkyl-2-arachidonoyl-sn-glycero-3phosphocholine, the precursor of platelet activating factor and leukotrienes [77,122]. The incorporation of PUFAs into phospholipid subclasses is highly choreographed such that most PUFAs are initially incorporated into 1,2-diacyl phospholipids subclasses before they are remodeled into the ether-linked phospholipids classes by coenzyme A (CoA)-dependent or CoA-independent transacylase activities [#CITATION_TAG,84,126,165,167].	3	In certain classes and subclasses found in cells or tissues, PUFAs are the major fatty acids at the sn-2 position. This distribution gives rise to subclasses of lipids that are targeted for the release of PUFAs and the generation of specific lipid mediators and signaling molecules. An example is 1-alkyl-2-arachidonoyl-sn-glycero-3phosphocholine, the precursor of platelet activating factor and leukotrienes [77,122]. The incorporation of PUFAs into phospholipid subclasses is highly choreographed such that most PUFAs are initially incorporated into 1,2-diacyl phospholipids subclasses before they are remodeled into the ether-linked phospholipids classes by coenzyme A (CoA)-dependent or CoA-independent transacylase activities [#CITATION_TAG,84,126,165,167].	i
CCT985	"(iv) Gestural Interaction Is Not an ""Add-On. The previous lessons made it clear that gestural interaction is not simply an additional input mode that can be added to an existing application. The direct mapping of mouse actions to hand gestures proved problematic due to technical limitations but also due to ergonomic considerations. Even if we had used the Leap Motion it would not have been clear whether users would have yielded higher performance or higher levels of satisfaction. Thus the game controls in the gestural mode should be redesigned to cope with the limited accuracy and to minimize fatigue and discomfort. For example, the second arm might be used for certain controls in order to provide more balance to body movements. Instead of point-andclick actions, the goal-crossing paradigm #CITATION_TAG could be used. Furthermore, when selecting the home square, only the target squares that constitute valid moves could be highlighted and enabled for selection. Goal-crossing might also benefit players with motor impairments. Highlighting and enabling only valid squares might benefit novices."	3	Even if we had used the Leap Motion it would not have been clear whether users would have yielded higher performance or higher levels of satisfaction. Thus the game controls in the gestural mode should be redesigned to cope with the limited accuracy and to minimize fatigue and discomfort. For example, the second arm might be used for certain controls in order to provide more balance to body movements. Instead of point-andclick actions, the goal-crossing paradigm #CITATION_TAG could be used. Furthermore, when selecting the home square, only the target squares that constitute valid moves could be highlighted and enabled for selection. Goal-crossing might also benefit players with motor impairments. Highlighting and enabling only valid squares might benefit novices.	d
CCT986	Advances in Materials Science and Engineering Different authors like Kelsey et al. [7], Gibson and Ashby [8], Zhang and Ashby [9], Klintworth and Stronge [10], Hohe and Becker [11], and Yang and Becker [12] developed the analytical schemes to estimate the equivalent properties of cellular core. Normally analytical theories are shape dependent and also not able to predict all the 9 engineering constants of the elastic orthotropic properties. In recent years, finite element analysis (FEA) has become a popular tool to determine the equivalent elastic properties of any cellular structure of periodic nature [13][14][15]#CITATION_TAG[17].	2	Advances in Materials Science and Engineering Different authors like Kelsey et al. [7], Gibson and Ashby [8], Zhang and Ashby [9], Klintworth and Stronge [10], Hohe and Becker [11], and Yang and Becker [12] developed the analytical schemes to estimate the equivalent properties of cellular core. Normally analytical theories are shape dependent and also not able to predict all the 9 engineering constants of the elastic orthotropic properties. In recent years, finite element analysis (FEA) has become a popular tool to determine the equivalent elastic properties of any cellular structure of periodic nature [13][14][15]#CITATION_TAG[17].	 
CCT987	Molecular dynamics (MD) is widely used to investigate function of biomolecular systems with large size and long time scales. Biomolecular complexes con-sisting of components such as proteins, lipids, DNA and RNA, and solvent are typically large in simulation terms. The explosive growth in interest in investigating inherently complex biomolecular systems such as solvated protein complexes leads to molecular systems with tens to hundreds of thousands of atoms, as for example in [39]. Parallel algorithms are critical to the application and progress of MD in order to 1) improve the accuracy of simulation models, 2) extend the length of simulations, and 3) simulate large, complex systems. Numerous MD parallelizations have been described in the literature, ranging from the easy to implement replicated algorithm [6,20] to the more difficult to implement spatial decomposition [#CITATION_TAG,30], which is generally more scalable. The force decomposition algorithm is an intermediate approach in that it is generally more efficient than the replicated algorithm and easier to implement than the spatial decomposition [27].	0	Biomolecular complexes con-sisting of components such as proteins, lipids, DNA and RNA, and solvent are typically large in simulation terms. The explosive growth in interest in investigating inherently complex biomolecular systems such as solvated protein complexes leads to molecular systems with tens to hundreds of thousands of atoms, as for example in [39]. Parallel algorithms are critical to the application and progress of MD in order to 1) improve the accuracy of simulation models, 2) extend the length of simulations, and 3) simulate large, complex systems. Numerous MD parallelizations have been described in the literature, ranging from the easy to implement replicated algorithm [6,20] to the more difficult to implement spatial decomposition [#CITATION_TAG,30], which is generally more scalable. The force decomposition algorithm is an intermediate approach in that it is generally more efficient than the replicated algorithm and easier to implement than the spatial decomposition [27].	r
CCT988	The ease of implementation of an MD algorithm is important given the need for multiple algorithms to address the variability encountered in mapping molecular dynamics algorithms onto parallel architectures [#CITATION_TAG,9]. In addition, experimenting with MD algorithms on novel parallel architectures is facilitated by tools aiding the parallelization process. Various tools have been applied to molecular dynamics simulations with varying success. Data parallel approaches have been found to be problematic due to the irregularity inherent to molecular dynamics [38], which is compounded by unstructured legacy applications [7]. Low-level tools such as MPI have been successful for performance [27], but do compromise readability and consequently maintenance after the development period. Many good tools have been developed for problems structured similarly to molecular dynamics, but often target regularly structured applications, for example [12].	0	The ease of implementation of an MD algorithm is important given the need for multiple algorithms to address the variability encountered in mapping molecular dynamics algorithms onto parallel architectures [#CITATION_TAG,9]. In addition, experimenting with MD algorithms on novel parallel architectures is facilitated by tools aiding the parallelization process. Various tools have been applied to molecular dynamics simulations with varying success. Data parallel approaches have been found to be problematic due to the irregularity inherent to molecular dynamics [38], which is compounded by unstructured legacy applications [7].	T
CCT989	A number of researchers have studied Nd-Sr isotopic and trace element geochemistry of river sediments and soils as tracers of clastic sources. The geochemical characterizations and Sr-Nd isotopic fingerprinting of sediments in any fluvial system can be done using radiogenic isotopic compositions [1][2][3][4][5]. Rare earth elements (REEs) compositions have been studied in stream sediments [6][7][8] and in chemical weathering of drainage systems [9][10][11][12]. A number of researchers have studied REE composition of both river sediments and river water and discovered that heavy REE concentration is higher in the river sediments than in suspended matter in river water. They also indicated that shale, Upper Continental Crust, and chondrite normalized REE patterns showed that chemical weathering from source rocks in the continental crust, erosion, and terrigenous fluviatile sediment sources can be distinguished using the REE compositions of rivers [13]#CITATION_TAG[15][16][17][18]. Leybourne et al. [19] indicated that Ce and Eu can be redox sensitive and attributed to determination of redox conditions. Yang et al. [8] stated that source rock composition is a more important factor affecting REE composition than weathering processes. There are fewer studies on the Euphrates River. Kalender and B√∂l√ºcek [20] studied the stream sediments in the north Keban Dam Lake in the Eastern Anatolian district and demonstrated that more REEs are transported with Fe and Mn rich oxides and fine size fraction sediments (e.g., clay minerals) via adsorption. Kalender and √á i√ßek U√ßar [21] indicated that the calculated enrichment factor values of the heavy REE are more than those of light REE in the Geli stream sediments. Geli stream is a tributary of the Euphrates River. Rivers carry the weathered rock products from the continents to the dam lakes, natural lakes, and the sea. Thus, this study focuses on the REE concentrations in river bank sediments from the initial point of the Euphrates River (10 kilometers upstream of Keban Dam) to Karakaya Dam Lake. In order to evaluate distribution of REE along the flowing direction of the Euphrates River, the sediment sources and lithological controls were identified using Upper Continental Crust (UCC), North American Shale (NAS), and Chondrite (Ch) normalized REE patterns (all average values taken from [8,[22][23][24][25]). Goldstein and Jacobsen [13] studied REE compositions in river water, and major rivers have LREE enriched patterns relative to the NAS, and negative Ce anomalies occur at high pH. This paper firstly presents REE concentrations and includes source rock composition of the Euphrates River sediments and waters.	0	The geochemical characterizations and Sr-Nd isotopic fingerprinting of sediments in any fluvial system can be done using radiogenic isotopic compositions [1][2][3][4][5]. Rare earth elements (REEs) compositions have been studied in stream sediments [6][7][8] and in chemical weathering of drainage systems [9][10][11][12]. A number of researchers have studied REE composition of both river sediments and river water and discovered that heavy REE concentration is higher in the river sediments than in suspended matter in river water. They also indicated that shale, Upper Continental Crust, and chondrite normalized REE patterns showed that chemical weathering from source rocks in the continental crust, erosion, and terrigenous fluviatile sediment sources can be distinguished using the REE compositions of rivers [13]#CITATION_TAG[15][16][17][18]. Leybourne et al. [19] indicated that Ce and Eu can be redox sensitive and attributed to determination of redox conditions. Yang et al. [8] stated that source rock composition is a more important factor affecting REE composition than weathering processes. There are fewer studies on the Euphrates River.	 
CCT990	A number of researchers have studied Nd-Sr isotopic and trace element geochemistry of river sediments and soils as tracers of clastic sources. The geochemical characterizations and Sr-Nd isotopic fingerprinting of sediments in any fluvial system can be done using radiogenic isotopic compositions [1][2][3][4][5]. Rare earth elements (REEs) compositions have been studied in stream sediments [6][7]#CITATION_TAG and in chemical weathering of drainage systems [9][10][11][12]. A number of researchers have studied REE composition of both river sediments and river water and discovered that heavy REE concentration is higher in the river sediments than in suspended matter in river water. They also indicated that shale, Upper Continental Crust, and chondrite normalized REE patterns showed that chemical weathering from source rocks in the continental crust, erosion, and terrigenous fluviatile sediment sources can be distinguished using the REE compositions of rivers [13][14][15][16][17][18]. Leybourne et al. [19] indicated that Ce and Eu can be redox sensitive and attributed to determination of redox conditions. Yang et al. [8] stated that source rock composition is a more important factor affecting REE composition than weathering processes. There are fewer studies on the Euphrates River. Kalender and B√∂l√ºcek [20] studied the stream sediments in the north Keban Dam Lake in the Eastern Anatolian district and demonstrated that more REEs are transported with Fe and Mn rich oxides and fine size fraction sediments (e.g., clay minerals) via adsorption. Kalender and √á i√ßek U√ßar [21] indicated that the calculated enrichment factor values of the heavy REE are more than those of light REE in the Geli stream sediments. Geli stream is a tributary of the Euphrates River. Rivers carry the weathered rock products from the continents to the dam lakes, natural lakes, and the sea. Thus, this study focuses on the REE concentrations in river bank sediments from the initial point of the Euphrates River (10 kilometers upstream of Keban Dam) to Karakaya Dam Lake. In order to evaluate distribution of REE along the flowing direction of the Euphrates River, the sediment sources and lithological controls were identified using Upper Continental Crust (UCC), North American Shale (NAS), and Chondrite (Ch) normalized REE patterns (all average values taken from [8,[22][23][24][25]). Goldstein and Jacobsen [13] studied REE compositions in river water, and major rivers have LREE enriched patterns relative to the NAS, and negative Ce anomalies occur at high pH. This paper firstly presents REE concentrations and includes source rock composition of the Euphrates River sediments and waters.	0	A number of researchers have studied Nd-Sr isotopic and trace element geochemistry of river sediments and soils as tracers of clastic sources. The geochemical characterizations and Sr-Nd isotopic fingerprinting of sediments in any fluvial system can be done using radiogenic isotopic compositions [1][2][3][4][5]. Rare earth elements (REEs) compositions have been studied in stream sediments [6][7]#CITATION_TAG and in chemical weathering of drainage systems [9][10][11][12]. A number of researchers have studied REE composition of both river sediments and river water and discovered that heavy REE concentration is higher in the river sediments than in suspended matter in river water. They also indicated that shale, Upper Continental Crust, and chondrite normalized REE patterns showed that chemical weathering from source rocks in the continental crust, erosion, and terrigenous fluviatile sediment sources can be distinguished using the REE compositions of rivers [13][14][15][16][17][18]. Leybourne et al. [19] indicated that Ce and Eu can be redox sensitive and attributed to determination of redox conditions.	r
CCT991	A number of researchers have studied Nd-Sr isotopic and trace element geochemistry of river sediments and soils as tracers of clastic sources. The geochemical characterizations and Sr-Nd isotopic fingerprinting of sediments in any fluvial system can be done using radiogenic isotopic compositions [1][2][3][4][5]. Rare earth elements (REEs) compositions have been studied in stream sediments [6][7][8] and in chemical weathering of drainage systems [9][10][11][12]. A number of researchers have studied REE composition of both river sediments and river water and discovered that heavy REE concentration is higher in the river sediments than in suspended matter in river water. They also indicated that shale, Upper Continental Crust, and chondrite normalized REE patterns showed that chemical weathering from source rocks in the continental crust, erosion, and terrigenous fluviatile sediment sources can be distinguished using the REE compositions of rivers [13][14][15][16][17][18]. Leybourne et al. [19] indicated that Ce and Eu can be redox sensitive and attributed to determination of redox conditions. Yang et al. [8] stated that source rock composition is a more important factor affecting REE composition than weathering processes. There are fewer studies on the Euphrates River. Kalender and B√∂l√ºcek [20] studied the stream sediments in the north Keban Dam Lake in the Eastern Anatolian district and demonstrated that more REEs are transported with Fe and Mn rich oxides and fine size fraction sediments (e.g., clay minerals) via adsorption. Kalender and √á i√ßek U√ßar #CITATION_TAG indicated that the calculated enrichment factor values of the heavy REE are more than those of light REE in the Geli stream sediments. Geli stream is a tributary of the Euphrates River. Rivers carry the weathered rock products from the continents to the dam lakes, natural lakes, and the sea. Thus, this study focuses on the REE concentrations in river bank sediments from the initial point of the Euphrates River (10 kilometers upstream of Keban Dam) to Karakaya Dam Lake. In order to evaluate distribution of REE along the flowing direction of the Euphrates River, the sediment sources and lithological controls were identified using Upper Continental Crust (UCC), North American Shale (NAS), and Chondrite (Ch) normalized REE patterns (all average values taken from [8,[22][23][24][25]). Goldstein and Jacobsen [13] studied REE compositions in river water, and major rivers have LREE enriched patterns relative to the NAS, and negative Ce anomalies occur at high pH. This paper firstly presents REE concentrations and includes source rock composition of the Euphrates River sediments and waters.	0	Yang et al. [8] stated that source rock composition is a more important factor affecting REE composition than weathering processes. There are fewer studies on the Euphrates River. Kalender and B√∂l√ºcek [20] studied the stream sediments in the north Keban Dam Lake in the Eastern Anatolian district and demonstrated that more REEs are transported with Fe and Mn rich oxides and fine size fraction sediments (e.g., clay minerals) via adsorption. Kalender and √á i√ßek U√ßar #CITATION_TAG indicated that the calculated enrichment factor values of the heavy REE are more than those of light REE in the Geli stream sediments. Geli stream is a tributary of the Euphrates River. Rivers carry the weathered rock products from the continents to the dam lakes, natural lakes, and the sea. Thus, this study focuses on the REE concentrations in river bank sediments from the initial point of the Euphrates River (10 kilometers upstream of Keban Dam) to Karakaya Dam Lake.	a
CCT992	As mentioned previously, rhythmic coughs have been shown to prolong consciousness in VF [2], whereas survivors of cardiac arrest have reported a broad range of cognitive experiences. Furthermore, 2% (2 of 101 patients) have reported retaining full awareness [3]. Although it is unclear whether the experiences during cardiac arrest refer to actual events or hallucinations, the finding that conscious   awareness can remain during cardiac arrest is intriguing and supports other recent studies indicating that consciousness may be present despite clinically undetectable consciousness. Another report has suggested that functional neuroimaging techniques can assist with the prognosis and diagnosis of patients with disorders of consciousness #CITATION_TAG. Notably, our patient displayed defensive motor reflexes in response to painful stimuli (chest compression) but denied any recollection.	3	As mentioned previously, rhythmic coughs have been shown to prolong consciousness in VF [2], whereas survivors of cardiac arrest have reported a broad range of cognitive experiences. Furthermore, 2% (2 of 101 patients) have reported retaining full awareness [3]. Although it is unclear whether the experiences during cardiac arrest refer to actual events or hallucinations, the finding that conscious   awareness can remain during cardiac arrest is intriguing and supports other recent studies indicating that consciousness may be present despite clinically undetectable consciousness. Another report has suggested that functional neuroimaging techniques can assist with the prognosis and diagnosis of patients with disorders of consciousness #CITATION_TAG. Notably, our patient displayed defensive motor reflexes in response to painful stimuli (chest compression) but denied any recollection.	t
CCT993	In PD, comparisons among diabetic and nondiabetic and anuric patients and patients with residual renal function are frequent, but comparisons between patients undergoing PD as first option versus PD as a second option after haemodialysis are scarce [7][8][9]#CITATION_TAG.	1	In PD, comparisons among diabetic and nondiabetic and anuric patients and patients with residual renal function are frequent, but comparisons between patients undergoing PD as first option versus PD as a second option after haemodialysis are scarce [7][8][9]#CITATION_TAG.	I
CCT994	Patient and technique survival are some of the most important indices in the assessment of the substitutive therapies; in our study, the comparison between both groups did not show statistical differences. Similar findings were observed by Zhang and coworkers [10]. Residual renal function plays an important role in the solute clearance and in fluids balance in the dialysis population; Heaf et al. inferred that preservation of the RRF in peritoneal dialysis could be a cause of better survival in the first 2 years of dialysis treatment regarding HD [38]. Some studies support that the diminution of urine volume is a predictor of technique failure and a cause of mortality [39][40][41][42]. In contrast, in the NECOSAD study, the authors considered anuric peritoneal dialysis patients to have acceptable patient and technique survival, and the risk factors for death were the same as in the dialysis population as a whole [43]; similar conclusions were found in the EAPOS study in anuric patients on APD [44] and in anuric patients with high body surface area #CITATION_TAG. Lobo and coworkers performed a nationwide study of 739 patients but did not find any differences between survival rates between patients with and patients without previous haemodialysis or in anuric or residual renal function patients [46]. As expected in our study, many patients from the second group were anuric (65.7%); however, we also did not observe statistical differences on the very long term when comparing these anuric patients versusPDF patients (Figures 3 and 4).	1	Similar findings were observed by Zhang and coworkers [10]. Residual renal function plays an important role in the solute clearance and in fluids balance in the dialysis population; Heaf et al. inferred that preservation of the RRF in peritoneal dialysis could be a cause of better survival in the first 2 years of dialysis treatment regarding HD [38]. Some studies support that the diminution of urine volume is a predictor of technique failure and a cause of mortality [39][40][41][42]. In contrast, in the NECOSAD study, the authors considered anuric peritoneal dialysis patients to have acceptable patient and technique survival, and the risk factors for death were the same as in the dialysis population as a whole [43]; similar conclusions were found in the EAPOS study in anuric patients on APD [44] and in anuric patients with high body surface area #CITATION_TAG. Lobo and coworkers performed a nationwide study of 739 patients but did not find any differences between survival rates between patients with and patients without previous haemodialysis or in anuric or residual renal function patients [46]. As expected in our study, many patients from the second group were anuric (65.7%); however, we also did not observe statistical differences on the very long term when comparing these anuric patients versusPDF patients (Figures 3 and 4).	o
CCT995	In PD, comparisons among diabetic and nondiabetic and anuric patients and patients with residual renal function are frequent, but comparisons between patients undergoing PD as first option versus PD as a second option after haemodialysis are scarce #CITATION_TAG[8][9][10].	1	In PD, comparisons among diabetic and nondiabetic and anuric patients and patients with residual renal function are frequent, but comparisons between patients undergoing PD as first option versus PD as a second option after haemodialysis are scarce #CITATION_TAG[8][9][10].	I
CCT996	Patient and technique survival are some of the most important indices in the assessment of the substitutive therapies; in our study, the comparison between both groups did not show statistical differences. Similar findings were observed by Zhang and coworkers [10]. Residual renal function plays an important role in the solute clearance and in fluids balance in the dialysis population; Heaf et al. inferred that preservation of the RRF in peritoneal dialysis could be a cause of better survival in the first 2 years of dialysis treatment regarding HD [38]. Some studies support that the diminution of urine volume is a predictor of technique failure and a cause of mortality [39][40][41][42]. In contrast, in the NECOSAD study, the authors considered anuric peritoneal dialysis patients to have acceptable patient and technique survival, and the risk factors for death were the same as in the dialysis population as a whole [43]; similar conclusions were found in the EAPOS study in anuric patients on APD #CITATION_TAG and in anuric patients with high body surface area [45]. Lobo and coworkers performed a nationwide study of 739 patients but did not find any differences between survival rates between patients with and patients without previous haemodialysis or in anuric or residual renal function patients [46]. As expected in our study, many patients from the second group were anuric (65.7%); however, we also did not observe statistical differences on the very long term when comparing these anuric patients versusPDF patients (Figures 3 and 4).	1	Similar findings were observed by Zhang and coworkers [10]. Residual renal function plays an important role in the solute clearance and in fluids balance in the dialysis population; Heaf et al. inferred that preservation of the RRF in peritoneal dialysis could be a cause of better survival in the first 2 years of dialysis treatment regarding HD [38]. Some studies support that the diminution of urine volume is a predictor of technique failure and a cause of mortality [39][40][41][42]. In contrast, in the NECOSAD study, the authors considered anuric peritoneal dialysis patients to have acceptable patient and technique survival, and the risk factors for death were the same as in the dialysis population as a whole [43]; similar conclusions were found in the EAPOS study in anuric patients on APD #CITATION_TAG and in anuric patients with high body surface area [45]. Lobo and coworkers performed a nationwide study of 739 patients but did not find any differences between survival rates between patients with and patients without previous haemodialysis or in anuric or residual renal function patients [46]. As expected in our study, many patients from the second group were anuric (65.7%); however, we also did not observe statistical differences on the very long term when comparing these anuric patients versusPDF patients (Figures 3 and 4).	o
CCT997	Colorectal cancer (CRC) is one of the most common cancer forms worldwide. The chance of surviving colorectal cancer depends on the stage of the disease. One third of diagnosed colorectal cancer patients have locally advanced disease with one or more lymph nodes affected, indicating a worse prognosis. Postoperative adjuvant chemotherapy with oxaliplatin can increase overall survival for this patient group [1][2][3][4][5]. Oxaliplatin can cause acute and chronic neurotoxicity and can be an intolerable burden for these patients #CITATION_TAG[7][8]. The severity of neurotoxic side effects depends on the dosage and duration of the oxaliplatin dose rate. Dose reduction and complete discontinuation of therapy is common because of fear of debilitating and prolonged neurotoxicity [9,10].	3	The chance of surviving colorectal cancer depends on the stage of the disease. One third of diagnosed colorectal cancer patients have locally advanced disease with one or more lymph nodes affected, indicating a worse prognosis. Postoperative adjuvant chemotherapy with oxaliplatin can increase overall survival for this patient group [1][2][3][4][5]. Oxaliplatin can cause acute and chronic neurotoxicity and can be an intolerable burden for these patients #CITATION_TAG[7][8]. The severity of neurotoxic side effects depends on the dosage and duration of the oxaliplatin dose rate. Dose reduction and complete discontinuation of therapy is common because of fear of debilitating and prolonged neurotoxicity [9,10].	i
CCT998	"The cancer disease itself had an impact on patients"" lives and they balanced the neurotoxic side effects against their survival. Expectation of a cure after completing treatment was a natural outcome and the patients looked forward to live as usual. These experiences were in agreement with results in other studies of cancer patients [21,22]. In the present study the patients expressed doubts three months after they had finished chemotherapy. After six months in the post-treatment phase the patients started to adapt to the neurotoxic side effects. One year after concluding chemotherapy the patients had learned to live with the neurotoxicity. These results showing the trajectory are not in agreement with any earlier studies. This could be due to our long term follow up. The post-treatment survivorship can be a distressed period of symptom burden, fatigue and reduced mental well-being [23,24]. The finding that neurotoxicity influences the patients"" daily life is a similar result to earlier studies [14,15,[25]#CITATION_TAG[27][28][29], but those studies had cross-sectional cohorts, other disease stages, and different study designs."	3	"These results showing the trajectory are not in agreement with any earlier studies. This could be due to our long term follow up. The post-treatment survivorship can be a distressed period of symptom burden, fatigue and reduced mental well-being [23,24]. The finding that neurotoxicity influences the patients"" daily life is a similar result to earlier studies [14,15,[25]#CITATION_TAG[27][28][29], but those studies had cross-sectional cohorts, other disease stages, and different study designs."	n
CCT999	"The cancer disease itself had an impact on patients"" lives and they balanced the neurotoxic side effects against their survival. Expectation of a cure after completing treatment was a natural outcome and the patients looked forward to live as usual. These experiences were in agreement with results in other studies of cancer patients [21,22]. In the present study the patients expressed doubts three months after they had finished chemotherapy. After six months in the post-treatment phase the patients started to adapt to the neurotoxic side effects. One year after concluding chemotherapy the patients had learned to live with the neurotoxicity. These results showing the trajectory are not in agreement with any earlier studies. This could be due to our long term follow up. The post-treatment survivorship can be a distressed period of symptom burden, fatigue and reduced mental well-being [23,24]. The finding that neurotoxicity influences the patients"" daily life is a similar result to earlier studies [14,15,#CITATION_TAG[26][27][28][29], but those studies had cross-sectional cohorts, other disease stages, and different study designs."	3	"These results showing the trajectory are not in agreement with any earlier studies. This could be due to our long term follow up. The post-treatment survivorship can be a distressed period of symptom burden, fatigue and reduced mental well-being [23,24]. The finding that neurotoxicity influences the patients"" daily life is a similar result to earlier studies [14,15,#CITATION_TAG[26][27][28][29], but those studies had cross-sectional cohorts, other disease stages, and different study designs."	n
CCT1000	"The cancer disease itself had an impact on patients"" lives and they balanced the neurotoxic side effects against their survival. Expectation of a cure after completing treatment was a natural outcome and the patients looked forward to live as usual. These experiences were in agreement with results in other studies of cancer patients [21,22]. In the present study the patients expressed doubts three months after they had finished chemotherapy. After six months in the post-treatment phase the patients started to adapt to the neurotoxic side effects. One year after concluding chemotherapy the patients had learned to live with the neurotoxicity. These results showing the trajectory are not in agreement with any earlier studies. This could be due to our long term follow up. The post-treatment survivorship can be a distressed period of symptom burden, fatigue and reduced mental well-being [23,#CITATION_TAG]. The finding that neurotoxicity influences the patients"" daily life is a similar result to earlier studies [14,15,[25][26][27][28][29], but those studies had cross-sectional cohorts, other disease stages, and different study designs."	3	"One year after concluding chemotherapy the patients had learned to live with the neurotoxicity. These results showing the trajectory are not in agreement with any earlier studies. This could be due to our long term follow up. The post-treatment survivorship can be a distressed period of symptom burden, fatigue and reduced mental well-being [23,#CITATION_TAG]. The finding that neurotoxicity influences the patients"" daily life is a similar result to earlier studies [14,15,[25][26][27][28][29], but those studies had cross-sectional cohorts, other disease stages, and different study designs."	-
